# Lecture 7

## Syntax Analysis

We had seen Lexical analysis so far. Syntax analysis discovers the larger structures in a program.

A syntax analyzer or parser

- Ensures that the input program is well-formed by attempting to group tokens according to certain rules. This is **syntax checking**.
- Creates a hierarchical structure that arises out of such grouping - **parse-tree**.

Sometimes, parser itself implements **semantic-analysis**. This way of compiler organization is known as parser driven front-end. On the other hand, if there is a separate semantic analyzer, then the organization is known as `parser driven back-end`?. Also, if the the entire compilation is interleaved along with parsing, then it is known as parser driven compilation. However, this organization is ineffective as optimizations are not possible.

Till the early 70s, parsers were written manually. Now, plenty of parser generating tools exist such as 

- Yacc/Bison - Bottom-up (LALR) parser generator
- Antlr - Top-down (LL) scanner cum parser generate.
- PCCTS, COCO, JavaCC, ...

To check whether a program is well-formed requires the specification to be unambiguous, correct and complete, convenient

A [**context free grammar**](https://sudhansh6.github.io/posts/automata#context-free-grammar) meets these requirements. Each rule in the grammar is called as a *production*. The language defined by the grammar is done via the notion of a derivation. That is, the set of all possible *terminal strings*  that can be derived from the start symbol of a CFG is the language of the CFG.

For example, consider the grammar to define the syntax for variable declaration

```
declaration -> type idlist;
type -> integer | float | string
idlist -> idlist, id | id
```

Now, the parser can check if a sentence belongs to the grammar to check the correctness of the syntax. Notice that the above grammar is in *Chomsky Normal Form*. However, sometimes our algorithms to check whether a word is present in a grammar don’t work. When the derivations are unambiguous, most of the algorithms work in all cases. 

Human language is context-sensitive not context-free. For example, “Kite flies boy” and “boy files kite” are both syntactically correct. Such problems also arise in case of programming languages, but these are easier to deal with. We shall see this issue in Semantic Analysis.

Equivalence of grammars in NP complete.

### Why “Context Free”?

The only kind of productions permitted are of the form `non-terminal -> sequence of terminals and non-terminals`. In a derivation, <u>the replacement is made regardless of the context</u> (symbols surrounding the non-terminal).

### Derivation as a relation

A string $$\alpha, \alpha \in (N \cup T)^*$$, such that $$ S \xrightarrow{*} \alpha$$, is called a **sentential form** of $$G$$.  

During a derivation, there is a choice of non-terminals to expand at each sentential form. We can arrive at leftmost or rightmost derivations.