# Lecture 24

> `13-04-22`

## Analysis of Sethi-Ullman algorithm

The register usage in the code fragment for a tree rooted at $$n$$ can be described by

- $$R(n)$$ the number of registers used by the code
- $$L(n)$$ the number of registers live after the code (the intermediate results that are required later)
- The algorithm minimises $$R(n)$$ to avoid storing intermediate results.

If the code computes the left child $$n_1$$ first then, $$R(n) = \max(R(n_1), L(n_1) + R(n_2))$$ and vice versa for the right child $$n_2$$. In order to minimise $$R(n)$$, we minimise $$L(n_1)$$ and $$L(n_2)$$. How do we do that?

- **Contiguous Evaluation** - We evaluate $$n_1$$ completely before evaluating $$n_2$$ or vice versa. The reason this minimises the registers is that when we evaluate a subtree completely, we need to hold only the final result in a register during the evaluation of the other subtrees. Otherwise, we may have to hold multiple intermediate results in a register during the evaluation of the other subtree.

- **Strongly Contiguous Evaluation** All subtrees of the children are also evaluated contiguously. 

In Sethi-Ullman algorithm, each node is processed exactly, and hence the algorithm is linear in the size of the tree. Also, recall that we always evaluate the lowermost subtrees first for optimisation as mentioned somewhere before.

### Arguing the Optimality

We define a node $$n$$ to be a

- **dense node** - if $$label(n) \geq k$$
- **major node** - if both of its children are dense. A major node falls in case 5 of the algorithm.

where $$k$$ is the number of registers, and $$label$$ refers to the number of registers required at this node. Note that every major node is dense but not vice-versa. The parent of every dense node is dense but the parent of every major node need not be major! Also, these categories are dynamic. That is, when we store a dense node, the parent of this node can cease to be a major node. The major nodes decrease by **at most 1** when we store a node. 

Now, the algorithm generates

- exactly one instruction per operator node
- exactly one load per left leaf
- no load for any right leaf

The algorithm is optimal with regards to these counts. The optimality now depends on not introducing extra stores. Consider an expression tree with $$m$$ major nodes. 

- A store can reduce the number of major nodes by at most one. This is because, the node that becomes non-major, still remains a dense node so its parents remain a major node.
- Hence, the tree would need at least $$m$$ stores regardless of the algorithm used for generating code
- The algorithm generates a single store for every major node as part of Case 5, thus it generates exactly $$m$$ stores
- Since this is the smallest number of stores possible, the algorithm is optimal.