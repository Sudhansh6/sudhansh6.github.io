# Lecture 28

> `17-03-22`

### Indexing Temporal Data

A time interval has a start and an end time. A query may ask for all tuples that are valid at a point in time or during a time interval. We can use a spatial index called an **R-tree** for indexing.

# ~Chapter 15: Query Processing

Database engines often apply optimisations based on statistics over data which are approximate. An annotated expression specifying a detailed execution strategy is called an **evaluation plan**. 

**Query optimisation** chooses an evaluation plan with the lowest cost (a metric based on approximated statistics). 

## Measures of Query Cost

Many factors contribute to time cost such as disk access, CPU, and network communication. Cost can be measured on **response time** or **total resource consumption**. As estimating the time is more difficult, we often resort to resource consumption for optimisation. This metric is also useful is shared databases. For our purposes, we will just consider costs related to I/O time. 

Now, the disk cost is estimated as the sum of average seeks, blocks read, and blocks written. For simplicity we just use the **number of block transfers from disk** and the **number of seeks**. Then, we get $$b \times t_T + S\times t_S$$. On a high end magnetic disk, $$t_S = 4ms, t_T = 0.1ms$$ and on a SSD, $$t_S = 20-90\mu s, t_T = 2-10 \mu s$$ for 4KB blocks.  

We assume no data is available in the buffer.

## Selection Operation

`A1`- **Linear Search** - Assume that file is stored sequentially. 

```
cost = b/2*t_T + 1*t_S
```

We do not consider binary search as it requires a lot more (random) accesses and access time is high in disks.

### Selection using Indices

`A2` - **Clustering index, Equality on key** - Retrieve a single record that satisfied the corresponding equality condition. 

```
cost = (h_i + 1)*(t_T + t_S)
```

Here, `h_i` is the height of the index (in $$B^+$$-tree?), and since we are doing random I/O for each case, we need to add both seek and transfer time.

`A3`-**Clustering index, equality on non-key** - Retrieve multiple records. Records will be on consecutive blocks. Let $$b$$ be the number of blocks containing matching records.

```
cost = h_i*(t_T + t_S) + t_S + t_T*b
```

`A4`-**Secondary index, equality on key/non-key**

If the search-key is a candidate key, then

```
cost = (h_i + 1)*(t_T + t_S)
```

> Why?

Otherwise, each of `n` matching records may b on a different block

```
cost = (h_i + n)*(t_T + t_S)
```

It might be cheaper to scan the whole relation as sequential access is easier than random I/O.

`A5`-**Clustering index, comparison**

```
cost = linear_cost for <
		 = index_equality_cost + linear_cost
```

`A6`-**Non-clustering index, comparison**

```
cost = cost + cost_records (I/O)
```

The difference between clustering and non-clustering indices is that we would have to fetch records in case of non-clustering indices in order to read the non-clustering index attribute. This is not the case in case of a clustering index.

Let me write my understanding of all this

>Indices are just files with pointers. Basically, scanning through indices is faster than scanning through a sequence of entire records, so we use indices. Instead of storing indices sequentially, we use $$B^+$$ trees so that its faster. We can’t do this with records directly because records are big and they may not reside in a single file (I think).
>
>Now, clustering indices are indices whose order is same as the order of the records. So, once we fetch a record for an index, all records corresponding to the next indices will be in a sequence. Therefore, we won’t have additional seek time.
>
>However, this is not the case for non-clustering indices. If we want records corresponding to the next indices of the current index, we’d have additional seek time as the records may lie in different blocks.

### Implementation of Complex Selections

How do we implement conjunctions? If all the attributes in the conjunction are indexed, then it is straightforward. We will just take the intersection of all results. Otherwise, test all the other conditions after fetching the records into the memory buffer.

Also, as we discussed before, we can use a composite index. 

Disjunctions are a slightly different. If we have all indexed attributes, we just take the union. Otherwise, we just have to do a linear scan. Linear scan is also the best way in most cases for negation.

## Bitmap Index Scan

We have seen that index scans are useful when less number of records match in the case of secondary indices. If more records match, we should prefer a linear scan. How do we decide the method beforehand? The **bitmap index scan** algorithm is used in PostgreSQL. 

We create a bitmap in memory with a bit for each page in the relation. A record ID is just the page ID and the entry number. We initially do an index scan to find the relevant pages, and mark these pages as 1 in the bitmap. After doing this, we just do a linear scan fetching only pages with bit set to 1. 

How is the performance better? It is same as index scan when only a few bits are set, and it is same as a linear scan when most bits are set. Random I/O is avoided in both cases.

## Sorting

For relations that fit in memory, we can use quicksort. Otherwise, we use **external sort merge**. 

![image-20220407235807034](/assets/img/Databases/image-20220407235807034.png)

![image-20220407235757873](/assets/img/Databases/image-20220407235757873.png)