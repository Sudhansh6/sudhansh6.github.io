<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://sudhansh6.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://sudhansh6.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-05-11T01:26:30+00:00</updated><id>https://sudhansh6.github.io/feed.xml</id><title type="html">Sudhansh Peddabomma</title><entry><title type="html">Reinforcement Learning in Nuclear Fusion</title><link href="https://sudhansh6.github.io/blog/Control-for-Nuclear-Fusion/" rel="alternate" type="text/html" title="Reinforcement Learning in Nuclear Fusion"/><published>2024-05-08T00:00:00+00:00</published><updated>2024-05-08T00:00:00+00:00</updated><id>https://sudhansh6.github.io/blog/Control-for-Nuclear-Fusion</id><content type="html" xml:base="https://sudhansh6.github.io/blog/Control-for-Nuclear-Fusion/"><![CDATA[<h1 id="introduction">Introduction</h1> <p>What is Nuclear fusion? A process where lighter nuclei combine to form heavier atoms. It is of interest to researchers because of its potential to provide clean and long-term energy source. Humans are able to (atleast trying) perform these reactions by carefully controlling plasma through magnetic fields. Plasma is a state of matter where the electrons are stripped from their atoms past a certain temperature. These are extremely hot and require precisely controlled magnetical fields to be stored.</p> <h2 id="fusion-methods">Fusion Methods</h2> <p>There are two methods through which nuclear fusion is being performed currently -</p> <ul> <li> <p>Inertial Confinement Fusion (ICF)</p> <ul> <li>These facilities tend to be very large, and are impractical to scale.</li> </ul> </li> <li> <p>Magnetic Confinement Fusion (MCF)</p> <ul> <li>The goal is to confine hot plasma without touching walls. The device used for this is called as a <strong>tokamak</strong> that uses a central solenoid and induced current to control the magnetic fields.</li> </ul> </li> </ul> <h3 id="tokamak">Tokamak</h3> <p>It’s a sonu shaped device with a central solenoid that generates toroidal and poloidal magnetic fields to confine plasma and maintain high temperatures. Through these fields we want to control the radial position, vertical extent and overall shape of the plasma which is important for the fusion reactions.</p> <p>Recently, KSTAR in South Korea was able to confine plasma for about a minute which is an impressive result for the current sota. In a huge international effort, ITER (International Thermonuclear Experimental Reactor), the world’s largest tokamak is currently being built in Southern France.</p> <h3 id="controls-engineering-process">Controls Engineering Process</h3> <ul> <li> <p><strong>Feedforward stage</strong> - Find the ideal setting for fusion experiment objectives - precompute coil curents, plasma shape, etc.</p> </li> <li> <p><strong>Feedback control stage</strong> - Closed loop control with magnetic measurements to determine the state of the plasma. Maintaining the required state boils down to solving a nonlinear PDE.</p> </li> </ul> <h2 id="better-control">Better control</h2> <p>Tradtional algorithms are able to control the vertical position of the plasma really well but they can be improved for radial control and are a result of intricately designed controllers stiched together. A black-box AI solution shows promise as a single control policy for more robust non-linear control. However, there can be a lack of performance guarantees along with non-interpretability with AI algorithms.</p> <p>To emphasise on safety certifications, there has been works using Lyapunov functions.</p> <h3 id="stability-guarantees">Stability Guarantees</h3> <p><strong>Lyapunov</strong> functions are scalar functions used to verify stability of a system by modeling evolution of system moving from one energy level to another. Recently, work in Neural Lyapunov controls has extended these stability guarantees with the use of neural networks.</p> <h3 id="deep-reinforcement-learning-approaches">Deep Reinforcement Learning Approaches</h3> <p>“<a href="https://www.nature.com/articles/s41586-021-04301-9">Magnetic control of tokamak plasmas through deep reinforcement learning</a>” by Degrace aims to provide a solution for feedback control stage by estimating the current state using various measurements. The challenge arises in modelling such a high-dimensional space - 92 system measurements (poloidal coil currents, flux loops, magnetic probes) and the actions are continuous (19 control coil voltages) and also the absence of a good simulator for this problem.</p> <p>The authors use a simulated environment which is implemented using a Forward FRad-Shafranov solve (FGE). Their algorithm was able to maintain different shapes of the plasma which is not possible with conventional algorithms.</p> <p>Another paper by KSTAR - <a href="https://iopscience.iop.org/article/10.1088/1741-4326/ac79be">Development of an operation trajectory design algorithm for control of multiple 0D parameters using deep reinforcement learning in KSTAR</a> - used <em>TD3</em> (RL algorithm) for feedforward controls. That is, to estimate the desired state of plasma required for the experiments. The states capture “how well the fusion reaction is going”, the safety indices, etc to determine the required controls.</p> <p>Interestingly, instead of a physics-based simulator, they used a data-based simulator trained using an LSTM network on around 5 years of data.</p> <h2 id="current-work">Current Work</h2> <p><strong>Neural Lyapunov control</strong> - Roughly, we want to generate a lyapunov risk formulation for the fusion environment. The challenge is the for the fusion environment, we do not know the system dynamics, and we want to build a neural approximation for estimating this value. This can then be used for the lyapunov risk, which can finally be used for the control algorithms <em>with safety guarantees</em>. In summary, we are trying to improve the above papers by embedding safety guarantees with the methods.</p>]]></content><author><name></name></author><category term="Research"/><summary type="html"><![CDATA[Introduction to reinforcement learning algorithms for control in nuclear fusion reactors]]></summary></entry><entry><title type="html">Scalable Behavior Planning for Autonomous Driving</title><link href="https://sudhansh6.github.io/blog/Behavior-Planning-for-Autonomous-Driving/" rel="alternate" type="text/html" title="Scalable Behavior Planning for Autonomous Driving"/><published>2024-05-01T00:00:00+00:00</published><updated>2024-05-01T00:00:00+00:00</updated><id>https://sudhansh6.github.io/blog/Behavior-Planning-for-Autonomous-Driving</id><content type="html" xml:base="https://sudhansh6.github.io/blog/Behavior-Planning-for-Autonomous-Driving/"><![CDATA[<p>A typical urban scene has numerous people and vehicles with various behaviors paths coupled with rules of the road. Building a framework for predicting behaviors for path planning in such scenes is a difficult task. The frameworks for building algorithms in these scenes involve</p> <ul> <li> <p>Sensors for Perception - RGB, LIDAR, Infra-red</p> </li> <li> <p>Control Algorithms - Motor commands</p> </li> </ul> <p>The planning algorithms have two components to them</p> <ul> <li> <p>Global planning - To plan the coarse waypoints from the source to the destination. Dijkstra’s and A$^*$ search are typically used for these.</p> </li> <li> <p>Motion planning - To plan the control commands based on the environment between the waypoints. It involves behavior planning and path planning algorithms. Behavior planning involves predicting motion of objects on the road and analysing the traffic signs. The path planning part involves generating multiple trajectories which are pruned down from the perception data (sorting them based on a cost function).</p> </li> </ul> <h2 id="behavior-planning">Behavior Planning</h2> <h3 id="state-diagram-algorithms">State Diagram Algorithms</h3> <p>Some classical approaches for this problem involves state diagrams that have a deterministic policy based on symbolic descriptions of the world. Basically, think of these as complicated <code class="language-plaintext highlighter-rouge">if-else</code> structures. <a href="https://ieeexplore.ieee.org/document/4290200/">Behavior Nets</a> is one of the state-of-the-art approaches in this realm.</p> <p>However, these approaches are prone to errors due to sensor uncertainity, state uncertainiity, uncertain temporal evolution and occlusions. These are corrected using Markov Decision Processes</p> <h3 id="markov-decision-processing">Markov Decision Processing</h3> <p>They involve deterministic or stochastic policy within a framework that models uncertainty by evaluating the future. The MDPs are coupled with a risk-factor to make the optimal strategy the safe strategy. One such approach is listed in <a href="https://ieeexplore.ieee.org/document/6082928">Probabilistic MDP-behavior planning for cars</a>. However, these do not work quite well in dynamic world. Also, in dense scenes the dimensionality becomes very high making this approach unscalable. The number of agent vary as well which cannot be modeled completely using an MDP.</p> <p>In <a href="https://arxiv.org/pdf/2011.04697">Behavior Planning at Urban Intersections through Hierarchical Reinforcement Learning</a> the authors simply choose the nearest $5$ agents to model the algorithm and use an RL algorithm to plan the path. However, this approach is data hungry, requires simulators, has low data coverage and oversimplifies the information in dense scenes.</p> <h3 id="online-algorithms">Online Algorithms</h3> <p>In <a href="https://www.ijcai.org/Proceedings/2017/664">Online Decision-Making for Scalable Autonomous Systems (MODIA)</a> the algorithm decomposes the dynamic scene into small decision problems for each agent in the environment. Each decision problem has a pre-defined MDP based on the class of the agent. After obtaining optimal actions from each of these problems, an <em>executor</em> finds the best action based on a <em>preference</em> function defined on a notion of safety. This way, the algorithm has a linearly-growing complexity and state abstractions which are explainable.</p> <h2 id="status-quo">Status-Quo</h2> <p>Taking a step back, we need to deal with dynamic and complex environments. We need to ensure the algorithms use limited computation power and work with the variety of sensors equipped in the vehicle.</p> <p>We do not have a good behavior-realisitc simulator and sufficient human labor annotations (in academic labs). Without enough data, how do we build algorithms for planning? The AVL Lab at UCSD does the following -</p> <ul> <li> <p>Collect rollouts - Data collection stack for behavior planning - point cloud maps, teleoperation platform that collects high and low-level control</p> </li> <li> <p>Training phase - Offline RL for each decision problem</p> </li> <li> <p>Real-world deployment - Online decision framework from MODIA.</p> </li> </ul> <p>This approach has many limitations. Since the number of states is very large, the state-transition matrix is very sparse, and this is not good for determining the optimal policy. These can be fixed using generative simulators (which do not work quite well cuurently) or bridging large dataset by outsourcing the data collection.</p>]]></content><author><name></name></author><category term="Research"/><summary type="html"><![CDATA[Discussion on algorithms for predicting behavior patters in dense urban scenes.]]></summary></entry><entry><title type="html">Structural Visualization for Neural Networks</title><link href="https://sudhansh6.github.io/blog/Structural-Visualization-for-Neural-Network/" rel="alternate" type="text/html" title="Structural Visualization for Neural Networks"/><published>2024-04-24T00:00:00+00:00</published><updated>2024-04-24T00:00:00+00:00</updated><id>https://sudhansh6.github.io/blog/Structural-Visualization-for-Neural-Network</id><content type="html" xml:base="https://sudhansh6.github.io/blog/Structural-Visualization-for-Neural-Network/"><![CDATA[<h1 id="introduction">Introduction</h1> <p>The structure of neural networks have been motivated from neurons in brains. Just like how brain has specialized regions for analysing different kinds of data, do neural networks have such mappings? Is there a way we can visually monitor this, analyse patterns and comment on the progress of training of the model?</p> <p>In simpler neural networks, the outputs from each layer can be visualized as linear separating functions. Such interfaces are available on websites like Tensorflow palyground. Other visualization methods like t-SNE, aim to classify data points in high dimensional spaces. Combining such approaches, the paper <a href="https://arxiv.org/abs/1908.02831">Visualizing the PHATE of Neural Networks</a> uses a kernel-based simentionality reduction</p> <blockquote> <p><strong>t-SNE</strong> is a statistical method to visualize high-dimensional data in two or three dimensional maps. The approach involves constructing a probability distribution over pairs of objects such that similar objects have a higher probability. Then, it uses KL-divergence to model a similar distribution in the low-dimensional space for visualization. <a href="https://en.wikipedia.org/wiki/Uniform_manifold_approximation_and_projection">UMAP</a> is another approach for this task. To read in detail refer to the <a href="https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding">Wiki</a>.</p> </blockquote> <h1 id="multi-layer-perceptrons">Multi-layer Perceptrons</h1> <p>The basic setup boils down to the graph drawing problem where we try to find a layout to better visualize a given graph \(G= (V, E)\). There are two approaches to this problem -</p> <ul> <li> <p><strong>Force-directed layout</strong> - Adds a potential field representing force on edges of the graph to help them spread out</p> </li> <li> <p><strong>Spectral layout</strong> - USes coordinates the eigenveectors of a matric such a the Laplacian derived from the degree matrix and adjacency matrix of the graph.</p> </li> </ul> <h3 id="graph-construction">Graph Construction</h3> <p>Use KNN similarity with spectral layout as the warm start, and then use the force-directed layout to plot the graph. But what do all these mean in the context of latent spaces of a neural network?</p> \[h_i^{(l)} = \phi^{(l)} \left(\sum_{i \in [k]} x_i w_i^{(l)} + b^{(l)}\right)\] <p>Consider the task of classification. What are we trying to visualize? Either the samples or the model weights can be visualized. Let us look at the samples.</p> <h3 id="results">Results</h3> <p>Through out the triaining process, inter-class nodes will gradually move further while the intra-class nodes move closer.</p> <h3 id="experiment---sensitvity-mapping">Experiment - Sensitvity Mapping</h3> <p>Do some embeddings contribute more on the final prediction? We can try visualizing the gradients contributed by the samples at each hidden layer.</p> <h3 id="experiment---neuron-x-sample-mapping">Experiment - Neuron x Sample Mapping</h3> <p>Can we add neurons alongside samples as nodes in the graph? The idea is as follows -</p> <ul> <li> <p>Represent neuron nodes with black nodes and samples nodes as colored ones</p> </li> <li> <p>No connectiones between colored nodes and black nodes</p> </li> <li> <p>A sample node is adjacent to a neuron node if the neuron node</p> </li> </ul> <p>The motivation for this experiment is to figure out if some of the embeddings contribute more on the final prediction.</p> <h1 id="observing-domains-in-generative-models">Observing Domains in Generative Models</h1> <p>Focusing on VAE models, which are characterized with an encoder-decoder architectures to reduce the reconstruction loss (for the decoder) and simialrity loss (for the encoder). The assumption is that any input can be mapped to a lower-dimensional distribution which can then be sampled with a conditional variable to reproduce the high-dimensional input. The similarity loss acts like a regularization term, forcing the distribution learnt by the encoder to match the normal distribution. Depending on the application, the weight of the similarity loss (represented by \(\beta\)) can be varied. The results on varying this parameter are shown below -</p> <Add image=""> Increasing this parameter to a high value causes *posterior collapse*, reducing the generalizability of the network. Essentially, the network generates only a certain instance/class from the distribution. ### Relevant Work [Variational Autoencoders Pursue PCA Directions (by Accident)](https://ar5iv.labs.arxiv.org/html/1812.06775#:~:text=Variational%20Autoencoders%20Pursue%20PCA%20Directions%20%28by%20Accident%29%201,3%20Results%203.1%20The%20problem%20with%20log-likelihood%20) is one such works that claims that the decoder models will promote orthogonality when transforming the z-embedding to the final output. The question of using this behavior to help us model data better is still an open question. ## Conclusion These approaches can be used for the following - Learning with trainability - Visualizing the entire course of training instead fthe final model. - Learning towards interpretability - Visualizing why models behave in certain ways through the lens of a graph - Learning towards robustness - Visualizing scrambled data points &lt;&gt; </Add>]]></content><author><name></name></author><category term="Research"/><summary type="html"><![CDATA[Analysing learning patterns in neural networks using graph visualization algorithms.]]></summary></entry><entry><title type="html">Advanced Computer Vision</title><link href="https://sudhansh6.github.io/blog/Advanced-Computer-Vision/" rel="alternate" type="text/html" title="Advanced Computer Vision"/><published>2024-04-06T00:00:00+00:00</published><updated>2024-04-06T00:00:00+00:00</updated><id>https://sudhansh6.github.io/blog/Advanced-Computer-Vision</id><content type="html" xml:base="https://sudhansh6.github.io/blog/Advanced-Computer-Vision/"><![CDATA[<h1 id="introduction">Introduction</h1> <p>Vision is a fundamental interface to the world, and it has become a crucial component in the development of intelligent systems. The field has deep and attractive scientific problems, which have been advancing at a rapid pace in the past few years.<br/> In the early days of research, the focus in vision was on engineering “good” features coupled with a optimisation algorithm or a shallow neural network. As the processors became more powerful, the emphasis shifted to end-to-end approaches with inclusion of self-supervision and multi-modal learning paradigms.</p> <p>It is often helpful to breakdown the perception tasks into known-algorithms. For example, in autonomous driving, the tasks include SLAM (visual, Structure from Motion), path planning (lane detection, obstacle detection, 3D localization), Semantic segmentation etc. Similarly, the tasks in augmented reality devices are gaze tracking, material and lighting estimation, head pose estimation, depth estimation, etc.</p> <p>Deep learning has opened new areas of research in vision. Features such as generation of high-quality content, end-to-end training, data-driven priors and highly parallelizable architectures have proven advantageous for many problems in computer vision. However, it is also important to note the limitations of these techniques -</p> <ul> <li>Large scale labeled data is not always available</li> <li>Lack of generalization to unseen domains</li> <li>Good at narrow “classification”, not at broad “reasoning”</li> <li>Lack of interpretability</li> <li>Lack of reliability, security or privacy guarantee</li> </ul> <p>To counter these problems, we typically couple our algorithms with self-supervision, physical modelling, multi-modal learning and <em>foundation models</em>. In the recent years, these techniques have been applied to various problems, and the following are arguably the biggest advances in Computer Vision -</p> <ul> <li>Vision Transformers</li> <li>Vision-Language Models</li> <li>Diffusion Models</li> <li>Neural Rendering</li> </ul> <p>These techniques show promise to solve keystone problems in augmented reality, interactive robotics, and autonomous driving. The course will cover the following these topics, along with other fundamentals required.</p> <blockquote> <p>Demonstrate code in presentation</p> </blockquote> <h3 id="neural-architectures">Neural Architectures</h3> <p>The motivation for an artificial neuron (perceptron), comes from a biological neuron where the output is linear combination of the inputs combined with a non-linear activation function. From here, we develop multi-layer networks which are again motivated from the Hubel and Weisel’s architecture in biological cells.</p> <h3 id="neural-networks">Neural Networks</h3> <p>The simplest neural network is a perceptron represented by \(\sigma (x) = \text{sign}(\sum_i w_i x_i + b)\) where the optimal weight values are obtained using an unconstrained optimization problem. These concepts can be extended for “Linear Regression” and “Logistic Regression” tasks.</p> <p>Non-linearity in neural networks is introduced through <strong>Activation functions</strong> such as</p> <ul> <li>Sigmoid - Have vanishing gradient issues</li> <li>tanh - Centered version of sigmoid</li> <li>ReLU - Simplest non-linear activation, with easy gradient calculation.</li> <li>ELU - Added to prevent passive neurons.</li> </ul> <p>At the <strong>output layer</strong>, we apply a final non-linear function is applied to calculate the <strong>loss</strong> in the predicted output. Typically for <strong>classification problems</strong>, <em>Softmax</em> function is used to map the network outputs to probabilities. One-hot representations are not differentiable, and are hence not used for this task. In image synthesis problems, the output layer usually has \(255*sigmoid(z)\).</p> <p><strong>Theorem (Universal function approximators)</strong>: A two-layer network with a sufficient number of neurons can approximate any continous function to any desired accuracy.</p> <p><strong>Width or Depth?</strong> A wider network needs more and more neurons to represent arbitrary function with high enough precision. A deeper network on the contrary, require few parameters needed to achieve a similar approximation power. However, “overly deep” plain nets do not perform well. This is due to the vanishing gradient problem, wherein we are not able to train deep networks with the typical optimization algorithms.</p> <h3 id="convolution-networks">Convolution Networks</h3> <p>The neural network architecture is modified for images using “learnable kernels” in convolutional neural networks. Each convolution layer consists of a set of kernels that produce feature maps from the input. These feature maps capture the <em>spatial</em> and <em>local</em> relationships in the input which is crucial for images.</p> <p>The <em>induction bias</em> in images is that neighbouring variables are locally correlated. An image need not be 2D, it can consist of multiple channels (RGB, hyperspectral, etc.), and convolutional layers work <em>across all</em> these channels to produce feature maps.</p> <p>In a classical neural network, each pixel in the input image would be connected to every neuron in the network layer leading to <em>many</em> parameters for a single image. Using kernels, we use <em>shared weights</em> across all pixel locations, and this greatly reduces the number of learnable parameters without losing much information.</p> <p>Convolution layers are generally accompanies with <strong>Pooling layers</strong> which do not have any learnable parameters, and are used to reduce the size of the output. These layers are invariant to small (spatial)transformations in the input and help observe a larger <em>receptive field</em> in the next layer. The latter property is important to observe hidden layers in the feature maps.</p> <p><strong>Receptive Field</strong> - It is the area in the input iamge “seen” by a unit in a CNN. Inits with deeper layers will have wider receptive fields whereas wider receptive fields allow more global reasoning across entire image. This way, the pooling leads to more rapid widening of receptive fields. We need \(\mathcal O(n/k)\) layers with \((k \times k)\) convolutional filters to have a receptive field of \(n\) in the input. <em>Dilation layers</em> are used to achieve the same receptive field with \(\mathcal O(\log n)\) layers.</p> <p>However, in practice, the empirical receptive fields in the deeper networks is lower than the theoretical value due to sparse weights.</p> <p>Convolution networks are augmented with <em>dense</em> layers to get the output, to learn from the feature maps.</p> <p>The vanishing gradient problem in deeper networks has been solved using <strong>skip connections</strong> wherein the features from the earlier layers are concatenated with the deeper ones to allow passage of information. This way, we provide the network with the original input allowing it to learn the smaller fluctuations in the input (rather than focusing on learning the input itself).</p> <p>In summary, the key operations in convolutional layers are</p> <p><code class="language-plaintext highlighter-rouge">Input image -&gt; Convlution -&gt; Non-linearity -&gt; Spatial Pooling -&gt; Feature Maps</code></p> <p>CNNs have the above set of operations repeated many times. CNNs have been successful due to the following reasons</p> <ul> <li>Good Abstractions - Hierarchical and expressive feature representations. Conventional image processing algorithms relied on a pyramidal representation of features, and this methodology has also paved its way in CNNs.</li> <li>Good inductive biases - Remarkable in transferring knowledge across tasks. That is, pretrained networks can be easily augmented with other general tasks.</li> <li>Ease of implementation - Can be trained end-to-end, rather than hand-crafted for each task, and they can easily be implemented on parallel architectures.</li> </ul> <p>The key ideas -</p> <ul> <li>Convolutional layers leverage the local connectivity and weight sharing to reduce the number of learnable parameters.</li> <li>Pooling layers allow larger receptive fields letting us capture global features.</li> <li>Smaller kernels limit the number of parameters without compromising the performance much. This design decision comes from preferring deeper networks over wider networks. For example, \((1 \times 1)\) kernels are reduce the dimension in the channels dimension.</li> <li>Skip connections allow easier optimization with greater depth.</li> </ul> <blockquote> <p>Why are (1, 1) kernels useful? Use fewer channels instead?</p> </blockquote> <h1 id="transformers">Transformers</h1> <p>Transformers have shown better results in almost every task that CNNs have shone previously in. CNNs require significant depth or larger kernels to share information between non-local spatial locations (recall receptive fields).</p> <p>Many tasks, such as question-answering, require <em>long-range</em> reasoning and transformers are very good at this. For example, placing objects in augmented reality requires reasoning about light-sources, surface estimation, occlusion/shadow detection, etc. This is the primary intuition behind <strong>attention mechanism</strong> which is representative of foveated vision in humans.</p> <p><img src="../../assets/img/Computer Vision/2024-04-11-12-10-13-image.png" alt=""/></p> <p><strong>Tokens</strong> - A data type than can be understood as a set of neurons obtained from vectorizing patches of an image. Typically need not be vectors, but they can be any structured froup that alows a set of differentiable operations. Note that these tokens in hidden layers might not correspond to pixels or interpretable attributes.</p> <p>The following captures a very good intuition for transformers.</p> <p><em>A transformers acts on tokens similarly as neural network acts on neurons. That is, combining tokens is same as for neurons, except tokens are vectors \(t_{out }= \sum_i w_i t_i\). In neural networks, linear layers are represented by \(x_{out} = W x_{in}\) and \(W\) is data-free, whereas in transformers, \(T_{out} = AT_{in}\), \(A\) depends on the data (attention). Again, non-linearity in neural networks is implemented via functions like ReLU whereas transformers use dense layers for non-linearity (applied token wise).</em></p> <p>The attention layer is a spsecial kind of linear transformation of tokens, wherein the attention function \(A = f(.)\) tells how much importance to pay to each token depending on the input query and other signals. <em>Attention-maps</em> help us visualize the global dependencies in the information. The required information is embedded in some dimension of the token representation. For example, the first dimension can count the number of horses in an iamge, and the bottom 3 dimensions can encode the color of the horse on the right. Attention has this flexibility to different allocations address different parts of a query. They can “attend” to only certain patches <em>which are important to the query</em>. This kind of functionality is difficult with CNNs.</p> <blockquote> <p>Apply embedding and neural network (before CNNs and Transofrmers)? Same number of parameters? Essentially similar thing? Associated higher weight to more related embedding.</p> </blockquote> <h3 id="query-key-value-attention">Query-Key-Value Attention</h3> <p>The mechanisms described previously are implemented by projecting tokens into queries, keys and values. Each of these are a vector of dimensions $p$, where $p &lt; d$. The <strong>query</strong> vector for the question is used to weigh the <strong>key</strong> vector for each token to obtain the <strong>values</strong>. This is done via computing the similarity between query and each key, and then the <em>attention</em> is given by the extent of similarities, normalized with softmax. The output token is obtained by summing all value vectors with weights assigned from the previous calculations. Roughly, the process looks like -</p> \[\begin{align*} \left. \begin{align*} q = W_q t \\ K_i = W_k t_i \end{align*} \right\} \implies s_i = q^T k_i \\ a_i = softmax(s_i) \\ t_{out} = \sum a_i v_i \end{align*}\] <p>The purpose of “values” is to ‘project’ back the similarities between queries and keys to the ‘token space’.</p> <p>Also note that, if the patch-size is too large, then we might lose the information within the patches. This is a tradeoff, and the decision is made based on the task at hand. For example, classification may work with large patches but tasks such as segmentation may not.</p> <h4 id="self-attention">Self-Attention</h4> <p>How do we learn implicit representations that can work with general queries? We compute <em>self-attention</em> using the image tokens as the queries - information derived from the image itself. How does this process help us? For example, if we are performing instance segmentation of an image with horses. Then, the concept of ‘horse’ is learned by attending more to tother horse tokens and less to background. Similarly, ‘a particular instance’ is learned by attending less to the tokens from other horses. When we do this for all pairs across \(N\) tokens gives us an \(N \times N\) attention matrix.</p> <p><img src="https://jalammar.github.io/images/t/self-attention-matrix-calculation.png" title="" alt="" width="307"/></p> <p><img src="https://jalammar.github.io/images/t/self-attention-matrix-calculation-2.png" title="" alt="" width="393"/></p> <p>Typically, this matrix is computed in the <strong>encoder</strong> part of a transformer. This matrix is then used in the decoder with an input query to obtain the required results.</p> <h3 id="encoders">Encoders</h3> <p>An encoder of a transformer typically consists of many identical blocks connected serially with one another. Each such encoder block, computes a self-attention matrix and passes it through a feed-forward neural network, and they need to be applied across all the tokens in the input. Since the embeddings of tokens are independent of one another, each level of encoder blocks can be applied <em>in parallel</em> to all the tokens (patches in vision transformers) to obtain the embeddings. Such parallel computations were not possible in previous models like RNNs, which heavily relied on sequential dependencies.</p> <p>The original transformers paper normalizes the similarities with \(\sqrt{N}\) where \(N\) is the embedding dimension. This allows the gradients to stabilise and gives much better performance. This a simplified view of the mechanisms used in transformers.</p> <p>In addition to these, transformers also use <em>positional encoding</em> to encode the position of the tokens in the input sequence. In the context of images, is encodes where each patch occurs in the image.</p> <p><img src="C:\Users\ITSloaner\AppData\Roaming\marktext\images\2024-04-10-18-07-17-image.png" alt=""/></p> <p>Positional encoding is usually done via sinusoidal functions. Other “learning-based” representations have been explored but they don’t have much different effect. This encoding structure allows extrapolation to sequnce lengths not seen in training.</p> <p>They also have <em>multi-head attention</em> which is equivalent to multiple channels in CNNs. That is, it allows patches to output more than one type of information.</p> <p><img src="https://jalammar.github.io/images/t/transformer_multi-headed_self-attention-recap.png" alt=""/></p> <p>This <a href="https://jalammar.github.io/illustrated-transformer/">blog</a> explains these mechanisms in-depth for interested readers. In summary, the functions of the encoder is visualized as</p> <p><img src="https://jalammar.github.io/images/t/transformer_resideual_layer_norm_3.png" alt=""/></p> <h3 id="decoders">Decoders</h3> <p>A decoder block is similar to an encoder block, with auto-regressive . The attention values learned in Encoders are used as ‘keys’ in the decoder attention block. This is called as <em>cross attention</em>.</p> <h2 id="vision-transformers">Vision-Transformers</h2> <p>Vision transformers build on the same ideas used in a transformer. Typically, they use only the encoder part of the architecture where patches are extracted from images and are flattened to form the tokens for the attention mechanism. They are usually projected using a linear layer or a CNN before performing the calculations. Apart from this, vision transformers also include an additional <em>class token</em> in the embeddings to help learn the global information across the image.</p> <p>CNNs typically have better inductive bias whereas transformers excel in shorter learning paths for long-range reasoning. However, the cost of self-attention is quadratic in the image size. Also note that, if the patch-size is too large, then we might lose the information within the patches. This is a tradeoff, and the decision is made based on the task at hand. For example, classification may work with large patches but tasks such as segmentation may not.</p> <h3 id="swin-transformers-and-dense-prediction-transformers">Swin Transformers and Dense Prediction Transformers</h3> <p>The vanilla vision transformer is restricted to classification tasks and is not optimal for other tasks like detection and segmentation. Also, as we have noted before, the quadratic complexity limit the number of patches in the image. Some image processing pipelines extract features across different scales of an image whereas the vanilla transformer is restricted to the uniform (coarse) scale.</p> <p>To address these limitations, <strong>swin transformers</strong> bring two key ideas from CNNs</p> <ul> <li> <p>Multi-scale feature maps - Feature maps from one resolution are downsampled to match the size in the next block.</p> <p><img src="../../assets/imgs/2024-04-12-17-27-50-image.png" title="" alt="" data-align="left"/></p> </li> <li> <p>Local connectivity -</p> <ul> <li> <p>Windowed self-attention - Limit the computations by considering a local window (this was actually left as future work in the original attention paper).</p> </li> <li> <p>Shifted window self-attention - Allows windowed self-attention to learn long-range features using “shifts”. Essentially, we move the patches around to bring farther patches close together.</p> </li> </ul> </li> </ul> <p>However, these modifications are not enough for tasks like segmentation. Instead, we use something called as a <em>dense prediction transformer</em> (<strong>DPTs</strong>) where we couple the transformer encoder with a convolutional decoder to upsample and predict the required output.</p> <blockquote> <p>CNNs are shift-invariant whereas ViTs are permutation invariant. Why?</p> </blockquote> <p><img src="../../assets/imgs/2024-04-12-17-36-33-image.png" alt=""/></p> <p>At each scale level in the above picture, we <em>reassemble</em> the tokens by concatenating and convolving with appropriate kernels to recover image-like representations in the decoder layers.</p> <h3 id="multimodality">Multimodality</h3> <p>Transformers allowed for easy multi-modal representations by tokenizing data from each modality with its own variant of <em>patches</em>. Works such as VATT have explored merging audio waveforms, text and images.</p> <h1 id="generative-models">Generative Models</h1> <h2 id="discriminative-and-generative-models">Discriminative and Generative Models</h2> <p>Disciminative models (classifiers) learn a many-to-one function \(f\) to learn labels for a given input. A generative model \(g\) maps these labels to the input space, and this function is one-to-many since one label can map to multiple inputs. It is difficult to model a stochastic function. Therefore, a generator model is coupled with a <em>noise vector</em> to construct a deterministic \(g\) with stochastic input \(z\). This variable \(z\) is called a <strong>latent variable</strong> since it is not observed in training data composed of \(\{x, y\}\) pairs.</p> \[\begin{align*} \text{Discriminative Models learn } P(Y \vert X) \\ \text{Generative Models learn } P(X, Y) \\ \text{Conditional Generator learn } P(X \vert Y) \\ \end{align*}\] <p>Let us focus on image generative models. Then, each dimension of the latent variable can encode the various characteristics of the image essentially allowing us to generate a wide variety of images. The labels \(y\) for images need not be classification labels, but textual descriptions can also be used for supervision.</p> <p>To understand how these models work, consider the case of uncoditional generative models. The goal is, given the real data \(x\), to generate synthetic data \(\hat x\) that <em>looks like</em> the real data. How do we quantify ‘looks like’?</p> <ul> <li> <p>We can try and match some marginal statistics - mean, variance, edge statistics, etc of the real data. Such measures are very useful in techniques for texture synthesis. For example, <a href="https://www.cns.nyu.edu/labs/heegerlab/content/publications/Heeger-siggraph95.pdf">Heeger-Bergen texture synthesis [1995]</a> uses an iterative process starting from the Gaussian noise and matches intensity histograms across different scales. Such design choices are used in modern techniques like <a href="https://en.wikipedia.org/wiki/StyleGAN">StyleGANs</a> and <a href="https://en.wikipedia.org/wiki/Diffusion_model">Diffusion models</a>.</p> </li> <li> <p>Have a high probability of success under a model fit to real-data (A discriminator).</p> </li> </ul> <p>The key-challenge in these models is novelity in the generation to ensure generalization.</p> <p>Generative models are classified into the following approaches -</p> <ul> <li> <p><strong>Energy-based models</strong> - Learn a scoring function \(s:X \to R\) that scores real-samples with a high score which represents energy/probability. During generation, return samples which have a high score. This paradigm is particularly useful for applications like anomaly detection.</p> </li> <li> <p><strong>Sampling from Noise</strong> - Learn a generative function \(g: Z \to X\) without needing to learn a probability density function. These methods explicitly model the data distribution, and techniques like GANs and Diffusion Models come under this regime.</p> </li> </ul> <h2 id="densityenergy-based-models">Density/Energy based models</h2> <p>Learn a scoring function \(s:X \to R\) that scores real-samples with a high score which represents energy/probability. During generation, return samples which have a high score. This paradigm is particularly useful for applications like anomaly detection.</p> <p>In these methods, we produce \(p_\theta\) fit to the training data by optimizing \(\arg\min_{p_\theta} D(p_{\theta}, p_{data})\). Since we don’t know \(p_{data}\) explicitly (we only have access to samples \(x \sim p_{data}\)), we minimize the <strong>KL-divergence</strong> to reduce the distance between the distributions using the samples.</p> \[\begin{align*} p_\theta^* &amp;= \arg\min_{p_\theta} KL(p_{data} \vert\vert p_\theta)\\ &amp;= \arg\max_{p_\theta} \mathbb E_{x\sim p_{data}}[\log p_\theta] - \mathbb E_{x\sim p_{data}}[\log p_{data}] \\ &amp;= \arg\max_{p_\theta} \mathbb E_{x\sim p_{data}}[\log p_\theta] \end{align*}\] <p>Intuitively, this way of optimization increases the density where the models are observed.</p> <p>The energy-based models have a slight modification wherein the energy function E_\theta is unnormalized unlike the probability density function p_\theta. Indeed, p_\theta can be determined as</p> \[\begin{align*} p_\theta &amp;= \frac{e^{-E_\theta}}{Z(\theta)}, \\ &amp;\text{ where } Z_\theta = \int_x e^{-E_{\theta}(x)} dx \end{align*}\] <p>This formulation is called as <em>Boltzmann or Gibbs</em> distibution. Learning energy function is convenient since normalization is intractable since we cannot see all the samples in the distribution. What is the motivation to use exponential functions?</p> <ol> <li> <p>It arises naturally in physical statistics</p> </li> <li> <p>Many common distributions (Normal, Poisson, …) are modeled using exponential functions.</p> </li> <li> <p>Want to handle large variations in probability</p> </li> </ol> <p>Although we don’t have the probabilities, we can still compare different samples using ratios of their energies. How do we sample in these approaches? Sampling approaches <strong>Markov Chain Monte Carlo</strong> (MCMC) only require relative probabilities for generating data. We can also find data points that maximize the probability.</p> \[\nabla_x \log p_\theta(x) = -\nabla_x E_\theta(x)\] <p>On the other hand, where would be prefer probability formulation over energy? Certain systems like safety in autonomous driving require absolute quantifiable probabilities rather than relative scores.</p> <p>In probability modeling, the probability of space where no samples are observed is automatically pushed down due to normalization. However, in energy based models, we need an explicit negative term to push energy up where no data points are observed. To do so, we set up an iterative optimization where the gradient of the log-likelihood function naturally decomposes into contrastive terms</p> \[\begin{align*} \nabla_\theta \mathbb E_{x \sim p_{data}} [\log p_\theta(x)] &amp;= \frac{1}{N}\nabla_\theta\sum_{i = 1}^N (\underbrace{-E_\theta(x^{(i)})}_{\text{ data samples}} + \underbrace{E_\theta(\hat x^{(i)})}_{\text{model samples}}) \\ &amp;= - \mathbb E_{x \sim p_{data}} [\nabla_\theta \mathbb E_\theta (x)] + \mathbb E_{x \sim p_\theta} [\nabla_\theta \mathbb E_\theta(x)] \end{align*}\] <h4 id="sampling">Sampling</h4> <p>We randomly initialize \(\hat x_0\)$ at \(t = 0\). Then, we repeat the following</p> <ol> <li> <p>Let \(\hat x' = \hat x_t + \eta\)$ where \(\eta\) is some noise</p> </li> <li> <p>If \(\mathbb E_\theta(\hat x') &lt; \mathbb E_\theta(\hat x_t)\), then choose \(\hat x_{t + 1} = \hat x'\).</p> </li> <li> <p>Else choose \(\hat x_{t + 1} = \hat x'\) with probability \(e^{(\mathbb E_\theta(\hat x_t) - \mathbb E_\theta(\hat x'))}\)</p> </li> </ol> <p>In practice, this algorithm takes a long time to converge. A variant of this called <strong>Langevin MCMC</strong> uses the gradient of the distribution to accelerate the sampling procedure</p> <ol> <li> <p>Choose \(q(x)\) an easy to sample prior distribution.</p> </li> <li> <p>Repeat for a fixed number of iterations \(t\)</p> \[\hat x_{t + 1} \sim \hat x_t + \epsilon \nabla_x \log p_\theta(\hat x_t) - \sqrt{2\epsilon} z_t\] <p>where \(z_t \sim \mathcal N(0, I)\). When \(\epsilon \to 0\), and \(t \to \infty\), we have \(\hat x_t \sim p_\theta\)</p> </li> </ol> <h2 id="diffusion-models">Diffusion Models</h2> <p>The inuition for these models builds from our previous approach. It is hard to map pure noise to \(x \sim N(0, I)\) to structured data, but it is very easy to do the opposite. To readers familiar with autoregressive models, where we remove one pixel of information at a time, this is much more generalized.</p> <p>The forward process in these models involves adding noise to the image \(x_0\) over many time steps. At time \(t\), we add noise \(\epsilon_t\) to obtain \(x_{t + 1}\) from \(x_{t}\). The noise addition is modeled with respect to the following equation</p> \[x_t = \sqrt{(1 - \beta_t) x_{t - 1}} + \sqrt{\beta_t}\epsilon_t, \quad \epsilon_t \sim N(0, I)\] <p>If this process is repeated for a large number of times, it can be shown that the final output simulates white noise. Now, in the learning part, we train a predictor to learn denoising from \(x_t\) to \(x_{t - 1}\). That is, given our model \(f_\theta\)</p> \[\hat x_{t - 1} = f_\theta(x_t , t)\] <h3 id="forward-noising">Forward Noising</h3> <p>Given an image \(x_0 \sim q(x)\), we essentially add the following Gaussian noise in \(T\) time steps</p> \[q(x_t \vert x_{t - 1}) = \mathcal N(x_t ; \sqrt{1 - \beta} x_{t - 1}, \beta_t I)\] <p>The term \(\beta_t\) is referred to as the schedule and \(0 &lt; \beta_t &lt; 1\). Typically, we set it to a small value in the beginning and do linear increments with time. The above process is a Markov’s process, resulting in the following property</p> \[q(x_{1:T} \vert x_0) = \prod_{t = 1}^T q(x_t \vert x_{t - 1})\] <p>Instead of a slow step-by-step process, training uses samples from arbitrary time step. To decrease the computations, we use the following properties of Gaussian distributions</p> <ul> <li> <p>Reparameterization trick: \(\mathcal N(\mu, \sigma^2)= \mu + \sigma \epsilon\) where \(\epsilon \sim \mathcal N(0, I)\)</p> </li> <li> <p>Merging Gaussians \(\mathcal N(0, \sigma_1^2 I)\) and \(\mathcal N(0, \sigma_2^2 I)\) is a Gaussian of the form\(\mathcal N(0, (\sigma_1^2 + \sigma_2^2) I)\)</p> </li> </ul> <p>Define \(\alpha_t = 1 - \beta_t\), and \(\bar \alpha_t = \prod_{i = 1}^t \alpha_i\), we can now sample \(x_t\) at an arbitrary time step</p> \[\begin{align*} x_t &amp;= \sqrt{\alpha_t} x_{t - 1} + \sqrt{1 - \alpha_t}\epsilon_{t - 1} \\ &amp;= \sqrt{\alpha_t\alpha_{t - 1}} x_{t - 1} + \sqrt{1 - \alpha_t\alpha_{t - 1}}\epsilon_{t - 1} \\ &amp;\dots \\ &amp;= \sqrt{\bar \alpha_t}x_0 + \sqrt{1 - \bar \alpha_t}\epsilon \end{align*}\] <p>When we schedule \(\beta_t\) such that \(\beta_1 &lt; \beta_2 &lt; \dots, \beta_T\) so that \(\bar \alpha_1 &gt; \dots, &gt; \bar \alpha_T\), such that \(\bar \alpha_T \to 0\), then</p> \[q(x_T \vert x_0) \approx \mathcal N(x_T; 0, I)\] <p>The intuition is that the diffusion kernel is a Gaussian</p> \[q(x_t) = \int q(x_0, x_t) dx_0 = \int q(x_0) q(x_t \vert x_0) dx_0\] <p>There are theoretical bounds showing a relation between the number of steps and overfitting of the model to the distribution. There are no such guarantees for VAEs.</p> <p>The increasing \(\beta_t\) schedule sort of accelerates the diffusion process wherein we simulate white noise with few iterations. However, the stable diffusion paper to generate images chose the cosine learning schedule which gave better results.</p> <h3 id="reverse-denoising">Reverse Denoising</h3> <p>The goal is to start with noise and gradually denoise to generate images. We start with \(x_T \sim \mathcal N(0, I)\) and sample form \(q(x_{t - 1} \vert x_t)\) to denoise. When \(\beta_t\) is small enough, we can show that this quantity is a Gaussian. However, estimating the quantity is difficult since it requires optimization over the whole dataset.</p> <p>Therefore, we learn a model \(p_\theta\) to reverse the process</p> \[P_\theta(x_{t - 1} \vert x_t) = \mathcal N(x_{t - 1}; \mu_\theta(x_t, t), \Sigma\] <p>#</p> <p>Essentially, the training objective is to maximise log-likelihood over the data distribution. A variational lower bound can be derived and is used in practice</p> \[\mathbb E_{q(x_0)}[-\log p_\theta(X_0)] \leq \mathbb E_{q(x_0) q(x_{1:T}\vert x_0)} \left[-\log \frac{p_\theta (x_{0:T})}{q(x_{1:T} \vert x_0)}\right]\] <p>Then, this decomposes into</p> \[\sum_{t &gt; 1} D_{KL} (q(x_{t - 1} \vert x_t, x_0) \vert\vert p_\theta(x_{t - 1} \vert x_t)) + \text{other terms}\] <p>The idea is that $q(x_{t - 1} \vert x_t, x_0)$ is tractable even though $q(x_{t - 1} \vert x_t)$ is not. That is because</p> \[\begin{align*} q(x_{t - 1} \vert x_t, x_0) &amp;= \mathcal N(x_{t - 1}; \tilde \mu_t(x_t, x_0), \tilde \beta_t I) \\ \text{where } \tilde \mu_t(x_t, x_0) &amp;= \frac{\sqrt{\bar \alpha_{t - 1}}}{1 - \bar \alpha_t}x_0 + \frac{\sqrt{1 - \beta_t} ( 1- \bar\alpha_{t - 1})}{1- \bar\alpha_{t - 1}}x_t \\ &amp;=\tilde \beta_t = \frac{1 - \bar \alpha_{t - 1}}{1 - \bar \alpha_t} \beta_t \end{align*}\] <h2 id="sampling-from-noise">Sampling from Noise</h2> <p>Generative Adversarial networks mainly fall in this domain. In these architectures, a generator network tries to fool the discriminator by generating real-looking images. In contrast, a discriminator network tries to distribguish between real and fake images. GANs don’t produce as good images as diffusion models, but the concept of adversarial learning is a crucial concept in many fields. The framework looks like this -</p> <p><img src="../../assets/img/Computer%20Vision/2024-04-24-17-21-56-image.png" alt=""/></p> <p>The objective function for a GAN is formulated as a mini-max game - the generator tries to maximize the loss function whereas the discriminator tries to reduce it.</p> \[L = \min_{\theta_g} \max_{\theta_d} [\mathbb E _{x \sim p_{data}} \log D_{\theta_d} (x) + \mathbb E_{z \sim p(z)} \log (1 - D(G_{\theta_g}(z)))]\] <p>The training is done alternately, performing gradient ascent on the generator and descent on the discriminator.</p> <h1 id="object-detection">Object Detection</h1> <p>Simply put, the goal is identify objects in a given image. The evolution of algorithms for object detection is summarized as</p> <ul> <li> <p>HoG + SVM - Sliding window mechanism for feature detection.</p> </li> <li> <p>Deformable Part Models -</p> </li> <li> <p>CNN - Using a sliding window mechanism is computationally expensive. Instead, these methods use region proposals and filter out the ones with satisfying criteria.</p> </li> <li> <p>Transformers</p> </li> <li> <p>Self-supervision</p> </li> <li> <p>Open vocabulary</p> </li> </ul> <h2 id="multi-stage-cnns">Multi-stage CNNs</h2> <h3 id="rcnn">RCNN</h3> <p>The first demonstration that showed classification features from CNNs can be used to detect objects. Essentially, the last layer of the ImageNet classifier network was removed . Each region proposal is warped/cropped to match the CNN input size. The post-processing involves bounding box regression</p> <h3 id="fastrcnn">FastRCNN</h3> <h3 id="fasterrcnn">FasterRCNN</h3> <p>Uses a Region Proposal Network (RPN) after the last convolutional layer. The RPN is trained to produce region proposals directly without any need for external region proposals. After RPN, the RoI Pooling and an upstream classifier are used as regressors similar to FastRCNN.</p> <h4 id="region-proposal-network">Region Proposal Network</h4> <p>The network does the following -</p> <ul> <li> <p>Slide a small window on the feature map</p> </li> <li> <p>A small network to do classification - object or no-object</p> </li> <li> <p>A regressor to give the bounding box</p> </li> </ul> <h4 id="anchors">Anchors</h4> <p>Anchors are a set of reference positions on the feature map</p> <p>3 dimensions with aspect ratio, 3 different scales of boxes,</p> <h4 id="training">Training</h4> <h4 id="non-maximal-supression">Non-Maximal Supression</h4> <p>Since, multiple anchor boxes can map to an object, we iteratively choose the highest scoring box among the predictions and supp ress the predictions that have high IoU with the currently chosen box.</p> <h2 id="transformer-based-architectures">Transformer based Architectures</h2> <h3 id="detr">DETR</h3> <p>Faster R-CNN has many steps, handcrafted architecture and potentially non-differentiable steps. In contrast, DETR was proposed - an end-to-end transformer based architecture for object detection. The motivation was to capture all the human-designed optimization parts of the pipeline into one black-box using a transformer.</p> <p><img src="../../assets/img/Computer%20Vision/2024-04-24-17-53-05-image.png" alt=""/></p> <p>Why do we want such an end-to-end architecture? They are more flexible to diverse data, capturing large datasets, finetuning, etc.</p> <p>In this architecture, a CNN backbone like ResNet extracts the features which are passed through the encoder to obtain latent representations. These are then used with a decoder along with object queries in the form of cross-attention to give bounding boxes as the output.</p> <p>After obtaining the bounding boxes, the loss is appropriately calculated by matching the boxes to the correct labels. It is our task to assign a ground truth label to the predictions</p> <blockquote> <p>Hungarian??</p> </blockquote> <p>The decoder takes object queries as input,</p> <p>500 epochs</p> <p>encoder is segmented, decoder is just getting bounding boxes</p> <h3 id="dino">DINO</h3> <p>lagging in scale variant objects.</p> <p>contrastive loss acting for negative samples</p> <p>YOLOX</p> <h2 id="single-shot-detectors">Single Shot-Detectors</h2> <p>The motivation for these networks is to infer detections faster without much tradeoff in accuracy.</p> <p><strong>Anchor boxes</strong></p> <p>no ambiguous IoU</p> <p>Hard negative mining</p> <h3 id="you-only-look-once-yolo">You Only Look Once (YOLO)</h3> <p>Divide into grids</p> <p>anchor boxes in grid and class probability map</p> <h3 id="yolo-x">YOLO-X</h3> <p>No anchored mechanism - hyperparameter tuning, more predictions, less generalization (OOD fails)</p> <p>Detection head decoupling, no anchor boxes, SimOTA</p> <p>predict size and centers rather than top-left</p> <p>mosaicing and mixing</p> <h3 id="pyramid-feature-extractions">Pyramid Feature Extractions</h3> <p>RFCN</p> <h1 id="semantic-segmentation">Semantic Segmentation</h1> <p>The goal in this task is much more fine-tuned wherein we assign class pixel-wise. We want locally accurate boundaries as compared to finding bounding boxes in object detection. The approaches require global reasoning as well.</p> <p>A naive approch would be to classify a pixel by considering the patch around the pixel in the image. This is very expensive computationally and does not capture any global information.</p> <p>Another approach is to consider image resolution convolutions (purely convolutions with stride 1, no pooling) and maining the image resolution to produce the output. This still does not work quite well, and they also consume more memory.</p> <p>Taking classification networks as the motications, some networks try pooling/striding to downsample the features. This architecture corresponds to the encoder part of the model, and the decoder then upsamples the image using transposed convolution, interpolation, unpooling to recover the spatial details in the original size. The convolutions can go deeper without occupying a lot of memory.</p> <p>How do we upsample?</p> <ul> <li> <p>Transposed convolution to upsample. The operation is shown below -</p> <table> <tbody> <tr> <td>![Transpose Convolution for Up-Sampling Images</td> <td>Paperspace Blog](https://blog.paperspace.com/content/images/2020/07/conv.gif)</td> </tr> </tbody> </table> <p>However, the outputs are not very precise. Combine global and local information.</p> </li> <li> <p>U-Net</p> </li> <li> <p>Unpooling followed by convolutions (simpler implementation of transposed convolution)</p> <p>The <strong>max-unpooling</strong> operation does the following -</p> <p>Why is this better? Lesser memory</p> </li> </ul> <p>In all the architectures above, once you downsample the image, you lose a lot of spatial information and the network uses a significant amount of parameters learning the upsampling process to represent the final output. To help with this, we can do the following</p> <ul> <li> <p>Predict at multiple scales and combine the predictions</p> </li> <li> <p><strong>Dilated convolutions</strong> - These are used to increase the receptive field without downsampling the image too much -</p> <p><img src="https://th.bing.com/th/id/R.4992be8ec58775d0f6f963c2ae7129b3?rik=orAxXCOkxWt5dw&amp;pid=ImgRaw&amp;r=0" alt="Animations of Convolution and Deconvolution — Machine Learning Lecture"/></p> <p>It’s multi-scale and also captures full-scale resolution. The idea of dilated convolution is very important in other tasks as well - It prevents the loss of spatial information in downsampling tasks. However, there are gridding artifacts and higher memory consumptions with Dilated networks.</p> <p><strong>Degridding solutions</strong></p> <ul> <li> <p>Add convolution layers at end of the network with progressively lower dilation</p> </li> <li> <p>Remove skip connections in new layers, can propogate gridding artefacts because skip connections transfer high-frequency information.</p> </li> </ul> </li> <li> <p>Skip-connections</p> </li> <li></li> </ul> <h1 id="physiological-grouping-for-perception">Physiological Grouping for Perception</h1> <h2 id="deeplab-v3">DeepLab v3+</h2> <h2 id="segformer">Segformer</h2> <h1 id="instance-segmentation">Instance Segmentation</h1> <h2 id="mask-rcnn">Mask RCNN</h2> <p>Predict eh</p> <h1 id="panoptic-segmentation">Panoptic Segmentation</h1> <p>Panoptic segmentation extends the idea of instance segmentation even further to segment objects beyond a fixed set of classes.</p> <p>#</p> <h1 id="universal-segmentation">Universal Segmentation</h1> <p>Specialized architectures for semantic</p> <h2 id="maskformer">MaskFormer</h2> <p>The architecture contains a strong CNN backbone for the encoder along with a query and pixel decoder. The query decoder essentially takes $n$ inputs to generate $n$ masks. The outputs from these layers are passed through an MLP to get binary masks for different classes.</p> <h2 id="masked2former">Masked2Former</h2> <p>Uses a masked attention layer instead of cross-attention to provide faster convergence</p> <h3 id="limitations">Limitations</h3> <p>Needs to be trained on speicfic datasets, struggles with small objects and large inference time.</p> <p>Hasn’t been extended to video segmentation and panoptic segmentation.</p> <h2 id="mask-dino">Mask DINO</h2> <p>Does both detection and segmentation. A Mask prediction branch along with box prediction in DINO.</p> <h3 id="unified-denoising-training">Unified Denoising Training</h3> <h1 id="foundation-models">Foundation Models</h1> <p>Models that have been trained on simple tasks which have good performance in the pipelines of other tasks for <strong>zero-shot transfer</strong> capabilities. Such models were first used in Natural Language Processing and using these in vision is typicalled hindered by unavailability of labeled data.</p> <h2 id="segment-anything">Segment Anything</h2> <p>A model developed by Meta with zero-shot segmentation capabilities. The task this model tries to solve is to allow for interactive and automatic use with zero-shot generatlization and re-use. The model allows for flexibile prompts with real-time usage and is ambiguity-aware. The model also has a data-engine which is used to generate data through the model.</p> <h3 id="promptable-segmentation">Promptable segmentation</h3> <p>The model generates a valid mask for a given prompt (even if ambiguous) as input. How is the ambiguity resolved? Ambiguous cases arise when the mutiple objects lie on top of each other.</p> <p><img src="../../assets/img/Computer%20Vision/2024-05-03-17-21-39-image.png" alt=""/></p> <p>The image encoder is heavy - a pretrained ViT with masked autoencoder. The design choice for the masking involved masking around 75% of the patches. Unlike NLP tasks, vision tasks rely heavily on spatial information and neighbor patches can be reconstructed without much effort. Also, NLP tasks can get away with a simple MLP for decoders but vision taks require strong decoders.</p> <p>The model allows for prompts using points, box or text. The decoder has self-attention on the primpts followed by cross-attention with image and MLP for non-linearity to get masks. The model also estimates the IoU to rank masks.</p> <p>The emphasis of the model was also to make it universal. Since the encoder is heavy, the embeddings are precomputed after which the prompt encoder and mask decoder work quite fast.</p> <h3 id="data-engine">Data Engine</h3> <p>There is no large-scale dataset available for training a segmentation model of this scale. Initially, the model has been trained iteratively on available datasets with several rounds of human correction. Following this, in the semi-automatic stage, the diversity of outputs (increasing ambiguity in overlapping objects) is improved by human refinement. Finally, in the fully automatic stage, prompting is introduced and masks with high IoU are preserved followed by NMS.</p> <h3 id="zero-shot-transfer-capabilities">Zero-shot transfer capabilities</h3> <p>The idea is to fine-tune the model for specific tasks like edge-derection, object proposals and isntance segmentation.</p> <h1 id="future-trajectory-prediction">Future Trajectory Prediction</h1> <p>This problem arises in many applications, particularly in autonomous driving. Given traffic participants and scene elements which are inter-dependent, we need to predict trajectories with scene awareness and multimodality. Humans are able to predict up to 10 seconds in highway scenes and plan their trajectory effectively whereas the SOTA models have a large gap in performance.</p> <p>More concretely, the algorithm takes a video sequence as an input, and needs to predict <strong>probabilistic</strong> trajectories which are diverse, have 3D awareness, capture semantics interactions and focus on <strong>long-term rewards</strong>. There are many components in these solutions including 3D localization module, generative sampling modules, semantic scene modules and scene aware fusion modules with encoders and decoders.</p> <p>#</p> <h3 id="representation-framework">Representation Framework</h3> <p>The past observed trajectories are represented by X = {X_{i, t - l + 1}, \dots, X_{i, t}} usng we which we wish to predict future trajectory Y_i = {Y_{i, t + 1}, \dots, Y_{i, t + \delta}}. The parameter \delta represents how far ahead we want to look in the future.</p> <p>The <em>sample generation module</em> produces future hypotheses \hat Y, and then a ranking module assigns a reward to each hypothesis considering long-term rewards. Following this, the refinement step calculates the displacement \Delta Y_t for the selected trajectory.</p> <p>Focusing on the sample generation module, the goal is to estimate posterior P(Y \vert X, I). Earlier, RNNs and other deterministic function maps from {X, I} to Y have been designed to address this. The problem with training in this approach is that the ground truth has a single future trajectory whereas the sampler predicts a distribution. How do we compare the two?</p> <h2 id="principal-component-analysis">Principal Component Analysis</h2> <p>Principal component analysis (PCA) is a linear dimensionality reduction technique where data is linearly transformed onto a new coordinate system such that the directions (principal components) capturing the largest variation in the data can be easily identified. PCA works well when the data is near a <strong>linear manifold</strong>* in high dimensional spaces.</p> <p>CAn we approximate PCA with a Network? Train a network with a bottleneck hidden layer, and try to make the output the same as the input. Without any activations, the neural network simply performs least-squares minimization which essentially is the PCA algorithm.</p> <p>Adding non-linear activation functions would help the network map non-linear manifolds as well. This motivates for autoencoder networks.</p> <h2 id="autoencoders">Autoencoders</h2> <p>Network with a bottleneck layer that tries to reconstruct the input. The decoder can map latent vectors to images essentially helping us reconstruct images from a low-dimension. However, this is not truly generative yet since it learns a one-to-one mapping. An arbitrary latent vector can be far away from the learned latent space, and sampling new outputs is difficult.</p> <h2 id="--variational-autoencoder">### Variational Autoencoder</h2> <p>This network extends the idea in autoencoders and trains the network to learn a Gaussian distribution (parametrized by $\mu, \sigma$) for the latent space. After learning, say, the normal distribution, sampling is quite easy to generate new samples representative of the trianing dataset using the decoder.</p> <p>To train this network, a distribution loss, like the KL-divergence is added in the latent space. But how do we backpropagate through random sampling? The reparametrization trick!</p> <h3 id="conditional-variational-autoencoder">Conditional Variational Autoencoder</h3> <p>The encoder and decoder networks are now conditioned on the class variable.</p> <h2 id="conditional-diffusion-models">Conditional Diffusion Models</h2> <p>Gradient of log, score function, conditioning at the cost of diversity - train a classifier and a diffusion model together in principle it’s fine. Potential issues - classifier can’t learn from noisy images and gradient of the classifier is not meaningful.</p> <h2 id="classifier-free-guidance">Classifier-Free Guidance</h2> <p>learn unconditional diffusion model $p_\theta(x)$ and use the conditional model $p_\theta(x \vert y)$ for some part of the training. this would not require any external classifier for training.</p>]]></content><author><name></name></author><category term="Notes"/><summary type="html"><![CDATA[Introduction Vision is a fundamental interface to the world, and it has become a crucial component in the development of intelligent systems. The field has deep and attractive scientific problems, which have been advancing at a rapid pace in the past few years. In the early days of research, the focus in vision was on engineering “good” features coupled with a optimisation algorithm or a shallow neural network. As the processors became more powerful, the emphasis shifted to end-to-end approaches with inclusion of self-supervision and multi-modal learning paradigms. It is often helpful to breakdown the perception tasks into known-algorithms. For example, in autonomous driving, the tasks include SLAM (visual, Structure from Motion), path planning (lane detection, obstacle detection, 3D localization), Semantic segmentation etc. Similarly, the tasks in augmented reality devices are gaze tracking, material and lighting estimation, head pose estimation, depth estimation, etc. Deep learning has opened new areas of research in vision. Features such as generation of high-quality content, end-to-end training, data-driven priors and highly parallelizable architectures have proven advantageous for many problems in computer vision. However, it is also important to note the limitations of these techniques - Large scale labeled data is not always available Lack of generalization to unseen domains Good at narrow “classification”, not at broad “reasoning” Lack of interpretability Lack of reliability, security or privacy guarantee To counter these problems, we typically couple our algorithms with self-supervision, physical modelling, multi-modal learning and foundation models. In the recent years, these techniques have been applied to various problems, and the following are arguably the biggest advances in Computer Vision - Vision Transformers Vision-Language Models Diffusion Models Neural Rendering These techniques show promise to solve keystone problems in augmented reality, interactive robotics, and autonomous driving. The course will cover the following these topics, along with other fundamentals required. Demonstrate code in presentation Neural Architectures The motivation for an artificial neuron (perceptron), comes from a biological neuron where the output is linear combination of the inputs combined with a non-linear activation function. From here, we develop multi-layer networks which are again motivated from the Hubel and Weisel’s architecture in biological cells. Neural Networks The simplest neural network is a perceptron represented by \(\sigma (x) = \text{sign}(\sum_i w_i x_i + b)\) where the optimal weight values are obtained using an unconstrained optimization problem. These concepts can be extended for “Linear Regression” and “Logistic Regression” tasks. Non-linearity in neural networks is introduced through Activation functions such as Sigmoid - Have vanishing gradient issues tanh - Centered version of sigmoid ReLU - Simplest non-linear activation, with easy gradient calculation. ELU - Added to prevent passive neurons. At the output layer, we apply a final non-linear function is applied to calculate the loss in the predicted output. Typically for classification problems, Softmax function is used to map the network outputs to probabilities. One-hot representations are not differentiable, and are hence not used for this task. In image synthesis problems, the output layer usually has \(255*sigmoid(z)\). Theorem (Universal function approximators): A two-layer network with a sufficient number of neurons can approximate any continous function to any desired accuracy. Width or Depth? A wider network needs more and more neurons to represent arbitrary function with high enough precision. A deeper network on the contrary, require few parameters needed to achieve a similar approximation power. However, “overly deep” plain nets do not perform well. This is due to the vanishing gradient problem, wherein we are not able to train deep networks with the typical optimization algorithms. Convolution Networks The neural network architecture is modified for images using “learnable kernels” in convolutional neural networks. Each convolution layer consists of a set of kernels that produce feature maps from the input. These feature maps capture the spatial and local relationships in the input which is crucial for images. The induction bias in images is that neighbouring variables are locally correlated. An image need not be 2D, it can consist of multiple channels (RGB, hyperspectral, etc.), and convolutional layers work across all these channels to produce feature maps. In a classical neural network, each pixel in the input image would be connected to every neuron in the network layer leading to many parameters for a single image. Using kernels, we use shared weights across all pixel locations, and this greatly reduces the number of learnable parameters without losing much information. Convolution layers are generally accompanies with Pooling layers which do not have any learnable parameters, and are used to reduce the size of the output. These layers are invariant to small (spatial)transformations in the input and help observe a larger receptive field in the next layer. The latter property is important to observe hidden layers in the feature maps. Receptive Field - It is the area in the input iamge “seen” by a unit in a CNN. Inits with deeper layers will have wider receptive fields whereas wider receptive fields allow more global reasoning across entire image. This way, the pooling leads to more rapid widening of receptive fields. We need \(\mathcal O(n/k)\) layers with \((k \times k)\) convolutional filters to have a receptive field of \(n\) in the input. Dilation layers are used to achieve the same receptive field with \(\mathcal O(\log n)\) layers. However, in practice, the empirical receptive fields in the deeper networks is lower than the theoretical value due to sparse weights. Convolution networks are augmented with dense layers to get the output, to learn from the feature maps. The vanishing gradient problem in deeper networks has been solved using skip connections wherein the features from the earlier layers are concatenated with the deeper ones to allow passage of information. This way, we provide the network with the original input allowing it to learn the smaller fluctuations in the input (rather than focusing on learning the input itself). In summary, the key operations in convolutional layers are Input image -&gt; Convlution -&gt; Non-linearity -&gt; Spatial Pooling -&gt; Feature Maps CNNs have the above set of operations repeated many times. CNNs have been successful due to the following reasons Good Abstractions - Hierarchical and expressive feature representations. Conventional image processing algorithms relied on a pyramidal representation of features, and this methodology has also paved its way in CNNs. Good inductive biases - Remarkable in transferring knowledge across tasks. That is, pretrained networks can be easily augmented with other general tasks. Ease of implementation - Can be trained end-to-end, rather than hand-crafted for each task, and they can easily be implemented on parallel architectures. The key ideas - Convolutional layers leverage the local connectivity and weight sharing to reduce the number of learnable parameters. Pooling layers allow larger receptive fields letting us capture global features. Smaller kernels limit the number of parameters without compromising the performance much. This design decision comes from preferring deeper networks over wider networks. For example, \((1 \times 1)\) kernels are reduce the dimension in the channels dimension. Skip connections allow easier optimization with greater depth. Why are (1, 1) kernels useful? Use fewer channels instead? Transformers Transformers have shown better results in almost every task that CNNs have shone previously in. CNNs require significant depth or larger kernels to share information between non-local spatial locations (recall receptive fields). Many tasks, such as question-answering, require long-range reasoning and transformers are very good at this. For example, placing objects in augmented reality requires reasoning about light-sources, surface estimation, occlusion/shadow detection, etc. This is the primary intuition behind attention mechanism which is representative of foveated vision in humans. Tokens - A data type than can be understood as a set of neurons obtained from vectorizing patches of an image. Typically need not be vectors, but they can be any structured froup that alows a set of differentiable operations. Note that these tokens in hidden layers might not correspond to pixels or interpretable attributes. The following captures a very good intuition for transformers. A transformers acts on tokens similarly as neural network acts on neurons. That is, combining tokens is same as for neurons, except tokens are vectors \(t_{out }= \sum_i w_i t_i\). In neural networks, linear layers are represented by \(x_{out} = W x_{in}\) and \(W\) is data-free, whereas in transformers, \(T_{out} = AT_{in}\), \(A\) depends on the data (attention). Again, non-linearity in neural networks is implemented via functions like ReLU whereas transformers use dense layers for non-linearity (applied token wise). The attention layer is a spsecial kind of linear transformation of tokens, wherein the attention function \(A = f(.)\) tells how much importance to pay to each token depending on the input query and other signals. Attention-maps help us visualize the global dependencies in the information. The required information is embedded in some dimension of the token representation. For example, the first dimension can count the number of horses in an iamge, and the bottom 3 dimensions can encode the color of the horse on the right. Attention has this flexibility to different allocations address different parts of a query. They can “attend” to only certain patches which are important to the query. This kind of functionality is difficult with CNNs. Apply embedding and neural network (before CNNs and Transofrmers)? Same number of parameters? Essentially similar thing? Associated higher weight to more related embedding. Query-Key-Value Attention The mechanisms described previously are implemented by projecting tokens into queries, keys and values. Each of these are a vector of dimensions $p$, where $p &lt; d$. The query vector for the question is used to weigh the key vector for each token to obtain the values. This is done via computing the similarity between query and each key, and then the attention is given by the extent of similarities, normalized with softmax. The output token is obtained by summing all value vectors with weights assigned from the previous calculations. Roughly, the process looks like - \[\begin{align*} \left. \begin{align*} q=W_q t \\ K_i=W_k t_i \end{align*} \right\} \implies s_i=q^T k_i \\ a_i=softmax(s_i) \\ t_{out} = \sum a_i v_i \end{align*}\] The purpose of “values” is to ‘project’ back the similarities between queries and keys to the ‘token space’. Also note that, if the patch-size is too large, then we might lose the information within the patches. This is a tradeoff, and the decision is made based on the task at hand. For example, classification may work with large patches but tasks such as segmentation may not. Self-Attention How do we learn implicit representations that can work with general queries? We compute self-attention using the image tokens as the queries - information derived from the image itself. How does this process help us? For example, if we are performing instance segmentation of an image with horses. Then, the concept of ‘horse’ is learned by attending more to tother horse tokens and less to background. Similarly, ‘a particular instance’ is learned by attending less to the tokens from other horses. When we do this for all pairs across \(N\) tokens gives us an \(N \times N\) attention matrix. Typically, this matrix is computed in the encoder part of a transformer. This matrix is then used in the decoder with an input query to obtain the required results. Encoders An encoder of a transformer typically consists of many identical blocks connected serially with one another. Each such encoder block, computes a self-attention matrix and passes it through a feed-forward neural network, and they need to be applied across all the tokens in the input. Since the embeddings of tokens are independent of one another, each level of encoder blocks can be applied in parallel to all the tokens (patches in vision transformers) to obtain the embeddings. Such parallel computations were not possible in previous models like RNNs, which heavily relied on sequential dependencies. The original transformers paper normalizes the similarities with \(\sqrt{N}\) where \(N\) is the embedding dimension. This allows the gradients to stabilise and gives much better performance. This a simplified view of the mechanisms used in transformers. In addition to these, transformers also use positional encoding to encode the position of the tokens in the input sequence. In the context of images, is encodes where each patch occurs in the image. Positional encoding is usually done via sinusoidal functions. Other “learning-based” representations have been explored but they don’t have much different effect. This encoding structure allows extrapolation to sequnce lengths not seen in training. They also have multi-head attention which is equivalent to multiple channels in CNNs. That is, it allows patches to output more than one type of information. This blog explains these mechanisms in-depth for interested readers. In summary, the functions of the encoder is visualized as Decoders A decoder block is similar to an encoder block, with auto-regressive . The attention values learned in Encoders are used as ‘keys’ in the decoder attention block. This is called as cross attention. Vision-Transformers Vision transformers build on the same ideas used in a transformer. Typically, they use only the encoder part of the architecture where patches are extracted from images and are flattened to form the tokens for the attention mechanism. They are usually projected using a linear layer or a CNN before performing the calculations. Apart from this, vision transformers also include an additional class token in the embeddings to help learn the global information across the image. CNNs typically have better inductive bias whereas transformers excel in shorter learning paths for long-range reasoning. However, the cost of self-attention is quadratic in the image size. Also note that, if the patch-size is too large, then we might lose the information within the patches. This is a tradeoff, and the decision is made based on the task at hand. For example, classification may work with large patches but tasks such as segmentation may not. Swin Transformers and Dense Prediction Transformers The vanilla vision transformer is restricted to classification tasks and is not optimal for other tasks like detection and segmentation. Also, as we have noted before, the quadratic complexity limit the number of patches in the image. Some image processing pipelines extract features across different scales of an image whereas the vanilla transformer is restricted to the uniform (coarse) scale. To address these limitations, swin transformers bring two key ideas from CNNs Multi-scale feature maps - Feature maps from one resolution are downsampled to match the size in the next block. Local connectivity - Windowed self-attention - Limit the computations by considering a local window (this was actually left as future work in the original attention paper). Shifted window self-attention - Allows windowed self-attention to learn long-range features using “shifts”. Essentially, we move the patches around to bring farther patches close together. However, these modifications are not enough for tasks like segmentation. Instead, we use something called as a dense prediction transformer (DPTs) where we couple the transformer encoder with a convolutional decoder to upsample and predict the required output. CNNs are shift-invariant whereas ViTs are permutation invariant. Why? At each scale level in the above picture, we reassemble the tokens by concatenating and convolving with appropriate kernels to recover image-like representations in the decoder layers. Multimodality Transformers allowed for easy multi-modal representations by tokenizing data from each modality with its own variant of patches. Works such as VATT have explored merging audio waveforms, text and images. Generative Models Discriminative and Generative Models Disciminative models (classifiers) learn a many-to-one function \(f\) to learn labels for a given input. A generative model \(g\) maps these labels to the input space, and this function is one-to-many since one label can map to multiple inputs. It is difficult to model a stochastic function. Therefore, a generator model is coupled with a noise vector to construct a deterministic \(g\) with stochastic input \(z\). This variable \(z\) is called a latent variable since it is not observed in training data composed of \(\{x, y\}\) pairs. \[\begin{align*} \text{Discriminative Models learn } P(Y \vert X) \\ \text{Generative Models learn } P(X, Y) \\ \text{Conditional Generator learn } P(X \vert Y) \\ \end{align*}\] Let us focus on image generative models. Then, each dimension of the latent variable can encode the various characteristics of the image essentially allowing us to generate a wide variety of images. The labels \(y\) for images need not be classification labels, but textual descriptions can also be used for supervision. To understand how these models work, consider the case of uncoditional generative models. The goal is, given the real data \(x\), to generate synthetic data \(\hat x\) that looks like the real data. How do we quantify ‘looks like’? We can try and match some marginal statistics - mean, variance, edge statistics, etc of the real data. Such measures are very useful in techniques for texture synthesis. For example, Heeger-Bergen texture synthesis [1995] uses an iterative process starting from the Gaussian noise and matches intensity histograms across different scales. Such design choices are used in modern techniques like StyleGANs and Diffusion models. Have a high probability of success under a model fit to real-data (A discriminator). The key-challenge in these models is novelity in the generation to ensure generalization. Generative models are classified into the following approaches - Energy-based models - Learn a scoring function \(s:X \to R\) that scores real-samples with a high score which represents energy/probability. During generation, return samples which have a high score. This paradigm is particularly useful for applications like anomaly detection. Sampling from Noise - Learn a generative function \(g: Z \to X\) without needing to learn a probability density function. These methods explicitly model the data distribution, and techniques like GANs and Diffusion Models come under this regime. Density/Energy based models Learn a scoring function \(s:X \to R\) that scores real-samples with a high score which represents energy/probability. During generation, return samples which have a high score. This paradigm is particularly useful for applications like anomaly detection. In these methods, we produce \(p_\theta\) fit to the training data by optimizing \(\arg\min_{p_\theta} D(p_{\theta}, p_{data})\). Since we don’t know \(p_{data}\) explicitly (we only have access to samples \(x \sim p_{data}\)), we minimize the KL-divergence to reduce the distance between the distributions using the samples. \[\begin{align*} p_\theta^* &amp;= \arg\min_{p_\theta} KL(p_{data} \vert\vert p_\theta)\\ &amp;= \arg\max_{p_\theta} \mathbb E_{x\sim p_{data}}[\log p_\theta] - \mathbb E_{x\sim p_{data}}[\log p_{data}] \\ &amp;= \arg\max_{p_\theta} \mathbb E_{x\sim p_{data}}[\log p_\theta] \end{align*}\] Intuitively, this way of optimization increases the density where the models are observed. The energy-based models have a slight modification wherein the energy function E_\theta is unnormalized unlike the probability density function p_\theta. Indeed, p_\theta can be determined as \[\begin{align*} p_\theta &amp;= \frac{e^{-E_\theta}}{Z(\theta)}, \\ &amp;\text{ where } Z_\theta = \int_x e^{-E_{\theta}(x)} dx \end{align*}\] This formulation is called as Boltzmann or Gibbs distibution. Learning energy function is convenient since normalization is intractable since we cannot see all the samples in the distribution. What is the motivation to use exponential functions? It arises naturally in physical statistics Many common distributions (Normal, Poisson, …) are modeled using exponential functions. Want to handle large variations in probability Although we don’t have the probabilities, we can still compare different samples using ratios of their energies. How do we sample in these approaches? Sampling approaches Markov Chain Monte Carlo (MCMC) only require relative probabilities for generating data. We can also find data points that maximize the probability. \[\nabla_x \log p_\theta(x) = -\nabla_x E_\theta(x)\] On the other hand, where would be prefer probability formulation over energy? Certain systems like safety in autonomous driving require absolute quantifiable probabilities rather than relative scores. In probability modeling, the probability of space where no samples are observed is automatically pushed down due to normalization. However, in energy based models, we need an explicit negative term to push energy up where no data points are observed. To do so, we set up an iterative optimization where the gradient of the log-likelihood function naturally decomposes into contrastive terms \[\begin{align*} \nabla_\theta \mathbb E_{x \sim p_{data}} [\log p_\theta(x)] &amp;= \frac{1}{N}\nabla_\theta\sum_{i = 1}^N (\underbrace{-E_\theta(x^{(i)})}_{\text{ data samples}} + \underbrace{E_\theta(\hat x^{(i)})}_{\text{model samples}}) \\ &amp;= - \mathbb E_{x \sim p_{data}} [\nabla_\theta \mathbb E_\theta (x)] + \mathbb E_{x \sim p_\theta} [\nabla_\theta \mathbb E_\theta(x)] \end{align*}\] Sampling We randomly initialize \(\hat x_0\)$ at \(t = 0\). Then, we repeat the following Let \(\hat x' = \hat x_t + \eta\)$ where \(\eta\) is some noise If \(\mathbb E_\theta(\hat x') &lt; \mathbb E_\theta(\hat x_t)\), then choose \(\hat x_{t + 1} = \hat x'\). Else choose \(\hat x_{t + 1} = \hat x'\) with probability \(e^{(\mathbb E_\theta(\hat x_t) - \mathbb E_\theta(\hat x'))}\) In practice, this algorithm takes a long time to converge. A variant of this called Langevin MCMC uses the gradient of the distribution to accelerate the sampling procedure Choose \(q(x)\) an easy to sample prior distribution. Repeat for a fixed number of iterations \(t\) \[\hat x_{t + 1} \sim \hat x_t + \epsilon \nabla_x \log p_\theta(\hat x_t) - \sqrt{2\epsilon} z_t\] where \(z_t \sim \mathcal N(0, I)\). When \(\epsilon \to 0\), and \(t \to \infty\), we have \(\hat x_t \sim p_\theta\) Diffusion Models The inuition for these models builds from our previous approach. It is hard to map pure noise to \(x \sim N(0, I)\) to structured data, but it is very easy to do the opposite. To readers familiar with autoregressive models, where we remove one pixel of information at a time, this is much more generalized. The forward process in these models involves adding noise to the image \(x_0\) over many time steps. At time \(t\), we add noise \(\epsilon_t\) to obtain \(x_{t + 1}\) from \(x_{t}\). The noise addition is modeled with respect to the following equation \[x_t = \sqrt{(1 - \beta_t) x_{t - 1}} + \sqrt{\beta_t}\epsilon_t, \quad \epsilon_t \sim N(0, I)\] If this process is repeated for a large number of times, it can be shown that the final output simulates white noise. Now, in the learning part, we train a predictor to learn denoising from \(x_t\) to \(x_{t - 1}\). That is, given our model \(f_\theta\) \[\hat x_{t - 1} = f_\theta(x_t , t)\] Forward Noising Given an image \(x_0 \sim q(x)\), we essentially add the following Gaussian noise in \(T\) time steps \[q(x_t \vert x_{t - 1}) = \mathcal N(x_t ; \sqrt{1 - \beta} x_{t - 1}, \beta_t I)\] The term \(\beta_t\) is referred to as the schedule and \(0 &lt; \beta_t &lt; 1\). Typically, we set it to a small value in the beginning and do linear increments with time. The above process is a Markov’s process, resulting in the following property \[q(x_{1:T} \vert x_0) = \prod_{t = 1}^T q(x_t \vert x_{t - 1})\] Instead of a slow step-by-step process, training uses samples from arbitrary time step. To decrease the computations, we use the following properties of Gaussian distributions Reparameterization trick: \(\mathcal N(\mu, \sigma^2)= \mu + \sigma \epsilon\) where \(\epsilon \sim \mathcal N(0, I)\) Merging Gaussians \(\mathcal N(0, \sigma_1^2 I)\) and \(\mathcal N(0, \sigma_2^2 I)\) is a Gaussian of the form\(\mathcal N(0, (\sigma_1^2 + \sigma_2^2) I)\) Define \(\alpha_t = 1 - \beta_t\), and \(\bar \alpha_t = \prod_{i = 1}^t \alpha_i\), we can now sample \(x_t\) at an arbitrary time step \[\begin{align*} x_t &amp;= \sqrt{\alpha_t} x_{t - 1} + \sqrt{1 - \alpha_t}\epsilon_{t - 1} \\ &amp;= \sqrt{\alpha_t\alpha_{t - 1}} x_{t - 1} + \sqrt{1 - \alpha_t\alpha_{t - 1}}\epsilon_{t - 1} \\ &amp;\dots \\ &amp;= \sqrt{\bar \alpha_t}x_0 + \sqrt{1 - \bar \alpha_t}\epsilon \end{align*}\] When we schedule \(\beta_t\) such that \(\beta_1 &lt; \beta_2 &lt; \dots, \beta_T\) so that \(\bar \alpha_1 &gt; \dots, &gt; \bar \alpha_T\), such that \(\bar \alpha_T \to 0\), then \[q(x_T \vert x_0) \approx \mathcal N(x_T; 0, I)\] The intuition is that the diffusion kernel is a Gaussian \[q(x_t) = \int q(x_0, x_t) dx_0=\int q(x_0) q(x_t \vert x_0) dx_0\] There are theoretical bounds showing a relation between the number of steps and overfitting of the model to the distribution. There are no such guarantees for VAEs. The increasing \(\beta_t\) schedule sort of accelerates the diffusion process wherein we simulate white noise with few iterations. However, the stable diffusion paper to generate images chose the cosine learning schedule which gave better results. Reverse Denoising The goal is to start with noise and gradually denoise to generate images. We start with \(x_T \sim \mathcal N(0, I)\) and sample form \(q(x_{t - 1} \vert x_t)\) to denoise. When \(\beta_t\) is small enough, we can show that this quantity is a Gaussian. However, estimating the quantity is difficult since it requires optimization over the whole dataset. Therefore, we learn a model \(p_\theta\) to reverse the process \[P_\theta(x_{t - 1} \vert x_t) = \mathcal N(x_{t - 1}; \mu_\theta(x_t, t), \Sigma\] # Essentially, the training objective is to maximise log-likelihood over the data distribution. A variational lower bound can be derived and is used in practice \[\mathbb E_{q(x_0)}[-\log p_\theta(X_0)] \leq \mathbb E_{q(x_0) q(x_{1:T}\vert x_0)} \left[-\log \frac{p_\theta (x_{0:T})}{q(x_{1:T} \vert x_0)}\right]\] Then, this decomposes into \[\sum_{t &gt; 1} D_{KL} (q(x_{t - 1} \vert x_t, x_0) \vert\vert p_\theta(x_{t - 1} \vert x_t)) + \text{other terms}\] The idea is that $q(x_{t - 1} \vert x_t, x_0)$ is tractable even though $q(x_{t - 1} \vert x_t)$ is not. That is because \[\begin{align*} q(x_{t - 1} \vert x_t, x_0) &amp;= \mathcal N(x_{t - 1}; \tilde \mu_t(x_t, x_0), \tilde \beta_t I) \\ \text{where } \tilde \mu_t(x_t, x_0) &amp;= \frac{\sqrt{\bar \alpha_{t - 1}}}{1 - \bar \alpha_t}x_0 + \frac{\sqrt{1 - \beta_t} ( 1- \bar\alpha_{t - 1})}{1- \bar\alpha_{t - 1}}x_t \\ &amp;=\tilde \beta_t = \frac{1 - \bar \alpha_{t - 1}}{1 - \bar \alpha_t} \beta_t \end{align*}\] Sampling from Noise Generative Adversarial networks mainly fall in this domain. In these architectures, a generator network tries to fool the discriminator by generating real-looking images. In contrast, a discriminator network tries to distribguish between real and fake images. GANs don’t produce as good images as diffusion models, but the concept of adversarial learning is a crucial concept in many fields. The framework looks like this - The objective function for a GAN is formulated as a mini-max game - the generator tries to maximize the loss function whereas the discriminator tries to reduce it. \[L = \min_{\theta_g} \max_{\theta_d} [\mathbb E _{x \sim p_{data}} \log D_{\theta_d} (x) + \mathbb E_{z \sim p(z)} \log (1 - D(G_{\theta_g}(z)))]\] The training is done alternately, performing gradient ascent on the generator and descent on the discriminator. Object Detection Simply put, the goal is identify objects in a given image. The evolution of algorithms for object detection is summarized as HoG + SVM - Sliding window mechanism for feature detection. Deformable Part Models - CNN - Using a sliding window mechanism is computationally expensive. Instead, these methods use region proposals and filter out the ones with satisfying criteria. Transformers Self-supervision Open vocabulary Multi-stage CNNs RCNN The first demonstration that showed classification features from CNNs can be used to detect objects. Essentially, the last layer of the ImageNet classifier network was removed . Each region proposal is warped/cropped to match the CNN input size. The post-processing involves bounding box regression FastRCNN FasterRCNN Uses a Region Proposal Network (RPN) after the last convolutional layer. The RPN is trained to produce region proposals directly without any need for external region proposals. After RPN, the RoI Pooling and an upstream classifier are used as regressors similar to FastRCNN. Region Proposal Network The network does the following - Slide a small window on the feature map A small network to do classification - object or no-object A regressor to give the bounding box Anchors Anchors are a set of reference positions on the feature map 3 dimensions with aspect ratio, 3 different scales of boxes, Training Non-Maximal Supression Since, multiple anchor boxes can map to an object, we iteratively choose the highest scoring box among the predictions and supp ress the predictions that have high IoU with the currently chosen box. Transformer based Architectures DETR Faster R-CNN has many steps, handcrafted architecture and potentially non-differentiable steps. In contrast, DETR was proposed - an end-to-end transformer based architecture for object detection. The motivation was to capture all the human-designed optimization parts of the pipeline into one black-box using a transformer. Why do we want such an end-to-end architecture? They are more flexible to diverse data, capturing large datasets, finetuning, etc. In this architecture, a CNN backbone like ResNet extracts the features which are passed through the encoder to obtain latent representations. These are then used with a decoder along with object queries in the form of cross-attention to give bounding boxes as the output. After obtaining the bounding boxes, the loss is appropriately calculated by matching the boxes to the correct labels. It is our task to assign a ground truth label to the predictions Hungarian?? The decoder takes object queries as input, 500 epochs encoder is segmented, decoder is just getting bounding boxes DINO lagging in scale variant objects. contrastive loss acting for negative samples YOLOX Single Shot-Detectors The motivation for these networks is to infer detections faster without much tradeoff in accuracy. Anchor boxes no ambiguous IoU Hard negative mining You Only Look Once (YOLO) Divide into grids anchor boxes in grid and class probability map YOLO-X No anchored mechanism - hyperparameter tuning, more predictions, less generalization (OOD fails) Detection head decoupling, no anchor boxes, SimOTA predict size and centers rather than top-left mosaicing and mixing Pyramid Feature Extractions RFCN Semantic Segmentation The goal in this task is much more fine-tuned wherein we assign class pixel-wise. We want locally accurate boundaries as compared to finding bounding boxes in object detection. The approaches require global reasoning as well. A naive approch would be to classify a pixel by considering the patch around the pixel in the image. This is very expensive computationally and does not capture any global information. Another approach is to consider image resolution convolutions (purely convolutions with stride 1, no pooling) and maining the image resolution to produce the output. This still does not work quite well, and they also consume more memory. Taking classification networks as the motications, some networks try pooling/striding to downsample the features. This architecture corresponds to the encoder part of the model, and the decoder then upsamples the image using transposed convolution, interpolation, unpooling to recover the spatial details in the original size. The convolutions can go deeper without occupying a lot of memory. How do we upsample? Transposed convolution to upsample. The operation is shown below - ![Transpose Convolution for Up-Sampling Images Paperspace Blog](https://blog.paperspace.com/content/images/2020/07/conv.gif) However, the outputs are not very precise. Combine global and local information. U-Net Unpooling followed by convolutions (simpler implementation of transposed convolution) The max-unpooling operation does the following - Why is this better? Lesser memory In all the architectures above, once you downsample the image, you lose a lot of spatial information and the network uses a significant amount of parameters learning the upsampling process to represent the final output. To help with this, we can do the following Predict at multiple scales and combine the predictions Dilated convolutions - These are used to increase the receptive field without downsampling the image too much - It’s multi-scale and also captures full-scale resolution. The idea of dilated convolution is very important in other tasks as well - It prevents the loss of spatial information in downsampling tasks. However, there are gridding artifacts and higher memory consumptions with Dilated networks. Degridding solutions Add convolution layers at end of the network with progressively lower dilation Remove skip connections in new layers, can propogate gridding artefacts because skip connections transfer high-frequency information. Skip-connections Physiological Grouping for Perception DeepLab v3+ Segformer Instance Segmentation Mask RCNN Predict eh Panoptic Segmentation Panoptic segmentation extends the idea of instance segmentation even further to segment objects beyond a fixed set of classes. #]]></summary></entry><entry><title type="html">Mathematics for Finance</title><link href="https://sudhansh6.github.io/blog/Mathematics-for-Finance/" rel="alternate" type="text/html" title="Mathematics for Finance"/><published>2024-04-01T00:00:00+00:00</published><updated>2024-04-01T00:00:00+00:00</updated><id>https://sudhansh6.github.io/blog/Mathematics-for-Finance</id><content type="html" xml:base="https://sudhansh6.github.io/blog/Mathematics-for-Finance/"><![CDATA[<h1 id="introduction">Introduction</h1> <p>We will discuss mathematics for options, pricing methods, and optimizing the performance of a portfolio. We will cover discrete (finite probability spaces, tree models) as well as continuous math (Brownian Motion, Black-Scholes formula, Martingale theory).</p> <p>The theory in the course revolves around the “No Arbitrage theorem” which is closely related to one-price principle. Similarly, the idea of one-price principle theorizes that a set of investments with the same net outcome, albeit with different transactions, should have the same price.</p> <h2 id="financial-markets">Financial Markets</h2> <p>A <em>financial market</em> consists of tradable products such as stocks, bonds, currencies and indices. The market consists of two parties - the buyers and the sellers, who buy and sell these products respectively trying to make an <em>arbitrage</em> from the transactions. Formally, an <em>arbitrage opportunity</em> is a chance for a risk-free profit.</p> <h3 id="odds-and-arbitrage">Odds and Arbitrage</h3> <p>Let us consider the example of a horse race, where \(P(\text {S wins}) = 3/4\) and \(P(\text{W wins}) = 1/4\). How do we calculate the odds against \(W\) winning? It is given by \(P(\text{W wins})/P(\text{W loses}) = 3\). This situation is called \(3\text{-to-}1\) odds. That means, a dollar bet \(\$ 1\) brings \(\$ 3\) if \(W\) wins. Similarly, for \(S\), it brings \(\$ 0.3\). These bets are an example of a fair game, the net reward \(\frac{1}{4} (3) + \frac{3}{4}(-1)\) is \(0\).</p> <p>A <em>bookmaker</em> sets the odds for such scenarios. Consider an other example where the odds are \(9\text{-to-}5\) against \(W\) and \(2\text{-to-}5\) against \(S\). We claim that this results in an arbitrage for the bookmaker. To illustrate this, consider the bets \(\$ 10\) on \(S\) and \(\$ 5\) on \(W\). The payoff for the bookmaker when \(S\) wins is \(5 - 10\frac{2}{5} = 1\). When \(W\) wins, the profit is \(10 - 5\frac{9}{5} = 1\). A bookmaker typically decides the odds after the bets are made so that arbitrage is made in any scenarios.</p> <p>Ideally, one wants to make profit from such games. How do we do this? In the first example, we considered the probabilities and calculated the odds. To decide the odds for arbitrage, we do the reverse. In the above scenario, given the odds, the probabilities are \(P(S) \approx 71\%\) and \(P(W) \approx 36\%\). The probabilities add up to slightly above \(100\%\), which makes up the arbitrage for the bookmaker.</p> <h2 id="contingent-claim">Contingent Claim</h2> <p>A <strong>derivative</strong> or a <strong>contingent claim</strong> is a security whose value depends on the value of an underlying asset. Forward contracts, futures contracts and options are examples of such securities. Interestingly, the markets around the world also use derivatives whose underlying asset is also a derivative. Such securities are called as <em>structured products</em>.</p> <p>With such contrived products, it is important to choose a <em>fair price</em> to ensure there are no arbitrage opportunities in the market. To do so, we introduce the required mathematical notation - \(X\) is a real-valued random variable defined on a probability space \((\Omega, \mathcal F, P)\) and \(\mathcal G\) is a sub-\(\sigma\)-algebra of \(\mathcal F\). For unfamiliar readers, in probability theory, a probability space consists of three elements -</p> <ul> <li>A sample space \(\Omega\), which is the set of all possible outcomes. For example, the sample space for a dice roll is \(\Omega = \{1, 2, 3, 4, 5, 6\}\).</li> <li>An event space or a set of events is represented by \(\mathcal F\). For example, the events constituting an odd dice roll is \(\mathcal F = \{1, 3, 5\}\).</li> <li>A probability function \(P\), assigns a probability (a number between \(0\) and \(1\)) to each event in the event space.</li> </ul> <p>The term \(\sigma\)-algebra on a set \(X\) refers to a nonempty collection \(\Sigma\) of subsets of \(X\) closed under complement, countable unions, and countable intersections. The pair \((X, \Sigma)\) is called a <strong>measurable space</strong>.</p> <p>In general, we model the price of a contract with a random variable \(X\) that evolves across time with \(X(w) \geq 0\) (all the values for the random variable are positive). For example, for the <em>call option</em> described in #options, we have</p> \[X(w) = (S(w)_t - K)^+\] <p>Similarly, for a <em>put</em> option, where the holder has the right to sell a certain asset at a fixed price, we get</p> \[X(w) = (K - S_T)^+\] <p>There can be other kinds of <em>structured products</em> like</p> <ul> <li> \[X = \max(S_1, \dots, S_T)\] </li> <li> \[X = \left(\frac{1}{T} \sum_{t = 1}^T S_t - K\right)^+\] </li> </ul> <p>In the above definitions, the variables \(w, S_t\) capture the evolution of price across time, and are described in the later section. The key takeaway is that, we are trying to price a contingent claim \(X\) - find \(C_0(X)\)</p> <h3 id="forwards-contract">Forwards Contract</h3> <p>A <strong>forward constract</strong> is an agreement to buy or sell an asset at a <em>certain</em> future time for a <em>certain</em> price. Consider the following example,</p> <ul> <li>\(A\) agrees at time \(t = 0\) to sell one share at time \(T\) for \(\$ F\). We assume that \(A\) buys the share at \(t = 0\) at price \(S_0\).</li> <li>\(B\) agrees at time \(t = 0\) to buy one share at time \(T\) for \(\$ F\)</li> </ul> <p>We assume that \(A, B\) don’t invest their own money, and borrow money from the bank to perform transactions. Given such a scenario, how do we decide a <em>fair price</em> \(F\)? To simplify the calculations, we assume the following -</p> <ul> <li>No transaction costs or dividends.</li> <li>Market is liquid - every transaction has a buyer and seller available.</li> <li>Investor is <em>small</em> compared to the market. That is, the action of the investor is not momentous enough to change the price of the stock in the market.</li> <li>Short selling/borrowing of stock is allowed.</li> </ul> <p>\(B\) can invest the amount in the bank for a <em>continuous compound</em> interest rate \(r\) during this term. The claim is that \(F = S_0 e^{rT}\) where \(S_0\) is the price of the share at \(t = 0\). To analyze this, we consider the following cases -</p> <ul> <li> \[F &gt; S_0 e^{rT}\] <p>\(A\) sells the share for \(\$ F\) and repays the loan of \(\$ S_0\) with interest - \(\$ S_0 e^{rT}\). The profit \(A\) gets is \(F - S_0 e^{rT}\)</p> </li> <li> \[F &gt; S_0e^{rT}\] <p>\(B\) short sells one share for \(\$ S_0\) and invests \(\$ S_0\) in the bank. The money in the bank will grow to \(S_0 e^{rT}\) at \(t = T\), and \(B\) buys one share at \(F\). The profit for \(B\) here is \(S_0 e^{rT} - F &gt; 0\)</p> </li> </ul> <p>So the fair price is \(S_0 e^{rT}\) where neither \(A\) nor \(B\) can take advantage.</p> <p><em>Note.</em> A <strong>futures contract</strong> is similar to a forward contract but is traded on a financial exchange. They typically have a delivery month rather than a delivery date, and are followed by a settlement procedure called <em>marking to market</em>.</p> <h3 id="options">Options</h3> <p>An <strong>option</strong> is a contract which gives the holder of the option the right, but not the obligation, to buy other sell a given security at a given price (called the <em>strike</em> price) within a fixed time period \([0, T]\). A <strong>call option</strong> gives the option holder the right to buy at the given price, whereas the <em>put option</em> gives the option holder the right to sell at the given price.</p> <h1 id="european-call-options">European Call Options</h1> <p>A <em>European option</em> can only be exercised by the holder of the option at the expiration time \(T\) (unlike an American Option, which will be discussed in the later sections). We have the following equation for profit of a <em>call option</em> holder, assuming the option is free -</p> \[P = (S_T - K)^+ = \begin{cases} S_T - K &amp; S_T &gt; K \\ 0 &amp; S_T \leq K \end{cases}\] <p>How do we decide the <em>fair price</em> at \(t = 0\) for the option? We need to use probability results to model the price movement to decide this. In discrete time settings, we use different models like Cox, Ross and Rubenstein. In continuous time frame, we use Brownian motion using the Black-Scholes model. In both cases, there exists a unique fair price. However, if the product is slightly more complicated, then there is no unique fair price.</p> <h2 id="binomial-model">Binomial Model</h2> <p>Also known as <strong>Cox-Ross-Rubenstein Model (CRR)</strong> is a discrete time model for a financial market defined for \(t = 0, 1, \dots, T\). At each time instant the model considers the following two types of assets</p> <h4 id="bonds">Bonds</h4> <p>Considered as a risk-free asset, a <em>bond</em> yields at a constant rate of return \(r \geq 0\) over each time period. The price is modeled as \(B_t = B_0 (1 + r)^t\) for \(t = 0, 1, \dots, T\). \(B_0\) is typically assumed as \(1\).</p> <h4 id="stocks">Stocks</h4> <p>Stocks are considered as risk-models where the price evolution is captured using binomial random variables. We consider the model \(S_t = s_o \zeta_1 \dots \zeta_{t_1} = S_{t - 1} \zeta_t\) where \(S_0 &gt; 0\) is the constant initial price. That is, the stock price process is modeled as an <em>exponential random walk</em>. In this model, we assume \(P(\zeta_t = u) = p\) and \(P(\zeta_t = d) = 1- p\) where \(0 &lt; d &lt; 1 + r &lt; u\) where \(d, u\) are the down and up movements respectively. That is, \(S_{t + 1} = S_t u\) represents the price of the stock if the price has moved upward at time \(t\).</p> <p>Concretely, the probability space \((\Omega, \mathcal F, P)\) is such that \(\Omega\) is the finite set of \(2^T\) possible outcomes for the values of stock price \((T + 1)\)-tuple (for \(S_0, S_1, \dots, S_T)\), \(\mathcal F\) is the \(\sigma\)-algebra consisting of all possible subsets of \(\Omega\), and \(P\) is the probability measure on \((\Omega, \mathcal F)\) associated with the Bernoulli probability \(p\).</p> <p>Let the field \(\mathcal F_0 = \{ \phi, \Omega\}\) and</p> \[\begin{align*} \mathcal F_1 &amp;= \sigma(S_1) \\ &amp;= \{ \phi, \Omega, \{w: S_1(w) = S_0u \}, \{w: S_1(w) = S_0 d\}\} \\ &amp;= \sigma(\{S_1 = S_0u\}), \{S_1 = S_0d\}) \end{align*}\] <p>This is a partition of \(\Omega\). Similarly, for \(t = 2\), we get</p> <p>\(\mathcal F_1 = \{ \phi, \Omega, \{uu, ud\}, \{dd, du\}\}\). Extrapolating this,</p> \[\mathcal F_t = \sigma(S_1, \dots, S_t) = \sigma(\zeta_2, \dots, \zeta_t)\] <p>We get \(\#(\mathcal F)_t = 2^t\). This evolution can be represented using a binomial tree of the following form -</p> \[\begin{align*} &amp;\boxed{} \\ \boxed{d} &amp;\quad \boxed{u} \\ \boxed{dd} \quad \boxed {du} &amp;\quad \boxed{ud} \quad \boxed{uu} \\ &amp;\dots \end{align*}\] <h2 id="trading-strategies-and-fair-pricing">Trading Strategies and Fair Pricing</h2> <p>A strategy \(\phi\) in stocks and bonds consists of sequence of random variable pairs \(\phi = \{(\alpha_t, \beta_t); t = 1, \dots, T\}\) where \(\alpha_t\) represents the holdings of a stock and \(\beta_t\) represents the holdings of a bond on day \(t\) (The unit for time can be taken as minutes, hours, etc., but we consider days). We also have the following assumptions</p> <ol> <li>Predictability: \(\alpha_t, \beta_t \in \mathcal F_{t - 1}, t = 1, \dots, T\)</li> <li>Self-financing: \(\alpha_t S_t + \beta_t B_t = \alpha_{t + 1} S_t + \beta_{t + 1}B_t\). That is, there is no influx or outflux of money asides from the changes in the underlying assets. We have some initial investment and assume that \(\alpha_1, \beta_1\) are \(\mathcal F_0\)-measurable are constant.</li> </ol> <p>The value of the portfolio at time \(t\) is given by \(V_t(\phi) = \alpha_t S_t + \beta_t B_t, t = 1, \dots, T\) and \(V_0(\phi) = \alpha_1 S_0 + \beta B_0 = \alpha_1 S_1 + \beta_1\) We can now define the concept of <strong>arbitrage</strong> formally.</p> <h3 id="arbitrage">Arbitrage</h3> <p>An arbitrage is a trading strategy \(\phi\) such that \(V_0(\phi) = 0\) and \(V_t(\phi) \geq 0\). That is, we don’t have any initial investment and get a profit at time \(t = T\). However, note that \(V_t(\phi)\) is a random variable, so the inequality is assumed to be a point-wise inequality wherein \(V_T(\phi)(w) \geq 0, \forall w \in \Omega\). This is a stronger assumption than \(P(V_T(\phi) &gt; 0) &gt; 0 \equiv E(V_T(\phi)) &gt; 0 \equiv V_T(\phi)(w) &gt; 0\) for some \(w \in \Omega\). Notice that the last equivalence does not have any probability term in the expression. This equivalence is important to note since it makes the definition invariant of the underlying probability assumptions.</p> <h3 id="hedge">Hedge</h3> <p>A hedging or a replicating strategy \(\phi\) has the property \(V_T(\phi) = X\). That is, to price a contingent claim \(X\), if we find a trading strategy \(\phi\) with cost (initial investment) \(V_0(\phi)\), such that \(V_T(\phi) = X\), then \(V_0(\phi)\) is a fair price of \(X\) by the one-price principle. Essentially, with the price “\(V_0(\phi)\)” we bought an opportunity that resulted in a value of “\(V_T(\phi)\)” at time \(T\). If a contingent claim \(X\) has the same value at time \(T\), then its fair price should be \(V_0(\phi)\) at \(t = 0\).</p> <p>Using this as a motivation, let us price a European call option. Our approach is as follows - an investment in the underlying stock and a bond should result in the same outcome as an investment in the option itself. The movements in the option will be correlated with those of the underlying stock, allowing us to correctly determine a fair price at every time instant.</p> <h4 id="hedging-for-t--1">Hedging for \(T = 1\)</h4> <p>Consider the following example, where we try to hedge \(X\) at \(t = 1\). That is, we are trying to find a strategy \(\phi = (\alpha_1, \beta_1)\) such that \(V_1(\phi) = \alpha_1 S_1 + \beta_1 B_1\equiv X\).</p> <p>We have two cases based on the stock movement -</p> <ul> <li> \[\alpha_1 S_0 u + \beta_1 (1 + r) = X^u\] </li> <li> \[\alpha_1 S_0 d + \beta_1 (1 + r) = X^d\] </li> </ul> <p>Equivalently, \(\alpha_1 S_0(u - d) = X^u - X^d\)</p> \[\begin{align*} \alpha_1 &amp;= \frac{X^u - X^d}{u - d}\frac{1}{S_0} \\ \beta_1 &amp;= \frac{uX^d - d X^u}{u - d}\frac{1}{B_1} \end{align*}\] <p>What do the above expressions mean? Investing \(\alpha_1\) in stock and \(\beta_1\) in bond at the end of day \(0\) will result in same price as \(X\) on day \(1\). Manipulating the expressions further,</p> \[\begin{align*} V_0 (\phi) &amp;= \alpha_1 S_0 + \beta_1 \\ &amp;= \frac{X^u - X^d}{u- d} + \frac{uX^d - d X^u}{u - d}\frac{1}{1 + r} \\ &amp;= \frac{1}{1 + r}\left\{X^u \left(\frac{1 + r - d}{u - d}\right) + X^d \left(\frac{u - 1 - r}{u - d}\right)\right\} \\ &amp;= \frac{1}{1 + r} \mathbb E^* (X) \end{align*}\] <p>The above expression is reminiscent of an expectation formulation where \(p^* = \frac{1 + r - d}{u - d}\) and \(0 &lt; p^* &lt; 1\). Here, the set of discounted stock prices \(\{S_0, S_1/(1 + r)\}\) form a \(p^*\)-martingale.</p> <p>What is a Martingale? A <strong>Martingale</strong> is a sequence of random variables representing a stochastic process for which, at a particular time, the conditional expectation of the next value in the sequence is equal to the present value, regardless of all prior values.</p> <p>In the above case, we have</p> \[\begin{align*} \mathbb E^* (S_1/(1 + r) \vert \mathcal F_0) &amp;= S_0 u \cdot p^* + S_0 d \cdot (1 - p)^* \\ &amp;= S_0 \implies \mathbb E^*(S_1) = S_0(1 + r) \end{align*}\] <p>It is important to realize that computing expectations under \(p^*\) is a mathematical device. We are not assuming that the stock price actually moves according to this probability. That is, \(p^*\) may be unrelated to the subjective probability \(p\) that we associate with the binomial model for movements in the stock price.</p> <p><strong>Theorem 1 (T = 1)</strong> <em>For a given \(X\), the value \(\mathbb E^*(X)/(1 + r)\) is the non-arbitrage price of \(X\) at \(t = 0\).</em> <em>Proof.</em> Let \(C_0\) is the market price of the contingent claim \(X\) and \(V_0 = \mathbb E^*(X)/(1 + r) = V_0(\bar \phi)\) where \(\bar \phi = (\bar \alpha_1, \bar \beta_1)\) (the values we calculated before). Consider the following cases -</p> <ol> <li> <p>Say \(C_0 &gt; V_0\) To make an arbitrage in this situation, we sell \(X\) for \(C_0\). We invest the amount \(V_0\) in the stock and amount \(C_0 - V_0 &gt; 0\) in bonds at \(t = 0\). At time \(t = 1\), we get \(V_1(\bar \phi) = X\) yielding \((C_0 - V_0)(1 + r) &gt; 0\) as profit from the bond.</p> </li> <li> <p>Say \(C_0 &lt; V_0\) We do the opposite from above, where we buy the asset \(X\). Short sell \(\bar \phi\) for \(V_0\), and invest \(C_0\) in \(X\) and \(V_0 - C_0\) in the bond. We get the profit \((V_0 - C_0)(1 + r)\) at \(t = 1\).</p> </li> <li> <p>Say \(C_0 = V_0\) Here, we can show that no one can make an arbitrage. Consider the strategy in stock, bond and contingent claim \(\psi = (\alpha_1, \beta_1, \gamma_1)\). We need to argue that no arbitrage can be made with any such strategy. We have,</p> </li> </ol> \[\begin{align*} V_0(\psi) &amp;= \alpha_1 S_0 + \beta_1 + \gamma_1 C_0 \\ V_1(\psi) &amp;= \alpha_1 S_1 + \beta B_1 + \gamma_1 X \\ \implies \mathbb E^*(V_1(\psi)) &amp;= \mathbb E^*(\alpha_1 S_1 + \beta_1 B1 + \gamma_1 X) \\ &amp;= \alpha_1 \mathbb E^*(S_1) + \beta_1 (1 + r) + \gamma_1 \mathbb E^*(X) \end{align*}\] <p>We can distribute the expectation this way due to the linearity property. Recall that, we typically assume \(B_0 = 1\) for brevity. Continuting the calculations,</p> \[\begin{align*} \mathbb E^*(V_1(\psi)) &amp;= \alpha_1 S_1(1 + r) + \beta_1(1 + r) + \gamma_1 V_0 (\bar \phi)(1 + r) \\ &amp;= \alpha_1 S_1(1 + r) + \beta_1(1 + r) + \gamma_1 C_0 (1 + r) \\ &amp;= (1 + r) V_0 (\psi) \end{align*}\] <p>If \(V_0(\psi) = 0\), then \(\mathbb E^*(V_1(\psi)) = 0\), and if \(V_1(\psi) \geq 0\), then \(P^*(V_1(\psi) = 0) = 1\). That is, \(V_1(\psi) = 0\) meaning no arbitrage can be made with any strategy \(\psi\).</p> <h4 id="general-t">General \(T\)</h4> <p>This analysis can be extended to derive the hedging strategy a general \(t &gt; 1\). Given an \(X\), find \(\phi = \{(\alpha_t, \beta_t): t = 1, \dots, T\}\) such that \(V_T(\phi) = X\) (resulting in \(C_0 = V_0(\phi)\)). To derive such a strategy, we work backwards in time starting from \(V_T(\phi) = X\). This way, we can also calculate the intermediate price - the price to enter the market at some intermediary time \(t\). It is helpful to think of the tree visualization for the price evolution.</p> \[\begin{align*} V_T(\phi) = \alpha_T S_T + \beta_T B_T = X \end{align*}\] <p>conditional on \(\mathcal F_{T - 1}\). Focusing on \(T - 1\) and \(T\), the analysis is similar to the previous case wherein \(X^U = X(w_1 \dots w_{T - 1} u)\) and \(X^d = X(w_1 \dots w_{T - 1} d)\). Doing so we get</p> \[\left. \begin{align*} \alpha_T = \frac{X^u - X^d}{u - d}\frac{1}{S_{T - 1}} \\ \beta_T = \frac{uX^d - dX^u}{u - d}\frac{1}{(1 + r)^T} \end{align*} \right\} \in \mathcal F_{T - 1}\] <p>Using the property of Martingales,</p> \[\begin{align*} \mathbb E^* (X \vert \mathcal F_{T - 1}) = \mathbb E^* [V_T(\phi) \vert \mathcal F_{T - 1}] &amp;= \mathbb E^*[\alpha_T S_T + \beta_T B_T \vert \mathcal F_{T - 1}] \\ &amp;= \alpha_T \mathbb E^*(S_T \vert \mathcal F_{T - 1}) + \beta_T B_T \\ &amp;= \alpha_T \left(p^* S_{T - 1} u + (1 - p^*) S_{T - 1} d\right) + \beta_T B_T \\ &amp;= \alpha_T S_{T - 1}(1 + r) + \beta_T B_T \end{align*}\] <p><em>Note.</em> \(\alpha_T, \beta_T\) are constants with respect to the <em>condition</em> \(\mathcal F_{T - 1}\), and that is why the linearity property can be used.</p> <p>Continuing the previous calculations</p> \[\begin{align*} \mathbb E^*(V_T \vert \mathcal F_{T - 1}) &amp;= \mathbb E^*(\alpha_T S_T + \beta_T B_T \vert \mathcal F_{T - 1}) \\ &amp;= \alpha_T S_{T - 1}(1 + r) + \beta_T B_{T - q}(1 + r) \\ &amp;= (1 + r) \left[\alpha_T S_{T - 1} + \beta_T B_{T - 1}\right] \\ &amp;= (1 + r) \left[\alpha_{T - 1} S_{T - 1} + \beta_{T - 1} B_{T - 1}\right] &amp;\because \text{ self-financing} \\ &amp;= (1 + r) V_{T - 1}(\phi) \end{align*}\] <p>As a result, we have a recursive property</p> \[\begin{align*} V_{t - 1}(\phi) &amp;= \frac{1}{1 + r} \mathbb E^*(V_t(\phi) \vert \mathcal F_{t - 1}) \\ \alpha_t &amp;= \frac{V_t^u - V_t^d}{u - d} \frac{1}{S_{t - 1}} \\ \beta_t &amp;= \frac{uV^d_t - dV^u_t}{u - d} \frac{1}{B_{t - 1}} \end{align*}\] <p>for \(t = T, \dots, 1\)</p> <p>The above relation can also be alternately derived using the <strong>Tower law</strong> to relate the value with \(V_t(\phi)\) for a general \(t\).</p> <blockquote> <p>Tower Law: If \(X\) is a random variable whose expected value \(E ⁡( X )\) is defined, and \(Y\) is any random variable on the same probability space, then \(E(X) = E (E (X \vert Y ) )\), i.e., the expected value of the conditional expected value of \(X\) given \(Y\) is the same as the expected value of \(X\).</p> </blockquote> <p>Then, we get \(\begin{align*} V_t(\phi) &amp;= \frac{1}{1 + r} \mathbb E^*(V_{t + 1} (\phi) \vert \mathcal F_t) \\ &amp;= \frac{1}{1 + r} \mathbb E^*\left(\frac{1}{1 + r} \mathbb E^*(V_{t + 2}(\phi) \vert \mathcal F_{t + 1} ) \vert \mathcal F_t\right) \\ &amp;= \frac{1}{(1 + r)^2} \mathbb E^*\left(\mathbb E^*\left(V_{t + 1} \vert \mathcal F_{t + 1}\right \vert \mathcal F_{t} \right) \\ &amp;= \frac{1}{(1 + r)^2} \mathbb E^*(V_{t + 2} \vert \mathcal F_t) \end{align*}\)</p> <p>Consequently,</p> \[\begin{align*} V_T(\phi) &amp;= \frac{1}{(1 + r)^{T - t}} \mathbb E^*(V_T (\phi) \vert \mathcal F_t) \\ &amp;= \frac{1}{(1 + r)^{T - t}} \mathbb E^*(X \vert \mathcal F_t) \\ V_0 (\phi) &amp;= \frac{1}{(1 + r)^T} \mathbb E^*(X) \end{align*}\] <h3 id="conditional-expectation-of-martingales">Conditional Expectation of Martingales</h3> <p>Given \((\Omega, \mathcal D, P)\) with \(g \subset \mathcal F\), \(X \in L'(\mathcal F)\) (the space of random variables that are integrable with respect to the \(\sigma\)-algebra \(\mathcal F\)) then \(Y = \mathbb E(X \vert g)\) is the random variable such that</p> <ol> <li> \[Y \in L'(g)\] </li> <li>\(\mathbb E(YZ) = \mathbb E(XZ)\) for all \(Z\) that are \(g\)-measurable.</li> </ol> <p>where \(L'\) represents integrability. The above property is the general statement for the law of general statician.</p> <p><em>Special case.</em> When \(\Omega\) is finite (\(\#(\Omega) &lt; \infty\)), then \(\mathcal F = \{ \text{all subsets of } \Omega\}\) and \(\mathcal G = \sigma(G_1, \dots, G_n)\) form a partition (\(G_i \cap G_j = \phi, \cup_{j = i}^n G_j = \Omega\)) of \(\Omega\) with \(P(G_k) &gt; 0\).</p> <p>A random variable \(Z\) is \(g\)-measurable iff \(Z(w) = \sum_{k = 1}^n \mathbb 1_{G_k} (w) \cdot c_k \equiv Z(w) = c_k \text{ if } w \in G_k\) where \(c_k\) is the cardinality of \(G_k\).</p> <p>Then,</p> \[\mathbb E[X \vert \mathcal G](w) = \sum_{k = 1}^n \left(\mathbb 1_{G_k}(w) \cdot E[X \vert G_k]\right)\] <p>From Bayes’ rule</p> \[\mathbb E(X \vert G_k) = \mathbb E(X . \mathbb 1_{G_k}) /P(G_k) = \mathbb E(X; G_k)/P(G_k)\] <p>Using the above results, we get</p> <ol> <li> <p>\(X \to \mathbb E(X \vert Y)\) is linear &amp; positive (\(X \geq 0 \implies \mathbb E(X \vert g) \geq 0\))</p> </li> <li> \[\mathbb E(\mathbb E (X \vert g)) = \mathbb E(X)\] </li> <li> \[\mathbb E(XZ \vert g) \equiv E(X \vert y) Z\] </li> <li>If \(\mathbb E \in g\), then \(E(X \vert g) = X\) and \(X \perp\!\!\!\perp g\), then \(\mathbb E(X \vert Y) = \mathbb E(X)\).</li> </ol> <p><strong>Exercise.</strong></p> <p>Show that \(E( \cdot \vert \mathcal G)\) is a \(\perp\) projection where \(d(X, \tilde X) = \sqrt{\mathbb E(X - \tilde X)^2}\)</p> <h3 id="tower-property">Tower Property</h3> <p>For any \(\mathcal G \subset \mathcal H ( \subset \mathcal F)\), we have \(\mathbb E[\mathbb E[X \vert \mathcal H] \vert \mathcal G] = \mathbb E[X \vert \mathcal G]\).</p> <p>What does \(\mathcal G \subset \mathcal H\) mean? In the discrete case where \(\mathcal G = \sigma(G_1, \dots, G_n)\) and \(\mathcal H = \sigma(H_1, \dots, H_m)\), we have \(G_k = \dot \cup_{j \in J(k)} H_j\) where \(J(1),\dots, J(n)\) is a partition of \(\{1, \dots, m\}\).</p> <p>Now, to show the tower property,</p> \[\begin{align*} \mathbb E[X \vert G_k] &amp;= \underbrace{\mathbb E[X; G_k]}_{P(G_k)} \\ &amp;= \sum_{j \in J(k)} \underbrace{\mathbb E(X; H_j)}_{P(H_j)}P(H_j \vert G_k) \\ &amp;= \sum_{j \in J(k)} \mathbb E(X \vert H_j)P(H_j \vert G_k) \end{align*}\] <p>In the trading strategy context, we have \(\mathcal F_0 \subset \mathcal F_1 \subset \dots \subset \mathcal F_n\).</p> <h3 id="martingales">Martingales</h3> <p>We now introduce Martingales formally - A Martingale is a sequence of random variables \(\{M_0, \dots, M_T\}\) such that</p> <ol> <li> <p><em>Adapted:</em> \(M_t \in \mathcal F_t\), for all \(t\)</p> </li> <li> <p><em>Integrable:</em> \(\mathbb E(\vert M_t\vert) &lt; \infty\) for all \(t\)</p> </li> <li> <p>\(\mathbb E(M_t \vert \mathcal F_{t - 1}) = M_{t - 1}\), \(1 \leq t \leq T\). From Tower law, \(\mathbb E[M_T \vert \mathcal F_s] = M_s\).</p> </li> </ol> <p>Let us now revert to our discussion on trading strategies with these formal definitions in mind.</p> <p>As we have seen before in #General \(T\), \(\phi\) that satisfied \(V_t^*(\phi) := V_t(\phi)/(1 + r)^t\) is a \(p^*\)-martingale, where \(p^* = \frac{1 + r - d}{u - d}\). A special case of this is \(S^*_t\) is a \(p^*\)- martingale. We have the following theorem,</p> <p><strong>Theorem 2. (General \(T\))</strong> \(V_0\) is the arbitrage-free price of \(V\)</p> <p><em>Proof.</em> We follow a similar structure as before,</p> <ol> <li> <p>\(C_0 \neq V_0\), then arbitrage is available</p> </li> <li> <p>\(C_0 = V_0\), we have for any strategy \(\psi = \{(\alpha_t, \beta_T, \gamma_1): t = 1, \dots, T\}\), \(V_0(\psi) = 0, V_T(\psi) \geq 0\) due to self-financing. Let \(\bar \phi = \{(\bar \alpha_t, \bar \beta_T): t = 1, \dots, T\}\) be the hedge for \(X\). Then, \(V_T(\bar \phi) = X\) and \(V_0(\bar \phi) = V_0\).</p> \[\begin{align*} V_0 (\psi) &amp;= \alpha_1 S_0 + \beta + \gamma_1 C_0 \\ V_T(\psi) &amp;= \alpha_T S_t + \beta_T B_T + \gamma_1 X \end{align*}\] <p>Continuing the calculations,</p> \[\begin{align*} \mathbb E^*(V^*_T(\psi)) &amp;= \mathbb E^*(\alpha_T S^*_T + \beta_T + \gamma_1 X^*) \\ &amp;= \mathbb E^*(V_T(\phi)) + \gamma_1 \mathbb E^*(X^*) \\ &amp;= V_0(\phi) + \gamma_1 C_0 \\ &amp;= V_0 (\psi) = 0 \implies V_T(\psi) = 0 \end{align*}\] <p>Therefore, no arbitrage is possible in this case.</p> </li> </ol> <p>Let us consider a numerical example to understand this better - Consider the call option \(X = (S_T - K)^+\), where \(T = 4, u = 1.2, d = 0.8, r = 0\) (\(p^* = 0.5\)). Let \(S_0 = 50\) and \(K = 40\). What is the fair price of \(X\)?</p> <p>Then, we have the following evolution for \(S_T\),</p> \[\begin{align*} &amp;50\\ 40&amp;\quad 60\\ 32\quad &amp;48\quad 72\\ 25.6\quad 38.4&amp;\quad 57.6\quad 86.4\\ 20.48\quad 30.72\quad &amp;46.08\quad 69.12\quad 103.68 \end{align*}\] <p>Consequently, the tree for \(V_0\) is</p> \[\begin{align*} &amp;13.54\\ 1&amp;\quad 21.66\\ 1.52\quad &amp;10.32\quad 32\\ 0\quad 3.04&amp;\quad 17.6\quad 46.4\\ 0\quad\quad 0 \quad &amp;6.08\quad 29.12 \quad 63.68 \end{align*}\] <p>We construct the tree recursively, starting from the bottom-most level. At time \(T\), we know \(V_T\), and then we use \(V_t^u p^* + V_t^d(1 - p^*)\) to get \(V_{t - 1}(1 + r)\).</p> <h2 id="call-put-parity">Call-Put Parity</h2> <p>A call option is represented as \(C_T = (S_T - K)^+\) and a put option is represented as \(P_T = (K - S_T)^+ = (S_T - K)^-\).</p> <p>For any \(b\), we have \(b^+ - b^- = b\) and \(b^+ + b^- = b\). In other words, the payoffs in call and put options are related to each other as</p> \[\begin{align*} C_T - P_T = S_T - K \\ C_T + K = S_T + P_T \end{align*}\] <p><strong>Claim.</strong> For \(t &lt; T\), we have</p> \[C_t + \frac{K}{(1 + r)^{T - t}} = S_t + P_t\] <p>This result can be proved using <strong>One price principle</strong>. Think of each side of the equation as separate investments</p> <ol> <li> <p>First investment has a call option and bonds with \(K\).</p> </li> <li> <p>Second investment has a put option and one share of the stock</p> </li> </ol> <p>We can see that at time \(T\), the values become equal \(C_T + K = S_T + P_T\)</p> <h1 id="american-options">American Options</h1> <p>In American Options, we have \(Y_0, Y_1, \dots, Y_T\) random payouts where each \(Y_t \in \mathcal F_T\). The holder of the options can take the payment at any time \(t \in [0, T]\) of choice. That is , unlike European options, American options have the choice of payment at any intermediate time. For example, consider a call option \(Y_t = (S_t - K)^+\) for \(t = 0, \dots, T\).</p> <p>Formally, we have the <strong>stopping time</strong> property represented as \(\mathcal T: \Omega \to \{0, 1, \dots, T\}\) such that \(\{\mathcal T \leq t\} = \{w \in \Omega: \mathcal T(W) \leq t\} \in \mathcal F_t, \forall t = 0, 1, \dots, T\). This is equivalent to saying, \(\{T = t\} \in \mathcal F_t, \forall t\).</p> <p>For example, consider \(Z_0, Z_1, \dots, Z_T\), we have \(\mathcal T:= \min \{t: Z_T \in B\} \wedge T\) where \(A \wedge b = \min(a, b)\). Then, \(\{\mathcal T = t\} = \{Z_) \not\in B, Z_1 \not\in B, \dots, Z_{t - 1} \not \in B, Z_t \in B\} \in \mathcal F_t\).</p> <h2 id="optional-stopping-theorem">Optional Stopping Theorem</h2> <p>Consider a stopping time \(\tau\) and a Martingale \((M_t)\), we have \(\mathbb E(M_\tau) = \mathbb E(M_0)\). Essentially, in a fair game, the average payout from exiting the option at an intermediate time is the same as the average payout till time \(t= T\).</p> <p>Here \(M_\tau\) is a random variable of the form \(M_{\tau(w)}(w)\) which we have represented in a singular form.</p> <p>Is the converse true? That is, a sequence of random variables have the optional stopping property where expectations are the same for the beginning and an intermediate time. Then do they constitute a Martingale? Yes, we have</p> \[\begin{align*} M_T &amp;= M_0 + \sum_{t = 1}^T (M_t - M_{t - 1}) \\ M_\tau &amp;= M_0 + \sum_{t = 1}^T (M_t - M_{t - 1}) \mathbb 1_{\{t \leq \tau\}} \end{align*}\] <p>The event \(\{t \leq \tau\}\) is equivalent to \(\{\tau \leq t - 1\}^c\). This allows us to get back the notion of \(\mathcal F_{t - 1}\)</p> \[\begin{align*} \mathbb E(M_\tau) &amp;= \mathbb E(M_0) + \sum_{t = 1}^T \mathbb E[(M_t - M_{t - 1} \mathbb 1_{\{t \leq \tau\}}] \\ &amp;= \mathbb E(M_0) + \sum_{t = 1}^T \mathbb E[\mathbb E[(M_t - M_{t - 1} \mathbb 1_{\{t \leq \tau\}} \vert \mathcal F_{t - 1}]] \\ &amp;= \mathbb E(M_0) + \sum_{t = 1}^T \mathbb E[\mathbb E[(M_t - M_{t - 1} \vert \mathcal F_{t - 1}] \mathbb 1_{\{t \leq \tau\}}] \\ &amp;= \mathbb E(M_0) \end{align*}\] <p>Let us consider an example of an American Put option to understand this better -</p> \[Y_t = (K - S_t)^+\] <p>where \(T = 1, u = 2, d = 0.5, r = 0.2, S_0 = 100, K = 150\). The value for \(p^*\) is \(7/15\). Then, we have the following tree evolution for \(S_t\)</p> \[\begin{align*} &amp;100 \\ 50 &amp;\quad 100 \\ 25 \quad 100 &amp;\quad 100 \quad 400 \end{align*}\] <p>The payment \(Y_t\) looks like</p> \[\begin{align*} &amp;50 \\ 100^{1} &amp;\quad 0 \\ 125 \quad 50 &amp;\quad 50 \quad 0 \end{align*}\] <p>How do we calculate a fair price in this case? We introduce the notion of a <strong>super-martingale</strong>. In comparison, in European call options, we get for \(V_t\)</p> \[\begin{align*} &amp;41.98 \\ 75^{1} &amp;\quad 22.\bar 2 \\ 125 \quad 50 &amp;\quad 50 \quad 0 \end{align*}\] <p>From the seller’s perspective, we have \(U_t\), and we use something called as a <strong>necessary wealth</strong> process - calculating the amount of money the seller requires at every node to pay the option holder. To do so, we need to consider the maximum of all possible payouts at every node. In the node labeled \(1\) above, if the buyer exits the option at \(t = 1\), then the seller needs a payout of \(100\). However, if the buyer exits at time \(t = 2\), the seller requires atleast \(75\) at \(t = 1\) (They can invest the \(75\) in the same stock using short sell to get the required payouts). Considering these scenarios, the seller requires \(100\) at the \(1\) node. Doing such a process for every node, we get \(U_t\)</p> \[\begin{align*} &amp;53.09 \\ 100 &amp;\quad 22.\bar 2 \\ 125 \quad 50 &amp;\quad 50 \quad 0 \end{align*}\] <p>We can see that the price of this option is slightly higher than European since the buyer has the choice of exiting the contract at any intermediate time.</p> <p>To formally describe the process we did above, we consider the following <em>recursion</em></p> \[\begin{align*} U_{t - 1} &amp;= \max \left(\frac{1}{1 + r} \mathbb E^*(U_t \vert \mathcal F_{t - 1}), Y_{t - 1}\right) \quad t = T, T - 1, \dots, 1 \\ U^*_{t - 1} &amp;= \max\left(\mathbb E^*(U^*_t \vert \mathcal F_{t - 1}), Y^*_{t - 1}\right) \\ &amp;\geq \mathbb E^*(U^*_t \vert \mathcal F_{t - 1}) \end{align*}\] <p>The variables \(U^*_{t} = U_t (1 + r)\) are called as <strong>super-martingales</strong>.</p> <p>Let us now delve deeper into the <em>necessary wealth</em> argument.</p> <h2 id="necessary-wealth">Necessary Wealth</h2> <p>We have \(Y = \{Y_0, \dots, Y_T\}\) representing the random variable for the payouts at each time \(t\). We formulated that</p> \[\begin{align*} U_T := Y_T \\ U_{t - 1} := \max\left(\frac{1}{1 + r} \mathbb E^*(U_t \vert \mathcal F_{t - 1}), Y_{t - 1}\right) \end{align*}\] <p>for \(t = T, T - 1, \dots, 1\). For each \(U_{t - 1}\),</p> \[\begin{align*} U_{t - 1} &amp;\geq \frac{1}{1 + r} \mathbb E^*(U_T \vert \mathcal F_{t - 1}) \\ U^*_{t - 1} &amp; \geq \mathbb E^*(U_t^* \vert \mathcal F_{t - 1}) \end{align*}\] <p>\(\{U_T^*: t = 0, 1, \dots, T\}\) form a \(p^*\)-supermartingale. Also note that, \(U^*_t \geq Y^*_t\) for \(t = 0, 1, \dots, T\). It is called as a <strong>Snell Envelope</strong> of \(\{Y_t\}\).</p> <p>Consider the probability space \((\Omega, \mathcal F, P)\) with the event spaces \((\mathcal F_t)_{t = 0}^T\). Then, we have the following claim -</p> <p><strong>Claim.</strong> There does not exist a supermartingale \((Z_t)\) such that</p> <ol> <li> <p>\(Z_t \geq Y_t\), for all \(t\)</p> </li> <li> \[Z_t = \max_{t \leq \tau \leq T} \mathbb E(Y_\tau \vert \mathcal F_t)\] </li> <li> <p>The maximum in the above equation is attained at \(\tau^*(t) = \min(s \geq t: Z_s = Y_S) \wedge T\)</p> </li> <li>The random variables \(Z_{T \wedge \tau^*(0)}\) for \(t = 0, 1, \dots, T\) is a martingale.</li> </ol> <p><strong><em>Proof.</em></strong> Define \(Z_t := \max_{t \leq \tau \leq T } \mathbb E(Y_T \vert \mathcal F_t)\). We can compute \(Z_t\) since it is a finite optimization problem. Since \(\{Y_t\}\) form a martingale, we get</p> \[Z_t \geq \mathbb[Y_T \vert \mathcal F_t] = Y_t\] <p>We use this result to show that \(Z_t\) form a supermartingale. Consider the stopping time \(\sigma\) between \(t\) and \(T\). Then, for attaining maximum</p> \[\begin{align*} Z_t &amp;= \mathbb E[Y_\sigma \vert F_t ]\\ \mathbb E[Z_t \vert \mathcal F_{t - 1}] &amp;= \mathbb E[\mathbb E[Y_\sigma \vert \mathcal F_t ] \vert \mathcal F_{t - 1}] \\ &amp;= \mathbb E[Y_\sigma \vert \mathcal F_{t - 1}] \leq Z_{t - 1} \end{align*}\] <p>How do we now show that this is minimal? \(Z_t\) being minimal implies that if \(Z_t\) is a supermarginale majorant of \(\{Y_t\}\), then \(X_t \geq Z_t\) for all \(t\).</p> \[\begin{align*} X_t(w) \geq Y_t(w) \forall t, \forall w \\ \implies X_{\tau(w)} (w) \geq Y_{\tau(w)}(w) , \forall w\end{align*}\] <p>Then, equivalently, \(X_\tau \geq Y_\tau\) for \(t \leq \tau \leq T\).</p> \[\begin{align*} X_t &amp;\geq \mathbb E(X_t \vert \mathcal F_t) \geq \mathbb E[Y_T \vert \mathcal F_t] \\ &amp;\geq \mathbb E[Y_T \vert \mathcal F_t], \forall t \end{align*}\] <p>Resulting in \(X_t \geq Z_t\). So far, we have shown (1) and (2) in the claim. Also, in the above proof, we use the following property. Let \(X_t\) be a supermartingale ifor \(t \leq \tau \leq T\). Then \(\mathbb E(X_\tau \vert \mathcal F_t) \leq X_t\). The proof is left as an exercise.</p> <p>How do we show (3) and (4) in the claim. For (4), we simply need to check the martingale property</p> \[\begin{align*} \mathbb E[Z_{(t + 1) \wedge \bar \tau} - Z_{t \wedge \bar \tau} \vert \mathcal F_t] &amp;\stackrel{?}{=} 0 \\ &amp;= \mathbb E[\mathbb 1_{t &lt; \bar \tau}(Z_{(t + 1) \wedge \bar \tau} - Z_{t \wedge \bar \tau} \vert \mathcal F_t] \\ &amp;= \mathbb E[\mathbb 1_{t &lt; \tau} (Z_{t + 1} = Z_t) \vert \mathcal F_t] \\ &amp;= \mathbb 1_{t &lt; \bar \tau} \left(\mathbb E(Z_{t + 1} \vert F_t) - Z_t\right) \\ \end{align*}\] <p>where \(\bar \tau(w) = \tau^*(0) (w)\). Now, rewriting the definition of \(Z_t\), we get</p> \[Z_t = \max \left(\mathbb E(Z_{T + 1} \vert \mathcal F_t, Y_t\right)\] <p>meaning for \(t &lt; \bar \tau \implies Z_t &gt; Y_t\) (from definition of \(\bar \tau\) in (3)) implying \(Z_t = \mathbb E(Z_{t + 1} \vert \mathcal F_t)\). This proves the required property.</p> <p>The last argument is to show that, given a supermartingale \(\tilde Z\) with \(\tilde Z_t \geq Y_t\) for all \(t\), then \(\tilde Z_t = Z_t\) for all \(t\). This proves uniqueness.</p> <p>We have</p> \[\begin{align*} \tilde Z_{t - 1} &amp;= \max(Y_{t - 1}, \mathbb E(\tilde Z \vert \mathcal F_{t - 1})) \\ &amp;\leq \max(Y_{t - 1}, \mathbb E(Z_t \vert \mathcal F_{t -1})) \\ &amp;\leq \max(Y_{t - 1}, Z_{t - 1}) = Z_{t - 1} \end{align*}\] <p>We have already shown that \((Z_t)_{t - 0}^T\) is the least supermartingale majorant of \((Y_t)_{t = 0}^T\). This proves uniqueness.</p> <h2 id="pricing-an-american-call">Pricing an American Call</h2> <p>Can we find a \(\phi^*\) such that \(V_t(\phi^*) \geq U_t\). We had derived the following before</p> \[\begin{align*} \tilde \alpha_t = \frac{U^u_t - U^d_t}{u - d} \frac{1}{S_{t - 1}} \\ \tilde \beta_t = \frac{uU^d_t - dU^u_t}{u - d} \frac{1}{B_{t - 1}} \end{align*}\] <p>An important to thing to note here is that these values are random variables and are measurable under \(\mathcal F_{t - 1}\). However, this strategy will not be self-financed due to the super-martingale property. The value of the portfolio is</p> \[\tilde \alpha_t S_t + \tilde \beta_t B_t \equiv U_t\] <p>Then we have,</p> \[\begin{align*} U_{t - 1} &amp;= Y_{t - 1} \vee \left(\frac{1}{1 + r} \mathbb E^*(U_t \vert \mathcal F_{t - 1})\right)\\ \tilde \delta_t &amp;:= U_{t - 1} - \frac{1}{1 + r} \mathbb E^*(U_t \vert \mathcal F_{T - 1}) \geq 0 \\ &amp;\because \tilde \delta_t \geq 0 \Leftrightarrow Y_{t - 1} &gt; \frac{1}{1 + r} \mathbb E^*(U_T \vert \mathcal F_{t - 1}) \end{align*}\] <p>Now, consider the following strategy</p> \[\begin{align*} \alpha^*_t &amp;= \tilde \alpha_t \\ \beta_t^* &amp;= \tilde \beta_t + \sum_{s = 1}^t \tilde \delta_s/B_{s - 1} \geq \tilde \beta_t \end{align*}\] <p>This trading strategy \(\phi^* = \{(\alpha^*, \beta^*): t = 1, \dots, T\}\) is a <strong>super-hedging strategy</strong> with \(V_t(\phi^*) \geq U_t\). We introduced \(\tilde \delta_t\) to make it a self-financing strategy.</p> <p>Define \(\bar \tau = \bar \tau(0) = \min(T: U_t = Y_T) \wedge T\). Then, \(U_{t - 1} &gt; Y_{t - 1}\) and \(\tilde \delta_t = 0\) for \(t = 1, \dots, \bar \tau(w)\). Consequently, \(V_{t \wedge \tau}(\phi^*) = U_{t \wedge \tau}\), and \(U^*_{t \wedge \tau} = \frac{U_{t \wedge \tau}}{(1 + r)^{t \wedge \tau}}\) forming a martingale.</p> <h2 id="arbitrage-1">Arbitrage</h2> <p>For a trading strategy \(\psi\), we have \(V_0(\psi) = 0\) and \(V_T(\psi) \geq 0\). Alternately, \(P(V_T(\psi) &gt; 0) &gt; 0\). In an American option, there is an asymmetry between the buyers and the sellers. The buyer has to choose only one time \(t \leq T\) to exit the option whereas the seller has to safeguard against an arbitrage in all possibilities.</p> <p>The <strong>seller’s arbitrage</strong> for a strategy \(\phi^s\) (in stocks and bonds) is then defined as</p> \[\begin{align*} V_0(\phi^s) &amp;= C_0 \\ \forall \tau V_\tau(\phi^s) &amp;\geq Y_\tau \\ &amp;&gt; \quad \quad \text{sometimes} \end{align*}\] <p>The seller sells an option for \(C_0\) and makes an investment of \(C_0\) in \(\phi_s\). Then an arbitrage for the seller is</p> \[V_T = (V_\tau(\phi^s) - Y_\tau)(1 + r)^{T - \tau}\] <p>where \(\tau\) is the time when the buyer exits the option. This value is always greater than or equal to \(0\) with a non-zero probability that it is strictly greater than \(0\).</p> <p>On the other hand, the <strong>buyer’s arbitrage</strong> for a strategy \(\phi_b\) is defined as</p> \[\begin{align*} V_0(\phi^b) &amp;= -C_0 \\ \exists \tau V_\tau(\phi^b) + Y_\tau &amp;\geq 0 \\ &amp;&gt; \quad \quad \text{sometimes} \end{align*}\] <p>The arbitrage at time \(T\) is \((V_\tau(\phi^b) + Y_\tau)(1 + r)^{T - \tau}\).</p> <p>What would be the good time to exercise the option? In the following sections, we’ll see that \(\tau = \bar \tau\) is the optimal time to exit the option.</p> <h3 id="example">Example</h3> <p>Consider a put option \(Y_T = (K - S_t)^+\) where \(K = 150, S_0 = 100, u = 2, d = 0.5, r = 0.2, T = 2\). We get \(U_0 = 53.09\) and \(Y_0 = 50\). Then, the super-hedging strategy is given by</p> \[\begin{align*} \end{align*}\] <p>To summarise, for a payout random variable \(Y = \{Y_0, \dots, Y_T\}\), we have \(U_t\) as the necessary wealth at each time \(t\). Then, the super-hedging strategy \(\phi^*\) has the following properties -</p> <ul> <li> <p>\(V^*_t(\phi^*)\) is a martingale</p> </li> <li> <p>\(V^*(\phi^*) \geq U^*_t \geq Y^*_t\) for all \(t\)</p> </li> </ul> <p>We define \(\bar \tau\) such that \(\bar \tau = \min\{t \vert U_t = Y_t) \wedge T\). With this definition, we have</p> \[V_t^*(\phi^*) = U_t^*\] <p>for \(t = 0, 1, \dots, \bar \tau\) and \(V_0(\phi^*) = U_0\).</p> <p><strong>Theorem.</strong> \(U_0\) is the no-arbitrage price for American call option based on \(Y\).</p> <p><em>Proof.</em></p> <ol> <li> <p>\(C_0 &gt; U_0\), then there’s arbitrage for the seller. The seller sells the claim for \(C_0\) and buys \(\phi^*\) for \(U_0\). The remaining amount, \(C_0 - U_0\) is invested in bonds. Then, for this strategy \(\phi^s\), we have</p> \[\begin{align*} V_t(\phi^s) &amp;= V_t(\phi^*)+ (C_0 - U_))B_t \\ V_\tau(\phi^s &amp;= V_\tau(\phi^*) + \underbrace{(C_0 - U_0)B_\tau}_{&gt;0} \\ &amp;\geq U_\tau + \dots \\ &amp;\geq Y_\tau + \dots \end{align*}\] </li> <li> <p>\(C_0 &lt; U_0\), we have a buyer’s arbitrage for the strategy \(\phi^b\)</p> \[\phi^b = \begin{cases} -U_0 &amp; \text{in } -\phi^* \\ U_0 - C_0 &amp; \text{in bond} \end{cases}\] <p>Then,</p> \[\begin{align*} V_0(\phi^b) &amp;= -C_0 \\ V_\tau(\phi^b) &amp;= - V_\tau(\phi^*) + (U_0 - C_0)B_\tau \end{align*}\] <p>Using \(\tau = \bar \tau\),</p> \[\begin{align*} V_{\bar \tau}(\phi^b) + Y_{\bar \tau} &amp;= -V_{\bar \tau}(\phi^*) + (U_0 - C_0)B_{\bar \tau} + Y_{\bar \tau} \\ &amp;= (U_0 - C_0) B_{\bar \tau} &gt; 0 \end{align*}\] </li> <li> <p>\(C_0 = U_0\). We need to show separately that there’s no seller’s and buyer’s arbitrage</p> <ol> <li> <p>No seller’s arbitrage - Suppose \(\phi^s\) is a seller’s arbitrage strategy. We have</p> \[V_0(\phi^s) = C_0, V_\tau(\phi^s) \geq Y_\tau\] <p>Note that all elements need not be strictly greater for an arbitrage. Computing the expectation,</p> \[\mathbb E^*(Y^*_\tau) &lt; \mathbb E^*(V^*_\tau(\phi^s)) = V_0(\phi^s) = U_0 = C_0\] <p>for all stopping times \(\tau\). However,</p> <blockquote> <p>why strictly less than in the above equation?</p> </blockquote> \[\mathbb E^*(Y^*_\tau) = \mathbb E^*(V_\tau^*(\phi^s)) = V_0(\phi^s) = C_0\] <p>This shows that no seller’s arbitrage is possible.</p> </li> <li> <p>No buyer’s arbitrage - Suppose \(\phi^b\) is such that</p> \[\begin{align*} V_0(\phi^b) &amp;= -C_0 \\ \exists \tau_0 V_{\tau_0} (\phi^b) + Y_{\tau_0} &amp;\geq 0 \quad (&gt; 0 \text{ sometimes}) \end{align*}\] <p>Then, computing the expectation</p> \[\begin{align*} \mathbb E^*(V^*_\tau(\phi^b)) &amp;= V_0(\phi^b) = -C_0 \\ \mathbb E^*(V_\tau^*(\phi^b) + Y_\tau^*) &amp;= -C_0 + \mathbb E^*(Y^*_\tau) \\ &amp;\leq -C_0 + \mathbb E^*(U^*_\tau) \\ &amp; \leq -C_0 + U_0 = 0 \end{align*}\] <p>This shows that no buyer’s arbitrage is possible. \(\square\)</p> </li> </ol> </li> </ol> <h3 id="example-1">Example</h3> <p>Consider anMerican Call \(S_0 = 4, r = 0.25, u = 2, d = 0.5, K = 4, T = 3\). This yields \(p^* = 0.5\). We have the following</p> \[S_t \implies \begin{align*} &amp;4 \\ 2 &amp;\quad 8 \\ 1 \quad &amp;4 \quad 16 \\ 0.5 \quad 2 &amp;\quad 8 \quad 32 \end{align*}\] \[Y_t \implies \begin{align*} &amp;0 \\ 0 &amp;\quad 4 \\ 0 \quad &amp;0 \quad 12 \\ 0 \quad 0 &amp;\quad 0 \quad 28 \end{align*}\] \[U_t = V_t \implies \begin{align*} &amp;\frac{64}{5} \\ \frac{16}{25} &amp;\quad \frac{144}{25} \\ 0 \quad &amp;\frac{8}{5} \quad \frac{64}{5} \\ 0 \quad 0 &amp;\quad 4 \quad 28 \end{align*}\] <h2 id="american-call-put-parity">American Call-Put Parity</h2> <p>The relation between call and put options in general can be shown using <strong>Jensen’s inequality</strong>. We have</p> \[\begin{align*} \mathbb E(\phi(X)) &amp;\geq \phi(\mathbb E(X)) \\ \mathbb E(\phi(X \vert \mathcal G)) &amp;\geq \phi(\mathbb E(X | \mathcal G)) \end{align*}\] <p>The payout functions for both call and put options are convex. We aim to show that \(U_t = V_t\) for \(t = T, T - 1, \dots, 1, 0\), using induction. The statement is true for \(t = T\).</p> <p>ASsume \(U_s = V_s\) for \(s = t, t + 1, \dots, T\), then</p> \[\begin{align*} U_{t - 1} &amp;= \max \left(Y_{t - 1} , \frac{1}{1 + r} \mathbb E^*(U_t \vert \mathcal F_{T - 1})\right)\\ &amp;= \max \left(Y_{t - 1} , \frac{1}{1 + r} \mathbb E^*(V_t \vert \mathcal F_{T - 1})\right)\\ \end{align*}\] <p>Substituting \(V_t = \frac{1}{(1 + r)^{T - \tau}} \mathbb E^*(V_t \vert \mathcal F_t)\),</p> \[\begin{align*} \mathbb E^*(V_t \vert \mathcal F_{t - 1}) &amp;= \frac{1}{(1 + r)^{T - t}} \mathbb E^*(V_T \vert \mathcal F_{t - 1}) \\ &amp;= \frac{1}{(1 + r)^{T - t}} \mathbb E^*((S_T - K)^+ \vert \mathcal F_{T - 1}) \\ &amp;\geq \frac{1}{(1 + r)^{T - t}} \left(\mathbb E^*(S_T \vert \mathcal F_{t - 1}) - K\right)^+ &amp; \because \text{Jensen's inequality}\\ &amp;= \frac{1}{(1 + r)^{T - t}} ((1 + r)^{T - t + 1}S_{t - 1} - K)^+ \\ &amp;= (1 + r)\left( S_{t - 1} - \frac{K}{(1 + r)^{T - t + 1}}\right)^+ \\ &amp;\geq (1 + r) (S_{t - 1} - K)^+ \\ &amp;= (1 + r) Y_{t - 1} \end{align*}\] <p>Using this result above, we have</p> \[\begin{align*} U_{t - 1} &amp;= \max \left(Y_{t - 1} , \frac{1}{1 + r} \mathbb E^*(V_t \vert \mathcal F_{T - 1})\right)\\ &amp;= \frac{1}{1 + r} \mathbb E^*(V_t \vert \mathcal F_{T - 1}) = V_{t - 1} \end{align*}\] <h1 id="finite-market-models">Finite Market Models</h1> <p>The binomial model we have discussed previously is an example of a finite market model. These structures can be generalised to markets with multiple stocks, bonds and contingent claims in a fixed time period \(T\). We shall derive results for pricing similarly like before for this general market. To do the analysis, the notation for probability space, portfolio, value, trading strategies and arbitrage has to be defined -</p> <h4 id="probability-space">Probability Space</h4> <p>Again, we consider a finite probability space \((\Omega, \mathcal F, P)\), that is \(\#(\Omega)&lt; \infty)\) with \(\mathcal F = \mathcal P(\Omega)\) (the power set) and \(P(A) = \sum_{w \in A} P(w), A \in \mathcal F\).</p> <p>We shall assume that every event has a non-zero probability. If there are events with zero-probability, they are not relevant to our discussion and we can simply prune these points.</p> <p>A <strong>filtration</strong> \(\mathcal F_0 \subset \mathcal F_1 \subset \cdots \subset \mathcal F_T\) represents the history of the market or the evolution of prices of assets in the market. Typically, \(\mathcal F_T = \mathcal F\).</p> <h4 id="assets-in-portfolio">Assets in portfolio</h4> <p>Now in this setup, we consider the assets - asset 0 bond and assets \(1, 2, \dots, d\) stocks. At any time \(t\), the prices are given by</p> \[S_t = (S^0_t, S^1_t, \dots, S^d_T), t = 0, 1, \dots, T\] <p>Where \(S^0_t\) is the bond-price and not random and \(S_t^U\) for \(i &gt; 0\) represent the stock prices.</p> <p>Each sequence \(\{S_t^i\}_{t = 0}^T\) is \(\mathcal F_t measurable\), that is \((S_t)\) is adapted to the filtration.</p> <h4 id="trading-strategy">Trading strategy</h4> <p>After defining the prices and the structure of the portfolio, we define a <em>trading strategy</em> for this market -</p> \[\phi = \{\phi_t: t = 1, \dots, T\}\] <p>where \(\phi_t = (\phi_t^0, \phi_t^1, \dots \phi_t^d)\) is a vector of holdings representing the assets held at time \(t\). That is, \(\phi_t^I\) is the number of shares of asset \(i\) to be held on day \(t\).</p> <p>The basic assumptions with our trading strategies are</p> <ul> <li>The trading strategy is predictable - \(\phi_t^i \in \mathcal F_{t - 1}\) for all \(i\) and \(t = 1, 2, \dots, T\).</li> <li>Self-financing - \(\phi_t \cdot S_t = \phi_{t + 1} \cdot S_t\) (note that these are vector dot products \(\phi_t \cdot S_t = \sum_{i = 1}^d \phi_t^i S_t^i\)).</li> </ul> <h4 id="value-of-the-portfolio">Value of the portfolio</h4> <p>The value of the portfolio at time \(t = 0\) is given by \(V_0(\phi) = \phi_1 \cdot S_0\) and for time \(t &gt; 0\), we have \(V_t(\phi) = \phi_t \cdot S_t\). For this market, the change in the value of portfolio across a day is given by \(\Delta V_t(\phi)\)</p> \[\begin{align*} \Delta V_t(\phi) &amp;:= V_t(\phi) - V_{t - 1}(\phi) \\ &amp;= \phi_t \cdot S_t - \phi_{t - 1}\cdot S_{t - 1} \\ &amp;= \phi_t \cdot (S_t - S_{t - 1}) \\ &amp;= \phi_t \cdot \Delta S_t \end{align*}\] <p>So the value at any time \(t\) can now be defined as</p> \[\begin{align*} V_t(\phi) &amp;= V_0(\phi) + \sum_{u = 1}^t \sum_{i = 0}^d \phi_u^i \Delta S_u^i \quad \quad\because \quad \text{Telescoping sum} \\ &amp;=V_0(\phi) + \sum_{u = 1}^t \phi_u \cdot \Delta S_u \end{align*}\] <p>for \(t = 0, 1, \dots, T\)</p> <p>To help us derive results in the later sections, we define the following notation for <strong>discounted stock prices</strong> -</p> \[\begin{align*} S_t^* &amp;= S_t /S^0_t \\ &amp;= (1, S_t^{1*}, \dots, S_t^{d*}) \end{align*}\] <p>It essentially divides the stock prices with the bond price at time \(t\). Similarly we can define discounted value of a portfolio.</p> <p>We can derive that the telescopic sum property still holds with the discounted values for the portfolio. That is,</p> \[V_T^*(\phi) = V_0^*(\phi) + \sum_{u = 1}^t \phi_u \cdot \Delta S_u^*\] <p>where \(\Delta S_u^* = S_u^* - S_{u - 1}^*\). This property will be useful for extracting Martingales from the price evolution tree. Specifically, we have the following lemma</p> <p><strong>Lemma 1</strong> If \((M_t: t = 0, 1, \dots, T)\) is a martingale and \((H_1,H_2, \dots, H_T)\) is a predictable sequence of random variables then</p> \[X_t := \sum_{u = 1}^T H_u \Delta M_u\] <p>is a martingale!</p> <h4 id="arbitrage-2">Arbitrage</h4> <p>The expressions are very similar to before wherein an arbitrage opportunity (risk-free profit) is a trading strategy \(\phi\) such that</p> \[\begin{align*} V_0(\phi) &amp;= 0 \\ V_T(\phi) &amp;\geq 0 \\ P(V_T(\phi) &gt; 0) &amp;&gt; 0 \end{align*}\] <p>The last condition essentially ensures that there is atleast one case where the profit is non-zero. Previously, we had used expectation to ensure this using the \(p^*\) model derived using the binomial model. However, we want a general scenario here and an expectation requires an associated probability distribution.</p> <p>The market is set to be <strong>viable</strong> if there are no arbitrage opportunities. We can show that the binomial model considered previously is viable if \(d &lt; 1 + r &lt; u\). So, when is a market non-viable? Consider \(\Omega = \{w_1, w_2\}, T = 1, d = 2\) with the stock price evolution \(S_0^0 = S_1^0 = 1\), \(S_0^1 = S_0^2 = 1\), and</p> <table> <thead> <tr> <th> </th> <th>( w_1 )</th> <th>( w_2 )</th> </tr> </thead> <tbody> <tr> <td>( S_1 )</td> <td>1</td> <td>2</td> </tr> <tr> <td>( S_2 )</td> <td>1</td> <td>3</td> </tr> </tbody> </table> <p>The trading strategy \(\phi = \{(0, -1, 1)\}\) has \(V_1(\phi) \geq 0\) in all entries and \(&gt;0\) in at least one entry.</p> <p>Notice the subtleties in this example. Previously, in the CRR model, we focused on finding an arbitrage-free pricing. We ensured there is no arbitrage in the market with this design. However, considering a trading strategy with only stocks in a bullish market, there is always an opportunity for arbitrage.</p> <p>For trading strategies with only stocks, the problem of finding a trading strategy boils down to solving some linear inequalities.</p> <h2 id="martingale-measure">Martingale Measure</h2> <p>As noted earlier, we will assume that \(P(w) &gt; 0\) or each \(w \in \Omega\). For a new measure \((\Omega, \mathcal F, Q)\), we say that \(Q\) is equivalent to \(P\) (\(Q \sim P\)) if for all \(A \in \mathcal F\)</p> \[Q(A) &gt; 0 \iff P(A) &gt; 0\] <p>With this infrastructure, we are aiming to find a new probability \(Q\) (like \(p^*\) in CRR model) to prove properties in a market.</p> <p><strong>Definition.</strong> A probability \(Q\) on \((\Omega, \mathcal F)\) is a <strong>martingale measure</strong> provided \(\{S_T^{i*}: t = 0, 1, \dots, T\}\) is a \(Q-martingale\) for each stock \(I = 1, \dots, d\).</p> <p>An <strong>equivalent martingale measure</strong> is a probability \(Q\) such that \(Q \sim P\) and \(Q\) is a martingale measure. With these tools, we now define the first fundamental theorem of asset pricing.</p> <h2 id="first-fundamental-theorem-of-asset-pricing">First Fundamental Theorem of Asset Pricing</h2> <p>A market is viable if and only if there exists at least one Equivalent Martingale Measure (EMM).</p> <p>To understand this better, consider the previous example of a market that is not viable. Suppose we have a martingale measure \(Q\), then</p> \[\mathbb E^Q(S_i^1) = S_0^i\] <p>for \(I = 1, 2\) using the martingale property. Letting \(a = Q(w_1), b = Q(w_2)\), we get the linear equations</p> \[\left. \begin{align*} a + 2b &amp;= 1\\ a + 3b &amp;= 1 \end{align*} \right\} b = 0\] <p>Since, $P(w_2) &gt; 0 \not\imply Q(w_2) &gt; 0$$, there cannot exist an Equivalent Martingale Measure in this market.</p> <h4 id="proof">Proof</h4> <p>(\(\Longleftarrow\)) Let \(Q\) be an EMM and \(\phi\) is a strategy making an arbitrage. That is, \(V_0(\phi) = 0, V_T(\phi) \geq 0\)</p> <p>Since \(\{S_t\}_{t = 1}^T\) is a martingale under \(Q\), the sequence \(\sum_{i = 1}^t \phi_u^I \cdot \Delta S_u^{i*}\) for \(t = 0, 1, \dots, T\) is a \(Q\)-martingale.</p> \[\begin{align*} V^*_T(\phi) &amp;:= V_T(\phi)/S_T^0 \\ &amp;= V_0^* + \sum_{u = 1}^T \phi_u \cdot \Delta S_u^* \\ &amp;= 0 + \sum_{u - 1}^T \sum_{i = 1}^d \phi_u^I \cdot \Delta S_u^{i*} \end{align*}\] <p>\(V_t^*\) is also a martingale under \(Q\), implying \(\mathbb E^Q(V_T^*(\phi)) = \mathbb E^Q(V_0^*(\phi)) = 0\). Since \(P \sim Q\), \(P(V_T(\phi) &gt; 0) = 0\).</p> <p>\((\implies)\) Now, we show the opposite direction, that is for a viable market, there exists an EMM.</p> <p>We have \(\#(\Omega) &lt; \infty\), where \(\Omega = \{w_1, w_2, \dots, w_n\}\). Consider a random variable \(X: \Omega \to \mathbb R\), then we have \((X(w_1), X(w_2), \dots, X(w_n) \in \mathbb R^n)\) and a distribution \(Q\) with probabilities \((Q(w_1), \dots, Q(w_n))\). Then, we have</p> \[\mathbb E^Q(V^*_T(\phi)) = \sum_{k = 1}^n Q(w_k) V^*_T(\phi) (w_k) = Q \cdot V^*_T(\phi)\] <p>It suffices to show that there exists a \(Q\) such that \(Q \perp \{V_T^*(\phi): \phi \text{ is a trading strategy with } V_0(\phi) = 0\} \subset \mathbb R^n\}\).</p> <p>We have seen before that as a result of a telscopric sum formulation, \(V^*_T(\phi) = V_0^*(\phi) + \sum_{u = 1}^T \phi_u \cdot \Delta S_u^*\).</p> <p><strong>Lemma 2</strong></p> <p>Suppose a \(M = (M_1, \dots, M_n)\) is an adapted sequence such that</p> \[\mathbb E\left(\sum_{u = 1}^T q_u \cdot \Delta M_u\right) = 0; \quad \Delta M_k = M_k = M_{k - 1}\] <p>for all predictable \((q_1, \dots, q_T)\), then \(M\) is a martingale.</p> <p><em>Proof.</em> To show, \(\mathbb E(M_t \vert \mathcal F_{t - 1}) = M_{t - 1}\) for \(t = 1, 2, \dots, T\). Equivalently, \(\mathbb E(M_t \cdot \mathbb 1_A) = \mathbb E(M_{t - 1} \cdot \mathbb 1_A)\) for all \(A \in \mathcal F_{t - 1}\).</p> <p>If \(X, Y\) are both \(\mathcal G\)-measurable and \(\mathbb E(X \cdot \mathbb 1_A) = \mathbb E(Y \cdot \mathbb 1_A)\) for all \(A \in \mathcal G\), then \(P(X = Y) = 1\) (Consider \(\{X &lt; Y\} = A\)).</p> <p>In our context \(X = \mathbb E(M_t \vert \mathcal F_{t - 1})\) and \(Y = M_{t - 1}\), leading to \(\mathbb (\Delta M_t \cdot \mathbb 1_A) = 0\). Fixing \(t\) and \(A \in \mathcal F_{t - 1}\), let</p> \[q_u = \begin{cases} \mathbb 1_A &amp; u = t \\ 0 &amp; u \neq t \end{cases}\] <p>Consequently,</p> \[\begin{align*} \sum_{u = 1}^T q_u \cdot \Delta M_u = \mathbb 1_A \cdot (M_t - M_{t - 1}) \end{align*}\] <p><strong>Lemma 3</strong> If we have, \(q_t^i \in \mathcal F_{t - 1}\) for \(i = 1, \dots, d\) amd \(t = 1, \dots, T\), then for any \(c \in \mathbb R\), there exists \(\phi^0_t\) for \(t = 1, \dots, T\) such that</p> \[\phi = \{(\phi_t^0, \phi_t^1, \dots, \phi_t^d): t = 1, \dots, T\}\] <p>is a <strong>self-financing</strong> trading strategy and \(V_0(\phi) = c\).</p> <p><strong>Proposition.</strong> Suppose \(Q \sim P\), such that \(\mathbb E^Q(V_T^*(\phi)) = 0\) for all trading strategies \(\phi\) with \(V_0(\phi) = 0\), then \(Q\) is an EMM. That is, we need to show \(S^{1*}_t\) is a Q-martingale. From lemma 2, it is equivalent to showing \(\mathbb E^Q(\sum_{u = 1}^T q_u \cdot \Delta S_u^{1*}) = 0\) for all \((q_1, \dots, q_T)\). Consider the following strategy</p> \[\phi^i_t = \begin{cases} q_t &amp; i = 1 \\ 0 &amp; i = 2, 3, \dots, d \\ \phi_t^0 \text{ from Lemma 3} \end{cases}\] <p>Then,</p> \[\begin{align*} \sum_{u = 1}^T q_u \Delta M_u &amp;= \mathbb 1_A (M_t - M_{t - 1}) \\ V^*_T(\phi) &amp;= \sum_{i = 0}^d \sum_{u = 1}^T (\phi_u^i \cdot S_u^{i*}) \\ &amp;= \sum_{u = 1}^T q_u \cdot \Delta S_u^{1*} \end{align*}\] <p>Now, for all trading strategies with the self-financing property, the set \(L:= {V_T^*(\phi): \phi \text{ with } V_0(\phi) = 0} \subset \mathbb R^n\) is a linear subspace of \(\mathbb R^n\). Similarly, consider the set \(D := \{Y \in \mathbb R^n : Y \geq 0 \text{ with } Y \neq 0\}\).</p> <p>Our goal boils down to show that a viable market exists if and only if \(L \cap D = \phi\). It is equivalent to show \(L \cap F = \phi\) for \(F:= \{Y \in D: \sum_{i = 1}^n Y_k = 1\}\).</p> <h4 id="assume-viability--">Assume viability -</h4> <p>We have noted that \(L\) is a subspace of \(\mathbb R^n\). Also, \(F\) is compact and convex.</p> <p><strong>Lemma.</strong> <strong><em>Separating Hyperplane Theorem</em></strong> For a vector subspace \(L \subseteq \mathbb R^n\) and a compact convex set \(F\), if \(L \cap F = \phi\), then there exists a \(\zeta \in \mathbb R^n\), \(\zeta \neq 0\) such that</p> \[\begin{align*} L &amp;\subset \{t: t \cdot \zeta = 0\} \\ F &amp;\subset \{y: y \cdot z &gt; 0\} \end{align*}\] <p><em>Proof.</em> Let \(G:= F - L = \{f - l: f \in F, l \in L\}\), then \(G\) is convex and closed and \(0 \not \in G\). We choose the vector \(\zeta \in G\) that minimizes \(\|x\|\), \(x \in G\). Now,</p> \[\beta := \inf \{\|x \|: x \in G \}\] <p>then for any sequence \(x_n \in G\) such that \(\|x_n\|\) converges to \(\beta\) (\(\|x_n\| \searrow \beta\)) , using the parallelogram law</p> \[\begin{align*} \|x_n - x_m\|^2 &amp;= 2(\|x_n\|^2 + \|x_m\|^2) - 4\left\|\frac{x_n + x_m}{2}\right\|^2 \\ \end{align*}\] <table> <tbody> <tr> <td>The terms \(|x_n|^2, |x_m|^2\) converge to \(\beta^2\) and the average $$\left</td> <td>\frac{x_n + x_m}{2}\right</td> <td>^2\(goes to\)\beta^2\(leading to\)|x_n - x_m|^2 \to 0\(for\)m, n \to \infty\(and\)x_n \to \zeta\(. Therefore,\){x_n}\(form a Cauchy sequence convergent to some\)\zeta\(. Since\)G\(is closed, this shows the existence of such\)\zeta \in G$$.</td> </tr> </tbody> </table> <p>Now, for any \(x \in G\), \(x \cdot \zeta \geq \|\zeta\|^2\). How do we show this? Consider any arbitrary vector formed by \(x, \zeta\), \(\|\alpha x + (1 - \alpha)\zeta\|^2 - \|\zeta\|^2 \geq 0\) (a quadratic in \(\alpha\), and \(0 \leq \alpha \leq 1\)). For \(\alpha \to 0\), we get</p> \[-2 \|\zeta^2\| + 2(x\cdot \zeta) \geq 0\] <p>Now, in particular, since \(0 \in L\), if \(f \in G\), then \(f \in F\). Consequently, if \(f \in F\), then for any \(\lambda \in \mathbb R, l \in L\), \(f - \lambda l \in G\). We get</p> \[f\cdot \zeta \geq \lambda (l \cdot \zeta) + \|\zeta\|^2\] <p>With the limits of \(\lambda\), we can conclude that \(l \cdot \zeta = 0\). \(\square\)</p> <p>How does this theorem help us show \(L \cap F = \phi\) for a viable market? Consider the EMM \(Q(w_k) = \frac{\zeta_k}{c} &gt; 0\). \(c = \sum_{i = 1}^n \zeta_i\). For a fixed \(k\), consider</p> \[Y_i = \begin{cases} 1 &amp; i = k \\ 0 &amp; i \neq k \end{cases}\] <p>Then for \(Y \in F\), \(Y \cdot \zeta &gt; 0\). Let \(\phi\) be a trading strategy with \(V_0(\phi) = 0\), then</p> \[\begin{align*} \mathbb E^Q(V_t^*(\phi)) &amp;= Q\cdot V^*_T(\phi) \\ &amp;= \frac{1}{c} \left[\zeta \cdot \underbrace{V_t^*(\phi)}_{\in L}\right] = 0 \end{align*}\] <h3 id="completeness-of-a-market">Completeness of a Market</h3> <p>A merket is complete if for every contingent claim \(X \in \mathcal F_T\), there exists a trading strategy \(\phi\) that can be replicate the claim with \(V_T(\phi) \equiv X\).</p> <h2 id="second-fundamental-theorem-of-asset-pricing">Second Fundamental Theorem of Asset Pricing</h2> <p>Assuming the market is viable, then the market is complete if and only if there is a unique EMM for the market.</p> <p><em>Proof.</em></p> <ol> <li> <p>\((\implies)\) Assume that the market is complete. Let \(P_1^*, P_2^*\) be the distinct EMMs. Then for a \(A \in \mathcal F_T\), define \(X:= \mathbb 1_A\). Due to completeness, \(\exists \phi\) with \(V_T(\phi) = \mathbb 1_A\).</p> \[\begin{align*} P_i^*(A) &amp;= \mathbb E_i^*(\mathbb 1_A) \\ &amp;= \mathbb E_1^*(V_T(\phi)) = \frac{S^0_T}{S^0_0} \cdot V_0(\phi) \end{align*}\] <p>Therefore, \(P_1^*(A) = P_2^*(A)\) for all \(A \in \mathcal F_T\) implying that \(P_1^* = P_2^*\).</p> </li> <li> <p>(\(\Longleftarrow\) ) Assuming that there is a unique EMM, we need to show that the market is complete. We do this by proving the contrapositive - a market is incomplete implies that there is no unique EMM for the market. We define</p> \[L:= \{V_T^*(\phi): \phi \text{ self-financing trading strategies }\}\] <p>Now, we show that the market is incomplete if and only if \(L \subsetneq \mathbb R^n\) and \(\exists z \neq 0\) such that \(z \perp L\). Consider the EMM \(Q\) for a viable market. Then, define \(\tilde Q(w_k) = Q(w_k) + c z_k\) for some \(c &gt; 0\). Then,</p> \[\sum_{k = 1}^n \tilde Q(w_k) = \sum_{k = 1}^n Q(w_k) + c (z \cdot \bf{1}) = 1 + 0\] <p>Is \(\bf{1} \in L\)? Yes, the strategy of investing in one bond yields a discounted value of \(1\) at \(T\).</p> </li> <li></li> </ol> <p>    Now, it is left to show that there exists a \(c\) such that \(\tilde Q(w_k) &gt; 0\). Consider the following formulation</p> \[c:= \frac{1}{2 \max_{1 \leq k \leq n} \left(\frac{\|z_k\|}{Q(w_k)}\right)}\] <p>Then,</p> \[\begin{align*} \frac{1}{2c} &amp;= \max_k \left(\frac{\|z_k\|}{Q(w_k}\right) \\ Q(w_k) &amp;\geq 2c \|z_k\| \\ \tilde Q(w_k) &amp;= Q(w_k) + cz_k \\ &amp;\geq 2c \|z_k\| + cz_k &gt; 0 \end{align*}\] <p>Finally, to show that \(\tilde Q\) is an EMM,</p> \[\begin{align*} \mathbb E^{\tilde Q}(V_T^*(\phi)) &amp;\stackrel{?}{=} 0 \quad \text{ if} V_0(\phi) = 0\\ &amp;= \mathbb E^Q (V_T^*(\phi)) + c z \cdot V_T^*(\phi) \quad \because z \perp L \\ &amp;= 0 \end{align*}\] <p>This proves the second fundamental theorem of asset pricing.</p> <p>Note that if \(Q_1, Q_2\) are two EMMs, then a linear combination of these \(\alpha Q_1(A) + (1 - \alpha) Q_2(A)\) for \(A \in \mathcal F\) and \(0&lt;\alpha&lt;1\) is also an EMM.</p> <h3 id="example-2">Example</h3> <p>For \(T = 1, \Omega = \{w_1, w_2,w_3\}\), let \(S_1^0 = S_0^0 = 1\), \(S_0^1 = 2\) and \(S_1^1 = \begin{pmatrix}1 &amp; 3 &amp; 5\end{pmatrix}^T\). To check if the market is viable, we try and solve for an EMM on this market - Let \(Q = (a, b, c)\), then</p> \[\begin{align*} a + b + c = 1, a &gt; 0,b&gt;0,c&gt;0\\ a + 3b + 5c = 2 \end{align*}\] <p>Solving, we get</p> \[Q^{(c)} = \left(\frac{1}{2} + c, \frac{1}{2} - 2c, c\right)\] <p>for \(0 &lt; c &lt; \frac{1}{4}\). This shows that the market is viable. Also, the market is not viable since there are multiple EMMs possible.</p> <p>For a contingent claim \(X\), we have</p> \[\begin{align*} \mathbb E^{(c)}(X^*) &amp;= \left(\frac{1}{2} + c\right)x_1 + \left(\frac{1}{2} - 2c\right)x_2 + cx_3 \\ &amp;= \frac{x_1 + x_2}{2} + c (x_1 + x_3 - 2x_2) \end{align*}\] <p>That means, when \(x_1 + x_3 - 2x_2\) is \(0\), then the expectation is independent of \(c\) - \(X\) can be replicated in some cases even if the market is incomplete!</p> <p>Let us try an replicate such an \(X\). Consider the bond holdings \(\alpha\) and stock holdings \(\beta\).</p> \[\begin{align*} \alpha S_1^1 + \beta S_1^0 &amp;= X \\ \alpha \begin{pmatrix}1 \\ 3 \\ 5\end{pmatrix} + \beta \begin{pmatrix}1 \\ 1 \\ 1\end{pmatrix} &amp;= \begin{pmatrix}x_1 \\ x_2 \\ x_3\end{pmatrix} \end{align*}\] <p>\(X\) is replicable iff \(X \in \text{span}(\begin{pmatrix}1 &amp; 3 &amp; 5\end{pmatrix}, \begin{pmatrix}1 &amp; 1 &amp; 1\end{pmatrix}) \equiv X \perp \begin{pmatrix}1 &amp; -2 &amp; 1\end{pmatrix}\). This again yields \(x_1 + x_3 - 2x_2\).</p> <p><strong>Theorem.</strong> In a viable and complete market, the number V_0(\phi) is the no-arbitrage price of a European Call Clain X = V_T(\phi).</p> <p><em>Note.</em> We have seen this before in the context of a binomial model, but this theorem is for a general market with discrete possibilities. In our previous proof, we did not use any binomial properties but rather showed the result using martingale properties. The same proof follows for this as well.</p> <p>How do we conclude such results in a general case? Even when the market is incomplete, how do we find contingent claims which can be replicated?</p> <p>Consider the set \(M = \{Q: Q \text{ is an EMM}\} \neq \phi\). Then for any measure in this set,</p> \[\begin{align*} \mathbb E^Q(V_T^*(\phi)) &amp;= V_0^*(\phi) \\ &amp; = \frac{V_0(\phi)}{S_0^0} \end{align*}\] <p>Now, for a contingent claim X, we have</p> \[\begin{align*} V_+(X)&amp;:= \inf \{V_0(\phi):V_T(\phi)\geq X\} \\ &amp;= \min \{V_0(\phi):V_T(\phi)\geq X\} \\ \hline \mathbb E^Q(X^*) &amp;\leq \mathbb E^Q(V_T^*(\phi)) \sout{S_T^0} = V_0(\phi) \frac{\sout{S_T^0}}{S_0^0} \\ &amp;\leq \frac{1}{S_0^0} V_+(X) \end{align*}\] <p>Similarly,</p> \[\begin{align*} V_-(X)&amp;:= \sup \{V_0(\phi):V_T(\phi)\leq X\} \\ &amp;= \max \{V_0(\phi):V_T(\phi)\leq X\} \\ \hline \\ V_-(X) &amp;\leq S_0^0 \mathbb E^Q(X^*) \leq V_+ (X) \end{align*}\] <p>Suppose \(X\) is replicable, then \(X = V_T(\tilde \phi)\) for some \(\tilde \phi\). Then,</p> \[\begin{align*} V_0(\tilde\phi) \geq V_+(X), V_0(\tilde\phi) \leq V_-(X) \\ V_-(X) \leq V_+(X) \end{align*}\] <p>leading to \(V_+(X) = V_-(X)\)!</p> <p>Does the converse hold? In the previous example, say we have a contingent claim \(X = \begin{pmatrix}1 &amp; 9 &amp; 25\end{pmatrix} = (S_1^1)^2\). Now consider a strategy \(\phi = (\alpha, \beta)\), we have</p> \[\begin{align*} V_0(\phi) &amp;= 2\alpha + \beta \\ V_1^1(\phi) &amp;\leq X \quad \text{ for } V_-(X) \\ \alpha \begin{pmatrix} 1 \\ 3 \\5 \end{pmatrix} + \beta \begin{pmatrix} 1 \\ 1 \\ 1\end{pmatrix} &amp;\leq \begin{pmatrix}1 \\9 \\ 25\end{pmatrix} \end{align*}\] <p>Solving these inequalities, we get \(V_-(X) = 5\), and similarly, \(V_+(X) = 7\). Let us check if \(X\) can be replicated</p> \[\mathbb E^{(c)}(X) = 5 + 8c, 0 &lt; c&lt; \frac{1}{4}\] <p>It is not possible for the expectation to be independent of \(c\). Also note that the range of the above expression is exactly \((5, 7)\).</p> <p>We have seen that $V_+(X) \geq V_-(X)$ for a contingent claim $X$.</p> <ul> <li> <p>If $C_0 &gt; V_+(X)$ then there is a seller’s arbitrage. How? There exists a strategy $\phi$ such that $V_T(\phi) \geq X$ and $V_0(\phi) = V_+(X) &lt; C_0$.</p> </li> <li> <p>Similarly. when $C_0 &lt; V_-(X)$ there is a buyer’s arbitrage.</p> </li> </ul> <p><strong>Theorem.</strong> A contingent claim $X$ is replicable <strong>if and only if</strong> $V_+(X) = V_-(X)$</p> <p><em>Proof.</em></p> <ul> <li> <p>($\implies$) We saw that previously</p> </li> <li> <p>($\Longleftarrow$) Assume $V_+(X) = V_-(X)$. Let $\phi^+$ be a trading strategy such that $V_T(\phi^+) \geq X$ and $\phi^-$ is such that $V_T(\phi^-) \geq X$. However, $V_0(\phi^+) = V_+(X) = V_-(X) = V_0(\phi^-)$ and consequently $V_T(\phi^+) - V_T(\phi^-) \geq 0$. Let $Q \in M$ be any martingale measure -</p> \[\begin{align*} \mathbb E^Q(V_T^*(\phi^+) - V_T^*(\phi^-)) &amp;= V_0^*(\phi^+) - V_0^*(\phi^-) \\ &amp;= (V_0(\phi^+) - V_0(\phi^-))/S_0^0 = 0 \end{align*}\] <p>Therefore, $V_T(\phi^+) \equiv V_T^(\phi^-) \equiv X$ implying that $\phi^+$ can be used to replicate $X$.</p> <p>Suppose $X$ is not replicable, then there is $\phi$ such that $V_T(\phi) \leq X$ and $V_0(\phi) = V_+(X)$.</p> <p><strong>Claim.</strong> $P(V_T(\phi) &lt; X) &gt; 0$. If it is equal to $0$, then $V_T(\phi) \equiv X$.</p> <p>So, any market price for $X$ with $C_) \not \in (V_-(X), V_+(X))$ yields an arbitrage.</p> </li> </ul> <p><strong>Theorem.</strong> $X$ is replicable <strong>if and only if</strong> $\mathbb E^Q(X)$ is the same for all $Q \in M$.</p> <p><em>Proof</em>.</p> <ul> <li> <p>$(\implies)$ $X = V_T(\phi)$ then</p> \[\mathbb E^Q(X) = \mathbb E^Q(V_T(\phi)) = V_0(\phi) \frac{S_T^0}{S_0^0}\] </li> <li> <p>$(\Longleftarrow)$ Assume for contradition $X$ is not replicable. As we’ve constructed before, let $L = {V_T(\phi): \phi \text{ is a trading strategy}}$. Since $X$ is not replicable, $X \not \in L$. Let $X = X_0 + Z$ such that $X_0 \in L$ and $Z \neq 0, \perp L$. For any $Q \in M$, we define $\tilde Q(w_k) = Q(w_k) + c Z_k$. Again, we choose a $c$ such that $\tilde Q &gt; 0$ and $\tilde Q \in M$. Then, since $\mathbb E^Q(X)$ is the same for all $Q \in M$, we have</p> \[\begin{align*} \mathbb E^Q(X) &amp;= \mathbb E^{\tilde Q}(X) \\ Q \cdot X &amp;= \tilde Q \cdot X = Q \cdot X + c Z \cdot X \\ &amp;\therefore Z \cdot X = 0 \end{align*}\] <p>implying that $X \in L$ giving a contradiction.</p> </li> </ul> <h3 id="dual-formulae">Dual Formulae</h3> <p>As a result of the above theorem, we can give alternate formulae to $V_+(X)$ and $V_-(X)$ (dual comes from linear programming)</p> \[\begin{align*} V_+(X) &amp;= \sup \{\mathbb E^Q(X): Q \in M\} \\ V_-(X) &amp;= \inf \{\mathbb E^Q(X) : Q \in M\} \end{align*}\] <h1 id="random-walk">Random Walk</h1> <p>In this section, we shall extend our theory beyond finite market models, wherein the price evolution is described using a random walk.</p> <p>Let $X_n = \xi_1 + \dots + \xi_n$ where $\mathbb E(\xi_k) = \mu$ and $\xi$ are iid for $n = 0, 1, 2, \dots$. Let $\mathcal F_n = \sigma(\xi_1, \dots, \xi_n)$ and $\mathcal F_n \perp !!! \perp \xi+{n + k}$ for $k \geq 1$. Then, consider set of random variables $M_n = X_n - n \mu$.</p> <p><strong>Claim.</strong> $M_n$ is a martingale with respect to $\mathcal F_n$.</p> <p><em>Proof.</em></p> \[\begin{align*} \mathbb E[M_{n + 1} \vert \mathcal F_n] &amp;= \mathbb E[X_{n + 1} \vert \mathcal F_n] - (n + 1)\mu\\ &amp;= \mathbb E[X_n + \xi_{n + 1} \vert \mathcal F_n] - (n + 1)\mu\\ &amp;= X_n + \mu - (n + 1)\mu = M_n \end{align*}\] <p>Assuming that $var(\xi_k) = \sigma^2$ is finite, consider $Y_n = M_n^2 - n\sigma^2$.</p> <p><strong>Claim.</strong> $Y_n$ is a martingale with respect to $\mathcal F_n$ when $\mu = 0$</p> <p><em>Proof.</em></p> \[\begin{align*} \mathbb E[Y_{n + 1} \vert \mathcal F_n]&amp;= \mathbb E[M^2_{n + 1} \vert \mathcal F_n] - (n + 1)\sigma^2\\ &amp;= \mathbb E[(M_n + \xi_{n + 1})^2 \vert \mathcal F_n] - (n + 1)\sigma^2\\ &amp;= M_n^2 + M_n \mu + \sigma^2 - (n + 1)\sigma^2 = Y_n \end{align*}\] <h2 id="optional-stopping">Optional Stopping</h2> <p>Let $\tau$ be a random variable representing stopping time. Then, we have</p> \[\mathbb E[M_\tau] = \mathbb E(M_0)\] <p>provided $\tau(w) \leq N$. That is, $M_{n \wedge \tau}$ is a martingale..</p> <h3 id="single-random-walk">Single Random Walk</h3> <p>We have the following setup</p> \[X_n = x + \xi_1 + \dots + \xi_n\] <p>where $\xi_k$ are i.i.d. Let $P(\xi= 1) = p$ and $P(\xi_k = -1) = q = 1 - p$ where $0 &lt; p &lt; 1$. We then have</p> \[\mu = 2p - 1, \sigma^2 = 1 - (2p - 1)^2\] <p>Let $\tau_b := \min(n \geq 0: X_n = b)$ and $\tau = \min(\tau_a, \tau_b)$.</p> <p><strong>Claim.</strong> Suppose $p &gt; \frac{1}{2}$ and $\mu &gt; 0$ then</p> \[\begin{align*} P_x(\tau_b &lt; \infty) = 1 \quad b \geq x \\ P_x(\tau_a &lt; \infty) &lt; 1\quad a &lt; x \end{align*}\] <p><em>Proof.</em> We construct a martingale of the form $M_n = \alpha^{X_n} \beta^n$ for some $\alpha &gt; 0$.</p> <p>For $\alpha &gt; 0$, we let $\frac{1}{\beta} = \mathbb E(\alpha^{\xi_k}) = \alpha p + \frac{1}{\alpha}(1 - p)$. Then,</p> \[\begin{align*} \mathbb E(M_{n + 1} \vert \mathcal F_n) &amp;= \alpha^{X_n} \beta^{n + 1} \mathbb E(\alpha^{\xi_{n + 1}} \vert \mathcal F_n) \\ &amp;= \alpha^{X_n} \beta^{n + 1} \frac{1}{\beta} = \alpha^{X_n} \beta_n = M_n \end{align*}\] <p>That concludes the proof.</p> <p><strong>Claim.</strong> When $p \geq \frac{1}{2}$, then $P_x(\tau_b &lt; \infty) = 1$ where $\tau_a = \min(n \geq 0: X_n = a)$ ($=\infty$ if no such $n$). Note that we are not dealing with finite timeframe anymore.</p> <p>The graph of $\beta$ looks like</p> <p><em>Proof.</em> So for $b \geq X$, we choose $0 &lt; \alpha &lt; 1$ such that $\beta &gt; 1$, then</p> \[\begin{align*} \alpha^X &amp;= \mathbb E_X(M_{n \wedge \tau_b}) \\ &amp;= \mathbb E_X(\alpha^{X_{n \wedge \tau_b}} \beta^{n \wedge \tau_b}) \\ &amp;\geq \mathbb E_X (\alpha^b \beta^{n \wedge \tau_b}) \geq \alpha^b \mathbb E_x(\beta^{n \wedge \tau_b}; \tau_b = \infty) \\ &amp;= \alpha^b \beta^n P_X(\tau_b = \infty) \end{align*}\] <p>Letting $n \to \infty$, we infer $P_X(\tau_b = \infty) = 0$.</p> <p><strong>Claim.</strong> When $p &gt; \frac{1}{2}$, then $P_x(\tau_a &lt; \infty) = \left(\frac{1}{p}\right)^{x - a}$.</p> <p><em>Proof.</em> For $\frac{q}{p} &lt; \alpha &lt; 1$, $0 &lt; \beta&lt; 1$</p> \[\begin{align*} \alpha^X &amp;+ \mathbb E_X(M_{n \wedge \tau_a} ) \\ &amp;= \mathbb E_X(\alpha^{X_n}\beta^n ; n &lt; \tau_a) + \mathbb E_X(\alpha^{X_{\tau_a} \beta^{\tau_a}}; n \geq \tau_a) \\ &amp;\leq \alpha^a \beta^n P_X(n &lt; \tau_a) + \alpha^a\mathbb E_X (\beta^{\tau_a}; \tau_a \leq n ) \\ \end{align*}\] <p>The second term can be simplified using the <strong>Monotone Convergence Theorem</strong> -</p> \[\begin{align*} \mathbb E_X (\beta^{\tau_a}; \tau_a &lt; n) &amp;= \mathbb E_X(\beta^{\tau_a}; \tau_a &lt; \infty) \\ &amp;=\alpha^{x - a} \end{align*}\] <p>Letting $\alpha \searrow q/p$, $\beta \nearrow 1$ and</p> \[\left(\frac{q}{p}\right)^{x - a} = \mathbb E_x( 1; \tau_a &lt; \infty) = \mathbb P_X(\tau_a &lt; \infty)\] <p>In summary, we have for $p &gt; \frac{1}{2}$</p> \[\begin{align*} P_X(\tau_a &lt; \infty) &amp;= \left(\frac{q}{p}\right)^{x - a} &lt; 1\\ P_X(\tau_b &lt; \infty) &amp;= 1 \end{align*}\] <p>For $p = \frac{1}{2}$,</p> \[P_X(\tau_b &lt; \infty) = P_X(\tau_a &lt; \infty) = 1\] <p>So irrespective of $p$, $P_X(\tau_a \wedge \tau_b &lt; \infty) = 1$.</p> <h4 id="example-3">Example</h4> <p>When $P_X(\tau_a &lt; \tau_b) = \frac{\rho^b - \rho^x}{\rho^b - \rho^a}$ where $M_n = \left(\frac{q}{p}\right)^{X_n} = \rho$ ($p \neq q$)</p> <p>Note that $M_n = X_n$ when $p = q$.</p> <p>Let $\tau = \tau_a \wedge \tau_b$ when $p \neq q$,</p> \[\rho^X = \mathbb E_X(M_{n \wedge \tau})\] <p>Using the <strong>Dominated Convergence Theorem</strong>,</p> \[\rho^X = \mathbb E_X(M_\tau)\] <p>and we get</p> \[\begin{align*} \rho^X &amp;= \rho^A P_X(\tau_a &lt; \tau_b) + \rho^b P_x(\tau_b &lt; \tau_a) \\ 1 &amp;= P_X(\tau_a &lt; \tau_b) + P_X(\tau_b &lt; \tau_a) \end{align*}\] <h4 id="example-4">Example</h4> <p>Let $M_n = X^2 - n$, with $M_0 = X^2$. Then, for $p = \frac{1}{2}, \sigma^2 = 1, \mu = 1$, $\tau = \tau_a \wedge \tau_b$, we have</p> \[\begin{align*} X^2 &amp;= \mathbb E_X (X^2_{n \wedge \tau}) - \mathbb E(n \wedge \tau) \\ X^2 + \mathbb E(n \wedge \tau) &amp;= \mathbb E_X (X^2_{n \wedge \tau}) \\ \end{align*}\] <p>Letting $n \to \infty$ and using Monotone convergence theorem on the left and Dominated convergence theorem on the right, we get</p> \[\begin{align*} X^2 + \mathbb E_X(\tau) &amp;= \mathbb E_X(X_\tau^2) \\ X^2 + \mathbb E_X(\tau) &amp;= a^2\frac{b - x}{b - a} + b^2 \frac{x - a}{b - a}\\ \end{align*}\] <p>resulting in $\mathbb E_X(\tau_a \wedge \tau_b) = (X - a)(b - X)$.</p> <h1 id="brownian-motion-wiener-process">Brownian Motion (Wiener Process)</h1> <p>Brownian motion is defined as a stochastic process defined on continuous time - $W = (W_t, t \geq 0)$. It is defined on a probability space $(\Omega, \mathcal F, P)$ and has the following properties -</p> <ul> <li> <p>$W_0 = 0$</p> </li> <li> <p><strong>Independent increments</strong> - Given a set of times $t_0, \dots, t_n$ such that $0 = t_0 &lt;t_1 &lt; \cdots &lt; t_n$ then $W_{t_1} - W_{t_0}, \dots, W_{t_{n}} - W_{t_{n - 1}}$ are independent.</p> </li> <li> <p><strong>Gaussian increments</strong> - For $0 \leq s \leq t$, $W_t - W_s \sim \mathcal N(0, t - s)$.</p> </li> <li> <p>For a fixed $\omega \in \Omega$, the function $t \to W_t(\omega)$ is continuous.</p> </li> </ul> <p>Equivalently, a Brownian motion is a stochastic process $(w_t: t \geq 0)$ is a Gaussian process with $\mathbb E(W_t) = 0, cov(W_s, W_t) = s \wedge t$ for all $s, t$ and $t \to W_t$ is continuous.</p> <p>This is equivalent to the third property, for $s &lt; t$,</p> \[\begin{align*} \mathbb E[W_sW_t] &amp;= \mathbb E[W_s(W_s + (W_t - W_s)] \\ &amp;= \mathbb E[W_s^2] + \mathbb E[W_s(W_t - W_s)] \\ \end{align*}\] <p>since $W_s - W_0$ is a Gaussian distribution and independent increments property,</p> \[\begin{align*} \mathbb E[W_sW_t] &amp;= \mathbb E[W_s^2] + \mathbb E[W_s(W_t - W_s)] \\ &amp;= s^2 + \mathbb E[W_s]\mathbb E[W_t - W_s] = s^2 \end{align*}\] <h3 id="symmetries">Symmetries</h3> <p>Brownian motion is a unique stochastic process that has</p> <h3 id="donskers-invariance-principle">Donsker’s Invariance Principle</h3> <p>A discrete random walk can be represented as $S_n = \xi_1 + \cdots + \xi_n$. When $n$ becomes very large, the magnitude of the random walk scales by $\frac{1}{\sqrt{n}}$. This is due to the Central Limit Theorem - $\lim_{n \to \infty} S_n/\sqrt{n} \sim \mathcal N(0, 1)$. This is a useful fact to note while visualizing the random walk to fit the evolution appropriately in space. Also,</p> \[W_n(t) = \begin{cases} \frac{S_k}{\sqrt{n}} &amp; t = \frac{k}{n}, k = 0, 1, \dots, n \\ \text{linearly interpolate otherwise}\end{cases}\] <p>Again, from the CLT, $\lim_{n \to \infty} W_n(t) \to \mathcal N(0, t)$. The above formulation takes care of appropriately representing large random walks in a bounded space (probabilistically). Alternately, $W_n$ can be understood as a function from the space $C([0, 1] \to \mathbb R)$ - continuous functions from $[0, 1]$ to $\mathbb R$.</p> <p>Now, we are interested in performing operations $F$ on these random walks -</p> \[\lim_{n \to \infty} \mathbb E[F(W_n)] \to \mathbb E[F(W)]\] <p>for all bounded continious functions $F: C \to \mathbb R$ (maps each walk $W_n$ to a real number). Here, $W$ is a standard Brownian motion. All the above equation is saying is that the discretized formulation $W_n$ is equivalent to a standard Brownian motion for practical purposes when $n$ is large.</p> <p>For example, let $F(x) = \int_{0}^1 x(t) dt$. Then,</p> \[\begin{align*} \vert F(x) - F(y) \vert &amp;\leq \int_0^1 \vert x(t) - y(t) \vert dt \\ &amp;\leq \max_t \vert x(t) - y(t) \vert = \|x - y\|_\infty \end{align*}\] <h3 id="binomial-model-as-a-random-walk">Binomial Model as a Random Walk</h3> <p>We have $S_t = S_{t - 1} \cdot \xi_t$ where $P(\xi_t = 1) = p, P(\xi_t = -1) = 1 - p$. How do we model this as a difference equation?</p> \[\begin{align*} S_t - S_{t - 1} &amp;= S_{t - 1} (\xi_t - 1) \\ \equiv \frac{dS_t}{S_t} &amp;= \xi_t - 1 \end{align*}\] <p>The RHS should be equated to $a \cdot dt + b \cdot dW_t$ for showing similarities with a random walk. Suppose we integrate with the above expression</p> \[\begin{align*} S_t - S_0 = \int_0^t S_u (a) du + \int_0^t S_u b dW_u \end{align*}\] <p>We evaluate the above expression using <strong>Ito’s Stochastic Integral</strong>.</p> <h2 id="itos-stochastic-integral">Ito’s Stochastic Integral</h2> <p>How do we calculate the integral $\int_0^t Y_s dW_s$? We formulate it as a combination of Riemman’s sums -</p> <ol> <li> <p>Let $Y_t = 1_{(u, v]}(s) \cdot H$ where $H \in L^2(\mathcal F_u)$</p> \[M_t = \int_0^t Y_s dW_s = \begin{cases} 0, &amp;t \leq u \\ H(W_t - W_u), &amp;u \leq t \leq v \\ H(W_v - W_u), &amp; t \geq v \end{cases} = H(W_{t \wedge v} - W_{t \lor u})\] <p><strong>Claim.</strong> $M$ is a <strong>continuous</strong> <strong>martingale</strong> and $\mathbb E[M_t^2] = \mathbb E[\int_0^t Y_s^2 ds]$</p> <p><em>Proof.</em> The continuous part is trivial since $W_{t}$ is continuous. We need to show that $\mathbb E[M_t \vert \mathcal F_s] \substack{?}{=} M_s$ for $s&lt; t$</p> \[\begin{align*} \mathbb E[M_t \vert F_s] &amp;= \mathbb E[H(W_t - W_u) \vert F_s] \\ &amp;= \mathbb E[HW_t \vert F_s] - E[HW_u \vert F_s] \\ &amp;= HW_s - HW_u = M_s \end{align*}\] <p>due to the martingale property of $W_t$. Finally, for the second moment, we have</p> \[\begin{align*} \mathbb E(M_t^2) &amp;= \mathbb E[H^2(W_{t \wedge v} - W_{t \wedge u})] \\ &amp;= \begin{cases} 0 &amp; t \leq u \\ \mathbb E[H^2(W_t - W_u)^2], &amp; u \leq t \leq v \\ \mathbb E[H^2(W_v - W_u)^2], &amp; t\geq u \end{cases} \\ &amp;= \begin{cases} 0 &amp; t \leq u \\ \mathbb E[H^2](t - u), &amp; u \leq t \leq v \\ \mathbb E[H^2](v - u), &amp; t\geq u \end{cases} \\ &amp;= \mathbb E[H^2(t \wedge u - t \wedge u)] = \mathbb E\left[\int_0^t H^2 1_{(u, v]} (s)ds\right] \end{align*}\] </li> <li> <p>Now, we need to add such $Y_k$’s for the required interval (Riemman sum). $Y_s = \sum_{k = 1}^n 1<em>{(u_k, v_k]} (s) H_k$ and $H_k \in L^2 (\mathcal F</em>{u_k})$ -</p> \[\int_0^t Y_s dW_s := \sum_{k = 1}^n \int_0^t Y_s^{(k)} dW_s\] <p>Since $Y_s$ is a continuous martingale in $t$. Also, the <strong>Ito’s Isometry</strong> property states that</p> \[\mathbb E((S_0^t Y_s dW_s)^2) = \mathbb E(\int_0^t Y_s^2 ds)\] <p>This is easy to show considering non-overlapping intervals. <em>Hint</em>. Consider conditional expectation using Tower law.</p> </li> <li> <p><strong>Progressively Measurable</strong> - Consider a finite segment of time $0 \leq t \leq T$. Then, a stochastic process $X_t(\omega)$ can be viewed as a function $\Omega \times [0, T] \to \mathbb R$. Then, the integral $\int_{0}^t X_s(\omega)ds$ can be viewed as a marginal integral of a joint function. The fact that $\int_0^t X_s(\omega) ds \in \mathcal F_s$ (the integral is measurable) comes from Fubini’s theorem in Measure theory. Specifically, the process $X_t(\omega)$ is on the domain $\Omega \times [0, t]$ and is consequently measurable on $\mathcal F_t \otimes \mathcal B[0, t]$. Here $\mathcal B$ refers to <strong>Borel Measurability</strong>. $(X_t)$ is said to be <strong>adapted</strong> to $(\mathcal F_t)$</p> <p><strong>Claim.</strong> If $X_t$ is <em>adapted</em> and $t \to X_t(\omega)$ is left-continuous for all $\omega \in \Omega$, then $X$ is progressively measurable.</p> <p>In the previous approach to integrate stochastic processes, we considered $\mathcal L_s$ measurable. Now, we generalise this notion using progressive measurability</p> \[\mathcal L = \{Y: Y \text{ is progressively measurable and } \mathbb E\left(\int_0^T Y_S^2ds\right) &lt; \infty\}\] <p>A key point to note is that $\mathcal L_s$ is dense in $\mathcal L$. That means, given $Y \in \mathcal L$, there exists a sequence of integrands $(Y^{(n)})_{n \geq 1}$ belonging to $\mathcal L_s$ such that</p> \[\lim_{n \to \infty} \mathbb E\left[\int_0^T (Y_s - Y_s^{(n)})]^2 ds\right] \to 0\] <p>Since each $(Y^{(n)})$ is continuous and a martingale, we will try to show that $M_t^{(n)} = \int_0^t Y_s^{(n)} dW_s$ is a Cauchy sequence converging to the above value -</p> \[\begin{align*} \mathbb E\left[ M_t^{(n)} - M_t^{(m)}\right] &amp;= \mathbb E\left[\int_0^t [Y_s^{(n)} - Y_s^{(m)}]\right] \\ &amp;\leq \mathbb E\left[\int_0^T [Y_s^{(n)} - Y_s^{(m)}]\right] \to 0 \end{align*}\] <p>Therefore, $(M_t^{(n)})_{n \geq 1}$ is Cauchy in $\mathcal L^2(\mathcal F_t)$. Consequently, there exists $M_t \in \mathcal L^w(\mathcal F_t)$ such that $M_t^{(n)} \to M_t$. Then, using Doob’s inequality</p> \[\begin{align*} \mathbb E\left(\sup_{0 \leq t \leq T} \vert M_t^{(n)} - M_t^{(m)}\vert^2 \right) \leq 4 \mathbb E[(M_T^{(n)} - M_T^{(m)})^2] \end{align*}\] <p>we can say that $(M_t)_{0 \leq t \leq T}$ is a path-continuous martingale and $\mathbb E[M_t^2] = \mathbb E[\int_0^t Y_s^2 ds]$ for all $t \in [0, T]$.</p> </li> <li> <p>If $Y \in \mathcal L$ is such that $s \to Y_s(w)$ is left-continuous for all $\omega \in \Omega$ then</p> </li> </ol> \[\int_0^t Y_S dW_s = \lim_n \sum_{k = 0}^{n - 1} Y_{\frac{k}{n}t}\left(W_{\frac{k + 1}{n} t} - W_{\frac{k}{n} t}\right)\] <p>is also a limiting sum of Riemann sums.</p> <p><strong>Example</strong> - Consider $\int_0^t W_s dW_s$ . Since $W \in \mathcal L$, this is integrable. Then, $\mathbb E(W_s^2) = s$ and</p> \[\mathbb E\left[\int_0^T W_s^2 ds \right] = \int_0^T \mathbb E(W_s^2) ds = \int_0^T sds &lt; \infty\] <h3 id="quadratic-variation">Quadratic Variation</h3> <p>Similarly, the following is an approximation to quadratic variation</p> \[\lim_{n \to \infty} Q_t^{(n)} = \lim_{n \to \infty} \sum_{k = 0}^{n - 1} (W_{\frac{k + q}{n} t} - W_{\frac{k}{n}t})^2 = t\] <p>This is because the increments are independent are from the distribution $\mathcal N(0, \frac{t}{n})$. To get the variance, we have</p> \[\mathbb E((Q_t^{(n)})^2 ) = 3n \left(\frac{t}{n}\right)^2 + n(n - 1)\left(\frac{t}{n}\right)^2\] <p>implying $Var(Q_t^{(n)}) = \frac{2}{n} t^2 \to 0$ as $n \to \infty$.</p> <p>Going back to our example, writing the integral as Riemann sums -</p> \[\begin{align*} W_t^2 &amp;= \sum_{k = 0}^{n - 1} (W^2_{\frac{k + 1}{n} t} - W^2_{\frac{k }{n} t}) \quad \because W_0^2 = 0\\ &amp;= 2 \sum_{k =0}^{n - 1} W_{\frac{k}{n}t} (W_{\frac{k + 1}{n} t} - W_{\frac{k }{n} t}) + Q_t^{(n)}\quad \because \text{telescopic sum} \\ &amp;= 2\int_0^t W_S dW_s + t \end{align*}\] <p>since the above is left-continuous, letting $n \to \infty$, we get the above expression. The above expression in reminiscent of the fundamental theorem of calculus. Using this, we now state the following theorem</p> <p><strong>Theorem (Ito’s Formula/Lemma)</strong> For a function $f \in C^2$ and $\vert f’(x) \vert \leq c_0 e^{c_1\vert x \vert}$ for constants $c_0, c_1$,</p> \[f(W_t) = f(W_0) + \int_0^t f'(W_s)sW_s + \frac{1}{2} \int_0^t f"(W_S) ds\] <p>This is sort of the fundamental theorem for stochastic calculus.</p>]]></content><author><name></name></author><category term="Notes"/><summary type="html"><![CDATA[Discussion on Discrete and continuous pricing models for Options, No-arbitrage pricing and the mathematics involved.]]></summary></entry><entry><title type="html">Lattices in Cryptography and Quantum Computers</title><link href="https://sudhansh6.github.io/blog/Lattices-in-Cryptography/" rel="alternate" type="text/html" title="Lattices in Cryptography and Quantum Computers"/><published>2024-03-06T00:00:00+00:00</published><updated>2024-03-06T00:00:00+00:00</updated><id>https://sudhansh6.github.io/blog/Lattices-in-Cryptography</id><content type="html" xml:base="https://sudhansh6.github.io/blog/Lattices-in-Cryptography/"><![CDATA[<h2 id="lattices">Lattices</h2> <p>Lattices are the most promising candidate for quantum security. We have been studying these problems since many years, and there is a significant amount of research in this topic. There are other schemes based on other assumptions like code based cryptographies, etc. These are important in the case Lattices are broken since these have completely independent assumptions.</p> <p>What is Lattice? A Lattice is defined over a space \(\mathbb R^n\) consisting of \(m\) linearly independent vectors \(b_1, \dots, b_m\). We refer to the matrix \(B = (b_1, \dots, b_m)\). Then,</p> \[\mathcal L(B) = \left\{ \sum_{i} x_i b_i \vert z_i \in \mathbb Z \right\}\] <p>We usually consider \(m = n\) in analysis. For example, in \(\mathbb R^2\), \(b_1 = (1, 2)^T, b_2 = (2, 1)^T\). This is equivalent to considering the integer grid points in the basis \(B\). This is a countable space unlike a normal vector space. A lattice is not unique to set of basis vectors! Any basis of the form \(x_1b_1 + x_2 b_2, y_1 b_1 + y_2 b_2\), where \(x_1y_2 - x_2y_1 = \pm 1\) and \(x_1, x_2, y_1, y_2 \in \mathbb Z\) will have the same basis.</p> <p>Consider a few computational problems in Lattices -</p> <ul> <li>Given \(v, B\), compute whether \(v \in \mathcal L(B)\). This is polynomial computable using Gaussian elimination.</li> <li>Given \(B, B’\), compute whether \(\mathcal L(B) = \mathcal L(B’)\). This is polynomial computable as well, using the above problem. An equivalent way to find this is to consider \(B = UB’\) iff \(U\) has integer entries and \(det(U) = \pm 1\) as seen above.</li> <li>SVP (Shortest Vector Problem) - Given a basis \(B\) in \(\mathbb R^n\), find the non-zero shortest vector in \(\mathcal L(B)\). This is computationally hard for higher \(n\) (quantumly hard too). An approximation is given by \(SVP_\gamma\) aims to find \(v \in \mathcal L(B)\), \(\|v\| \leq \gamma \|\text{shortest}\|\).</li> <li>CVP (Closest Vector Problem) - Given a basis \(B \in \mathbb R^n\) and \(v \in \mathbb R^n\), find \(v \in \mathcal L(B)\) such that \(\|u - v\|\) is minimized. This problem is equivalent to the above problem.</li> </ul> <p>Conjectures - SVP and CVP are quantumly hard!</p> <p>Can we use NP-complete problems for cryptography? Most of these problems are worst-case hard, and there are good approximation algorithms for the average case. So with these problem constructions, we are looking for average-case hard complexity. The knapsack problem, for example, is related to Lattice problems.</p> <p>How can we construct public key cryptography schemes with lattices? The basis assumption is that computing a ‘good’ basis from a ‘bad’ basis is intractable. For example, consider the following</p> <ul> <li>A secret key is constructed using a ‘good’ basis (for CVP) - \(B\)</li> <li>A public key is constructed using a ‘bad’ basis - \(B’\)</li> <li>\({\sf Enc} (pk, m) \to \text{ sample } v \in \mathcal L(B')\) such that \(v\) encodes \(m\). The cipher text is \(u = v + \eta\) where usually \(\eta \sim \mathcal N(0, \sigma^2)\) so that the problem reduces to CVP</li> <li>\({\sf Dec}(sk, u)\) recovers \(v\) using \(B\).</li> </ul> <p>There are more computationally hard problems like the SIS (Shortest Integer Solution) and LWE (Learning with Errors). SIS and LWE can be reduced to one another and both of them are harder than \(SVP/SVP_\gamma\) and \(CVP/CVP_\gamma\). For example, Learning With Errors is much harder problem - it is average case hard if \(CVP_\gamma\) is worst case hard for \(\gamma = {\sf poly}(n)\). These problems, especially LWE, present a new paradigm in cryptography known as <em>homographic encryption</em>. The idea is that any operations performed on the messages (decrypted space) can be reflected in the encrypted space. For example, say we are encrypting photos uploaded to the cloud. If you are adding a new picture, then we should be able to encrypt the new data alongside the old one without recomputing the encryption for the data as a whole again. In homographic encryption, we need not perform the encryption again for all the set of pictures, but rather just on the new picture and append it to the old data.</p> <p>Let us see the definitions of these problems -</p> <ul> <li>Shortest Integer Solution - Let \(A \in \mathbb Z^{n \times m}_q\), \(A = (a_1, \dots, a_m)\) \(a_i \in \mathbb Z_q\). The goal is to find \(z \in \mathbb Z^m\) such that <ul> <li> \[Az \equiv 0 ({\sf mod } q)\] </li> <li>\(z\) is ‘short’ - \(\|z\|_2 \leq \beta\) and \(z \in \{-1, 0, 1\}^m\)</li> </ul> <p>The parameters used to define this problem are given by \(m = {\sf poly} (n)\), \(q = {\sf poly} (n)\) and \(\beta = c \sqrt{m}\) for some \(c \in \mathbb R\). These parameter choices can be chosen to be something else if the theoretical bounds exist, but this particular set of parameters can be reduced to \(CVP_\gamma\) where \(\gamma = \mathcal O(n)\).</p> <p>There is a variant of this problem known as Inhomogeneous Short Integer Solution (ISIS) - We equate \(Az \equiv t ({\sf mod} q)\) instead of equating to \(0\).</p> <p>How are these related to lattices? All solutions \(Az \equiv 0 ({\sf mod } q)\) form a lattice defined by</p> \[L^\perp(A) = \left\{z \in \mathbb Z^m \vert Az \equiv 0 ({\sf mod } q)\right\}\] <p>Consider any \(z_1, z_2 \in \mathcal L^\perp(A)\), then it is easy to see that for any \(a, b \in \mathbb Z\), \(A(az_1 + bz_2) \equiv 0({\sf mod}q)\). Let us define a cryptographic application to get a gist of how we use these problems -</p> <ol> <li>Collision-Resistant Hash Function - The security for such a function is that, given the description of such a hash function, it is <em>difficult</em> to find a collision. Using Grover’s Algorithm, typical hash functions can be broken with a quadratic speed-up as compared to classical algorithms. Here, we construct a hash function using SIS that cannot be broken with Grover’s - <ul> <li>Construction - Sample \(A \in \mathbb Z_q^{m\times n}\), \(f_A(x \in \{0, 1\}^m) = Ax ({\sf mod} q)\). Unlike SIS, the input here is binary rather than from \(\mathbb Z_q\).</li> <li>Security - Assume we find \(x, x’\) such that \(f_A(x) = f_A(x’) \implies A(x - x') \equiv 0 ({\sf mod} q)\). Since \(x, x’ \in \{0, 1\}^m\), \(x - x’ \in \{-1, 0, 1\}^m\).</li> </ul> <p>There are other implementations more efficient that this construction, but it acts like a good starting point.</p> </li> <li>Signatures (GPV Signature) - Unlike the previous case, this is the most efficient construction we know for public key cryptography. For a signature, we need to define the constructions for a verification key \(vk\) and a signing key \(sk\) - a trapdoor \(T\) to help us find solutions for ISIS. <ul> <li>\(Sign(sk, m)\) maps \(m \mapsto t \in \mathbb Z_q^m\), use \(T\) to find \(v\) such that \(Av \equiv t ({\sf mod} q)\) and set \(sk = \sigma = v\).</li> <li>\(Ver(vk, m, \sigma)\) maps \(m \mapsto t \in \mathbb Z_q^m\), check whether \(A \sigma \equiv t ({\sf mod} q)\) and \(\sigma\) is ‘short’.</li> </ul> <p>Intuitively, we are able to find a secret key \(v\) using a trapdoor that satisfied ISIS. The verification procedure is simple wherein \(v\) can be verified to be short and satisfying the modulus equation.</p> <p>The research for \(T\) concluded in 2010’s. The gist of the trapdoor is the following - suppose we sample \(A \in \mathbb Z^{n \times m}_q\) and \(t \gets \text{ all short vectors}\). Then, we construct \(A' = [A \vert \texttt{-}At] \equiv A' \in \mathbb Z_1^{n \times (m + 1)}\). Then \(t’ = (t, 1)^T\) satisfies \(A’t’ \equiv 0({\sf mod} q)\).</p> <p>The National Institute of Standards and Technology (NIST) submitted FALCON and DILITHIUM based on GPV signatures along with other building blocks for post-quantum cryptography.</p> </li> </ol> <p>The SIS problem still has limited structure limiting its applications. Next, we shall see LWE which allows us to construct many cryptographic schemes.</p> </li> <li> <p>Learning With Errors (LWE) - The parameters used in this problem are \(n, m , q, \mathcal X\) where \(m,q = poly(n)\) and \(\mathcal X\) is an error probability distribution. The problem is as follows - say there is a uniformly random \(s \in \mathbb Z_q^n\), then the goal is to given \(m = poly(n)\) samples of \(\langle a_i, s\rangle + \eta_i \equiv ({\sf mod} q)\) where \(a_i \in \mathbb Z_q^n\) and \(\eta \sim \mathcal X^m\), determine \(s\). Note that if there were no error involved, then this problem is very easy - perform Gaussian elimination to recover \(a_i\). \(\mathcal X\) is typically chosen as a Gaussian distribution modified to work with the \(\mathbb Z_q\) space -</p> \[\Psi_\alpha = \text{sample } v \in \mathbb Z_q \\ \text{w.p. proportional to } \left(e^{\frac{-|v|^2}{\alpha^2}}/c\right)\] <p>where \(\alpha = \mathcal O\left(1/\sqrt{n}\right)\).</p> <p>More elegantly, the LWE problem is described using a matrix formulation -</p> <p>Given \(A \in \mathbb Z^{n \times m}_q\) and \(e \sim X^m\) , determine \(s \in Z_q^n\) from \(s^T A + e^T ({\sf mod} q)\). This is known as the <em>search version</em> of LWE. <em>Distinguish LWE</em> is an equivalent formulation where, given \(A, e, s\) with the same distributions as before, the goal is to distinguish \(A, s^T A + e^T\) and \(A, r^T\) where \(r \in \mathbb Z^m_q\). To get an intuition, we consider the following example schemes -</p> </li> </ul> <ol> <li> <p>Public-key Encryption -</p> <p>Kyber is one such scheme, motivated from this, which is now being used by Apple (as of 2024) to encrypt messages on iMessage. SABER, NTRU are other public-key encryption schemes.</p> <ul> <li> \[pk = A, u = s^T A + e^T\] </li> <li> \[sk = s\] </li> <li>\({\sf Enc} (pk, m \in \{0, 1\}^n) :=\) choose \(x \in \{0, 1\}^m\) and output \(c_0 = Ax ({\sf mod} q), c_1 = \left(ux + \left[\frac{q}{2}\right].m \right)({\sf mod} q)\)</li> <li> <p>\({\sf Dec}(sk, c_0, c_1) :=\) output</p> \[\begin{align*} c_1 - s^T c_0 &amp;= \left(ux + \left[\frac{q}{2}\right].m - s^T Ax\right) {\sf mod } q \\ v &amp;= \left(e^T x + \left[\frac{q}{2}\right].m \right) {\sf mod } q \end{align*}\] <p>Now, since \(x \in \{0, 1\}^m\) and \(e\) is ‘short’, we can bound \(\|e^Tx \| &lt; q/4\) (A loose bound). We have the following range for \(v\).</p> \[\begin{align*} 0 |————|\underbrace{————|————}|————| q \\ m = 0 \quad\quad\quad\quad m = 1 \quad\quad\quad\quad m = 0 \quad \end{align*}\] </li> <li><strong>Security -</strong> Consider the following two problems - <ul> <li>Given \(pk = A, u = s^T A + e^T\), and \(c_0 = Ax, c_1 = ux + \frac{q}{2} m\), find \(m\).</li> <li>Given \(pk = A, u = r^T\) and \(c_0 = Ax, c_1 = ux + \frac{q}{2}m\), find \(m\)</li> </ul> <p>Now, distinguishing the above two scenarios is equivalent to solving the DLWE problem! This proves the security.</p> </li> </ul> </li> <li> <p>Key-Agreement Protocol - In this scenario, we want two parties \(A, B\) to establish a secret key. Let us say \(A, B\) have a common matrix \(M \in \mathbb Z_q^{n \times n}\) they agree on.</p> <ul> <li>To do so, \(A\) samples \(r \in \mathbb Z^n\) and \(B\) samples \(s \in \mathbb Z^n\) such that \(r, s\) are short. This ensures that \(r, s\) are in \(Z_q^n\) as well. They also have associated error distributions \(e, e’\) respectively.</li> <li>\(A\) sends \(u^T = r^T M + e^T\) and \(B\) sends \(v = Ms + e\)</li> <li>\(A\) computes \(r^Tv = r^T(As + e’) \approx r^T As\)</li> <li>\(B\) computes \(u^T s = (rA + e^T) s \approx r^T As\)</li> <li>To avoid the small chance of error, \(A, B\) choose the first \(m\) bits of the obtained values. The error will most likely not affect these bits, and both parties obtain the same key.</li> <li>For an eavesdropper, both \(u^T, v\) are completely random and the security is guaranteed by LWE.</li> </ul> </li> </ol> <p>LWE has properties such begin fully homomorphic and identity-based (encrypt the message for a specific group of secret-keys). LWE can also be used for the proof of quantumness.</p> <p>The bigger picture has more problems as compared to LWE. However, the theory for LWE is robust and therefore is widely used in post-quantum cryptographic protocols.</p> <h2 id="quantum-computers">Quantum Computers</h2> <p>How do we make qubits, gates and quantum computers. The first Turing complete programmable computer is the ENIAC. It was built using vacuum tubes and occupied a lot of space. After that we transitioned to transistors, and the growth has been exponential. Since 1950’s to 2010’s, we were able to progress from 1 transistor to 1-trillion transistors packed in the same area. This was correctly predicted by the Moore’s law - the number of transistors in an integrated circuit doubles roughly every two years (or eighteen months).</p> <p>In quantum computers, we are currently at the initial stage like the ENIAC - trying to figure out how to efficiently store the qubits. The following technologies are being experimented with -</p> <ul> <li>Atoms - Trapped Ions, Cold Atoms - We prepare individual wells or <em>prisons</em> where ions are trapped electromagnetically. Two ions trapped can represent an entangled state. Lasers are used to control the properties of these ions. The qubits remain coherent for an impressive amount of time - for a few minutes. Typically, qubits are heavily influenced by the environment - the environment gets decohered easily. However, this technology is not easy to scale - the best we can do is 30 qubits. Also, applying 2-qubit gates using lasers is quite difficult.</li> <li>Superconductors - The idea is to cool certain metals to \(0K\) - The materials then lose their electromagnetic properties. When two metals close together are cooled down, then they form a qubit due to <em>quantum tunnelling effect</em>. The operations are still conducted by lasers but the scalability is better. The quantum computers currently being used by Google and IBM are made from this technology. The accuracy is not high but scalability is easy (these companies use those big numbers to increase stock prices). The longevity is in the order of microseconds!</li> <li>Photons - There are some controversies with photons, with regards to using them as universal qubits. The qubits are formed using circulating in waveguides using the polarity of photons. This are difficult to scale and it is difficult to use them for ‘quantum speedup’ algorithms.</li> <li>Silicon dots - Artificial atoms made by adding an electron to silicon and these are controlled by microwaves. This is still in the experimental stage.</li> </ul> <p>Currently, the accuracy for quantum gates is not as good for consumer use - the accuracy is 99.9%. IonQ based on trapped ions is currently at around ~35 qubits whereas IBM based on superconducting technology is at a 1000 qubits. However, the error per qubit in the latter case is around 2% making it infeasible to do any practical applications with these chips. Both these strides in accuracy and size are needed to reach quantum supremacy. How many years would it take to reach fault-tolerant quantum computers with a million qubits? We are not sure. The problem is not with the technology, but with the engineering - quantum computers require a lot of calibration to work with a good accuracy.</p> <p>Recently, a few noisy qubits (53 in total) were able to outperform the fastest classical computers on the Poisson sampling problem. The fastest classical computers would take around 10,000 years to solve this problem!<sup><a href="#footnote1">1</a></sup> This shows promise in the era of quantum computing.</p> <p><a name="footnote1">1</a>: IBM showed that this result is feasible using their classical supercomputer which took 2 days to solve the problem. Even then, a few qubits solved this in minutes, so quantum supremacy is still a promising avenue.</p>]]></content><author><name></name></author><category term="Notes"/><summary type="html"><![CDATA[Introduction to lattice problems and their relevance in post-quantum cryptography. A brief discussion of the current state of quantum computers.]]></summary></entry><entry><title type="html">Object Detection</title><link href="https://sudhansh6.github.io/blog/Object-Detection/" rel="alternate" type="text/html" title="Object Detection"/><published>2024-01-15T00:00:00+00:00</published><updated>2024-01-15T00:00:00+00:00</updated><id>https://sudhansh6.github.io/blog/Object-Detection</id><content type="html" xml:base="https://sudhansh6.github.io/blog/Object-Detection/"><![CDATA[<p><strong>What</strong> objects are <strong>where</strong>? Object detection can be performed using either traditional (1) image processing techniques or modern (2) deep learning networks.</p> <ul> <li>Image processing techniques generally don’t require historical data for training and are unsupervised in nature. OpenCV is a popular tool for image processing tasks. <ul> <li>Pros: Hence, those tasks do not require annotated images, where humans labeled data manually (for supervised training).</li> <li>Cons: These techniques are restricted to multiple factors, such as complex scenarios (without unicolor background), occlusion (partially hidden objects), illumination and shadows, and clutter effect.</li> </ul> </li> <li>Deep Learning methods generally depend on supervised or unsupervised learning, with supervised methods being the standard in computer vision tasks. The performance is limited by the computation power of GPUs, which is rapidly increasing year by year. <ul> <li>Pros: Deep learning object detection is significantly more robust to occlusion, complex scenes, and challenging illumination.</li> <li>Cons: A huge amount of training data is required; the process of image annotation is labor-intensive and expensive. For example, labeling 500’000 images to train a custom DL object detection algorithm is considered a small dataset. However, many benchmark datasets (MS COCO, Caltech, KITTI, PASCAL VOC, V5) provide the availability of labeled data.</li> </ul> </li> </ul> <p>The field of object detection is not as new as it may seem. In fact, object detection has evolved over the past 20 years. The progress of object detection is usually separated into two separate historical periods (before and after the introduction of Deep Learning):</p> <ul> <li>Object Detector Before 2014 – Traditional Object Detection period <ul> <li>Viola-Jones Detector (2001), the pioneering work that started the development of traditional object detection methods</li> <li>HOG Detector (2006), a popular feature descriptor for object detection in computer vision and image processing</li> <li>DPM (2008) with the first introduction of bounding box regression Object Detector</li> </ul> </li> <li>After 2014 – Deep Learning Detection period Most important two-stage object detection algorithms <ul> <li>RCNN and SPPNet (2014) - Region CNN</li> <li>Fast RCNN and Faster RCNN (2015)</li> <li>Mask R-CNN (2017)</li> <li>Pyramid Networks/FPN (2017)</li> <li>G-RCNN (2021) - Granulated RCNN</li> </ul> </li> <li>Most important one-stage object detection algorithms <ul> <li>YOLO (2016)</li> <li>SSD (2016)</li> <li>RetinaNet (2017)</li> <li>YOLOv3 (2018)</li> <li>YOLOv4 (2020)</li> <li>YOLOR (2021)</li> <li>YOLOv7 (2022)</li> <li>YOLOv8 (2023)</li> </ul> </li> </ul> <p>In general, deep learning based object detectors extract features from the input image or video frame. An object detector solves two subsequent tasks:</p> <ul> <li>Task #1: Find an arbitrary number of objects (possibly even zero), and</li> <li>Task #2: Classify every single object and estimate its size with a bounding box.</li> </ul> <h3 id="yolo---you-only-look-once">YOLO - You Only Look Once</h3> <p>It is a popular family of real-time object detection algorithms. The original YOLO object detector was first released in 2016. It was created by Joseph Redmon, Ali Farhadi, and Santosh Divvala. At release, this architecture was much faster than other object detectors and became state-of-the-art for real-time computer vision applications.</p> <p><img src="/assets/img/Object%20Detection/Untitled.png" alt="Untitled"/></p> <p>The algorithm works based on the following four approaches:</p> <ul> <li> <p>Residual blocks - This first step starts by dividing the original image (A) into NxN grid cells of equal shape, where N in our case is 4 shown on the image on the right. Each cell in the grid is responsible for localizing and predicting the class of the object that it covers, along with the probability/confidence value.</p> <p><img src="/assets/img/Object%20Detection/Untitled%201.png" alt="Untitled"/></p> </li> <li> <p>Bounding box regression -</p> <p>The next step is to determine the bounding boxes which correspond to rectangles highlighting all the objects in the image. We can have as many bounding boxes as there are objects within a given image.</p> <p>YOLO determines the attributes of these bounding boxes using a single regression module in the following format, where Y is the final vector representation for each bounding box.</p> \[Y = [pc, bx, by, bh, bw, c1, c2]\] <p>where \(pc\) is the probability score of the grid containing the object. \(c1, c2\) correspond to the object classes - ball and player.</p> </li> <li> <p>Intersection Over Unions or IOU for short</p> <p>Most of the time, a single object in an image can have multiple grid box candidates for prediction, even though not all of them are relevant. The goal of the IOU (a value between 0 and 1) is to discard such grid boxes to only keep those that are relevant. Here is the logic behind it:</p> <ul> <li>The user defines its IOU selection threshold, which can be, for instance, 0.5.</li> <li>Then YOLO computes the IOU of each grid cell which is the Intersection area divided by the Union Area.</li> <li>Finally, it ignores the prediction of the grid cells having an IOU ≤ threshold and considers those with an IOU &gt; threshold.</li> </ul> <p><img src="/assets/img/Object%20Detection/Untitled%202.png" alt="Untitled"/></p> </li> <li> <p>Non-Maximum Suppression.</p> <p>Setting a threshold for the IOU is not always enough because an object can have multiple boxes with IOU beyond the threshold, and leaving all those boxes might include noise. Here is where we can use NMS to keep only the boxes with the highest probability score of detection.</p> </li> </ul> <p>Although YOLO was state-of-the-art when it released, with much faster detection, it had a few disadvantages. It is unable to detect smaller objects within a grid as each grid is designed for single object detection. It is unable to detect new or unusual shapes, and the same loss function is used for both small and large bounding boxes which creates incorrect localizations.</p> <p><img src="/assets/img/Object%20Detection/Untitled%203.png" alt="Untitled"/></p> <p><strong>YOLOv2</strong> improvised over the existing architecture using <strong><a href="https://paperswithcode.com/method/darknet-19">Darknet-19</a></strong> as new architecture (Darknet is an open-source neural network framework in C and CUDA),</p> <ul> <li>batch normalization - reduced overfitting using a regularization effect.</li> <li>higher resolution of inputs,</li> <li>convolution layers with anchors - Replaces fully connected laters with anchor boxes to prevented predicting the exact coordinate of bounding boxes. Recall improved, accuracy decreased. Anchor boxes are predefined grids with certain aspect ratios spatially located in an image. These boxes are checked for an object probability score and are selected accordingly.</li> <li>dimensionality clustering - The previously mentioned anchor boxes are automatically found by YOLOv2 using k-means dimensionality clustering with k=5 instead of performing a manual selection. This novel approach provided a good tradeoff between the recall and the precision of the model.</li> <li>Fine-grained features - YOLOv2 predictions generate 13x13 feature maps, which is of course enough for large object detection. But for much finer objects detection, the architecture can be modified by turning the 26 × 26 × 512 feature map into a 13 × 13 × 2048 feature map, concatenated with the original features.</li> </ul> <p><strong>YOLOv3</strong> is an incremental improvement using Darknet-53 instead of Darknet-19. <strong>YOLOv4</strong> is an optimized for parallel computations. This architecture, compared to YOLOv3, adds the following information for better object detection:</p> <ul> <li>Spatial Pyramid Pooling (SPP) block significantly increases the receptive field, segregates the most relevant context features, and does not affect the network speed.</li> <li>Instead of the Feature Pyramid Network (FPN) used in YOLOv3, YOLOv4 uses <strong><a href="https://bio-protocol.org/exchange/minidetail?type=30&amp;id=9907669">PANet</a></strong> for parameter aggregation from different detection levels.</li> <li>Data augmentation uses the mosaic technique that combines four training images in addition to a self-adversarial training approach.</li> <li>Perform optimal hyper-parameter selection using genetic algorithms.</li> </ul> <p><strong>YOLOR</strong> is based on the unified network which is a combination of explicit and implicit knowledge approaches - (1) feature alignment, (2) prediction alignment for object detection, and (3) canonical representation for multi-task learning.</p> <p>Then, <strong>YOLOX</strong>, using a modified version of YOLOv3, decoupled classification and localization increasing the performance of the model. <a href="https://medium.com/mlearning-ai/yolox-explanation-mosaic-and-mixup-for-data-augmentation-3839465a3adf">Mosaic and MixUp data augmentation approaches</a> were added. Removed the anchor-based system that used to perform clustering under the hood. Introduced SimOTA instead of IoU.</p> <p><strong>YOLOv5</strong> uses Pytorch rather than Darknet, and has 5 different model sizes. <strong>YOLOv6</strong> was developed for industrial applications and introduced three improvements - a hardware-friendly backbone and neck design, an efficient decoupled head, and a more effective training strategy.</p> <p><strong>YOLOv7</strong> - <strong><a href="https://arxiv.org/pdf/2207.02696.pdf">Trained bag-of-freebies sets new state-of-the-art for real-time object detectors</a>.</strong> It reformed the architecture by integrating Extended Efficient Layer Aggregation Network (E-ELAN) which allows the model to learn more diverse features for better learning. The term <strong>bag-of-freebies</strong> refers to improving the model’s accuracy without increasing the training cost, and this is the reason why YOLOv7 increased not only the inference speed but also the detection accuracy.</p> <h3 id="r-cnn---region-based-convolutional-neural-networks">R-CNN - Region-based Convolutional Neural Networks</h3> <p><strong>R-CNN</strong> models first select several proposed regions from an image (for example, anchor boxes are one type of selection method) and then label their categories and bounding boxes (e.g., offsets). These labels are created based on predefined classes given to the program. They then use a convolutional neural network (CNN) to perform forward computation to extract features from each proposed area.</p> <p>In 2015, <strong>Fast R-CNN</strong> was developed to significantly cut down train time. While the original R-CNN independently computed the neural network features on each of as many as two thousand regions of interest, Fast R-CNN runs the neural network once on the whole image. This is very comparable to YOLO’s architecture, but YOLO remains a faster alternative to Fast R-CNN because of the simplicity of the code.</p> <p>At the end of the network is a novel method known as Region of Interest (ROI) Pooling, which slices out each Region of Interest from the network’s output tensor, reshapes, and classifies it (Image Classification). This makes Fast R-CNN more accurate than the original R-CNN.</p> <p><strong>Mask R-CNN</strong> is an advancement of Fast R-CNN. The difference between the two is that Mask R-CNN added a branch for predicting an object mask in parallel with the existing branch for bounding box recognition. Mask R-CNN is simple to train and adds only a small overhead to Faster R-CNN; it can run at 5 fps.</p> <h3 id="other-approaches">Other Approaches</h3> <p><strong>SqueezeDet</strong> was specifically developed for autonomous driving, where it performs object detection using computer vision techniques. Like YOLO, it is a single-shot detector algorithm. In SqueezeDet, convolutional layers are used only to extract feature maps but also as the output layer to compute bounding boxes and class probabilities. The detection pipeline of SqueezeDet models only contains single forward passes of neural networks, allowing them to be extremely fast.</p> <p><strong>MobileNet</strong> is a single-shot multi-box detection network used to run object detection tasks. This model is implemented using the Caffe framework.</p> <h3 id="references">References</h3> <ul> <li> <p><a href="https://www.datacamp.com/blog/yolo-object-detection-explained">Datacamp YOLO</a></p> </li> <li> <p><a href="https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-convolutional-neural-networks">Stanford CNNs</a> - Good site</p> </li> <li> <p><a href="https://viso.ai/deep-learning/yolov7-guide/">Viso AI YOLOv7</a></p> </li> <li> <p><a href="https://viso.ai/deep-learning/object-detection/">Viso AI Object Detection</a></p> </li> <li> <p><a href="https://viso.ai/computer-vision/what-is-computer-vision/">Viso AI Computer Vision</a></p> </li> </ul>]]></content><author><name></name></author><category term="Research"/><summary type="html"><![CDATA[A brief survey of object detection methods in 2023.]]></summary></entry><entry><title type="html">Numerical Analysis Notes</title><link href="https://sudhansh6.github.io/blog/NumAn/" rel="alternate" type="text/html" title="Numerical Analysis Notes"/><published>2022-01-10T00:00:00+00:00</published><updated>2022-01-10T00:00:00+00:00</updated><id>https://sudhansh6.github.io/blog/NumAn</id><content type="html" xml:base="https://sudhansh6.github.io/blog/NumAn/"><![CDATA[<h1 id="lecture-1">Lecture 1</h1> <p><em>Numerical Analysis</em> is the study of various methods</p> <ul> <li>to solve <ul> <li>differential equations,</li> <li>systems of linear equations,</li> <li>\(f(x) = \alpha\).</li> </ul> </li> <li>to approximate functions and</li> <li>to study the corresponding errors.</li> </ul> <p><strong>Example.</strong> \(e = \lim_{n \to \inf} (1 + 1/n)^n)\). How do we approximate \(e\) to an arbitrary accuracy? Since, the \(exp\) function is infinitely many times differentiable, we can approximate the function using Taylor’s theorem to any degree of precision we want.</p> <div style="text-align: center;"> $$ \text{Taylor's theorem} \\ f(x) = f(a) + f'(a)(x - a) + \cdots + \\ \frac{f^{(k)}(a)}{k!}(x - a)^k + \frac{f^{(k + 1)}(c)}{k!}(x - a)^{k + 1} $$ </div> <p>Using this, we get</p> <div style="text-align: center;"> $$ e = 1 + \frac{1}{1!} + \frac{1}{2!} + \cdots + \\ \frac{1}{n!} + \frac{e^c}{(n + 1)!} $$ </div> <p>where \(c\) is some real number between 0 and 1. Here, the error term at the \(n\)-th approximation is the term \(e^c/(n + 1)!\). We know that \(e^c\) is less than 3 so we can compute \(n\) where the error term is less than the prescribed error!</p> <p>For example, suppose we want the error to be less than \(10^{-10}\), then we use \(e^c/(n + 1)! &lt; 10^{-10}\).</p> <p><strong>Note.</strong> The last term is not the error in our approximation! We are choosing \(e^c = 3\) for no particular reason. It can be any value greater than the true value of \(e^c\). For instance, we can take \(e^c = 1000\) too. If we want our calculated value \(e\) value to be precise till the 10th decimal, then we ensure that \(1000/(n + 1)! &lt; 10^{-10}\) by tuning \(n\) appropriately.</p> <h2 id="aspects-of-numerical-analysis">Aspects of numerical analysis</h2> <ul> <li>The theory behind the calculation, and</li> <li>The computation.</li> </ul> <p>Some calculators have a loss of information due to limits in precision. This is due to the round-off error. We need to be able to detect and deal with such cases.</p> <h1 id="lecture-2">Lecture 2</h1> <h2 id="finite-digit-arithmetic">Finite digit arithmetic</h2> <p>When we do arithmetic, we allow for infinitely many digits. However, in the computational world, each representable number has only a fixed and finite number of digits. In most cases, the machine arithmetic is satisfactory, but at times problems arise because of this discrepancy. The error that is produced due to this issue is called the <strong>round-off</strong> error.</p> <p>A 64-bit representation is used for a real number. The first bit is a <strong>sign indicator</strong>, denoted by <em>s</em>. This is followed by an 11-bit exponent, <em>c</em>, called the <strong>characteristic</strong>, and a 52-bit binary fraction, <em>f</em>, called the <strong>mantissa</strong>. To ensure that numbers with small magnitude are equally representable, 1023 is subtracted from the characteristic, so the range of the exponent is actually from -1023 to 1024.</p> <p>Thus, the system gives a floating-point number of the form</p> <div style="text-align:center;"> $$ (-1)^s\cdot2^{c - 1023}\cdot(1 + f) $$ </div> <p>Since 52 binary digits correspond to between 16 and 17 decimal digits, we can assume that a number represented in this system is accurate till the 16th decimal.</p> <blockquote> <p>Can’t a single number be represented in many ways through this representation? Think about 1 for instance.</p> </blockquote> <p>The smallest positive number that can be represented is with \(s = 0, c = 1, f = 0\), so it is</p> <div style="text-align:center;"> $$ 2^{-1022}\cdot(1 + 0) \approx 0.22251 \times 10^{-307} $$ </div> <p>Numbers occurring in calculations that have a magnitude less than this number result in <strong>underflow</strong> and are generally set to 0.</p> <p>The largest positive number is</p> <div style="text-align:center;"> $$ 2^{1023}\cdot (2 - 2^{-52}) $$ </div> <p>Numbers above this would result in an <strong>overflow</strong>.</p> <h2 id="floating-point-representation">Floating-point representation</h2> <p>We will use numbers of the form</p> <div style="text-align:center;"> $$ \pm 0.d_1d_2\dots d_kd_{k + 1} \times 10^n $$ </div> <p>with \(1 \leq d_1 \leq 9\). There are two ways to get the floating-point representations \(fl(p)\) of a positive number \(p\)</p> <ul> <li><strong>Chopping.</strong> We simply chop off the \(d_{k + 1}, d_{k + 2}, \dots\) and write \(0.d_1d_2\dots d_k \times 10^n\)</li> <li><strong>Rounding.</strong> We add \(5 \times 10^{n - (k + 1)}\) to the number and then chop the result to obtain \(0.\delta_1\delta_2\dots \delta_k \times 10^n\)</li> </ul> <h2 id="errors">Errors</h2> <p>This approximate way of writing numbers is bound to create errors. If \(p\) is a real number and if \(p^*\) is its approximation then the <strong>absolute error</strong> is \(\|p - p ^*\|\) while the <strong>relative error</strong> is \(\|p - p ^*\|/p\) whenever \(p \neq 0\). Relative error is more meaningful as it takes into account the size of the number \(p\).</p> <p><strong>Note.</strong> Relative error can be negative as we take the value of \(p\) in the denominator!</p> <h2 id="significant-digits">Significant digits</h2> <p>We say that the number \(p^*\) approximates \(p\) to \(t\) significant digits if \(t\) is the largest non-negative integer for which</p> <div style="text-align:center;"> $$ \frac{\|p - p^*\|}{p} &lt; 5 \times 10^{-t} $$ </div> <h2 id="finite-digit-arithmetic-1">Finite Digit Arithmetic</h2> <p>The arithmetic in machines in defined by the following -</p> <div style="text-align:center;"> $$ x \oplus y := fl(fl(x) + fl(y)) $$ </div> <h1 id="lecture-3">Lecture 3</h1> <h2 id="major-sources-of-errors">Major sources of errors</h2> <p>One of the major sources of errors is cancellation of two nearly equal numbers. Suppose we have</p> <div style="text-align:center"> $$ fl(x) = 0.d_1d_2\dots d_p\alpha_{p + 1}\dots\alpha_k \times 10^n \\ fl(y) = 0.d_1d_2\dots d_p\beta_{p + 1}\dots\beta_k \times 10^n \\ fl(fl(x) - fl(y)) = 0.\gamma_{p + 1}\dots\gamma_k \times 10^{n - p} $$ </div> <p>In the above set of equations, the difference \(x \ominus y\) has \(k - p\) digits of significance compared to the \(k\) digits of significance of \(x\) and \(y\). The number of significant digits have reduced which leads to errors in further calculations.</p> <p>Another way the errors creep in is when we divide by number of small magnitude or multiply by numbers of large magnitude. This is because the error gets multiplied by a factor which increases its absolute value.</p> <p>Consider the expression \(-b \pm \sqrt{b^2 - 4ac}/2a\). By default, we consider positive square roots. Here, if \(b^2\) is large compared to \(4ac\) then the machine is likely to treat \(4ac\) as zero. How do we get around this error? <strong>Rationalization</strong></p> <div style="text-align:center"> $$ \frac{-b + \sqrt{b^2 - 4ac}}{2a} \times \frac{-b - \sqrt{b^2 - 4ac}}{-b - \sqrt{b^2 - 4ac}} = \frac{-2c}{b + \sqrt{b^2 - 4ac}} $$ </div> <p>​ Notice what happened here. Previously, the roots would have become zero because \(4ac\) could have been approximated as zero. However, this does not happen after rationalization! Also, do note that this won’t work when \(b&lt;0\) as we are considering positive square roots. If \(b&lt;0\), we can use the formula without rationalization. Think about the other root using such cases. Thus, the cancellation error can come in two major ways:</p> <ul> <li>when we cancel two nearly equal numbers, and</li> <li>when we subtract a small number from a big number</li> </ul> <h3 id="errors-propagate">Errors propagate</h3> <p>Once an error is introduced in a calculation, any further operation is likely to contain the same or a higher error.</p> <h2 id="can-we-avoid-errors">Can we avoid errors?</h2> <p>Errors are inevitable in finite arithmetic. There are some measures that we can take to try to avoid errors, or minimize them. For example, a general degree 3 polynomial can be written as a nested polynomial.</p> <div style="text-align:center"> $$ ax^3 + bx^2 + cx + d - x(x(ax + b) + c) + d $$ </div> <p>Computations done using this form will typically have a smaller error as the number of operations has reduced (from 5 to 3). Now, we are done with the first theme of our course - <strong><em>Machine arithmetic</em></strong>.</p> <h1 id="lecture-4">Lecture 4</h1> <h2 id="roots-of-equations">Roots of equations</h2> <p>The zeros of a function can give us a lot of information regarding the function. Why specifically zero? Division is in general more difficult to implement in comparison to multiplication. Division is implemented via the solution to roots of an equation in computers. There are other reasons such as eigenvalue decomposition. We shall see all of this later in the course.</p> <p><strong><em>Theorem.</em></strong> <em>Intermediate Value Theorem</em>. If \(f: [a, b] \to \mathbb R\) is a continuous function with \(f(a)\cdot f(b) &lt; 0\) then there is a \(c \in [a, b]\) such that \(f(x) = 0\).</p> <h3 id="bisection-method">Bisection method</h3> <p>The bisection method is implemented using the above theorem. To begin, we set \(a_1 = a\) and \(b_1 = b\), and let \(p_1\) be the midpoint of \([a, b]\);</p> <ul> <li>If \(f(p_1) = 0\), then we are done</li> <li>If \(f(p_1)f(a_1)&gt;0\), then the subinterval \([p_1, b_1]\) contains a root of \(f\), we then set \(a_2 = p_1\) and \(b_2 = b_1\)</li> <li>If \(f(p_1)f(b_1)&gt;0\), then the subinterval \([a_1, p_1]\) contains a root of \(f\), we then set \(a_2 = a_1\) and \(b_2 = p_1\)</li> </ul> <p>We continue this process until we obtain the root. Each iteration reduces the size of the interval by half. Therefore, it is beneficial to choose a small interval in the beginning. The sequence of \(\{p_i\}\) is a Cauchy sequence. IT may happen that none of the \(p_i\) is a root. For instance, the root may be an irrational number and \(a_1, b_1\) may be rational numbers. There are three criteria to decide to stop the bisection process.</p> <ul> <li>\(\|f(p_n)\| &lt; \epsilon\) - not very good because it may take a long time to achieve it, or that it may be achieved easily and yet \(p_n\) is significantly many steps away from a root of \(f\)</li> <li>\(\|p_n - p_{n-1}\| &lt;\epsilon\) is not good because it does not take the function \(f\) into account. While \(p_n\) and \(p_{n-1}\) may be close enough but the actual root may still be many steps away.</li> <li>\(p_n \neq 0 \text{ and } \frac{\|p_n - p_{n-1}\|}{\|p_n\|} &lt; \epsilon\) looks enticing as it mimics the relative error but again it does not take \(f\) into account.</li> </ul> <p>The bisection method has significant drawbacks - It is relatively slow to converge, and a good intermediate approximation might be inadvertently discarded. However, the method has the important property that is always converges to a solution.</p> <h1 id="lecture-5">Lecture 5</h1> <h2 id="fixed-points-and-roots">Fixed points and roots</h2> <p>A <em>fixed point</em> of \(f : [a,b] \to \mathbb R\) is \(p \in [a,b]\) such that \(f(p) = p\). Finding a fixed point of the function \(f\) is equivalent to finding the root of the function \(g(x) = f(x) - x\). We can create many such functions which give fixed points of \(f\) on solving for the roots of the function.</p> <p><strong><em>Theorem.</em></strong> <em>Fixed Point Theorem</em>. If \(f: [a,b] \to [a,b]\) is continuous then \(f\) has a fixed point. If, in addition, \(f’(x)\) exists on \((a, b)\) and \(\vert f’(x)\vert \leq k &lt; 1\) for all \(x \in (a, b)\) then \(f\) has a unique fixed point in \([a, b]\).</p> <p>The hypothesis is sufficient but not necessary!</p> <h3 id="fixed-point-iteration">Fixed point iteration</h3> <p>We start with a continuous \(f: [a,b] \to [a,b]\). Take any initial approximation \(p_0 \in [a,b]\) and generate a sequence \(p_n = f(p_{n - 1})\). If the sequence \(\{p_n\}\) converges to \(p \in [a, b]\) then</p> <div style="text-align:center"> $$ \begin{align} f(p) &amp;= f(\lim_n p_n) \\ &amp;= \lim_n f(p_n) = \lim_n p_{n + 1}\\ &amp;= p \end{align} $$ </div> <p>This method is called the <em>fixed point iteration method</em>. It’s convergence is not guaranteed.</p> <p>For instance, consider the roots of the equation \(x^3 + 4x^2 - 10 = 0\). The following functions can be used to find the roots using the fixed points.</p> <div style="text-align:center"> $$ \begin{align} x &amp;= g_1(x) = x - (x^3 + 4x^2 - 10)\\ x &amp;= g_2(x) = (\frac{10}{x} - 4x)^{1/2} \\ x &amp;= g_3(x) = \frac{1}{2}(10 - x^3)^{1/2} \end{align} $$ </div> <p>The results using different \(g\)’s in the Fixed Point Iteration method are surprising. The first two functions diverge, and the last one converges. This problem is because the hypothesis of the FPT does not hold in the first two functions. While the derivative \(g’(x)\) fails to satisfy in the FPT, a closer look tells us that it is enough to work on the interval \([1, 1.5]\) where the function \(g_3\) is strictly decreasing.</p> <p>So now we have the question - How can we find a fixed point problem that produces a sequence that reliably and rapidly converges to a solution to a given root-finding problem?</p> <h1 id="lecture-6">Lecture 6</h1> <h2 id="newton-raphson-method">Newton-Raphson method</h2> <p>This is a particular fixed point iteration method. Assume that \(f: [a, b] \to \mathbb R\) is twice differentiable. Let \(p \in [a, b]\) be a solution of the equation \(f(x) = 0\). If \(p_0\) is another point in \([a, b]\) then Taylor’s theorem gives</p> \[\begin{align} 0 &amp;= f(p) \\ &amp;= f(p_0) + (p - p_0)f'(p_0) + \frac{(p - p_0)^2}{2}f''(\xi) \end{align}\] <p>for some \(\xi\) between \(p\) and \(p_0\). We assume that \(\vert p - p_0 \vert\) is very small. Therefore, \(0 \approx f(p_0) + (p - p_0)f’(p_0)\). This sets the stage for the Newton-Raphson method, which starts with an initial approximation \(p_0\) and generate the sequence \(\{p_n\}\) by</p> \[p_n = p_{n - 1} - \frac{f(p_{n - 1})}{f'(p_{n - 1})}\] <p>What is the geometric interpretation of this method? It approximates successive tangents. The Newton-Raphson method is evidently better than the fixed point iteration method. However, it is important to note that \(\vert p - p_0 \vert\) is need to be small so the third term in the Taylor’s polynomial can be dropped.</p> <p><strong><em>Theorem.</em></strong> Let \(f: [a, b] \to \mathbb R\) be twice differentiable. If \(p \in (a, b)\) is such that \(f(p) = 0\) and \(f’(p) \neq 0\), then there exists a \(\delta &gt; 0\) such that for any \(p_0 \in [p - \delta, p + \delta]\), the Newton-Raphson method generates a sequence \(\{p_n\}\) converging to \(p\).</p> <p>This theorem is seldom applied in practice, as it does not tell us how to determine the constant \(\delta\). In a practical application, an initial approximation is selected and successive approximations are generated by the method. These will generally either converge quickly to the root, or it will be clear that convergence is unlikely.</p> <h1 id="lecture-7">Lecture 7</h1> <h3 id="problems-with-the-newton-raphson-method">Problems with the Newton-Raphson method</h3> <p>We have</p> \[p_n = p_{n - 1} - \frac{f(p_{n - 1})}{f'(p_{n - 1})}\] <p>One major problem with this is that we need to compute the value of \(f’\) at each step. Typically, \(f'\) is far more difficult to compute and needs more arithmetic operations to calculate than \(f\).</p> <h2 id="secant-method">Secant method</h2> <p>This method is a slight variation to NR to circumvent the above problem. By definition,</p> \[f'(a) = \lim_{x \to a} \frac{f(a) - f(x)}{a - x}\] <p>If we assume that \(p_{n - 2}\) is reasonable close to \(p_{n - 1}\) then</p> \[f'(p_{n - 1}) \approx \frac{f(p_{n - 1}) - f(p_{n - 2})}{p_{n - 1} - p_{n - 2}}\] <p>This adjustment is called as the <em>secant method</em>. The geometric interpretation is that we use successive secants instead of tangents. Note that we can use the values of \(f(p_{n - 2})\) from the previous calculations to prevent redundant steps. We need two initial guesses in this method.</p> <p>Secant method is efficient in comparison to Newton-Raphson as it requires only a single calculation in each iteration whereas NR requires 2 calculations in each step.</p> <h2 id="the-method-of-false-position">The method of false position</h2> <p>The NR or the Secant method may give successive approximations which are on one side of the root. That is \(f(p_{n - 1}) \cdot f(p_n)\) need not be negative. We can modify this by taking the pair of approximations which are on both sides of the root. This gives the <strong><em>regula falso method</em></strong> or the <em>method of false position</em>.</p> <p>We choose initial approximations \(p_0\) and \(p_1\) with \(f(p_0)\cdot f(p_1) &lt; 0\). We then use Secant method for successive updates. If in any iteration, we have \(f(p_{n - 1})\cdot f(p_n) &gt; 0\), then we replace \(p_{n - 1}\) by \(p_{n - 2}\).</p> <p>The added requirement of the regula falsi method results in more calculations than the Secant method.</p> <h2 id="comparison-of-all-the-root-finding-methods">Comparison of all the root finding methods</h2> <ul> <li>The bisection method guarantees a sequence converging to the root but it is a slow method.</li> <li>The other methods are sure to work, once the sequence is convergent. The convergence typically depends on the initial approximations being very close to the root.</li> <li>Therefore, in general, bisection method is used to get the initial guess, and then NR or the Secant method is used to get the exact root.</li> </ul> <h1 id="lecture-8">Lecture 8</h1> <p>We are reaching the end of the <em>equations in one variable</em> theme.</p> <h2 id="order-of-convergence">Order of convergence</h2> <p>Let \(\{p_n\}\) be a sequence that converges to \(p\) with \(p_n \neq p\) for any \(n\). If there are positive constants \(\lambda\) and \(\alpha\) such that</p> \[\lim_n \frac{\vert p_{n + 1} - p \vert}{\vert p_n - p \vert^\alpha} = \lambda\] <p>then the <strong>order of convergence</strong> of \(\{p_n\}\) to \(p\) is \(\alpha\) with <em>asymptomatic error</em> \(\lambda\). An iterative technique of the form \(p_n = g(p_{n - 1})\) is said to be of order \(\alpha\) if the sequence \(\{p_n\}\) converges to the solution \(p = g(p)\) with order \(\alpha\).</p> <p>In general, a sequence with a high order of convergence converges more rapidly than a sequence with a lower order. The asymptotic constant affects the speed of convergence but not to the extent of the order.</p> <p>Two cases of order are given special attention</p> <ul> <li>If \(\alpha = 1\) and \(\lambda &lt; 1\), the sequence is <strong>linearly convergent</strong>.</li> <li>If \(\alpha = 2\), the sequence is <strong>quadratically convergent</strong>.</li> </ul> <h3 id="order-of-convergence-of-fixed-point-iteration-method">Order of convergence of fixed point iteration method?</h3> <p>Consider the fixed point iteration \(p_{n + 1} = f(p_n)\). The Mean Value Theorem gives</p> \[\begin{align} p_{n + 1} - p &amp;= f(p_n) - f(p) \\ &amp;= f'(\xi_n)(p_n - p) \end{align}\] <p>where \(\xi_n\) lies between \(p_n\) and \(p\), hence \(\lim_n\xi_n = p\). Therefore,</p> \[\lim_n \frac{\vert p_{n + 1} - p \vert}{\vert p_n - p \vert} = \lim_n \vert f'(\xi_n)\vert = \vert f'(p)\vert\] <p>The convergence of a fixed point iteration method is thus <strong>linear</strong> if \(f’(p) \neq 0\) and \(f’(p) &lt; 1\).</p> <p>We need to have \(f’(p) = 0\) for a higher order of convergence.</p> <blockquote> <p>why?</p> </blockquote> <p><strong><em>Theorem.</em></strong> Let \(p\) be a solution of the equation \(x = f(x)\). Let \(f’(p) = 0\) and \(f’'\) be continuous with \(\vert f''(x) \vert &lt; M\) nearby \(p\). Then there exists a \(\delta &gt; 0\) such that, for \(p_0 \in [p - \delta, p + \delta]\), the sequence defined \(p_n = f(p_{n - 1})\) converges at least quadratically to \(p\). Moreover, for sufficiently large values of \(n\)</p> \[\vert p_{n+1} - p \vert &lt; \frac{M}{2}\vert p_n - p \vert^2\] <p>For quadratically convergent fixed point methods, we should search for functions whose derivatives are zero at the fixed point. If we have the root-finding problem for \(g(x) = 0\), then the easiest way to construct a fixed-point problem would be</p> \[\begin{align} f(x) &amp;= x - \phi(x)g(x)\\ f'(x) &amp;= 1 - \phi'(x)g(x) - \phi(x)g'(x) \\ 0 &amp;= f'(p) = 1 - \phi(p)g'(p) \\ &amp; \implies \phi(p) = {g'(p)}^{-1} \end{align}\] <p>where \(\phi\) is a differentiable function, to be chosen later. Therefore, define \(phi(x) = {g’(x)}^{-1}\) which gives</p> \[p_{n + 1} = f(p_n) = p_n - \frac{g(p_n)}{g'(p_n)}\] <p>This is the Newton-Raphson method! We have assumed that \(g’(p) \neq 0\) in the above analysis. The NR/Secant method will not work if this assumption fails.</p> <h2 id="multiplicity-of-a-zero">Multiplicity of a zero</h2> <p>Let \(g: [a, b] \to \mathbb R\) be a function and let \(p \in [a, b]\) be a zero of \(g\). We say that \(p\) is a <strong>zero of multiplicity</strong> \(m\) of \(g\) if for \(x \neq p\), we can write \(g(x) = (x - p)^mq(x)\) with \(\lim_{x \to p}q(x) \neq 0\).</p> <p>Whenever \(g\) has a simple zero (\(m = 1\)) at \(p\), then the NR method works well for \(g\). However, NR does not give a quadratic convergence if the order of the zero is more than 1.</p> <h1 id="lecture-9">Lecture 9</h1> <p><strong>Note.</strong> \(n\)-digit arithmetic deals with \(n\) significant digits and not \(n\) places after the decimal.</p> <h2 id="order-of-the-fixed-point-iteration-method">Order of the fixed point iteration method</h2> <p>Summarizing the last lecture we have</p> <ul> <li>If we have a function \(g(x)\) whose roots are to be found, we can convert it to a fixed point problem by appropriately constructing a \(f(x)\).</li> <li>If we construct \(f(x)\) such that it’s derivative is non-zero at the root, then the fixed point iteration method is <u>linear</u>.</li> <li>Otherwise, if the derivative is zero, then the fixed point iteration method is quadratic or higher. For example, we constructed such a \(f(x)\) which mirrored the Newton-Raphson method.</li> <li>In the Newton-Raphson method itself, if the root is a simple zero of \(g\), the method has quadratic convergence. However, if it is not a simple zero if \(g\) then the method may not have a quadratic convergence.</li> </ul> <p>Can we modify NR to overcome the limitation of multiplicity of the zero?</p> <h2 id="modified-newton-raphson">Modified Newton-Raphson</h2> <p>For a given \(g(x)\), we define a function \(\mu\)</p> \[\mu(x) = \frac{g(x)}{g'(x)}\] <p>If \(x = p\) is a xero of \(g\) with multiplicity \(m\), we have</p> \[\mu(x) = (x - p)\frac{q(x)}{mq(x) + (x - p)q'(x)}\] <p>Notice that \(x = p\) is a simple root of \(\mu\). Further, assume \(g, q\) are continuous. Then, if \(g(x)\) has no other zero in a neighborhood of \(x = p\) then \(\mu(x)\) will also not have any other zero in that neighborhood. We can now apply Newton-Raphson method to \(\mu(x)\).</p> <p>The fixed point iteration is given by</p> \[\begin{align} f(x) &amp;= x - \frac{\mu(x)}{\mu'(x)} \\ &amp;= x - \frac{g(x)/g'(x)}{(g'(x)^2 - g(xg''(x)))/g'(x)^2} \\ &amp;= x - \frac{g(x)g'(x)}{g'(x)^2 - g(x)g''(x)} \end{align}\] <p>This iteration will converge to \(p\) with at least the quadratic order of convergence. The only theoretical drawback with this method is that we now need to compute \(g’’(x)\) at each step. Computationally, the denominator of the formula involves cancelling two nearly equal terms (\(x = p\) is a root of both \(g, g’\)).</p> <p>Note that if \(x = p\) is a simple zero, the modified Newton-Raphson still bodes well. It’s just that there are a lot more calculations in the modified NR method.</p> <h2 id="an-other-methods">An other methods?</h2> <p>There are many methods other than the 4 we considered so far. Suppose that \(\{p_n\}\) converges to \(p\) linearly. For large enough \(n\), we have \((p_{n + 1} - p)^2 \approx (p_n - p)(p_{n + 2} - p)\) which further gives</p> \[p \approx p_n - \frac{(p_{n + 1} - p_n)^2}{p_{n + 2} - 2p_{n + 1} + p_n} = \hat p_n\] <p>This is called <strong>Aitken’s</strong> \(\mathbf{\Delta^2}\)<strong>-method</strong> of accelerating convergence. So, if we have a sequence \(\{p_n\}\) converging to \(p\) linearly, we can come up with an alternate sequence \(\{\hat p_n\}\) using the original sequence that converges faster.</p> <p>This brings us to the end of the second theme of our course - <em>Equations in one variable</em>.</p> <h1 id="lecture-10">Lecture 10</h1> <p>We begin the third theme of our course - <em>Interpolation</em></p> <p>Polynomials are very well studied functions. They have the form \(P(x) = a_nx^n + \cdots + a_1x + a_0\). Given any continuous function \(f: [a, b] \to \mathbb R\), there exists a polynomial that is as close to the given function as desired. In other words, we can construct a polynomial which exactly matches the function in a finite interval. This is known as <strong><em>Weierstrass approximation theorem</em></strong>. Another reason to prefer polynomials is that the derivatives of polynomials are also polynomials.</p> <h2 id="taylor-polynomials">Taylor polynomials</h2> <p>We can consider the polynomials formed by Taylor’s theorem. However, these polynomials approximate the function only at a single point. The advantage of using these polynomials is that the error between the function and the polynomial can be determined accurately. For ordinary computational purposes it is more efficient to use methods that include information at various points.</p> <h2 id="lagrange-interpolating-polynomials">Lagrange interpolating polynomials</h2> <p>Let \(f\) be a function with \(f(x_0) = y_0\). Is there a polynomial \(P(x)\) with \(P(x_0) = y_0\).</p> <p>The simplest case is \(P(x) = y_0\). If we have two points \(x_0\) and \(x_1\), then we can have \(P(x) = y_0\frac{x - x_1}{x_0 - x_1} + y_1\frac{x - x_0}{x_1 - x_0}\) . We can generalize this for more number of points.</p> <p>Let \(x_0, x_1, \dots, x_n\) be distinct \((n + 1)\)-points and let \(f\) be a function with \(f(x_i) = y_i, \forall i \in [n]\). We want to find a polynomial \(P\) that equals \(f\) at these points. To do this, we first solve \(n + 1\) special problems, where \(y_i = \delta_{i, n + 1}\). We find polynomials \(L_{n, i}\) with</p> \[L_{n, i}(x_j) = \delta_{i, j} = \cases{0 &amp; i $\neq$ j \\ 1 &amp; i = j}\] <p>For a fixed \(i\), \(L_{n, i}(x_j) = 0\) for \(j \neq i\). So \((x - x_j)\) divides \(L_{n, i}(x)\) for each \(j \neq i\). Since the points \(x_i\) are all distinct, we have that the product of all such \((x - x_j)\)‘s divides \(L_{n, i}(x)\). We define \(L_{n, i}(x)\) as</p> \[L_{n, i}(x) = \frac{(x - x_0)\dots(x - x_{i - 1})(x - x_{i + 1})\dots (x - x_n)}{(x_i - x_0)\dots(x_i - x_{i - 1})(x_i - x_{i + 1})\dots(x_i - x_n)}\] <p>then \(L_{n, i}(x_j) = \delta_{i, j}\). Now, \(P\) can be constructed as</p> \[P(x) = y_0L_{n, 0}(x) + \dots + y_nL_{n, n}(x)\] <p>The validity of this polynomial can be checked easily.</p> <h1 id="lecture-11">Lecture 11</h1> <blockquote> <p>What if you take a linear function and use \(n &gt;2\) points for Lagrange interpolation? Will the final function be linear? It should be.</p> <p>For example, in class we considered \(f(1) = 1\) and \(f(2) = 1\). These values gave a constant polynomial.</p> </blockquote> <p>In general, for \((n + 1)\)-points, the interpolating polynomial will have degree <strong>at most</strong> \(n\).</p> <h2 id="uniqueness-of-the-interpolating-polynomial">Uniqueness of the interpolating polynomial</h2> <p>For a given set of \((n + 1)\) points, we can have infinitely many polynomials which interpolate it. However, there exists a <strong>unique polynomial with degree</strong> \(\mathbf {\leq n}\). This result follows from the well-known theorem -</p> <p><strong><em>Theorem.</em></strong> A polynomial of degree \(n\) has at most \(n\) distinct zeroes.</p> <p><strong>Corollary.</strong> A polynomial with degree \(\leq n\) with \((n + 1)\) zeroes is the zero polynomial.</p> <h2 id="error-of-the-interpolating-polynomial">Error of the interpolating polynomial</h2> <p><strong><em>Theorem.</em></strong> Let \(f:[a,b] \to \mathbb R\) be \((n + 1)\)-times continuously differentiable. Let \(P(x)\) be the polynomial interpolating \(f\) at distinct \((n + 1)\) points \(x_0, x_1, \dots, x_n \in [a, b]\). Then, for each \(x \in [a, b]\), there exists \(\xi(x) \in (a, b)\) with</p> \[f(x) = P(x) + \frac{f^{(n + 1)}(\xi(x))}{(n + 1)!}(x - x_0)(x - x_1)\cdots (x - x_n)\] <blockquote> <p>How? Intuition?</p> </blockquote> <p>Using the above theorem, we can calculate the <u>maximum possible value of the absolute error</u> in an interval.</p> <p><strong>Note.</strong> While checking for extreme values in an interval, do not forget to check the value of the function at the edge of the interval!</p> <h1 id="lecture-12">Lecture 12</h1> <p><strong>Note.</strong> The value of \(\xi(x)\) for the error calculation depends on the point \(x\) at which error is being calculated.</p> <h3 id="practical-difficulties-with-lagrange-polynomials">Practical difficulties with Lagrange Polynomials</h3> <p>To use the error form, we need some information about \(f\) in order to find its derivative. However, this is often not the case. Also, the computations of the lower degree interpolating polynomials does not quite help the computations of the higher degree ones. We would like to find a method that helps in computing the interpolating polynomials cumulatively.</p> <h3 id="cumulative-calculation-of-interpolating-polynomials">Cumulative calculation of interpolating polynomials</h3> <p>Let us assume that \(f\) is given on distinct nodes \(x_0, x_1, \dots, x_n\). Now, the constant polynomial for the node \(x_0\) will be \(P_0(x) = f(x_0)\) and that for the node \(x_1\) will be \(Q_0(x) = f(x_1)\). Using Lagrange interpolation, we have</p> \[\begin{align} P_1(x) &amp;= \frac{x - x_1}{x_0 - x_1}f(x_0) + \frac{x - x_0}{x_1 - x_0}f(x_1) \\ &amp;= \frac{(x - x_1)P_0(x) - (x - x_0)Q_0(x)}{(x_0 - x_1)} \end{align}\] <p>Can we generalize this? Let us try to construct the quadratic polynomial. Now, suppose we have \(P_1(x)\) and $Q_1(x)$. The quadratic polynomial for the nodes \(x_0, x_1, x_2\) is given by,</p> \[\begin{align} P_2(x) &amp;= \frac{x - x_2}{x_0 - x_2}\left[\frac{x - x_1}{x_0 - x_1}f(x_0) + \frac{x - x_0}{x_1 - x_0}f(x_1)\right] \\ - &amp;\frac{x - x_0}{x_0 - x_2}\left[\frac{x - x_2}{x_1 - x_2}f(x_1) + \frac{x - x_1}{x_2 - x_1}f(x_2)\right] \\ \\ &amp;= \frac{(x - x_2)P_1(x) - (x - x_0)Q_1(x)}{x_0 - x_2} \end{align}\] <p>We shall see the general formula in the next lecture.</p> <h1 id="lecture-13">Lecture 13</h1> <p>Before we move on to the general formula, let us take the previous calculations one step further. Suppose we had to calculate the cubic polynomial in terms of the quadratic polynomials. The tedious way to do this is to expand each formula and substitute. We also have an easy way to do this. Recall the ‘unique polynomial’ theorem from last week. If we guess the formula of the cubic polynomial using induction, then all we have to do is check the value of the function at the 4 points which define it. If the value matches, then it is the polynomial we are looking for due to uniqueness.</p> <h2 id="nevilles-formula">Neville’s formula</h2> <p>Let \(f\) be defined on \(\{x_0, x_1, \dots, x_n\}\). Choose two distinct nodes \(x_i\) and \(x_j\). Let \(Q_i\) be the polynomial interpolating \(f\) on all nodes except \(x_i\), and let \(Q_j\) be the one interpolating \(f\) on all nodes except \(x_j\). If \(P\) denotes the polynomial interpolating \(f\) on all notes then</p> \[P(x) = \frac{(x - x_j)Q_j(x) - (x - x_i)Q_i(x)}{x_i - x_j}\] <p>In Neville’s formula we can get the interpolating for higher degree from any two polynomials for two subsets of nodes which are obtained by removing a single node. Through such cumulative calculations, we can calculate the interpolating polynomials up to a certain degree until we get the required accuracy. Neville’s method gives the values of the interpolating polynomials at a specific point, without having to compute the polynomials themselves.</p> <h2 id="divided-differences">Divided Differences</h2> <p>Given the function \(f\) on distinct \((n + 1)\) nodes, there is a unique polynomial \(P_n\) interpolating \(f\) on these nodes. We define \(f[x_0, \dots, x_n]\) to be the coefficient of \(x^n\) in \(P_n\). Now, it follows readily that the value of \(f[x_0, \dots, x_n]\) does not depend on the ordering of the nodes \(x_i\). Now, we shall try to get a recurrence formula for the coefficients \(f[x_0, \dots, x_n]\).</p> <p>Let \(P_{n - 1}\) and \(Q_{n - 1}\) be the polynomials interpolating \(f\) on the nodes \(x_0, \dots, x_{n - 1}\) and \(x_1, \dots, x_n\) respectively. We can get \(P_n\) from these two polynomials using Neville’s method. The coefficient of \(x^n\) in \(P_n\) is then</p> \[\frac{\text{coefficient of } x^{n - 1} \text{ in } Q_{n - 1} - \text{coefficient of } x^{n - 1} \text{ in } P_{n - 1}}{x_n - x_0} \\ = \frac{f[x_1, \dots, x_n] - f[x_0, \dots, x_{n - 1}]}{x_n - x_0}\] <p>Also note that for \(i &lt; n, P_n(x_i) = P_{n - 1}(x_i)\). That is, \(P_n - P_{n - 1} = \alpha(x - x_0)\dots (x - x_{n - 1})\) where \(\alpha\) is a real number. Hence, \(f[x_0, \dots, x_n] = \alpha\) and we have</p> \[P_n = P_{n - 1} + (x - x_0)\dots (x - x_{n - 1})f[x_0, \dots, x_n]\] <p>This formula is known as Newton’s finite differences formula.</p> <h1 id="lecture-14">Lecture 14</h1> <p>We have</p> \[P_n - P_{n - 1} = f[x_0, \dots, x_n](x - x_0)\dots (x - x_{n - 1}) \\ \\ f[x_0, \dots, x_n] = \frac{f[x_1, \dots, x_n] - f[x_0, \dots, x_{n - 1}]}{x_n - x_0}\] <p>Since the order of the nodes does not matter, we can traverse the recursion in a forward/backward manner. The forward formula is given by,</p> \[P_n(x) = f(x_0) + f[x_0, x_1](x - x_0) + f[x_0, x_1, x_2](x - x_0)(x - x_1) + \\ \cdots + f[x_0, x_1, \dots, x_n](x - x_0)\cdots (x - x_{n - 1})\] <p>The backward formula simply replaces \(i\) by \(n - i\) for \(i \in [0, \dots, n]\). For clarity, look at the following example.</p> <p><img src="/assets/img/Numerical Analysis/image-20220127150002932.png" alt="image-20220127150002932"/></p> <h3 id="nested-form-of-the-interpolating-polynomial">Nested form of the interpolating polynomial</h3> \[P_n(x) = f(x_0) + (x - x_0)\big[f[x_0, x_1] + (x - x_1)[f[x_0, x_1, x_2] + \\ \cdots + (x - x_{n - 1})f[x_0, \dots, x_n]\big]\] <p>Neste form of the interpolating polynomial is useful for computing the polynomials \(P_n\) effectively.</p> <h3 id="divided-differences-as-a-function">Divided differences as a function</h3> <p>We now give a definition of the divided differences when some of the nodes may be equal to each other. By the Mean Value Theorem, \(f[x_0, x_1] = f’(\xi)\) for some \(\xi\) between \(x_0\) and \(x_1\). In fact, we also have the following theorem,</p> <p><strong><em>Theorem.</em></strong> If \(f\) is \(n\)-times continuously differentiable on \([a, b]\) then</p> \[f[x_0, \dots, x_n] = \frac{f^{(n)}(\xi)}{n!}\] <p>for some \(\xi \in [a, b]\).</p> <p>Since \(f[x_0, x_1] = f'(\xi)\) for some \(\xi\) between \(x_0\) and \(x_1\), we define \(f[x_0, x_0] = f’(x_0) = \lim_{x_1 \to x_0}f[x_0, x_1]\). Similarly, we define \(f[x_0, \dots, x_n]\) in a similar way using limits. For instance,</p> \[f[x_0, x_1, x_0] = \frac{f[x_0, x_1]- f'(x_0)}{x_1 - x_0}\\ f[x_0, x_0, x_0] = f^{(2)}(x_0)/2\] <p>We have thus defined \(f[x_0, \dots, x_n]\) in general. Now, by letting the last \(x_n\) as variable \(x\), we get a function of x: \(f[x_0, \dots, x_{n - 1}, x]\). This function is continuous.</p> \[f[x_0, x] = \begin{cases} \frac{f(x) - f(x_0)}{x - x_0} &amp; x \neq x_0 \\ f'(x_0) &amp; x = x_0 \end{cases}\] <h1 id="ma214-post-midsem-notes">MA214 post-midsem notes</h1> <ul> <li> <p><strong>Composite numerical integration</strong> - Newton-Cotes doesn’t work for large intervals. Therefore, we divide the interval into sub-parts. We are essentially doing a spline sorta thing instead of a higher degree polynomial. \(\begin{align} \int_a^b f(x)dx &amp;= \sum_{j = 1}^{n/2} \left\{\frac{h}{3}[f(x_{2j - 2} + 4f(x_{2j - 1} + f(x_{2j}] - \frac{h^5}{90}f^{(4)}(\xi_j)\right\} \\ &amp;= \frac{h}{3}\left[f(a) + 2\sum_{j = 1}^{n/2 - 1}f(x_{2j}) + 4\sum_{j = 1}^{n/2}f(x_{2j - 1}) + f(b)\right] - \frac{b - a}{180}h^4f^{(4)}(\mu) \end{align}\)</p> </li> <li> <p>Error in composite trapezoidal rule is \(\frac{b - a}{12}h^2f''(\mu)\), and in composite Simpson’s rule is \(\frac{b - a}{180}h^4f''(\mu)\).</p> </li> <li> <p>The round-off error does not depend on the number of calculations in the composite methods. We get \(e(h) \leq hn\epsilon = (b - a)\epsilon\) Therefore, integration is stable.</p> </li> <li> <p><strong>Adaptive Quadrature method</strong> - \(S(a, b) - \frac{h^5}{90}f^{(4)}(\xi) \approx S(a, \frac{a+ b}{2}) + S(\frac{a + b}{2}, b) - \frac{1}{16}\frac{h^5}{90}f^{(4)}(\xi')\) <strong>We will assume \(f^{(4)}(\xi) \approx f^{(4)}(\xi’)\).</strong> Using this assumption, we get that composite Simpson’s rule with \(n = 2\) is <strong>15</strong> times better than normal Simpson’s rule. If one of the subintervals has error more than \(\epsilon/2\), then we divide it even further.</p> <blockquote> <p>Check this properly!</p> </blockquote> </li> <li> <p><strong>Gaussian Quadrature method</strong> -</p> <p>Choose points for interval in an optimal way and not equally spaced. We choose \(x_i\) and \(c_i\) to minimise the error in \(\int_a^bf(x)dx \approx \sum_{i = 1}^nc_if(x_i)\) There are \(2n\) parameters, then the largest class of polynomials is the set of polynomials with degree \(2n - 1\) for the approximation to be exact.</p> <p><strong>Note.</strong> Work with special cases of polynomials like \(1, x, x^2, \dots\) to get the values of the coefficients easily. (because all polynomials in the set must satisfy the approximation)</p> <p><strong>Legendre polynomials</strong> - There exist polynomials \(\{P_n(x)\}\) for \(n = 0, 1, \dots\)satisfying</p> <ul> <li>\(P_n(x)\) is a monic polynomials</li> <li>\(\int_{-1}^1P(x)P_n(x) = 0\) whenever the degree of \(P(x)\) is less than \(n\).</li> </ul> <p>For example, \(P_0(x) = 1, P_1(x) = x\). \(P_2\) can be computed from \(P_0\) and \(P_1\) as \(\int P_0P_2\) and \(\int P_1P_2\) are 0.</p> <p><img src="/assets/img/Numerical Analysis/image-20220323155057163.png" alt="image-20220323155057163"/></p> </li> <li> <p><strong>Multidimensional integrals</strong> - Composite trapezoidal rule has square of the number of function evaluations required for a single integral (for 2D).</p> <p><img src="/assets/img/Numerical Analysis/image-20220323161302337.png" alt="image-20220323161302337"/></p> <blockquote> <p>See if problems to be practiced here.</p> </blockquote> </li> <li> <p><strong>Improper integrals</strong> - Function is unbounded or the interval is unbounded. We will deal with functions where the function is unbounded on the left end.</p> </li> <li> <blockquote> <p><strong><em>Aside.</em></strong> \(a^b\) is defined as \(\exp(b \log a)\) in the complex domain. \(\log\) is not defined as the inverse of \(\exp\) as \(\exp\) is neither surjective (doesn’t take the value 0) nor injective (periodic in \(\mathbb C\)). \(\exp\) is defined by the power series and so is \(\log\). The solution set of \(z\) for \(e^z = w\) where \(z, w \in \mathbb C\) is given by \(\{\log |w| + \iota(\arg w + 2\pi k) : k \in \mathbb Z\}\)</p> </blockquote> <p>If \(f(x) = \frac{g(x)}{(x - a)^p}\) where \(0 &lt; p&lt; 1\) and \(g: [a,b] \to \mathbb R\) is continuous then the improper integral \(\int_a^b f(x)dx\) exists. Assume \(g\) is 5-times continuously differentiable. We can estimate the integral of \(f(x)\) using the following</p> <ul> <li>Get \(P_4(x)\) which is the 4th degree Taylor’s polynomial of \(g\).</li> <li>Get the <strong>exact</strong> value of \(\int_a^b P_4(x)/(x - a)^p\).</li> <li>Get the value of the difference by defining the value at \(z = a\) as \(0\) using composite Simpson’s rule.</li> </ul> <blockquote> <p>Why can’t we do Simpson’s on everything? That would lead to a similar thing. <em>Think</em>. Also, we require 4 times continuously differentiable for Simpson’s</p> </blockquote> <p>The other type of improper integral involves infinite limits of integration. The basic integral is of the type \(\int_a^\infty 1/x^p dx\) for \(p &gt; 1\). Then, we substitute \(x = 1/t\) and proceed.</p> </li> <li> <p><strong><em>Ordinary Differential Equations</em></strong> We shall develop numerical methods to get solutions to ODEs at a given point. Then, we can use interpolation to get an approximate continuous solution.</p> <p>A function \(f(t, y)\) is said to satisfy a <strong>Lipschitz condition</strong> in the variable \(y\) on a set \(D \subset \mathbb R^2\) if a constant \(L &gt; 0\) exists with \(\mid f(t, y_1) - f(t, y_2) \mid \leq L\mid y_1 - y_2 \mid\) <img src="/assets/img/Numerical Analysis/image-20220323191549861.png" alt="image-20220323191549861"/></p> <p>IVP is well-posed if it has a unique solutions, and an IVP obtained by small perturbations also has a unique solution. We consider IVPs of the form \(dy/dt = f(t, y)\), \(a \leq t \leq b\), \(y(a) = \alpha\).</p> <p><img src="/assets/img/Numerical Analysis/image-20220323193242124.png" alt="image-20220323193242124"/></p> </li> <li> <p><strong>Euler’s method</strong> - We generate <em>mesh points</em> and interpolate. As we are considering IVPs of a certain form, we can just use 1st degree Taylor’s polynomial to approximate the solution to the IVP. We take \(q_0 = \alpha\) and \(w_{i + 1} = w_i + hf(t_i, w_i)\) for \(i \geq 0\) where \(w_i \approx y(t_i)\). The error grows as \(t\) increases, but it is controlled due to the stability of Euler’s method. It grows in a linear manner wrt to \(h\).</p> </li> <li> <p><u>Error in Euler’s method</u> - Suppose \(\mid y''(t) \mid \leq M\), then \(\mid y(t_i) - w_i \mid \leq \frac{hM}{2L}(\exp (L(t_i - a)) - 1)\). What about round-off errors? We’ll get an additional factor of \(\delta/hL\) in the above expression along with the constant \(\delta_0 \exp (L(t_i - a))\). Therefore, \(h = \sqrt(2\delta/M)\).</p> </li> <li> <p><strong>Local truncation error</strong> - <strong>\(\tau_{i + 1}(h) = \frac{y_{i + 1} - y_i}{h} - \phi(t_i, y_i)\).</strong> It is just \(hM/2\) for Euler’s method (\(\phi\) refers to the Taylor polynomial). We want truncation error to be as \(\mathcal O(h^p)\) for as large \(p\) as possible.</p> <p><strong>Higher order Taylor methods</strong> - Assume \(f\) is \(n\)-times continuously differentiable. We get \(\mathcal O(n)\) for \(n\)th degree Taylor polynomial. However, the number of computations are a bit high.</p> <blockquote> <p>Practice problems on this</p> </blockquote> </li> <li> <p>What about interpolation? We should use cubic Hermite interpolation (to match the derivative too).</p> </li> <li> <p>Now, we try to reduce the computation of higher order derivatives. <strong>Runge-Kutta methods</strong> - Based off Taylor’s theorem in two variables.</p> <p><img src="/assets/img/Numerical Analysis/image-20220323210229698.png" alt="image-20220323210229698"/></p> <p>Order 2- We get \(a = 1, \alpha = h/2, \beta = f(t, y)h/2\) by equating \(af(t + \alpha, y + \beta)\) to \(T(t, y) = f(t, y) + h/2 f'(t, y)\). This specific Runge-Kutta method of Order 2 is known as the <strong>midpoint-method</strong>. (2D of Taylor order 2) \(w_{i + 1} = w_i + hf\left(t_i + \frac{h}{2}, w_i + \frac h 2 f(t_i, w_i)\right)\) The number of nesting \(f\)‘s represents the order of the differential equation.</p> <p>Suppose we try the form \(a_1f(t, y) + a_2 f(t + \alpha_2, y + \delta_2 f(t, y))\) containing 4 parameters to approximate. We still get \(\mathcal O(n^2)\) as there is only one nesting.</p> </li> <li> <p>However, the flexibility in the parameters allows us to derive the <strong>Modified Euler method</strong>. \(w_{i + 1} = w_i + \frac h 2[f(t_i, w_i) + f(t_{i + 1}, w_i + hf(t_i, w_i))]\) <strong>Higher-order Runge-Kutta methods</strong> - The parameter values are used in the <strong>Heun’s method</strong>.</p> <p><img src="/assets/img/Numerical Analysis/image-20220323212528107.png" alt="image-20220323212528107"/></p> <p>The most common Runge-Kutta is order 4 whose local truncation error is \(\mathcal O(n^4)\).</p> <p><img src="/assets/img/Numerical Analysis/image-20220323212907583.png" alt="image-20220323212907583"/></p> </li> <li> <p><u>Error control in Runge-Kutta methods</u>. Adaptive step size for lower error. Single step approximation - uses \(i-\) for \(i\). Given an \(\epsilon &gt; 0\), we need to be able to give a method that gives \(\mid y(t_i) - w_i\mid &lt; \epsilon\). \(y(t_{i + 1}) = y(t_i) + h\phi(t_i, y(t_i), h) + \mathcal O(h^{n + 1}) \\\) Local truncation error assumes \(i\)th measurement is correct to find error in the \(i + 1\)th measurement. We get \(\tau_{i + 1}(h) \approx \frac 1 h (y(t_{i + 1}) - w_{i + 1})\) assuming \(y_i \approx w_i\). For \(n\)th degree truncation error, we get \(\tau_{i + 1}(h) \approx \frac 1 h (w^{n + 1}_{i + 1} - w^{n}_{i + 1})\). After a few approximations, we get that the local truncation error changes by a factor of \(q^n\) when the step size changes by a factor of \(q\).</p> </li> <li> <p><strong>Runge-Kutta-Fehlberg Method</strong> - It uses a Runge-Kutta method with local truncation error of order five. We change the step size if \(q &lt; 1\). These methods are just an analogue of adaptive quadrature methods of integrals.</p> </li> <li> <p><strong>Multi-step methods</strong>. Methods that use the approximation at more than one previous mesh point to determine the approximation at the next point. The general equation is implicit where \(w_{i + 1}\) occurs on both sides of the equation. Implicit methods are more accurate than explicit methods.</p> <p><img src="/assets/img/Numerical Analysis/image-20220324124220485.png" alt="image-20220324124220485"/></p> </li> <li> <p><strong>Predictor-Corrector Method</strong> - How do we solve implicit methods? We can use the root-finding procedures we learnt. All of this can get quite cumbersome. We just use implicit methods to improve the prediction of the explicit methods. We insert the solution of explicit method (prediction) and insert it on the rhs of the implicit method (correction).</p> </li> <li> <p><strong>Consistency and Convergence</strong></p> <p>One-step difference method is <strong>consistent</strong> if \(\lim_{h \to 0}\max_{1 \leq i \leq n}\mid \tau_i(h)\mid = 0\). But we also need the global measure - <strong>convergence</strong> - \(\lim_{h \to 0}\max_{1 \leq i \leq n}\mid y_i(t_i) - w_i\mid = 0\)</p> <p><strong>stability</strong> considering round-off errors. For the function \(\phi\) satisfying Lipschitz condition with a \(h_0\), the one-step difference method <strong>is convergent iff it is consistent</strong>. The local truncation error is bounded, and we get \(\mid y(t_i) - q_i \mid \leq \frac {\tau(h)}{L}e^{L(t_i - a)}\).</p> <p>Analysis of consistency, convergence, and stability is difficult for multi-step methods. Adams-* methods are stable.</p> </li> <li> <p><strong><em>Numerical Linear Algebra</em></strong> - Basics - \(Ax = b\) has a unique solution iff \(A\) is invertible, and it does not have a unique or has no solution otherwise.</p> <p><strong>Cramer’s rule</strong> - \(x_j = \frac{\det A_j}{\det A}\). However, this is cumbersome. Determinant of an upper triangular matrix is product of the diagonal entries.</p> <p><strong>Gaussian Elimination Method</strong> - \(A = LU\) for most matrices \(A\). \(L\) is a lower triangular matrix and \(U\) is an upper triangular matrix. Form the augmented matrix \([ A \mid b]\). Linear combination of rows and swapping of rows can be performed. What is the total number of arithmetic operations?</p> <p>For converting to triangular - We use \((n - i)\) divisions for each row and \((n - i + 1)\) multiplications for each column of each row. Also, we have \((n - i)(n - i + 1)\) subtractions. In total, we have \((n - i)(n - i + 2)\) multiplications. Summing, we get \(\mathcal O(n^3)\) multiplications (\((2n^3 + 3n^2 - 5n)/6\)) and subtractions \(((n^3 - n)/3)\).</p> <p>For back substitution - multiplication is \((n^2 + n)/2\) and subtraction is \((n^2 - n)/2\).</p> </li> <li> <p>We have not considered finite digit arithmetic for GEM previously. The error dominates the solution when the pivot has a low absolute value. In general, we need to ensure that the pivot does not have very low magnitude by interchanging rows (followed by interchanging columns for triangular form if needed) - <strong>partial pivoting</strong>. However, this might not be enough to get rid of the rounding error. Therefore, we need to consider <strong>scaled partial pivoting</strong>. Define \(s_i\) as the maximum magnitude in the \(i\)th row. Now, the first pivot is chosen by taking the row with the maximum value of \(a_{i1}/s_i\). The operation count order still remains the same. You need not calculate scale factors more than once.</p> </li> <li> <p><strong>LU Decomposition</strong> - The conversion of \(A\) to a triangular form using the above method can be represented as a sequence of matrix multiplications (if \(A\) does not require any row interchanges). The inverse of a matrix depicting operations on \(A\) can be seen a matrix depicting the same inverse operations on \(A\). In the end, we get \(A = (L^{(1)} \dots L^{(n - 1)})(M^{(1)}\dots M^{(n-1)}A)\) where each \(M^{(i)}\) represents the action that uses \(A_{ii}\) as a pivot. Once we get \(L\) and \(U\), we can solve \(y = Ux\) and \(Ly = b\) separately. There are multiple decompositions possible which are eliminated by imposing conditions on the triangular matrices. One such condition is setting \(L_{ii} = U_{ii}\) which is known as <em>Cholesky Decomposition</em>.</p> <p>We had assumed that row interchanges are not allowed. However, we can build <strong>permutation matrices</strong> for row interchanges which will be of the form of an identity matrix with row permutations.</p> <p>Therefore, we get <strong>PLU decomposition</strong>.</p> </li> <li> <p><strong>Diagonally dominant matrices</strong> - An \(n \times n\) matrix \(A\) is said to be diagonally dominant when \(\mid a_{ii} \mid \geq \sum^n \mid a_{ij} \mid\) for all rows. <u>A strongly diagonally dominant matrix is invertible</u>. Such matrices will not need row interchanges, and the computations will be stable wrt the round off errors.</p> <blockquote> <p>Why this instead of \(\mid a_{ii} \mid \geq \max \mid a_{ij} \mid\)</p> </blockquote> <p>A matrix \(A\) is <strong>positive definite</strong> if \(x^tAx &gt; 0\) for every \(x \neq 0\). We shall also consider \(A\) to be symmetric in the definition. Every positive definite matrix is invertible, \(A_{ii} &gt; 0\) for each \(i\), \((A_{ij})^2 &lt; A_{ii}A_{jj}\), and \(\max_{1\leq k, j \leq n} \mid A_{kj} \mid \leq \max_{1 \leq i \leq n}\mid A_{ii}\mid\).</p> <p>A <strong>leading principal submatrix</strong> of matrix \(A\) is the top-left \(k \times k\) submatrix of \(A\). \(A\) <u>is positive definite iff each leading principal submatrix of</u> \(A\) <u> has a positive determinant.</u></p> <p>Gaussian Elimination on a symmetric matrix can be applied without interchanging columns iff the matrix is positive definite.</p> <p>A matrix \(A\) is positive definite iff \(A = LDL^t\) where \(L\) is lower triangular with 1’s on the diagonal and \(D\) is a diagonal matrix with positive diagonal entries. Alternatively, \(A\) is positive dfinite iff \(A = LL^t\) where \(L\) is a lower triangular matrix. <strong>Note.</strong> Positive definite is stronger than Cholesky decomposition.</p> </li> <li> <p>We have been seeing direct methods for solving \(Ax = b\). We shall see some iterative methods now. We need a distance metric to check the closeness of the approximation. We will consider \(l_2\) distance = \(\| x - y\|_2 = \left( \sum_{i = 1}^n (x_i - y_i)^2 \right)^{1/2}\) and \(l_\infty\) distance = \(\| x - y\|_2 = \max_{i = 1}^n \mid x_i - y_i \mid\). Also, \(\|x - y\|_\infty \leq \|x - y\|_2 \leq \sqrt n\|x - y\|_\infty\). We also need to consider distances in matrices.</p> </li> <li> <p><strong>Distances in Matrices</strong> - \(\|A\|_2 = \max_{\|x\|_2 = 1} \|Ax\|_2\) and \(\|A\|_\infty = \max_{\|x\|_\infty = 1} \|Ax\|_\infty\). The \(l_\infty\) can be directly calculated using \(\|A\|_\infty = ]max_{i} \sum_j \mid A_{ij} \mid\).</p> </li> <li> <p><strong>eigenvalues, eigenvectors</strong> - A <strong>non-zero</strong> vector \(v \in \mathbb R^n\) is an eigenvector for \(A\) if there is a \(\lambda \in \mathbb R\) such that \(Av = \lambda v\) and \(\lambda \in \mathbb R\) is the eigenvalue. The <strong>characteristic polynomial</strong> of \(A\) is \(\det(A - \lambda I)\). We do not consider the complex roots that are not real for these polynomials to calculate eigenvalues.</p> <p><strong>Spectral radius</strong> - \(\rho(A) = \max \mid \lambda \mid\). Then, we have the relation that \(\|A\|_2 = [\rho(A^tA)]^{1/2}\) and also \(\rho(A) \leq \|A\|_2\) and \(\rho(A) \leq \|A\|_\infty\).</p> <p><strong>Convergent matrices</strong> - It is of particular importance to know when powers of a matrix become small, that is, when all the entries approach zero. An \(n \times n\) matrix \(A\) is called convergent if for each \(1 \leq i, j \leq n\), \(\lim_{k \to \infty}(A^k)_{ij} = 0\).</p> <ul> <li>\(A\) is a convergent matrix</li> <li> \[\lim_{n \to \infty} \|A^n\|_2 = 0\] </li> <li> \[\lim_{n \to \infty} \|A^n\|_\infty = 0\] </li> <li> \[\rho(A) &lt; 1\] </li> <li>\(\lim_{n \to \infty} A^nv =0\) for every vector \(v\).</li> </ul> <p>The above statements are all equivalent.</p> </li> <li> <p>Iterative techniques are not often used for smaller dimensions. We will study <strong>Jacobi</strong> and the <strong>Gauss-Seidel</strong> method.</p> <p><strong>Jacobi Method</strong> - We assume that \(\det(A)\) being non-zero (as matrix must be invertible for solution) and the diagonal entries of \(A\) are also non-zero. We have</p> <p>Jacobi suggested that we start with an initial vector \(x^{(0)} = [x_1^{(0)}, \dots, x_n^{(0)}]\) and for \(k \geq 1\)</p> \[x_i^{(k)} = \frac{b_i - \sum_{j \neq i} a_{ij}x_j^{(k - 1)}}{a_{ii}}\] <p>The error in the iterations is given by</p> \[\mid x_i - x_i^{(k)} \mid \leq (\sum_{j \neq i} \frac{a_{ij}}{a_{ii}})\|x_j - x_j^{(k - 1)}\|_\infty\] <p>which gives</p> \[\| x - x^{(k)} \|_\infty \leq (\max_i \sum_{j \neq i} \frac{a_{ij}}{a_{ii}})\|x_j - x_j^{(k - 1)}\|_\infty\] <p>If \(\mu = \max{i}\sum_{j \neq i} \frac{a_{ij}}{a_{ii}} &lt; 1\), then convergence is guaranteed. If \(\mu &lt; 1\), then the condition is nothing but that of strictly diagonally dominant matrices.</p> <p><strong>Gauss-Seidel method</strong> - The idea is that once we have improved one component, we use it to improve the component of the next component and so on.</p> \[x_i^{(k)} = \frac{1}{a_{ii}} \left[b_i - \sum_{j = 1}^{i - 1}a_{ij}x_j^{(k)} - \sum_{j = i + 1}^n a_{ij}x_j^{(k - 1)}\right]\] <p>There are linear systems where Jacobi method converges but Gauss-Seidel method does not converge. If \(A\) is strictly diagonally dominant, then both methods converge to the true solution.</p> </li> <li> <p><strong>Residual vector</strong> - If \(\tilde x\) is an approximation to \(Ax = b\), then \(r = b - A\tilde x\) is the residual vector. However, it is not always true that when \(\|r \|\) is small then \(\|x - \tilde x\|\) is also small. This is because \(r = A(x - \tilde x)\), and that represents the affine transformation of space. This phenomenon is captured as follows</p> <p>For a non-singular \(A\), we have</p> \[\|x - \tilde x\|_\infty \leq \|r \|_\infty \cdot \|A^{-1}\|_\infty\] <p>If \(x \neq 0\) and \(b \neq 0\)</p> \[\frac{\|x - \tilde x \|_\infty}{\|x\|_\infty} \leq \|A\|_\infty\cdot \|A^{-1}\|_\infty \cdot \frac{\|r\|_\infty}{\|b\|_\infty}\] <p>These relations work for \(l_2\) norm too.</p> <blockquote> <p>I think \(\|A\|_\infty \|x\|_\infty \geq \|b\|_\infty\)</p> </blockquote> <p>The <strong>condition number</strong> of a non-singular matrix \(A\) is</p> \[K(A) = \|A\|_\infty \cdot \|A^{-1}\|_\infty\] <p>Also, \(\|AA^{-1}\|_\infty \leq \|A\|_\infty \|A^{-1}\|_\infty\). A non-singular matrix \(A\) is said to be <strong>well-conditioned</strong> if \(K(A)\) is close to 1.</p> <p>However, the condition number depends on the round-off errors too. The effects of finite-digit arithmetic show up in the calculation of the inverse. As the calculation of inverse is tedious, we try to calculate the condition number without the inverse. If we consider \(t\)-digit arithmetic, we approximately have</p> \[\|r\|_\infty \approx 10^{-t}\|A\|_\infty \cdot \|\tilde x \|_\infty\] <p>One drawback is that we would have to calculate \(r\) is double precision due to the above relation. The approximation for \(K(A)\) comes from \(Ay = r\). Now, \(\tilde y \approx A^{-1}r = x - \tilde x\). Then,</p> \[\|\tilde y\| \leq \|A^{-1}\| \cdot (10^{-t}\cdot \|A\| \|\tilde x\|)\] <p>Using the above expression, we get</p> \[K(A) \approx \frac{\|\tilde y\|}{\|\tilde x\|}10^t\] <p>The only catch in the above method is that we need to calculate \(r\) in \(2t\)-finite arithmetic.</p> <p><strong>Iterative refinement</strong> - As we had defined \(\tilde y = x - \tilde x\), in general, \(\tilde x + \tilde y\) is more accurate. This is called as iterative improvement. If the process is applied using \(t\)-digit arithmetic and if \(K(A) \approx 10^q\), then after \(k\) iterations, we have approximately \(\min(t, k(t - q))\) correct digits. When \(q&gt; t\), increased precision must be used.</p> </li> <li> <p><strong>Approximations for eigenvalues</strong></p> <p><strong>Gerschgorin theorem</strong> - We define discs \(D_i = \left\{ z \in \mathbb C: \mid z - a_{ii} \mid \leq \sum_{j \neq i} \mid A_{ij} \mid \right\}\). Then, all eigenvalues of \(A\) are contained in the union of all the disks \(D_i\). The union of any \(k\) of the disk that do not intersect the remaining \(n - k\) disks contains precisely \(k\) of the eigenvalues including the multiplicity. From this theorem, we get that strictly diagonally dominant matrices are invertible. This is also true for strictly diagonally column dominant matrices.</p> <p>The above theorem provides us the initial approximations for the eigenvalues. We shall see the Power method.</p> <p><strong>Power method</strong> - We assume \(\mid \lambda_1 \mid &gt; \mid \lambda_2 \mid \geq \dots \geq \mid \lambda_n \mid\), and that \(A\) has \(n\) linearly independent eigenvectors. Choose a non-zero \(z \in V\), and compute</p> \[\lim_{k \to \infty} A^k z\] <p>to get the eigenvalue! (Think of vector space transformations geometrically).</p> <p>If \(z = \sum \alpha_i v_i\), we get</p> \[A^k z = \lambda^k_1 \alpha_1 v_1 + \dots + \lambda^k_n \alpha_n v_n = \lambda_1^k \alpha_1 v_1\] <p>for high values of \(k\).</p> <p>Sometimes, \(z\) may not have the component of \(v_1\). We choose a vector such that this is not the case.</p> <p>Sometimes, it may also be the case that</p> <p>\(\mid \lambda_1 \mid \geq \mid \lambda_2 \mid \geq \dots &gt; \mid \lambda_n \mid &gt; 0\). \(A\) is invertible iff this holds. Then, we use the power method on \(A^{-1}\).</p> <p>Sometimes, \(\mid \lambda_1 \mid &lt; 1\) and we’ll converge to 0. On the other hand, if it is more than 1, the limit will shoot to infinity. To take care of these, we scale \(A^k(z)\), so that it is finite and non-zero.</p> <p>Firstly, we choose \(z\) such that \(\|z^{(0)}\| = 1\) and we choose a component \(p_0\) of \(z^{(0)}\) such that \(\mid z_{p_0}^{(0)} \mid = 1\). Following this, we scale each subsequent value as follows - Let \(w^{(1)} = Az^{(0)}\) and \(\mu^{(1)} = w_{p_0}^{(1)}\).</p> \[\mu^{(1)} = \lambda_1 \frac{\alpha_1(v_1)_{p_0} + \dots + (\lambda_n/ \lambda_1) \alpha_n (v_n)_{p_0}}{\alpha_1(v_1)_{p_0} + \dots + \alpha_n (v_n)_{p_0}}\] <p>Now, we choose \(p_1\) to be the least integer with \(\mid w_{p_1}^{(1)}\mid = \|w^{(1)}\|\) and define \(z^{(1)}\) by</p> \[z^{(1)} = \frac{1}{w_{p_1}^{(1)}} Az^{(0)}\] <p>Then, in general,</p> \[\mu^{(m)} = w_{p_{m - 1}}^{(m)} = \lambda_1 \frac{\alpha_1(v_1)_{p_0} + \dots + (\lambda_n/ \lambda_1)^m \alpha_n (v_n)_{p_0}}{\alpha_1(v_1)_{p_0} + \dots + (\lambda_n/ \lambda_1)^{m - 1}\alpha_n (v_n)_{p_0}}\] <p>Now, \(\lim_{m \to \infty} \mu^{(m)} = \lambda_1\).</p> <p>To find other eigenvalues, we use <strong>Gram-Schmidt orthonormalisation</strong>.</p> <p><img src="/assets/img/Numerical Analysis/image-20220415200748597.png" alt="image-20220415200748597"/></p> </li> </ul> <hr/> <h4 id="end-of-course">END OF COURSE</h4> <hr/>]]></content><author><name></name></author><category term="Notes"/><summary type="html"><![CDATA[A course disucssing interpolation theory, numerical intergration, numerical solutions to ordinary differential equations, numerical solutions to system of linear equations and roots of non-linear equations.]]></summary></entry><entry><title type="html">Automata Notes</title><link href="https://sudhansh6.github.io/blog/automata/" rel="alternate" type="text/html" title="Automata Notes"/><published>2022-01-06T00:00:00+00:00</published><updated>2022-01-06T00:00:00+00:00</updated><id>https://sudhansh6.github.io/blog/automata</id><content type="html" xml:base="https://sudhansh6.github.io/blog/automata/"><![CDATA[ <h2 id="overview">Overview</h2> <p>Theory of Computation discusses what <em>can</em> and <em>cannot</em> be done with computers. Moreover, how “<em>hard</em>” or “<em>easy</em>” a given problem is. For instance, consider the problem of determining whether a given multivariate polynomial with integer coefficients has integer roots. This problem is <em>undecidable</em> - we cannot write a deterministic algorithm which halts in finite time that always gives the correct answer for a given polynomial. Through the course, we will explore various techniques and theorems through the course to answer questions like these.</p> <p><strong><em>Example.</em></strong> Given a language \(L_1 = \{a^nb^m: n,m \geq 0\}\), decide whether a word is present in this language or not. We will see that such a language can be written using a DFA.</p> <p><strong><em>Example.</em></strong> Suppose we have \(L_2 = \{a^nb^n: n \geq 0\}\). Can we construct a DFA for the same?</p> <p>It can be shown that such a language cannot be represented using a DFA. Instead, we use an instrument known as <strong><em>pushdown automaton</em></strong>.</p> <p>A <em>pushdown automaton</em> has a stack associated with a DFA. Every transition in the automaton describes an operation such as “push” and “pop” on the stack. A string is accepted by the automaton if the stack is empty at the end of the string. The languages accepted by such automatons are known as <strong><em>context-free grammar</em></strong>.</p> <p><strong><em>Example.</em></strong> Extending the previous example, consider the language \(L_3 = \{a^nb^nc^n:n \geq 0\}\). Turns out, a pushdown automaton cannot represent this language.</p> <p>We have a <strong><em>Turing machine</em></strong> that represents the ultimate computer that can perform any computation (not all). This machine has a ‘tape’ associated with it along with different decisions at each section of the tape. The languages associated with these machines are known as <strong><em>unrestricted grammar</em></strong>.</p> <p>These machines and the associated languages can be represented using a diagram known as <a href="#chomsky-hierarchy">Chomsky hierarchy</a>. We will also prove that adding non-determinism affects the expressive power of PDAs but not of DFAs and TMs.</p> <p><strong><em>Definition.</em></strong> A <em>finite state automaton</em> is defined as a tuple \((Q, \Sigma, \delta, q_0, F)\), where</p> <ul> <li>\(Q\) is a finite non-empty set of states,</li> <li>\(\Sigma\) is the alphabet with a set of symbols,</li> <li>\(\delta: Q \times \delta \to Q\) is the state-transition function,</li> <li>\(q_0 \in Q\) is the initial state, and</li> <li>\(F \subseteq Q\) is the set of accepting states.</li> </ul> <p>A language \(L\) is a subset of strings over \(\Sigma\), whereas \(\Sigma^*\) represents the set of all possible strings that can be constructed with the alphabet. The \(*\) operator is known as <strong>Kleene-star</strong> operator representing \(0\) or more repetitions of symbols from an alphabet.</p> <blockquote> <p>Is the set \(\Sigma^*\) countable?</p> </blockquote> <p><strong><em>Example.</em></strong> Let us consider the language \(L_2 = \{a^nb^n:n\geq 0\}\) we saw before. How do we write the <em>context-free grammar</em> for this language? We write a set of <u>base cases and inductive rules</u> as follows -</p> <div style="text-align:center;"> $$ \begin{align} S &amp;\to \epsilon \\ S &amp;\to aSb \end{align} $$ </div> <p>Typically, we use \(S \to \epsilon\) as the base case. We start out with the string \(S\), and then use the above rules to keep replacing the \(S\) until we obtain a string consisting only of <em>terminals</em>. Here, the symbols \(a, b,\) and \(\epsilon\) are terminals whereas \(S\) is a non-terminal.</p> <p><strong><em>Example.</em></strong> Consider the grammar of matched parentheses. This is given by -</p> <div style="text-align:center;"> $$ \begin{align} S &amp;\to ()\\ S &amp;\to (S)\\ S &amp;\to SS \end{align} $$ </div> <p><strong><em>Definition.</em></strong> A <em>context-free grammar</em> is defined as a tuple \((V, \Sigma, R, S)\), where</p> <ul> <li>\(V\) is a set of <em>non-terminals</em> or <em>variables</em>,</li> <li>\(\Sigma\) is the alphabet,</li> <li>\(R: V \to (V \cup \Sigma)^*\) is the finite set of <em>rules</em>, and</li> <li>\(S \in V\) is the <em>start</em> symbol.</li> </ul> <p>The language of a given grammar is the set of all strings derivable using the rules.</p> <p><strong><em>Example.</em></strong> Consider the language \(\{a^nb^nc^n: n &gt; 0\}\). This can be represented by the unrestricted grammar as -</p> <div style="text-align:center;"> $$ \begin{align} S &amp;\to abc \\ S &amp;\to aAbc \\ Ab &amp;\to bA \\ Ac &amp;\to Bbcc \\ bB &amp;\to Bb \\ aB &amp;\to aa \\ aB &amp;\to aaA \end{align} $$ </div> <p>These set of rules are very similar to CFG except for the fact that, now, we have strings on the LHS too. Notice how \(A, B\) are used to convey information across the string when new \(a\)’s or \(b\)’s are added.</p> <blockquote> <p><strong><em>Homework.</em></strong> Write the unrestricted grammar rules for the language \(L = \{a^{n^2} : n \in \mathbb Z^+\}\)</p> </blockquote> <p><strong><em>Definition.</em></strong> An <em>unrestricted grammar</em> is defined as a tuple \((V, \Sigma, R, S)\), where</p> <ul> <li>\(V\) is a set of <em>non-terminals</em> or <em>variables</em>,</li> <li>\(\Sigma\) is the alphabet,</li> <li>\(R: (V \cup \Sigma)^* \to (V \cup \Sigma)^*\) is the finite set of <em>rules</em>, and</li> <li>\(S \in V\) is the <em>start</em> symbol.</li> </ul> <p><strong><em>Definition.</em></strong> <em>Regular expressions</em> are defined by the following set of rules -</p> <ol> <li> <p>\(\phi, \{\epsilon\}, \{a\}\) (for any \(a \in \Sigma\)) are regular expressions.</p> </li> <li> <p>If \(E_1, E_2\) are regular expressions,</p> <ol> <li>\(E_1 + E_2\) (union),</li> <li>\(E_1E_2\) (concatenation)</li> <li>\(E_1^*\) (<strong>Kleene star</strong>), and</li> <li>\((E_1)\) (parenthesis)</li> </ol> <p>are all regular expressions.</p> </li> </ol> <p><strong><em>Example.</em></strong> Consider \(L = \{\text{strings with even number of a's}\}\). This can be represented using the regular expression \(b^*(ab^*ab^*)^*\).</p> <blockquote> <p><strong><em>Homework.</em></strong> Suppose \(L\) is restricted to have only an odd number of \(b\)’s. How do we write the regular expression for this language?</p> </blockquote> <p>In general, PDAs are represented as a Finite State Machine. That is, we have an action associated with each transition. An empty stack is denoted using the symbol \(Z_0\). That is, the stack begins with a single symbol \(Z_0\). Each transition is represented as \(l, A\), where \(l\) is a letter and \(A\) is an action such as</p> <ul> <li>\(X \vert aX\) - push</li> <li>\(aX \vert X\) - pop</li> <li>\(W\vert Wa\) - not sure what this is</li> </ul> <p>Now, a string is rejected by the FSM in two scenarios -</p> <ol> <li>There is no transition defined at the current state for the current symbol in the string, and</li> <li>The stack is not empty, i.e. popping the stack does not yield \(Z_0\) at the end of the string input.</li> </ol> <h2 id="chomsky-hierarchy">Chomsky Hierarchy</h2> <p><img src="/assets/img/Automata\image-20220106090455841.png" alt="image-20220106090455841"/></p> <h2 id="regular-expressions">Regular Expressions</h2> <p>We define these languages using a base case and an inductive rule. <strong>Empty string</strong> is not the same as the <strong>empty set</strong>. The base case to be considered is \(L = \{\epsilon\}\)?</p> <h3 id="inductive-rules">Inductive Rules</h3> <p><strong>Lemma.</strong> If \(E_1, E_2\) are regular expressions, then so are</p> <ul> <li>\(E_1 + E_2\) - Union</li> <li>\(E_1.E_2\) - Concatenation</li> <li>\(E_1^*\) - Kleene star</li> <li>\((E_1)\) - Parentheses</li> </ul> <p>“Nothing else” is a regular expression. That is, we must use the four rules mentioned above to construct a regular expression.</p> <p>The fourth rule can be used as follows - \(L((ab)^*) = \{\epsilon, ab, abab, ababab, ...\}\). The parentheses help us group letters from the alphabet to define the language.</p> <p><strong><em>Example.</em></strong> Construct a language with <u>only even number of a's'</u>. Good strings include \(\{aba, baabaa\}\), and bad strings include \(\{abb, bbabaa\}\).</p> <p>The automata can be easily drawn as -</p> <p><img src="/assets/img/Automata\image-20220106085034344.png" alt="image-20220106085034344"/></p> <p>How do we write a regular expression for this? Consider the expression \(R = (ab^*ab^*)^*\). However this expression does not include strings that start with \(b\).</p> <blockquote> <p><strong><em>Homework.</em></strong> Try and fix this expression -</p> \[R = b^*.(ab^*ab^*)^*\] </blockquote> <p><strong><em>Example.</em></strong> Construct an expression for defining the language \(L = \{\text{all strings with even number of a's} \text{and odd number of b's}\}\)</p> <p>The following automaton would work for this language -</p> <p><img src="/assets/img/Automata\image-20220106085649521.png" alt="image-20220106085649521"/></p> <blockquote> <p><strong><em>Homework</em></strong>. Find a regular expression for the above language.</p> </blockquote> <p><strong><em>Example.</em></strong> What language does the regular expression \(b^*ab^*(ab^*ab^*)^*\)?</p> <p>It represents the language with an <u>odd</u> number of \(a\)’s. How do we check this? Start with the base cases - It has \(\epsilon\), and it also has \(\{ab, ba\}\). Try to check the pattern and use induction.</p> <p>We will soon learn how to derive relations such as “Is \(L = \phi\)?”, “Is \(\|L\| = \infty\)?”, “Is \(L_1 \subset L_2\)?”… All we are doing right now is exploring all the topics in the course using a BFS approach.</p> <h2 id="representation-of-push-down-automata">Representation of Push-Down Automata</h2> <p>The bottom of the stack contains a special character that indicates the bottom of the stack. We design a Finite State Machine which knows the special characters (for bottom of the stack or other purposes) and also the top element in the stack. This FSM can pop or push on the stack to go to the next state.</p> <p><strong><em>Example.</em></strong> Represent \(L = \{a^nb^n\}\) using a FSM.</p> <p><img src="/assets/img/Automata/image-20220106091221465.png" alt="image-20220106091221465"/></p> <p>This is how a FSM is represented. A string is accepted <strong>iff</strong> the stack is empty. Note the transition from \(q_0\) to \(q_1\). It says that the top of the stack must be \(a\). In case it isn’t the case, the string is rejected.</p> <p>In a FSM, the string is rejected due to one of the two reasons -</p> <ul> <li>No transition for the given input symbol or we reach the top stack symbol (in the case of finite length languages)</li> <li>Input is over, and the stack is not empty.</li> </ul> <p><strong><em>Example.</em></strong> Try the same for \(L = \{\text{equal \#}a's \text{ and } b's\}\).</p> <p><img src="/assets/img/Automata/image-20220106092231128.png" alt="image-20220106092231128"/></p> <p>Does this work?</p> <h2 id="non-determinism">Non-determinism</h2> <p><strong><em>Example.</em></strong> Represent \(L = \{ww^R\} \| w \in (a + b)^*\}\). Here, “R” represents reverse. That is, this language is the language of palindromes. Here, we keep pushing and then we keep popping after a decision point. <u>The decision point is a non-deterministic guess</u>. If there is a correct guess, then the algorithm will work.</p> <p><strong><em>Example.</em></strong> Is \(n\) composite? How do we design a non-deterministic algorithm for this problem?</p> <ol> <li>Guess for a factor \(p &lt; n\)</li> <li>Check if \(p\) divides \(n\). If the answer is “yes” then it is composite, else repeat.</li> </ol> <blockquote> <p>How do we reject empty strings in PDA?</p> <p>Does adding accepting states in the FSM increase the representation power? Does using the special symbol in between the stack increase the representation power?</p> </blockquote> <p>The reference textbook for this course is “Hopcroft Ullman Motwani.”</p> <blockquote> <p><strong><em>Homework.</em></strong> Find the number of binary strings of length 10 with no two consecutive 1’s.</p> <p><em>Answer.</em> \(f\) considers bit strings starting with \(0\) and \(g\) considers bit strings starting with \(1\).</p> \[\begin{align} f(1) &amp;= 1; f(2) = 2; \\ g(1) &amp;= 1; g(2) = 1 \\ f(n) &amp;= f(n - 1) + g(n - 1); \\ g(n) &amp;= f(n - 1); \end{align}\] <p>\(f: \{1, 2, 3, 5, 8, \dots\} \\ g: \{1, 1, 2, 3, 5, \dots \}\) Therefore, there are \(144\) such required strings.</p> </blockquote> <p><strong><em>Example.</em></strong> How do we construct an automata which captures the language of binary strings with no two consecutive 1’s? We use something known as a <strong>trap state</strong>. All the bad strings will be <em>trapped</em> in that state, and no transition from the trap state will lead to a final state. Consider the following automaton.</p> <p><img src="/assets/img/Automata/image-20220111114750638.png" alt="image-20220111114750638"/></p> <p>Here, the 3rd state is the trap state.</p> <h3 id="extended-transition-function">Extended transition function</h3> <p>\(\hat \delta : Q \times\Sigma^* \to 2^Q\) is defined as</p> \[\hat \delta(S, aW) = \begin{cases} \delta(S, a) &amp; w = \epsilon \\ \hat \delta(\delta(S, a), W) &amp; \text{otherwise} \end{cases}\] <p>For the sake of convenience we drop the hat and use \(\delta\) for the extended function (polymorphism).</p> <blockquote> <p><strong><em>Homework.</em></strong> Read the proof for showing the equivalence of language sets in DFA.</p> </blockquote> <h2 id="non-determinism-1">Non-determinism</h2> <p>Non-determinism basically refers to the procedures where we get the same output from the same input through <em>multiple runs</em>. In <strong>don’t care</strong> non-determinism, we get the same output with different algorithms/procedures. However, in <strong>don’t know</strong> non-determinism, a single stochastic algorithm goes through many runs (scenarios) to get the answer.</p> <p>A deterministic automaton has a single choice of transition from a given state for a given symbol from the alphabet. However, in the case of a non-deterministic automata, such guarantee does not exist. The next state for a given symbol from a given state of the NFA is a set of states rather than a single state. There are two types of NFA as discussed previously.</p> <ul> <li>Don’t know NFA - Guess the right choice</li> <li>Don’t care NFA - All choices give the same result</li> </ul> <p>One might ponder if NFAs are more expressive than DFAs. The answer is surprisingly no. Non-determinism can be introduced to an automaton in two ways -</p> <ul> <li>Choice of subset of states for each transition</li> <li>\(\epsilon\)-transitions</li> </ul> <p><strong>Example.</strong> Construct an automaton to represent the language \(L = \{abc\} \cup \{\text{all strings ending in b}\}\) whose alphabet is \(\{a,b,c\}\)</p> <p><img src="/assets/img/Automata/image-20220113085632353.png" alt="image-20220113085632353"/></p> <p><strong>Note.</strong> We have introduced \(\epsilon\)-transitions in this automaton.</p> <p>As we shall see later in the course, the three models - DFA, NFA, and NFA with \(\epsilon\)-transitions; are all equivalent in terms of expressive power.</p> <h2 id="properties-of-languages">Properties of Languages</h2> <p>We mainly check two properties of languages - decision and closure.</p> <ul> <li> <p>Decision - Is \(w \in L\)? (Membership Problem) - decidable for regular languages.</p> <p>Decidable problems - Problems for which we can write a <strong>sound</strong> algorithm which <strong>halts in finite time</strong>.</p> <p>We can also consider problems like - Given \(DFA(M_1)\) and \(DFA(M_2)\), Is \(L(M_1) = L(M_2)\)? or \(L(M_1) \subset L(M_2)\)?</p> <p>Is \(L = \phi\)? Is \(L\) finite? Is \(L\) finite and has an even number of strings? We can also ask questions about the DFA - Can \(L(M)\) be accepted by a DFA with \(k &lt; n\) states (minimalism)?</p> <p><strong><em>Example.</em></strong> Can we build a DFA whose language is \(L = \{\text{bit strings divisible by } 7\}\) with less than 7 states? Turns out, the answer is no.</p> <p>Finally, we can ask a very difficult question such as - Show \(L\) cannot be accepted by any DFA. The technique for solving such a question is known as the <strong><em>Pumping Lemma</em></strong>. This lemma is based on the <em>Pigeonhole principle</em>.</p> </li> <li> <p>Closure - closure using Union, Intersection, Kleene Star, and Concatenation. The question we ask is if \(L_1, L_2\) belong to class \(C\), then does \(L_1 \texttt { op } L_2\) belong to \(C\)?</p> </li> </ul> <p>We plan to show the equivalence of the following models -</p> <ul> <li>DFAs</li> <li>NFAs</li> <li>NFA-\(\epsilon\)</li> <li>Regular Expressions</li> </ul> <blockquote> <p><strong><em>Homework.</em></strong> Draw a DFA for the language \(L_1 \cup L_2\) where \(L_1\) is \(a\) followed by even number of \(b\)s and \(L_2\) is \(a\) followed by odd number of \(c\)s.</p> </blockquote> <h2 id="regular-expressions-1">Regular Expressions</h2> <p>They are defined using base cases and inductive cases. Before we discuss this, we define <strong>closed-world</strong> assumption. It is the presumption that a statement that is true is also known to be true. Therefore, conversely, what is not currently known to be true, is false. More info regarding this topic can be found <a href="https://en.wikipedia.org/wiki/Closed-world_assumption">here</a>. The base cases for regular expressions are given as follows.</p> \[\begin{align} L(a) &amp;= \{a\} \\ L(\epsilon) &amp;= \{\epsilon\} \\ L(\phi) &amp;= \phi \text{ (An empty set)} \end{align}\] <p>The inductive cases are</p> \[\begin{align} L_1, L_2 &amp;\to L_1 \cup L_2 \\ L_1, L_2 &amp;\to \{uv \vert u \in L_1, v \in L_2\} \\ L &amp;\to L_1^* \end{align}\] <h2 id="re-equiv-nfa-epsilon">RE \(\equiv\) NFA-\(\epsilon\)</h2> <p>To begin with, we convert the base cases of regular expressions to NFA-\(\epsilon\)s. Here are the automatons</p> <p><img src="/assets/img/Automata/image-20220131011047071.png" alt="image-20220131011047071"/></p> <p>Now, for the inductive cases -</p> <ul> <li> <p>For union of \(L_1\) and \(L_2\), consider the NFAs of both languages. Create a new start state \(s\) and final state \(f\). Connect \(s\) to the start states of both NFAs with \(\epsilon\) transitions and the final states of both NFAs to \(f\) with the same transitions.</p> <blockquote> <p>How do we prove that this construction represents the union?</p> </blockquote> </li> <li> <p>For concatenation of \(L_1\) and \(L_2\), connect all the final states of \(L_1\)’s NFA to all the start states of \(L_2\)’s NFA using \(\epsilon\) transitions.</p> </li> <li> <p>For \(L^*\), connect all the final states of the NFA to the start states of the NFA using \(\epsilon\) transitions. However, this does not accept \(\epsilon\). Fix it. Think.</p> </li> </ul> <h2 id="decision-properties">Decision Properties</h2> <h3 id="membership-problem">Membership Problem</h3> <p>Does \(w \in L\)? How do we show that this problem is decidable? The algorithm is well-known.</p> <h3 id="emptiness-problem">Emptiness Problem</h3> <p>Is \(L(M) = \phi\)? This problem can be solved using <em>reachability</em> in graphs. One can check if the final states are reachable from the start state. It can be achieved using <strong>fixed point</strong>. This method is essentially propagating the frontier from the start state. We add neighbors of all the states in the current frontier and keep expanding it. We do this until our frontier does not change. This frontier is the fixed point.</p> <h3 id="infiniteness-problem">Infiniteness Problem</h3> <p>Is \(L(M)\) finite? We need to search for a loop in the graph to answer this question. Suppose our DFA has \(N\) states. If the DFA accepts a string whose length is greater than or equal to \(N\), then a state has to repeat while forming this string. This observation is a result of the <strong>Pigeonhole principle</strong>.</p> <p>This check is both necessary and sufficient. If a language is infinite, then it means that it has a string of length greater than \(N\). How are we going to use this property to check the infiniteness of the language? Is there a decidable algorithm?</p> <p><strong><em>Claim.</em></strong> If there is a string of length \(\geq N\) in \(L\), then there is a string of length between \(N\) and \(2N - 1\). Think about the proof. <em>Clue.</em> You can use at the most \(N - 1\) self loops.</p> <p>It is sufficient to test for the membership of all strings of length between \(N\) and \(2N - 1\).</p> <h2 id="pumping-lemma">Pumping Lemma</h2> <p><strong><em>Problem.</em></strong> Show that \(L = \{a^nb^n\}\) is not regular.</p> <p>We use proof by contradiction. Assume that a \(DFA(M)\) with \(N\) states accepts \(L\).</p> <p><strong><em>Theorem.</em></strong> <em>Pumping Lemma</em>. For every regular language \(L\), there exists an integer \(n\) , called the <em>pumping length</em>, where every string \(w \in L\) of length \(\geq n\) can be written as \(w = xyz\) where</p> \[\begin{align} \vert xy \vert &amp;\leq n \\ \vert y\vert &amp;&gt; 0\\ \forall i \geq 0,\ &amp; x(y)^iz \in L \end{align}\] <p>Let us understand this by proving \(L = \{a^nb^n \vert n &gt; 0\}\) is not regular using contradiction. Assume there is a \(DFA(M)\) with \(N\) states that accepts \(L\).</p> <p>Now, consider the string \(a^Nb^N\). Now, define \(a^n\) as \(xy\). Let \(x = a^j\) and \(y = a^k\) where \(n \leq N\). According to the pumping lemma, \(a^j(a^k)^ib^N \in L\). Therefore, there can’t exist a DFA that represents \(L\).</p> <blockquote> <p><strong><em>Homework.</em></strong> Prove that the language with equal number of \(a\)‘s and \(b\)’s is not regular.</p> <p>The idea is to use closure properties.</p> </blockquote> <blockquote> <p><strong><em>Homework.</em></strong> Prove the pumping lemma.</p> <p><em>Answer.</em> Consider a DFA\((Q, \Sigma, Q_0, \delta, F)\) with \(N\) states, and a word \(w\) such that \(\vert w \vert = T \geq N\) belongs to \(L\). Now, let \((S_i)_{i =0}^T\) (0 - indexed) be the sequence of states traversed by \(w\). The state \(S_L\) is an accepting state as \(w \in L\). Also, there exist \(0 \leq i &lt; j \leq N\) such that \(S_i = S_j\) as there are only \(N\) states in the DFA (Pigeonhole principle). Now, define the string formed by \(S_0, \dots, S_i\) as \(x\), the one formed by \(S_i, \dots, S_j\) as y, and that formed by \(S_j, \dots, S_T\) as \(z\). We have \(w = xyz\). Also, \(\vert y \vert &gt; 0\) as \(i &lt; j\) and \(\vert xy \vert \leq N\) as \(j \leq N\).</p> <p>Since \(S_i = S_j\), we can <em>pump</em> the string \(y\) as many times as we wish by traversing cycle \(S_i, \dots, S_j\). Now, since \(S_T \in F\), the string formed by the sequence \(S_0, \dots, \{S_i, \dots, S_j\}^t, \dots, S_T\) (\(t \geq 0\)) also belongs to \(L\). This word is equivalent to \(xy^iz\). \(\blacksquare\)</p> </blockquote> <h2 id="nfa-equiv-dfa">NFA \(\equiv\) DFA</h2> <p>We convert a NFA to DFA using <strong>subset construction</strong>. That is, if \(Q\) is the set of states in the NFA, then \(2^Q\) will the set of states in the DFA. Initially, we construct the start states using the subset of start states in the NFA. Then, we build the following states in the DFA by tracing all the states reached by each character in the NFA into a single subset. If any of the subset consists of a final state, then that subset state is made into a final state in the DFA.</p> <p>This equivalence can also be extended to show the equivalence of NFA-\(\epsilon\) and \(DFA\).</p> <h2 id="dfa-minimization">DFA Minimization</h2> <p>All DFAs with minimal number of states are <strong>isomorphic</strong>.</p> <h3 id="distinguishable-states">Distinguishable states</h3> <p>Consider a DFA \((Q, \Sigma, Q_0, \delta, F)\). States \(q_i,q_j \in Q\) are said to be distinguishable iff there exists a word \(w \in \Sigma^*\) such that \(\delta(q_1, w) \not \in F\) and \(\delta(q_2, w) \in F\) or vice versa.</p> <p>One can merge indistinguishable states to minimize a DFA.</p> <h2 id="context-free-grammar">Context-Free Grammar</h2> <p>Let us try to write the grammar for the language \(L = \{a^ib^jc^k \vert i = j \text{ or } j = k\}\). Consider the following rules</p> \[\begin{align} S &amp;\to S_1 \vert S_2 \\ S_1 &amp;\to aS_1bC \vert C \\ S_2 &amp;\to AbS_2c \vert \epsilon \\ C &amp;\to cC \vert \epsilon \\ A &amp;\to aA \vert \epsilon \end{align}\] <p>In general, union is straightforward to write in CFG due to rules like rule 1. However, there is an ambiguity in the above rules. For example, the word \(a^3b^3c^3\) can be generated using different derivations. We’ll discuss this later in the course.</p> <p>As we discussed before, a context free grammar \(G\) is defined by \((V, \Sigma, R, S)\). A string is accepted by the grammar if \(w \in \Sigma^*\) and \(R \xrightarrow{*} w\). That is, the rules must be able to <em>derive</em> \(w\).</p> <p>A one-step derivation is given by \(u_1Au_2 \to u_1\beta u_2\) if \(A \to \beta \in R\) and \(u_1, u_2 \in (V \cup \Sigma)^*\).</p> <p>Consider the set of rules for defining arithmetic expressions. The language is defined over \(\Sigma = \{+, -, \times, \div, x, y, z, \dots\}\).</p> \[\begin{align} S &amp;\to x \vert y \vert z \\ S &amp;\to S + S \\ S &amp;\to S - S \\ S &amp;\to S \times S \\ S &amp;\to S \div S \\ S &amp;\to (S) \end{align}\] <p>Now, for an expression such \(x + y \times z\), we can give a left-most derivation or a right-most derivation. A precedence order removes ambiguities in the derivation. In programming languages, a parser removes these ambiguities using some conventions.</p> <blockquote> <p><strong><em>Homework.</em></strong> Try and write the set of rules for the language which consists of \(a\)s and \(b\)s such that every string has twice the number of \(a\)s as that of \(b\)s.</p> <p><em>Answer.</em> We try to write the rules for equal number of a’s and b’s, and try to extend them.</p> \[\begin{align} S &amp;\to \epsilon \\ S &amp;\to aSb \ \vert \ Sab \ \vert \ abS \\ S &amp;\to bSa \ \vert \ Sba \ \vert \ baS \end{align}\] <p>Does this work?</p> </blockquote> <p><strong>Note.</strong> \(\vert R \vert\) is finite.</p> <p>We had seen the CFG for the language \(L = \{a^nb^n\}\). How can one prove that the rules represent that language? That is, how do we know that the rules generate <u>all the strings</u> in the language and <u>no other strings</u>?</p> <p>Consider the language we saw in the previous lecture - strings with equal number of a’s and b’s. The possible set of rules are -</p> \[\begin{align} S &amp;\to aB \ \vert \ bA \\ B &amp;\to b \ \vert \ bS \ \vert \ aBB \\ A &amp;\to a \ \vert \ aS \ \vert \ bAA \\ \end{align}\] <p>The thinking is as follows -</p> <ul> <li>\(S\) generates strings with equal number of a’s and b’s. \(B\) generates strings with one more b than a’s, and similarly for \(A\).</li> <li>To write the inductive cases of \(S\), we consider strings starting with both a and b. Inductive cases for \(A, B\) are also constructed similarly.</li> </ul> <p>Another possible set of rules are -</p> \[\begin{align} S &amp;\to aSb \ \vert \ bSa \\ S &amp;\to \epsilon \\ S &amp;\to SS \\ \end{align}\] <p>These rules are the minimized set of the rules I wrote for the hw in the last lecture.</p> <h2 id="grammars">Grammars</h2> <p>We can write grammars in canonical forms. A grammar is said to be in <strong>Chomsky normal form</strong> if the rules are of the form</p> \[\begin{align} C \to DE &amp;\text{ - one non-terminal replaced by 2 non-terminals} \\ C \to a &amp;\text{ - one terminal replaced by a terminal} \end{align}\] <p><strong><em>Claim.</em></strong> Any grammar \(G\) (\(\epsilon \not\in L(G)\)) can be converted to an equivalent Chomsky Normal form.</p> <p>Another canonical form of grammar is <strong>Greibach normal form</strong>. The rules are of the form</p> \[\begin{align} C &amp;\to a\alpha \end{align}\] <p>Each non-terminal converts to a terminal followed by a symbol in \((V \cup \Sigma)^*\). Similar to the Chomsky form, every grammar can be converted to the Greibach normal form.</p> <h2 id="push-down-automatons">Push Down Automatons</h2> <p>Consider the language \(L = \{wcw^R \vert w \in (a + b)^*\}\).</p> <blockquote> <p><strong><em>Aside.</em></strong> Try writing the Chomsky normal form rules for the above language. \(\begin{align} S &amp;\to AA_0 \mid BB_0 \mid c \\ A_0 &amp;\to SA \\ B_0 &amp;\to SB \\ A &amp;\to a \\ B &amp;\to b \\ \end{align}\)</p> </blockquote> <p>The pushdown automaton for this language is given by -</p> <p><img src="/assets/img/Automata/image-20220131205500689.png" alt="image-20220131205500689"/></p> <p>How do we take a grammar and produce the normal form of the grammar? We shall learn techniques such as eliminating useless symbols, elimination epsilon and unit productions. These will be used to get the designable form of the grammar that can also be used to show languages which are context-free using the pumping lemma.</p> <p>The notation \(\alpha_1 \xrightarrow{n} \alpha_2\) is used to denote that \(\alpha_2\) can be derived from \(\alpha_1\) in \(n\) steps. The \(*\) over the arrow represents the derivative closure of the rules.</p> <p>Grammars \(G_1, G_2\) are equivalent iff \(L(G_1) = L(G_2)\). For example, we have seen two grammars for the language \(L = \text{ strings with } \#a = \#b\), and they are both equivalent.</p> <h3 id="derivation-trees">Derivation trees</h3> <ul> <li>Trees whose all roots are labeled.</li> <li>The root of the tree is labeled with the start symbol of the grammar \(S\).</li> <li>Suppose A is the label of some internal node, then A has a children \(X_1, \dots X_R\) iff \(A \to X_1\dots X_R \in R\).</li> <li>\(\epsilon\) can only be the label of leaf nodes.</li> </ul> <h3 id="derivations">Derivations</h3> <p>Grammars with multiple derivation trees are ambiguous. Are there languages for which any grammar is ambiguous? Such languages are called as <strong>inherently ambiguous</strong>.</p> <blockquote> <p><strong><em>Homework.</em></strong> Find examples of inherently ambiguous grammars.</p> </blockquote> <h2 id="simplifying-grammars">Simplifying grammars</h2> <p><strong><em>Definition.</em></strong> A variable \(B\) is productive in \(G\) iff \(B \xrightarrow[G]{*} w\) for some \(w \in \Sigma^*\).</p> <p><strong><em>Definition.</em></strong> A variable \(B\) is reachable from the start symbol \(S\) of \(G\) if \(S \xrightarrow[G]{*} \alpha B \beta\) for some \(\alpha, \beta \in (\Sigma \cup V)^*\).</p> <p>We useful variable \(X\) is productive and reachable. These are necessary conditions but not sufficient. For example, consider the following grammar.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>S -&gt; AB
A -&gt; c
</code></pre></div></div> <p>Here, \(A\) is useless even if it is productive and reachable.</p> <p><strong><em>Definition.</em></strong> A variable \(X\) is useless if there is no derivation tree that gives \(w \in \Sigma^*\) from \(S\) with \(X\) as the label of some internal node.</p> <h3 id="fixed-point-algorithm">Fixed point algorithm</h3> <p>The idea is to find a monotonic algorithm which gives us the set of useful symbols at the fixed point of the underlying function.</p> <p>Firstly, let us try this for productive variables. We propose the following algorithm.</p> \[\begin{align} P_0 &amp;= \phi \\ P_i &amp;\to P_{i + 1} \\ &amp;\triangleq P_i \cup \{N \mid N \to \alpha \in R \text{ and } \alpha \in (\Sigma \cup P_i)^* \} \end{align}\] <p>For example, consider the grammar</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>S -&gt; AB | AA
A -&gt; a
B -&gt; bB
-- The algorithm
P_o = \phi
P_1 = {A} // Rule 2
P_2 = {A, S} // Rule 1
P_3 = {A, S}
</code></pre></div></div> <p>Therefore, the symbols \(S, A\) are productive in the above grammar. We propose a similar algorithm for reachable states in the grammar.</p> \[\begin{align} R_0 &amp;= \phi \\ R_i &amp;\to R_{i + 1} \\ &amp;\triangleq R_i \cup \{P \mid Q \to \alpha P \beta; \alpha, \beta \in (\Sigma \cup P_i)^* \text{ and } Q \in R_i\} \end{align}\] <p><strong><em>Definition.</em></strong> A <strong>nullable</strong> symbol is a symbol which can derive \(\epsilon\). These symbols can be eliminated.</p> <p><strong><em>Definition.</em></strong> A unit production is a rule of the form \(A \to B\) where \(A, B \in V\).</p> <p>We shall continue discussing simplifying grammars. As an initial step, we can get rid of symbols which are either unreachable or unproductive. However, the order in which we check productivity and reachability affects how the grammar is simplified. For example, consider the grammar</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>S -&gt; a
S -&gt; AB
A -&gt; a
</code></pre></div></div> <p>Now, if we eliminate unreachable symbols first (that is none), and then eliminate unproductive symbols (\(B\)), we get</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>S -&gt; a
A -&gt; a
</code></pre></div></div> <p>Notice that the above simplified grammar has a redundant rule. However, if we check for productivity (\(B\) is eliminated) and then reachability (\(A\) is unreachable), we get</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>S -&gt; a
</code></pre></div></div> <p><strong><em>Claim.</em></strong> <u>Eliminating unproductive symbols followed by unreachable symbols gives a grammar without any useless variables.</u></p> <blockquote> <p><strong><em>Homework.</em></strong> Prove the above claim.</p> </blockquote> <h3 id="epsilon-productions">\(\epsilon\)-productions</h3> <p>Suppose \(G\) is a CFG such that \(L(G)\) has \(\epsilon\), then \(L(G) - \{\epsilon\}\) can be generated by a CFG \(G_1\) which has no \(\epsilon\)-productions (rules of the form \(A \to \epsilon\)).</p> <h3 id="nullable-symbols">Nullable symbols</h3> <p>\(A\) is <strong>nullable</strong> if \(A \xrightarrow[G]{*} \epsilon\).</p> <p>How do we remove nullable symbols? We can’t just take out a rule of the form \(A \to \epsilon\) as it may make \(A\) unproductive. The way to go about this is to replace each rule of the form \(A \to X_1\dots X_n\) to \(A \to \alpha_1 \dots \alpha_n\) where</p> \[\alpha_ i = \begin{cases} X_i &amp; X_i\text{ is not nullable}\\ \epsilon &amp;\text{otherwise} \end{cases}\] <p>However, one must be cautious about replacing all the symbols by \(\epsilon\) and also about recursive rules. For instance, consider the following grammar</p> \[S \to \epsilon \mid aSb \mid bSa \mid SS\] <p>Now, \(S\) is nullable but we can’t replace \(S \to aSb\) by \(S \to ab\) simply. We also need to have the rule \(S \to aSb\) in place for recursion. Basically, for each rule of the form \(A \to X_1\dots X_n\), we need to have all the rules of the form \(A \to \alpha\) where \(\alpha\) spans over all subsets of \(X_1 \dots X_n\).</p> <h3 id="unit-productions">Unit Productions</h3> <p>To remove unit productions, let us assume that there are no \(\epsilon\)-productions and useless symbols. Now, we need to find all pairs \((X, Y)\) such that \(X \xrightarrow[G]{*} Y\). Once we find such pairs, we can try and eliminate the unit symbols themselves, or solely the rules.</p> <p>Let us take the following grammar for \(L \{w \mid n_a(w) = n_b(w)\}\)</p> \[S \to \epsilon \mid aSb \mid bSa \mid SS \\ \text{ simplified to } \\ S \to abS \mid bSa \mid SS \mid ab \mid ba\] <p>and</p> \[S \to \epsilon \\ S \to aB \mid bA \\ B \to b \mid bS \mid aBB \\ A \to a \mid aS \mid bAA \\ \text{ simplified by just removing } S \to \epsilon\\\] <p>To convert the grammar into Chomsky normal form, we do approximately the following - we replace each rule of the form \(A \to X_1 \dots X_n\) with \(A \to X_1B\) and \(B \to X_2 \dots X_n\). We keep repeating this until there is only a single terminal symbol on the rhs, or two non-terminals.</p> <p>Consider a grammar in Chomsky form. The derivation tree will consist of nodes with either 2 children (\(A \to BC\)), 1 child (\(A \to a\)) or leaf nodes.</p> <p>Let the longest path in the derivation tree be \(k\). Then, the upper bound on the length of the word formed is \(2^{k - 1}\) and lower bound is \(k\). <strong>Note.</strong> The variables from \(V\) can repeat across a path.</p> <h2 id="pumping-lemma-for-cfg">Pumping Lemma for CFG</h2> <p>For any CFL \(L\), the language \(L - \{\epsilon \}\) has a Chomsky Normal form grammar.</p> <p><strong><em>Theorem.</em></strong> <em>Pumping Lemma</em> For every CFL \(L\), there is a \(n\) such that for all strings \(\vert z \vert \geq n\) with \(z \in L(G)\), there are strings \(u, v, w, x, y\) such that \(z = uvwxy\) and</p> <ul> <li> \[\vert vwx \vert \leq n\] </li> <li> \[\vert vx \vert \geq 1\] </li> <li>for all \(z_i = u v^iwx^iy\), \(i \geq 0\), \(z_i \in L(G)\).</li> </ul> <p>It is easy to show \(L = \{a^nb^nc^n \mid n \geq 1\}\) is not a CFL using the above lemma.</p> <h3 id="proof-of-the-lemma">Proof of the lemma</h3> <p>If there is a \(z \in L(G)\) such \(\vert z \vert \geq n = 2^k\), then there must be a path of length at least \(k + 1\). Now, due to pigeonhole principle, a variable must repeat in this path in the derivation tree of \(z\).</p> <p>Now, consider the path \(S, \dots, A, \dots, A, \dots, a\).</p> <ul> <li>It is easy to the see that the word formed by the subtree below the first \(A\) has length \(\leq n\).</li> <li>Also, as there are 2 \(A\)s in the path, the number of letters in the “left” subtree and “right” subtree would be greater than 1.</li> <li>These “left” and “right” subtrees can be derived an arbitrary number of times as \(A\) can be derived from \(A\).</li> </ul> <p><em>Note.</em> To draw some more intuition, call the subtree formed by the first \(A\) as \(T_1\), and the subtree formed by the second \(A\) as \(T_2\). We shall label the word formed by \(T_2\) as \(w\), and the word labeled by \(T_1\) as \(vwx\). Now, \(\vert vx \vert \geq 1\). <em>Think.</em> The “left” and “right” subtree in the above explanation together are formed by the set \(T_1 \setminus T_2\).</p> <blockquote> <p><strong><em>Homework.</em></strong> Show that the following languages cannot be represented by CFG.</p> <ul> <li> \[L = \{a^ib^ic^i \mid j \geq i\}\] </li> <li> \[L = \{a^ib^jc^k \mid i \leq i \leq k\}\] </li> <li> \[L = \{a^ib^jc^id^j \mid i, j \geq 1\}\] </li> </ul> </blockquote> <p>We shall see that 2 stacks PDA is the most expressive Turing machine.</p> <blockquote> <p>Can’t there be useless symbols in normal forms? yes -&gt; \(S \to AB\)</p> </blockquote> <h2 id="ogdens-lemma">Ogden’s Lemma</h2> <p>This lemma is a generalization of pumping lemma. Consider the pumping lemma for the FSA. It basically said that some state must repeat for a string of length \(\geq n\) in the language. Ogden’s lemma talks about a similar claim for CFGs. It will be formally discussed in the next lecture.</p> <h2 id="closure-properties">Closure properties</h2> <p>The union, concatenation and Kleene closure of CFGs are also CFGs. Proof is left as a homework.</p> <p><strong>Intersection</strong> is not context-free!</p> <h2 id="pushdown-automata">Pushdown Automata</h2> <p>Consider the languages \(L_1 = \{wcw^R \mid w \in (0 + 1)^* \}\) and \(L_3 = \{ww^R \mid w \in (0 + 1)^* \}\). Let us build PDAs for these two models.</p> <p>The stack of the PDA uses different symbols that those from \(\Sigma\). We shall denote the superset of symbols of stack by \(T\). Each transition in the PDA depends on the input symbol and the symbol on the top of the stack. These are similar to the FSA transition diagram. If both of these symbols are satisfied for the transition, we perform <em>an action</em> on the stack by pushing or popping symbols. Note that we can also choose to not perform any action.</p> <p>We shall also use the symbol \(X\) to denote ‘matching any character’ for the symbols on stack. We can also have \(\epsilon\) transitions in non-deterministic PDAs. \(\epsilon\) transitions basically denote ignoring input symbols.</p> <p><strong>Note.</strong> We can push multiple symbols in each transition but we can only pop one symbol in each transition.</p> <p>The PDA for \(L_1\) is given by</p> \[\begin{align} \delta(q_1, c, X) &amp;= (q_2, X) \\ \delta(q_1, 1, X) &amp;= (q_1, GX) \\ \delta(q_1, 0, X) &amp;= (q_1, BX)\\ \delta(q_2, 0, B) &amp;= (q_2, \epsilon) \\ \delta(q_2, 1, G) &amp;= (q_2, \epsilon) \\ \delta(q_2, \epsilon, Z_0) &amp;= (q_2, \epsilon) \\ \end{align}\] <p>The PDA for \(L_3\) is similar but we cannot express this language without non-determinism. We can’t guess where the “middle of the string” occurs without <em>guessing</em>. Therefore, non-deterministic PDAs are more expressive than deterministic ones.</p> <p>Remember that the non-deterministic PDA accepts a string if there is at least one run that accepts it.</p> <h3 id="formal-definition-of-pda">Formal definition of PDA</h3> <p>A Pushdown automata is formally given by the 7 element tuple \(M \lang Q, \Sigma, \Tau, \delta, q_0, Z_0, F \rang\) where</p> <ul> <li>\(\Tau\) is the set of stack symbols</li> <li>\(Z_0\) is a special symbol denoting the bottom of the stack</li> <li>\(F\) is the set of final states of the automata</li> <li>\(\delta: Q \times (\Sigma \cup \epsilon) \times \Tau \to (Q, \lambda)\) where \(\lambda \in \Tau^*\) is an action performed on the transition.</li> </ul> <p>A string is accepted if one of the runs ends with an empty stack or at a final state. That is, \(L(M) = \{w \mid (q_0, w, Z_0) \vdash^*_M (p, \epsilon, \epsilon)\} \cup \{ w \mid (q_0, w, Z_0) \vdash^*_M (q, \epsilon, \lambda), q \in F\}\). In the following lectures, we shall prove DPDA \(\neq\) NPDA, ‘accepting by empty stack’ \(\equiv\) ‘accepting by final state’ and PDA (NPDA) \(=\) CFG.</p> <p>We define a <strong>move</strong> or an <strong>arrow</strong> as a transition in the PDA.</p> <p><strong>Instantaneous Description</strong> refers to the property of defining a system using a <em>single number</em>. In case of a PDA, the description is given by a numerical representation of (Current string, Remaining input tape, Stack content). These values, that constitute the dynamic information of a PDA, keep changing during moves. The notation \(ID_1 \vdash_M ID_2\) denotes a single transition in the PDA. The notation \(ID_1 \vdash^*_M ID_2\) is a sequence of 0 or more moves.</p> <p>We have seen the <strong>accept criteria</strong> in the last lecture. We will show that a PDA built on the final state accept criteria has an equivalent PDA built on the empty state accept criteria.</p> <h2 id="greibach-normal-form">Greibach Normal Form</h2> <p>CFGs of the form \(A \to a\alpha\).</p> <p><strong>Note.</strong> \(\alpha\) in the above expression consists of non-terminals only!</p> <p>What are the challenges involved in converting a grammar to a Greibach normal form? It involves the following steps.</p> <h3 id="elimination-of-productions">Elimination of productions</h3> <p>Suppose we want to remove the rule \(A \to \alpha_1 B \alpha_2\) and keep the language of the CFG same. Then, we consider all rules of the form \(B \to \beta\) and replace each of them by \(A \to \alpha_1 \beta \alpha_2\). After doing this, we can delete the initial production involving \(A\).</p> <h3 id="left-recursion">Left Recursion</h3> <p>Suppose we have rules of the form \(A \to A\alpha_1 \mid A\alpha_2 \mid \dots \mid A\alpha_r\) which we wish to remove. Now, there would be other rules involving \(A\) of the form \(A \to \beta_1 \mid \dots \mid \beta_s\).</p> <p>Now, we define a new variable \(B \not\in V\). Then, we write rules of the form \(A \to \beta_1B \mid \dots \mid \ \beta_s B\) and \(\beta \to \alpha_1 B \mid \dots \mid \alpha_r B\). We can then remove all the left-recursive productions of \(A\). Basically, we have replaced left-recursion rules with right-recursion rules.</p> <h3 id="ordering-of-variables">Ordering of Variables</h3> <p>Simplify the variables in one order? <em>Wasn’t taught?</em></p> <h2 id="equivalence-of-pda-and-cfg">Equivalence of PDA and CFG</h2> <p>Given any CFG \(G\), we convert it into Greibach normal form. Then, we choose the non-terminals as the stack symbols. The initial symbol in the grammar is taken as the top symbol of the stack initially. For each rule \(A \to a\alpha\) we write the transition \(\delta(q, a, A) = (q’, \alpha)\). We start with a single state in the DFA, and write all the rules on this state. Through this intuition, we have shown that every CFG has a corresponding PDA. Then, we need to show that every PDA has a corresponding CFG.</p> <p>To show that CFG \(\subseteq\) PDA, we need to show the equivalence of a language in both directions. That is, for every string accepted by the CFG, we need to show that the PDA also accepts it and vice versa. Note that we also have to prove PDA \(\subseteq\) CFG.</p> <p>## Ogden’s Lemma revisited</p> <p>Suppose we had to prove the language \(L = \{a^ib^jc^kd^l \mid i = 0 \text{ or } j = k = l\}\) is not CFG. Can we do this using pumping lemma? No. <em>Think</em>.</p> <p>We do this using Ogden’s lemma which goes something like this. You can give a \(z = z_1 \dots z_m\) such that \(m \geq n\). Now, we can mark positions by choosing a subset of \(z_i\)’s. Then, the \(vwx\) from the pumping lemma must have at most \(n\) marked positions and \(vx\) has at least one marked position. This is a stronger condition as compared to the pumping lemma.</p> <blockquote> <p><strong><em>Homework.</em></strong> Show that \(L = \{a^ib^jc^k \mid i \neq j, j \neq k, i \neq k\}\) is not context-free using Ogden’s lemma.</p> </blockquote> <h2 id="closure-properties-of-cfls">Closure properties of CFLs</h2> <ul> <li><strong>Union</strong> - \(L(G_1) \cup L(G_2)\) regular? Yes. Add a rule \(S \to S_1 \mid S_2\).</li> <li><strong>Kleene closure</strong> - \((L(G_1))^*\) regular? Yes. Add a rule \(S \to S_1S \mid \epsilon\).</li> <li><strong>Concatenation</strong> - \(L(G_1). L(G_2)\) regular? Yes. Add a rule \(S \to S_1 S_2\).</li> <li><strong>Intersection</strong> - Consider the example \(L_1 = \{a^ib^ic^j \mid i, j \geq 1\}\) and \(L_2 = \{a^ib^jc^i \mid i, j \geq 1\}\). Both of them are context free but their intersection is not.</li> <li><strong>Complement</strong> - Easy to show from intersection.</li> </ul> <h2 id="decision-properties-of-cfls">Decision properties of CFLs</h2> <h3 id="is-the-language-empty">Is the language empty?</h3> <p>This is easy to check. Remove useless symbols and show that \(S\) is useful.</p> <h3 id="is-the-language-finite">Is the language finite?</h3> <p>Consider the Chomsky normal form of the grammar. <u>Draw a graph corresponding to the grammar such that every node has a single edge directed to a terminal or two edges directed to non-terminals</u>.</p> <p><strong><em>Claim.</em></strong> If the graph has a cycle, then the language formed by the grammar is infinite. This is intuitive.</p> <p>We can find cycles using DFS simply.We can derive more efficient methods which is not the goal of this course.</p> <h3 id="does-a-string-belong-to-the-language">Does a string belong to the language?</h3> <p>The first approach is the following. Get the Greibach form of the grammar. Now, for each letter \(c\) in the string check whether there are rules of the form \(A \to c\alpha\). We consider the values of all such \(\alpha\)s and continue parsing the rest of the input string. Therefore, at each letter in the string we limit the number of possible derivations. If we reach the end of the string without running out of possible derivations at each letter, then the string belongs to the language. Remember that we will start with the start symbol for the beginning of the string.</p> <p>However, we can see that this method is not very efficient. We shall see the CYK algorithm which works in \(\mathcal O(n^3)\).</p> <h2 id="additional-closure-properties-of-cfls">Additional closure properties of CFLs</h2> <ul> <li> <p>\(L(G) \cap R\), where \(R\) is a regular language, is also context-free.</p> <p>How do we show that \(L = \{ww \mid w \in (a + b)^*\}\) is not context free? It can be shown via pumping lemma which is complicated. However, it is very easy to prove it using the above property.</p> <p>How do we prove the closure property? Consider a \(PDA(M_1)\) for \(L(G)\) and \(DFA(M_2)\) for \(R\). Now, we construct a ‘product’ PDA similar to what we did in NFAs. We use the ‘final state’ accept PDA for the purpose. The final states would be \(F_1 \times F_2\). It is easy to see that we can get the required property.</p> </li> </ul> <h2 id="cyk-algorithm">CYK algorithm</h2> <p>The Cocke-Younger-Kasami algorithm can be used to check if a string \(w\) belongs to \(L(G)\).</p> <p>Suppose there is a \(w = w_1 w_2 \dots w_i \dots w_l \dots w_n\) whose membership we need to check. We consider subproblems of the form: Is \(w_{ij} \triangleq w_i \dots w_{i + j - 1}\) derivable from any non-terminal in the grammar? Then, finally, we need to answer is \(w_{1n}\) can be derived from \(S\).</p> <p>We consider the Chomsky normal form of the grammar for this algorithm. All strings of the form \(w_{j1}\) can be checked easily. For each \(w_{i1}\) we store all the non-terminals that can derive it. Now, the recursion for all \(j \geq 2\) is given by</p> \[f(w_{in}) = \bigcup_{j = 1}^{n - 1}\bigcup_{A \in f(w_{ij})} \bigcup_{B \in f(w_{i(n - j)})} \{C \mid (C \to AB) \in G \}\] <p>See the following example using the CYK algorithm.</p> <p><img src="/assets/img/Automata/image-20220222011041265.png" alt="image-20220222011041265"/></p> <p>It is easy to see that this algorithm takes \(\mathcal O(n^3)\).</p> <h3 id="epsilon-closure">\(\epsilon\) closure</h3> <p>We define \(\epsilon\) closure for a state \(q\) in a DFA as all the states that \(q\) can reach via \(\epsilon\) transitions. Then, to remove all the \(\epsilon\) transitions from \(q\), we add a transition corresponding to all transitions from \(q\) to each of the states in the \(\epsilon\) closure of \(q\). Also, if any state in the \(\epsilon\) closure of \(q\) is final, then \(q\) can also be made as a final state.</p> <p><strong>Note.</strong> Minimal DFAs need not be unique. They are isomorphic.</p> <h2 id="satan-cantor-game">Satan-Cantor Game</h2> <p>The game goes like this. Satan chooses a random natural number and asks Cantor to guess the number. Cantor gets a chance to guess once on each day. If Cantor guesses the right number, then he can go to heaven. Does Cantor have a strategy that will guarantee him going to heaven? Yes, Cantor can choose numbers in the sequence \(1, 2, 3, \dots\) and eventually <em>it is guaranteed</em> that Cantor chooses the correct number.</p> <p>Suppose, Satan changes the game by choosing a random integer. Does Cantor have a strategy then? Yes, choose numbers of the form \(0, 1, -1, 2, -2, \dots\). Now, suppose Satan chooses a pair of integers, then how do we get a strategy? We can order the points based on the distance from the origin in the 2D Cartesian plane (<strong>Cantor’s pairing function</strong>). Similarly, a tuple of \(n\) integers is also enumerable.</p> <p>Can we give a set for Satan such that the elements are not enumerable? What if Satan chooses \((n_1, \dots, n_k)\) where \(k\) is not known to Cantor. Can Cantor win in this case? Yes. <em>Proof is homework</em>.</p> <p>Satan can choose the set of real numbers, and in that scenario Cantor would not be able to win. The key idea here is <a href="https://www.cse.iitb.ac.in/~mp/teach/ds/aut19/slides/21.pdf"><strong>Cantor’s diagonalization argument</strong></a>.</p> <p>Also, look up <a href="https://en.wikipedia.org/wiki/Kolmogorov_complexity">Kolmogorov complexity</a>. Enumerability \(\equiv\) Countability.</p> <h2 id="enumerability-in-languages">Enumerability in Languages</h2> <p>A language which is finite will be regular, and we can build an FSA for it. How about infinite languages? CFLs can represent a subset of these languages.</p> <p>If we categorise the infinite languages as languages which are <u>recursively enumerable</u> and <u>uncountable</u>. Can we build models for recursively enumerable languages?</p> <h2 id="turing-machines">Turing Machines</h2> <p>Turing wanted to build a machine that could recognize any enumerable language. The inspiration is drawn from the <em>recursive function theory</em> developed by Alonzo Church. There are other people who developed <strong>Type-0 grammars</strong> which are similar to CFGs but the left hand side of the rules can consist of a string composed of terminals and non-terminals making it context-dependent.</p> <p>Church and Turing came up with a thesis, and they proposed that Church’s theory and Turing’s machine can be used to compute any <em>effectively computable</em> function.</p> <blockquote> <p><strong><em>Aside.</em></strong> Aren’t all languages enumerable with alphabet being a finite set?</p> </blockquote> <p>“Is \(L(G)\) empty?” is a decidable problem. However, “Is the complement of \(L(G)\) empty?” is not decidable! This property was proven by Godel.</p> <p>We shall now introduce the notion of Turing machines. Instead of a stack, we have an <strong>input tape</strong> with a <em>fixed left end</em>. A string is written in the tape with each letter being in a <strong>cell</strong> of the tape. The machine also involves a control which is essentially a FSM that takes the input from the tape, and performs actions on it. Basically, in PDAs, we could only see the top of the stack, but here we are able to freely traverse over the tape.</p> <h2 id="definitions-from-set-theory">Definitions from set theory</h2> <p><strong><em>Definition.</em></strong> <strong>Enumerable</strong> of a set refers to the property of being able to define a one-to-one correspondence from the elements of the set to positive integers.</p> <p><strong><em>Definition.</em></strong> In computability theory, a set \(S\) of natural numbers is called computably enumerable, recursively enumerable, semi-decidable, partially decidable, listable, provable or Turing-recognisable if</p> <ul> <li>there is an algorithm such that the set of input numbers for which the algorithm halts is exactly \(S\).</li> <li>or equivalently, there is an algorithm that enumerates the members of \(S\). That means that its output is simply a list of all the members of \(S = \{s_1, s_2, s_3, \dots\}\) . If \(S\) is infinite, this algorithm will run forever.</li> </ul> <h2 id="dovetailing">Dovetailing</h2> <p>In the Satan-Cantor game, the idea was to enumerate all possible answers “fairly”.</p> <p>Let us consider the scenario where Satan chooses a \(k\) tuple of integers where \(k\) is unknown. How do we enumerate this set? We use dovetailing for the same. Consider the tuple \((k, n)\). For one such given tuple, we will enumerate all \(k\)-tuples with distance from origin being less than \(n\). The idea is that we are balancing the enumeration across two dimensions, \(k\) and \(n\), together.</p> <h2 id="cantors-diagonalization">Cantor’s diagonalization</h2> <p>How is the above set different from the power set of natural numbers? Let us consider the question in terms of languages. Consider a language \(L \subseteq \Sigma^*\) with a finite \(\Sigma\). \(\Sigma^*\) is enumerable (\(\epsilon, a, b, c, aa, ab, ac, \dots\)). Now, is the set of all languages \(\mathcal L\) enumerable? We know that \(\mathcal L = 2^{\Sigma^*}\).</p> <p>We shall use contradiction to show that the set is not enumerable. Consider the following table -</p> <table> <thead> <tr> <th> </th> <th>\(\epsilon\)</th> <th>\(a\)</th> <th>\(\dots\)</th> </tr> </thead> <tbody> <tr> <td>\(L_1\)</td> <td>1</td> <td>0</td> <td> </td> </tr> <tr> <td>\(L_2\)</td> <td>1</td> <td>1</td> <td> </td> </tr> <tr> <td>\(\vdots\)</td> <td> </td> <td> </td> <td>\(\ddots\)</td> </tr> </tbody> </table> <p>The table consists of all the languages (assuming they are enumerable) with the respective strings in the language tagged as 1. Define the language \(L_{new} = \{w_i \mid w_i \not \in L_i\} \forall i \in \mathcal N\). We then have a contradiction that \(\exists L_{new}\) such that \(l_{new} \neq L_i\) for any \(i\).</p> <p><strong>Claim.</strong> The state of every computer can be encoded as a <em>single</em> number.</p> <h2 id="turing-machines-2">Turing Machines (2)</h2> <p>The machine can do the following things</p> <ul> <li>Replace the symbols on the tape by symbols in \(T\) where \(\Sigma \subseteq T - \{B\}\). \(B\) is a blank symbol to denote an empty cell</li> <li>Move left or right by one step</li> <li>Go to the next state</li> </ul> <p>So, the labels on the transitions of the FSM are of the form \(X \mid Y, D\) where \(X, Y \in T\) and \(D = L \mid R\). It means that the symbol \(X\) in the cell is replaced by the symbol \(Y\). The machine has to <em>definitely</em> move left or right in each transition. A “run” starts from the first cell and the state \(q_0\) in the FSM. As an example, we consider the following FSM for the language \(L = \{0^n1^n \mid n \geq 1\}\).</p> <p><img src="/assets/img/Automata/image-20220312155130493.png" alt="image-20220312155130493"/></p> <p><strong>TODO</strong> Draw the above diagram again.</p> <p>In a Turing machine, we halt when there is no move possible.</p> <p>Formally, a Turing machine is defined as \(T = (Q, \Sigma, T, \delta, q_0, B, F)\) where \(\delta: Q \times T \to Q \times T \times \{L, R\}\). There are many variations possible to this machine which we shall show are equivalent to this simple definition. For example, we can have multiple tapes, output tape, non-determinism, etc.</p> <blockquote> <p>Is countable same as enumerable? Countable implies that there is a one-to-one mapping from the elements in the set to natural numbers. This definition is equivalent to that of enumerability.</p> <p>A Turing machine can enumerate a language. A language is <strong>recursively enumerable</strong> if a Turing machine can enumerate it.</p> <p>\(\Sigma^*\) is enumerable but there are languages in \(\Sigma^*\) which are not enumerable.</p> </blockquote> <p>The theory of Turing machines was developed in the 1930s.</p> <p>Consider the derivation \((q_0, w_{inp}) \vdash^*_M (q_k, x)\) where the machine halts. A machine halts when there is no move at any given state. If \(q_k \in F\) and the machine \(M\) halts, then \(M\) accepts \(w_{inp}\).</p> <h3 id="variations-of-turing-machines">Variations of Turing Machines</h3> <ul> <li>2-way infinite tapes</li> <li>Multi-tape heads</li> <li>Non-determinism</li> <li>Output type (write only, immutable)</li> </ul> <p>Let us try and build the Turing machine for \(L = \{a^nb^nc^n \mid n \geq 1\}\). We’ll use the following logic. In each pass, we will change 1 a, 1 b and 1 c to X, Y and Z respectively. If we have any extra a’s, b’s or c’s, then we will halt.</p> <p><img src="/assets/img/Automata/image-20220312183041093.png" alt="image-20220312183041093"/></p> <p>The machine is given in the above diagram.</p> <blockquote> <p><strong><em>Homework.</em></strong> Draw a Turing machine for the language \(L = \{ww \mid w \in (a + b)^+\}\). Hint - Think of subroutines. That is, tackle smaller problems like “Find the middle of the string”, and then match left and right.</p> <p><strong><em>Homework.</em></strong> Try \(L = \{a^n \mid n \text{ is prime}\}\)</p> </blockquote> <h2 id="type-0-grammars">Type-0 Grammars</h2> <p>These are also known as <strong>Unrestricted grammars</strong>. These are essentially same as CFGs but the LHS of rules can be any string. Consider the language \(L = \{a^nb^nc^n\mid n \geq 0\}\). The grammar can be as follows</p> \[\begin{align} S &amp;\to ABCS \mid T_c \\ CA &amp;\to AC \\ BA &amp;\to AB \\ CB &amp;\to BC \\ CT_c &amp;\to T_cc \\ BT_b &amp;\to T_bb \\ AT_a &amp;\to T_aa \\ T_c &amp;\to T_b \\ T_b &amp;\to T_a \\ T_a &amp;\to \epsilon \end{align}\] <p>If one notices closely, then there are a few issues with this grammar. However, it is correct considering non-determinism. That is, a terminal string derived from this grammar will be in \(L\).</p> <blockquote> <p><strong><em>Homework.</em></strong> Write the Type-0 grammar for \(L = \{ww \mid w \in (a + b)^+\}\)</p> </blockquote> <p>Let us go back to the \(L = \{a^nb^nc^n\}\) language. How do we come up with a deterministic grammar? We use the idea of <strong>markers</strong>.</p> <ul> <li> <p>1-end marker</p> \[\begin{align} S &amp;\to S_1$ \\ S_1 &amp;\to ABC \mid ABCS_1 \\ CA &amp;\to AC \\ CB &amp;\to BC \\ BA &amp;\to AB \\ C$ &amp;\to c ,\; Cc \to cc \\ Bc &amp;\to bc ,\; Bc \to bb \\ Ab &amp;\to ab ,\; Aa \to aa \\ \end{align}\] <p>The problem with the above grammar is obvious. This issue is often prevented using priority rules in hierarchical grammars. Another fix for this is, adding the following set of rules</p> \[\begin{align} Ca &amp;\to aC ,\; ca \to ac\\ Cb &amp;\to bC ,\; cb \to bc\\ Ba &amp;\to aB ,\; ba \to ab \end{align}\] <blockquote> <p>Check if this is correct</p> </blockquote> </li> <li> <p>2-end marker</p> </li> </ul> <h3 id="tm-as-a-recogniser">TM as a recogniser</h3> <p>Are the set of moves on a TM a decision procedure? A decision procedure refers to a procedure that outputs yes or no for a given input. It involves <em>correctness</em> and <em>termination</em>. No, TM does not do that. For example, consider never halting TMs. Therefore, TM is a semi-decision procedure. In order to classify TM as a decision procedure, we need to show that it halts on every input. Also, we need to show that it gives the correct answer.</p> <h3 id="tm-as-a-computer">TM as a “computer”</h3> <p>Can TM replicate any function of the form \(y = f(X_1, \dots, X_n)\) where the arguments belong to $\mathbb N$. Yes, it can be done. What should a Turing machine do when we give invalid arguments to partial functions? It should never halt. On total functions, the TM must always halt and give the correct answer. For example, we have the following TM for \(f(x, y) = max(0, x - y)\). Numbers \(x\) and \(y\) are written consecutively on the tape in unary form separated by a \(1\).</p> <p><img src="/assets/img/Automata/image-20220328173509367.png" alt="image-20220328173509367"/></p> <p>If the TM has to halt when \(w \not \in L\), then we shall see that this set of TMs will only recognise recursively enumerable languages. For TMs to accept all the enumerable languages, we must allow the TM to not halt for certain inputs.</p> <h3 id="tm-as-an-enumerator">TM as an enumerator</h3> <p>Such TMs do not take any input. It continuously writes input on the tape and never halts. The TM prints a sequence that looks like the following \(w_1 \# w_2 \# \dots\) for each \(w_i \in L\). The machine halts if \(L\) is finite, but doesn’t otherwise. \(L\) is recursively enumerable iff a TM can enumerate the language.</p> <p><strong>Semi-Decision Procedure</strong> - Given \(M_1\) for \(L\) as an enumerator, construct \(M_2\) as a recogniser for \(L\). In \(M_2\), we can just check if the given input is present in the list of words printed by \(M_1\). Now, we have come up with a semi-decision procedure based on an enumerator.</p> <p>Our goal is to determine if there are any functions that cannot be computed by TMs. Or rather, are there any languages that TM cannot enumerate or recognise. Enumeration and Recognition are equivalent (hint: dovetailing).</p> <h2 id="recursive-function-theory">Recursive Function Theory</h2> <p>Let \(N = \{0, 1, \dots\}\). Any function we consider will be of the form \(f: N^k \to N\). How do we define these functions? We start with base cases and recursion. To define these functions, we shall define some basic functions that will be used to define the others.</p> <ul> <li><strong>Constant function</strong> - \(C^k_n(x_1, \dots, x_k) = n\) for all \(x_1, \dots, x_k \in N\).</li> <li><strong>Successor functions</strong> - \(S(x) = x + 1\).</li> <li><strong>Projection function</strong> - \(P^k_i(x_1, \dots, x_i, \dots, x_k) = x_i\) for \(1 \leq i \leq k\).</li> </ul> <p>We move on to more primitive recursive functions.</p> <ul> <li><strong>Composition</strong> - \(f(x_1, \dots, x_k) = h(g_1(x_1, \dots, x_k), \dots, g_m(x_1, \dots, x_k))\)</li> </ul> <p>Primitive recursion is given by</p> <ul> <li><strong>Basecase</strong> - \(f(0, x_1, \dots, x_k) = g(x_1, \dots, x_k)\)</li> <li><strong>Recursion</strong> - \(f(S(y), x_1, \dots) = h(y, f(y, x_1, \dots, x_k), x_1, \dots, x_k)\)</li> </ul> <p>For example, the formal definition of \(+\) is given by</p> \[\begin{align} +(0, x) &amp;= P^1_1(x) \\ +(S(y), x) &amp;=h(y, +(y, x), x) \\ h(y, +(y, x), x) &amp;= S(+(y, x)) \end{align}\] <p>There are functions which are not primitive recursive.</p> <p>We shall see that primitive recursion is not expressive enough, Adding “minimization” to our set of rules will help us define any total function. We shall also see <strong>Equational Programming</strong> that is Turing-complete.</p> <p>As we have seen earlier, we are using 3 base functions - constant, successor, and projection. Composition is depicted as \(f = h \circ (g_1, \dots, g_m)\).</p> <p>Primitive-Recursion in layman’s terms refers to recursion using for loops. We write the functions as \(f = \rho(g, h)\) where \(g, h\) are the same functions that are used in the recursive definition. For example, \(add \triangleq \rho(P_1^1, S \circ P_2^3)\). The recursion must be of this form. The formal definition of \(mult\) is given by \(mult \triangleq \rho(C_0^1, add \circ (P_1^3, P_2^3))\).</p> <p>How do we write functions such as \(div\). Do we need <code class="language-plaintext highlighter-rouge">if-then-else</code> notion in our theory? Before we define this, let us try to define \(prev\) functions. We will define that \(prev(0) = 0\) for totality of the function. Then, we can define the function as \(prev \triangleq \rho(C_0^0, P_1^2)\). Using, \(prev\) we can define \(monus\) as \(monus(y, x) = x \dot- y \triangleq \rho(P_1^1, prev \circ P_2^3)\).</p> <p>Now, to introduce the notion of booleans, we define \(isZero \triangleq \rho(C_1^0, C_0^2)\). We can use this function to utilise booleans. Similarly, \(leq \triangleq \rho(C_1^1, isZero \circ monus \circ (S \circ P_1^3, P_3^3))\). Using similar logic, we can implement looping and branching.</p> <p>We will now see the limitations of primitive-recursion.</p> <h2 id="limitations-of-primitive-recursion">Limitations of primitive recursion</h2> <p>We have seen composition as \(h \circ (g_1, \dots, d_n)\). This concept is equivalent to passing parameters to functions in programming. To refresh the shorthand notion of primitive recursive functions, we define if-then-else as \(if\_then\_else(x, y, z)\) as \(y\) when \(x &gt; 0\) and \(z\) otherwise. Therefore, \(if\_then\_else(x, y, z) = \rho(P_2^2, P_3^4)\). Using this, we define</p> \[\begin{align} quotient(x, y) &amp;\triangleq \rho ( ite \circ (P_1^1, 0, \infty), \\ &amp; ite \circ (P_3^3, ite \circ ( \\ &amp;monus \circ (mult \circ (P_3^3, S\circ P_2^3) , \\ &amp;S \circ P_1^3) , P_2^3 , S \circ P_2^3), \infty) ) \end{align}\] <h3 id="ackermann-function">Ackermann function</h3> <p>Many mathematicians tried to show that primitive recursion is not enough to represent all functions. In this pursuit, Ackermann came up with the following function</p> \[\begin{align} A(0, x) &amp;= x + 1\\ A(y + 1, 0) &amp;= A(y, 1) \\ A(y + 1, x + 1) &amp;= A(y, A(y + 1, x)) \\ \end{align}\] <p>Similarly, there is a ‘91-function’ that Mc Carthy came up with. It is given as</p> \[M_c (x) \begin{cases} x - 10 &amp; x&gt; 100 \\ M_c(M_c(x + 11)) &amp; \text{otherwise} \end{cases}\] <p>The above function always returns \(91\) for \(x &lt; 100\). However, it requires a lot of recursive calls for evaluating its value.</p> <h3 id="all-primitive-functions-are-total">All primitive functions are total</h3> <p>The converse of the above statement is false. For example, the Ackermann function is not primitive. The idea is to show that any \(f\) defined using primitive recursion grows slower than \(A(n_f, y)\) for some \(n_f\). Using <em>Godel numbering</em> we can count all the possible primitive recursive functions.</p> <h2 id="partial-recursive-functions">Partial Recursive functions</h2> <p>We use the idea of <strong>minimisation</strong> to define partial functions and also increase the expressive power of our definitions. We have the following definition</p> \[\mu(f)(x_1, \dots, x_k) \triangleq \begin{cases} z &amp; \forall z_1 &lt; z \; f(z_1, x_1, \dots, x_k) &gt; 0 \land f(z, x_1, \dots, z_k) = 0\\ \end{cases}\] <p>Notice that the first case in the above definition behaves like a while loop, as it gives the smallest value of \(z\) that renders the function zero. The ‘partiality’ in the function definition comes from the fact that \(f\) may never be zero.</p> <p><u>The Church-Turing thesis states that all definable functions that can be defined using primitive recursion, minimisation, and substitution can be computed by a Turing machine.</u> There is no proof for this yet. The set of these functions is the set of ‘all effectively computable functions’. However, there are undecidable functions that are not computable by a TM.</p> <h2 id="equational-logic">Equational Logic</h2> <p>This paradigm has the same expressive power as primitive recursion but is easier to express. To start off, we consider the function \(leq\). We will define \(N\) as \(\{0, S(0), S(S(0)), \dots\}\). We write the rules as</p> \[\begin{align} leq(0, x) &amp;= S(0) \\ leq(S(x), 0) &amp;= 0 \\ leq(S(x), S(y)) &amp;= leq(x, y) \end{align}\] <p>This way of writing rules is known as <strong>Pattern matching</strong>. Similarly, \(gcd\) is given by</p> \[\begin{align} gcd(0, x) &amp;= x \\ gcd(add(x, y), x) &amp;= gcd(y, x) \\ gcd(y, add(x, y)) &amp;= gcd(y, x) \\ \end{align}\] <p>In the above definition, the pattern matching is <em>semantic</em> and not <em>syntactic</em>. The <em>syntactic</em> pattern matching definition uses \(if\_then\_else\). However, note that \(if\_then\_else\) is always assumed to be calculated in a <strong>lazy manner</strong>. That is, the condition is evaluated first and the corresponding branch is then evaluated. If the expressions in the two branches are evaluated along with the condition, then there is a chance that the computation never ends.</p> <p>Also, the factorial function \(fact\) is given by</p> \[\begin{align} fact(0) &amp;= S(0) \\ fact(S(x)) &amp;= mult(S(x), fact(x)) \end{align}\] <p>Another way of writing the factorial function using <strong>tail recursion</strong> is</p> \[\begin{align} f(x) &amp;= f_a(1, x) \\ f(y, 1) &amp;= y \\ f_a(y, S(x)) &amp;= f_a(y\times S(x), x) \end{align}\] <p>Notice that the first definition of \(fact\) is very inefficient compared to the latter. The second definition does inline multiplication with the arguments carrying the answer. However, the values are pushed on to the stack in the case of the first definition. These concepts of optimisation come to great use in building compilers.</p> <h2 id="term-rewriting">Term-rewriting</h2> <p>We have seen 3 computation paradigms</p> <ul> <li>Turing machine</li> <li>Type-0 grammars</li> <li>Partial recursive functions</li> </ul> <p>Now, we shall see a 4th paradigm called as term rewriting.</p> <p>We have <strong>terms</strong> and <strong>domains</strong>. There a few constructors involved with a domain. For example, we have \(0, S\) for \(N\). Also, for lists we have \(nl\) (empty list) and \(\bullet\) (cons/pipe). We use them as follows</p> <p><img src="/assets/img/Automata/image-20220330010921594.png" alt="image-20220330010921594"/></p> <p>There are also constants (\(0\)) and function symbols/constructors (\(S\)). Termination is guaranteed in normal forms. We also want unique normal form. This will ensure that a term gives a single answer with different recursions (<strong>confluence</strong>). If we get two answers, we call it ill-defined systems.</p> <p>To understand this better, we shall define \(exp\).</p> \[\begin{align} exp(x, 0) &amp;= s(0) \\ exp(x, S(y)) &amp;= mult(x, exp(x, y)) \end{align}\] <p>\(max\) is defined as</p> \[\begin{align} max(0, y) &amp;= y \\ max(S(x), S(y)) &amp;= max(x, y) \\ max(x, 0) &amp;= x \\ \end{align}\] <h3 id="lists">Lists</h3> <p>Suppose we want to define \(app\). We then have</p> \[\begin{align} app(nl, y) &amp;= y \\ app(\bullet(x, y), z) &amp;= \bullet(x, app(y, z)) \end{align}\] <p>Similarly,</p> \[\begin{align} rev(nl) &amp;= nl \\ rev(\bullet(x, y)) &amp;= app(rev(y), \bullet(x, nl)) \end{align}\] <blockquote> <p><strong><em>Homework.</em></strong> Show that \(len(x) = len(rev(x))\)</p> </blockquote> <p>How do we sort a list of numbers?</p> \[\begin{align} sort(nl) &amp;= nl \\ sort(\bullet(x, y)) &amp;= ins(x, sort(y)) \\ ins(x, nl) &amp;= \bullet(x, nl) \\ ins(x, \bullet(y, z)) &amp;= \bullet(\min(x, y), ins(\max(x, y), z)) \end{align}\] <blockquote> <p><strong><em>Homework.</em></strong> Try quick sort and merge sort.</p> </blockquote> <h3 id="termination">Termination</h3> <p>We have termination on \(N\) due to \(&gt;\). How about \(N \times N\)? We use <strong>lexicographic ordering</strong>. One might think it’s not well-founded. This is because \((9, 1)\) is greater than \((5, 1000)\). However, it is well-founded for finite length tuples. In case of strings, the length need not be finite in lexicographic ordering. Therefore, the ordered list need not be finite.</p> <blockquote> <p><strong><em>Homework.</em></strong> Give an ordering rule for multi-sets</p> </blockquote> <h3 id="predicates-and-branching">Predicates and Branching</h3> <p>It is easier to express these things in the term-rewriting paradigm. I’m skipping these for brevity.</p> <p>Can we write \(isPrime\), \(gcd\), and \(nth-prime\)? This paradigm naturally develops to Functional Programming. It’s essentially writing everything in terms of functions as we’ve been doing so far.</p> <h3 id="logic-programming">Logic Programming</h3> <p>Suppose we give the black-box the input \(x + 3 = 10\). Can we determine \(x\)? Can we ask multiple answers in case of \(u + v = 10\)? It is possible to do so in logic programming. We do this by <u>passing parameters by unification</u>. That is, we try to convert the parameters \(u, v\) to look like the parameters given in the rules of \(+\). This is known as <strong>backtracking</strong>.</p> <p>Term matching is don’t care non-determinism. There might be multiple possible reductions at any given situation, and all will lead to the same answer in case of well-formed normal forms. Also, all the paths should terminate.</p> <p>What are the strategies for computing normal forms?</p> <ul> <li><strong>Hybrid</strong> - Check if sub-term matches rule-by-rule</li> <li><strong>Innermost</strong> - Many programming languages adopt this. Evaluate the “lowest” redex first.</li> <li><strong>Outermost</strong> - This is lazy evaluation. We evaluate topmost redex first.</li> </ul> <p>Redex is a sub-term where a rule can be applied.</p> <p>And then, sir lost his connection :D</p> <blockquote> <p><strong><em>Aside.</em></strong> Write primality test function using primitive recursion. \(\begin{align} prime(0) &amp;= 0 \\ prime(S(x)) &amp;= g(x, S(x)) \\ \\ g(0, y) &amp;= 0 \\ g(S(x), y) &amp;= ite(isZero(y), 1,\\ &amp;ite(isZero(monus(S(x), gcd(S(x), y))), 0, g(x, y))) \\ \\ gcd(0, y) &amp;= y \\ gcd(S(x), y) &amp;= ite(gte(S(x), y), \\ &amp;gcd(monus(S(x), y), y), gcd(y, x)) \end{align}\)</p> </blockquote> <p>We were discussing the definition of \(quotient\) in the previous lecture. In terms of minimisation, we can write the definition as</p> \[\begin{align} quotient(x, y) &amp;= \mu(f)(x, y) \\ f(k, x, y) &amp;= y*k &gt; x \end{align}\] <h2 id="encoding-turing-machines">Encoding Turing machines</h2> <p>Let us consider the example of enumerating all the finite subsets of \(N\). A subset \((n_1, n_2, \dots, n_k)\) is represented as \(m = p_1^{n_1} \times \dots \times p_k^{n_k}\) where \(p_1, \dots, p_k\) are the first \(k\) prime numbers. Note that we need to ignore trailing zeros for this.</p> <p>Can we enumerate Turing Machines? Let us try to encode a Turing Machine as a bit string. The core idea is that a Turing Machine has a finite set of states. We can encode a transition in the following way - Suppose we have the transition \(\delta(q_3, X_1) = (q_7, X_2, D_0)\). Then, the bit string corresponding to this is \(11\; 000 \;1 \; 0000000 \; 1\; 0 \; 1 \; 00 \; 1 \; 0 \; 11\) Here, a \(1\) just acts as a separator, and every state, tape symbol and direction are encoded in unary format. A substring \(11\) represents the start of a transition, followed by \(q_3, q_7, X_1, X_2, D_0\) for the above example. This way, we can list all the transitions of the Turing Machine. All the transitions can be enclosed between a pair of substrings \((111, 111)\). Now, we just need to add the set of final states.</p> <p>Instead of listing out all the final states, we can convert the Turing Machine to an equivalent TM which has a single finite state.</p> <blockquote> <p><strong><em>Homework.</em></strong> Prove that the above conversion can be done for any Turing Machine.</p> </blockquote> <p>Now that we have encoded a TM, how do we enumerate the set of all TMs? We know how to enumerate bit strings based on the value and the length (ignore leading \(0\)‘s for non-ambiguity). We need out to weed out the bit strings that do not represent a valid TM.</p> <p>What features are present in a bit string that represents a TM? It needs to start with \(111\), and end with \(111\). If there is a \(11\) in between the above substrings, there need to be at least 4 \(1\)‘s in between with appropriate number of \(0\)’s in between. This concludes our discussion on encoding TMs.</p> <h2 id="variants-of-tm">Variants of TM</h2> <p>Let us consider the time of execution with a single computer and \(n\) computers. Any task will have at most \(n\) times speedup when done on \(n\)-computers in comparison to a single computer (generally). For example, matrix multiplication can be heavily parallelised. However, tasks such as gcd calculation of \(k\) numbers is <em>inherently sequential</em> and it is not easy to speed it up using parallel computation.</p> <p>Now, we shall consider variants of TMs and show equivalence of each with the 1-way infinite tape variant.</p> <h3 id="2-way-infinite-tape">2-way infinite tape</h3> <p>It is easy to see that a 2-way infinite tape can be restricted of the left movement beyond a point to simulate all the 1-way infinite tape machines.</p> <p>To prove the other direction, we will consider a multi-track 1-way TM. That is, every cell will now contain 2 elements. The basic idea is that a 2-way machine of the form \(\dots \mid B_1 \mid B_0 \mid A_0 \mid A_1 \mid \dots\) will be converted to \((A_0, C) \mid (A_1, B_0) \mid \dots\).</p> <p>The states in the 2-way machine will be separated based on whether the transition is on the left side of the tape or the right side. Then, based on the side, we will work on the first element in the tuple of each cell or the second element. The formal proof is left to the reader.</p> <h3 id="multi-tapes">Multi tapes</h3> <p>There are multiple tapes under a single control. Therefore, each transition is represented as \(( X_1, \dots, X_k )\mid ( Y_1, \dots, Y_k) , (D_1, \dots, D_k)\). One can see that all the logic boils down to the Satan-Cantor puzzle.</p> <p>Again, one direction of the equivalence is straightforward. The other half involves converting a \(k\)-tuple to a natural number.</p> <h3 id="non-determinism-2">Non-Determinism</h3> <p>The equivalence can be shown in a similar way as that of regular languages.</p> <h3 id="k-head-machine">k-head machine</h3> <p>We have a single tape which has multiple heads that move independently.</p> <h3 id="offline-tm">Offline TM</h3> <p>The input tape never changes. That is, the actions are read-only.</p> <h2 id="universal-turing-machine">Universal Turing Machine</h2> <p>The intention is to build a general purpose computer. Recollect that a Turing Machine is represented as \(M = (Q, \Sigma, T, \delta, q, B, F)\).</p> <p>Every Turing Machine has an equivalent TM</p> <ul> <li>whose alphabet is \(\{0, 1\}\) and the set of tape symbols is \(\{0, 1, B\}\), and</li> <li>has a single final state.</li> </ul> <p>\(L\) is</p> <ul> <li><strong>recursively enumerable</strong> - there exists a TM (recogniser) that accepts \(L\) (need not halt on wrong input, think of recogniser built from enumerators).</li> <li><strong>recursive</strong> - there is a TM that accepts \(L\) <u>which halts on all inputs</u>.</li> </ul> <p>For example, consider the language that accepts a pair of CFGs \((G_1, G_2)\) if \(L(G_1) \cap L(G_2) \neq \phi\). To show that this language is recursively enumerable, we will give a <em>high level</em> algorithm in terms of primitive steps that we know can be converted to a TM. We consider the following algorithm.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>- Enumerate L(G_1) // enumerate w, check G_1 =&gt;* w (CYK)
- For each w in L(G_1) check if G_2 =&gt;* w
</code></pre></div></div> <p>Now, if we generate a word and check for the word in the other grammar alternately, then the algorithm will halt if the input is acceptable. However, it is not guaranteed to halt in case of unacceptable input for this algorithm. Does that mean the language is recursively enumerable?</p> <p>We need to show that we can’t construct an algorithm that halts in case of an unacceptable input. Then, we can conclusively state that the language is recursively enumerable.</p> <p>In conclusion, there are language that are recursively enumerable, and languages that are not recursively enumerable. The set of recursive languages are a strict subset of the set of recursively enumerable languages.</p> <h3 id="non-recursive-language">Non-recursive language</h3> <p>We know that we can enumerate all TMs and all \(w \in \Sigma^*\). Then, we draw a 2D infinite bit matrix A where \(A_{ij}\) tells whether \(w_i \in M_j\). Now, we use the Cantor’s diagonalization argument to conclude that \(L_d = \{i \mid A_{ii} = 0\}\) is not recursively enumerable. <strong>Genius proof</strong> based off Barber’s paradox.</p> <p>If \(L\) is not recursively enumerable, then \(\bar L\) is also not recursively enumerable. That is, show that if TM accepts \(L\), then it must also accept \(\bar L\).</p> <p>One might ponder on how we construct the table \(A\) when some TM may not halt for a few inputs. The important distinction is that, we are “defining” this table conceptually and not “computing” it. The concept of dovetailing also comes to use here.</p> <h3 id="recursively-enumerable-but-not-recursive">Recursively enumerable but not Recursive</h3> <p>The language of the <strong>Universal Turing Machine</strong> is the required example. We formally define this language as \(L_u = \{( M, w) \mid\ M \text{ halts on } w\}\).</p> <p>Equivalently, we are trying to write a Python script that takes another Python script as input along with some arguments. This script should halt when the input python script halts on the input argument, and need not halt otherwise. Basically, we are trying to build a simulator TM.</p> <blockquote> <p>No lectures 32 and 33.</p> </blockquote> <h2 id="undecidability">Undecidability</h2> <p>A language \(L \subseteq \Sigma^*\) is <strong>recursive</strong> if there is a Turing Machine \(M\) that halts in an accept state if \(w \in L\) and in a reject state if \(w \not\in L\). It <em><u>need</u></em> not halt in reject states for <strong>recursively enumerable</strong> languages. The algorithms similar to the latter TMs are <strong>semi-decidable</strong>.</p> <p>We were looking for languages that are not recursively enumerable \(L_d\) and languages that are recursively enumerable but not recursive \(L_u\). For the latter set, we had seen the universal TM. We also have the language of “polynomials that have integer roots”. How do we show that this is recursively enumerable? The key idea lies in encoding polynomials as a number. The motivation for this language comes from <strong>Hilbert’s 10th Problem</strong>.</p> <p>Another example for an undecidable problem is the <strong>Halting Problem</strong>.</p> <p>Let us continue the discussion on \(L_u\) and \(L_d\) from the last lecture. We had constructed a matrix \(A\) and showed using the diagonalization argument that there are languages that are not recursively enumerable. However, we did not address two issues</p> <ul> <li>There are multiple TMs that accept the same language - It does not matter.</li> <li>How do we fill the table? - Computation vs Definition.</li> </ul> <p>Also, all the languages defined by each row \(A_i\) in the matrix form the set of recursively enumerable languages.</p> <p>We had defined \(L_u\) as \(\{(M_i, w_j) \mid M_i \text{ accepts } w_j \}\). We will show that this language is recursively enumerable by constructing a Turing Machine \(M\) that accepts this language. The input tape will initially have the encoding of \(M_i\) followed by the encoding of \(w_j\). Now, we use two more tapes</p> <ul> <li>One for copying \(w_j\)</li> <li>Another tape for keeping track of the state in \(M\), starting with state 0.</li> </ul> <p>Now, we give the higher level logic of \(M\).</p> <ul> <li>Validate \(M_i\). This can be done using a TM.</li> <li>Run \(M_i\) step-by-step. Pick the top state from the 3rd tape, find the corresponding move from the first tape, and update the 2nd and 3rd tapes.</li> </ul> <p>The last two tapes help simulate any input TM. In conclusion, we have constructed a universal TM. Therefore, the TM paradigm is powerful enough to perform <strong>self-introspection</strong>.</p> <p>Note that we have still not shown \(L_u\) is not recursive. We will use the properly of \(L_d\) not being recursively enumerable to show this.</p> <p>Let us continue the discussion on the Universal Turing Machine. The encoding of a move \(\delta(q_i, X_j) = (q_k, Xl, D_m)\) in a Turing Machine is \(0^i10^j10^k10^l10^m\). The universal TM works in 3 steps</p> <ul> <li>Decode/Validate</li> <li>Set up the tapes</li> <li>Simulate</li> </ul> <p>Also, we had shown that \(L_u\) is recursively enumerable by the construction of the universal TM. Suppose, there is a TM that halts every time for \(L_u\). Now, we will show that \(L_u\) is recursive then \(L_d\) is recursive. To do that, we will convert \(L_d\) into an instance of \(L_u\).</p> <p><img src="/assets/img/Automata/image-20220413194329791.png" alt="image-20220413194329791"/></p> <p>Here, we can see that we are able to answer the question \(w_i \in L_d\) by constructing a TM using the Universal TM. That is, if the Universal TM is recursive, then \(L_d\) is also recursive. <em>Think</em>.</p> <h2 id="reduction-technique">Reduction Technique</h2> <p>To understand this technique, consider the following two problems</p> <ul> <li>\(L_{ne} = \{( M ) \mid L(M) \neq \phi\}\) - Machine accepts at least one string</li> <li>\(L_{rec} = \{( M ) \mid L(M) \text { is recursive}\}\) - Machine halts on all inputs</li> </ul> <p>We can show that both are recursively enumerable. The first language can be shown as recursively enumerable using dovetailing (words and moves being the dimensions). To show non-recursivity, we convert \(L_d\) or \(L_u\) to an instance of this language. We need to try and come up with an algorithm that halts for machines with empty languages.</p> <blockquote> <p>How do we do this?</p> </blockquote> <p>The second problem is a little bit more difficult.</p> <p>In conclusion, given a language</p> <ul> <li>To prove that it is recursive, we need to construct a TM that halts on all inputs.</li> <li>To prove that it is recursively enumerable, we just need to construct a TM that halts on good inputs. To show that it is not recursive, we need to use reductions probably.</li> <li>To prove non recursively enumerable, we need to show that we can’t construct any TM.</li> </ul> <p>TM is a powerful model as it is universal (self-referential), and it has many undecidable problems. They can represent Type-0 Grammar, Partial Recursive functions, and RAM (random access mechanism).</p> <h2 id="post-correspondence-problem">Post Correspondence Problem</h2> <p>Post is a mathematician. Consider the following table</p> <table> <thead> <tr> <th>w</th> <th>x</th> </tr> </thead> <tbody> <tr> <td>1</td> <td>111</td> </tr> <tr> <td>1011</td> <td>10</td> </tr> <tr> <td>10</td> <td>0</td> </tr> </tbody> </table> <p>Now, take the string \(101111110\). Can we decompose this string in terms of \(w_i\) or \(x_i\)? For example, we can decompose the string as \(2113\) in terms of \(w's\) and \(2113\) again in terms of \(x’s\). These decompositions need not be unique.</p> <p>So, PCP is stated as follows.</p> <p>Given \(w = \{w_i \mid w_i \in \Sigma^* \}, x = \{x_i \mid x_i \in \Sigma^*\}\) and a string \(s \in \Sigma^*\), we need to be able to come up with decompositions \(s = w_{i1} \dots w_{il}\) and \(s = x_{j1}\dots x_{jl}\) such that \(ik = jk\) for \(k \in \{1, \dots, l\}\).</p> <p>Consider the following table.</p> <table> <thead> <tr> <th>w</th> <th>x</th> </tr> </thead> <tbody> <tr> <td>10</td> <td>101</td> </tr> <tr> <td>011</td> <td>11</td> </tr> <tr> <td>101</td> <td>011</td> </tr> </tbody> </table> <p>Now, for any string \(s\), we will not be able to come up with decompositions that are equal for the above sets.</p> <p>The reason we came up with this problem, is to show that PCP is undecidable (not recursive). That is, no TM can halt correctly on all PCP instances. However, it is recursively enumerable as we can enumerate all sequences fairly. This can be shown by a reduction of \(L_u\) to PCP.</p> <p>Let us now consider another problem - Ambiguity of CFGs. Can we build a TM that halts with a ‘yes’ if the input CFG has an ambiguity and with a ‘no’ is it does not. In an ambiguous grammar, a single word has multiple derivations in the grammar. That is, we have multiple structurally different derivation trees. Using this problem we are trying to show the importance of <strong>direction of reduction</strong>. We know that PCP is undecidable. Therefore, we need to reduce PCP to an instance of the CFG problem. That is, we’ll essentially show that is the CFG problem is decidable, then so is PCP.</p> <p>PCP is essentially a pair of sets of strings. What is the grammar corresponding to these sets such that when PCP has a solution, the grammar is ambiguous and unambiguous otherwise? We introduce \(k\) new symbols \(a_1, \dots, a_k\). We construct the following grammar</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>S -&gt; Sa | Sb
Sa -&gt; w_i Sa a_i | w_i a_i
Sb -&gt; x_i Sb a_i | x_i a_i
</code></pre></div></div> <p>It is easy to see that this grammar meets our requirements. To prove this, we need to show the proof in two directions</p> <ul> <li>If PCP has a solution, then G is ambiguous</li> <li>If G is ambiguous, then PCP has a solution. Here, we need to show that ambiguity happens only due to <code class="language-plaintext highlighter-rouge">Sa</code> and <code class="language-plaintext highlighter-rouge">Sb</code>.</li> </ul> <blockquote> <p>Why did we introduce <code class="language-plaintext highlighter-rouge">a</code>?</p> </blockquote> <p><strong>Note.</strong> To show problem A is undecidable knowing that problem B is undecidable, we essentially show that A is a subroutine of B.</p> <h2 id="properties-of-recursive-languages">Properties of Recursive Languages</h2> <p>If \(L_1\) and \(L_2\) are both recursive, then so are</p> <ul> <li> \[L_1 \cup L_2\] </li> <li> \[L_1 \cap L_2\] </li> <li> \[L_1 - L_2\] </li> <li> \[L_1^c\] </li> <li> \[L_1L_2\] </li> </ul> <p>The intersection and complement closure break in case of recursively enumerable languages <strong>(?)</strong></p> <p><strong>Note.</strong> Don’t get confused into thinking there are three (disjoint) kinds of sets: decidable, semi-decidable, and undecidable. There are two kinds: decidable and undecidable. Semi-decidable falls under undecidable.</p> <h2 id="np-completeness">NP-Completeness</h2> <h3 id="decision-problems">Decision Problems</h3> <p>These are a class of problems that deal with problem instances like Fermat’s last theorem - \(\forall n &gt; 2\exists a, b, c, a^n + b^n = c^n\)? We also have the law of excluded middle in decision problems - The answer is either ‘yes’ or ‘no’.</p> <p>Optimisation problems can be converted to a decision problem.</p> <h3 id="decidable-problems">Decidable Problems</h3> <p>We solve these problems by building a brute-force TM - <strong>generate and test method</strong>. For example, consider the problem of finding a vertex cover in a graph of size \(k\). Now, the TM will enumerate all subsets of size \(k\) and check each one for vertex cover conditions.</p> <p>We come up with “algorithms” for these problems and check their efficiency. Apart from time and space complexity, we also consider <strong>descriptive (Kolmogorov) complexity</strong>. It refers to the program size. In our case, it refers to the size of the TM.</p> <h3 id="complexity-classes">Complexity Classes</h3> <p>Given two problems, which problem is “more difficult”? The difficulty criterion we consider is time. We define two classes of problems \(P\) and \(NP\).</p> <ul> <li><strong>P</strong> is the class of (decision) problems that can be solved in “polynomial time” by a deterministic Turing Machine \(M\).</li> <li><strong>PSPACE</strong> refers to the class of problems that use polynomial number of cells in the tape.</li> <li><strong>NP</strong> is the class of (decision) problems that can be solved in <strong>polynomial time</strong> by <u>non-deterministic TM</u>. This is equivalent to guessing a solution in polynomial time followed by checking using a deterministic TM in polynomial time. The claim is that this is same as a non-deterministic TM. We shall use this technique to show that problems are in NP. That is, we’ll show that we can guess in P-time and verify in P-time.</li> </ul> <p>For example, let us try to show vertex cover problem is in \(NP\). Aside - A polynomial algorithm was developed in the 1980s for the problem “Is \(n\) a prime number” in IITK (Manindra Agarwal).</p> <h3 id="more-difficult-problem">More difficult problem</h3> <p>Given \(L_1\) and \(L_2\), which one is more difficult? We use reduction to answer this question.</p> \[L_1 \leq_{P} L_2\] <p>If \(L_1\) can be converted to an instance of \(L_2\) in polynomial time, then we have the above defined relation. That is, \(L_2\) is at least as difficult as \(L_1\).</p> <h3 id="completeness">Completeness</h3> <p>We try to determine the most difficult problem amongst all the problems. To start off, we define that \(L_{sat}\) belongs to NP-complete set. This problem refers to the satisfiability of propositional logic expressions.</p> <p>Every problem in \(NP\) can be reduced to \(L_{sat}\). In some sense, \(L_{sat}\) is the most difficult problem. But how did we come to this conclusion without knowing all the problems in \(NP\)? We can show that <u>any non-deterministic TM can be reduced to</u> \(L_{sat}\).</p> <p>We define hard problems as anything not in \(P\). There are problems that are more difficult than the ones in \(NP\)!</p> <p>We classify decidable problems as the set of recursive languages. These problems can be further classified as</p> <ul> <li>Deterministic TM takes only polynomial number of steps in terms of the input size to halt.</li> <li> <p>A non-deterministic TM takes polynomial number of steps.</p> </li> <li>A non-deterministic TM needs \(\Omega (2^n)\) number of steps.</li> </ul> <h3 id="sat-problem-p_sat">SAT Problem \(P_{sat}\)</h3> <p>Given a well formed formula \(F\), is \(F\) satisfiable? A well formed formula is a formula that is formed via the base case (propositional variables) and inductive rules (using connectors like negation, ‘and’ and ‘or’).</p> <p>This problem can be solved via brute force but that is exponential. So we now ask the following questions</p> <ul> <li>Is \(P_{sat} \in P\)?</li> <li>Is \(P_{sat} \in NP\)?</li> </ul> <p>We’ll answer the second question first. It is easy to construct a non-deterministic TM that solves the problem in polynomial steps. We can generate a random guess (bit string) and verify (check satisfiability) in polynomial steps. This procedure is the way to show that any problem is in \(NP\).</p> <h3 id="comparison-of-problems">Comparison of Problems</h3> <p>Let us revisit the topic of \(\leq_{P}\). \(P_{sat} \leq_{P} 3\text{-}SAT\), and \(3\text{-}SAT \leq_P VC\) where \(VC\) is the vertex cover problem.</p> <p>To do perform the latter reduction, we construct nodes for \(p\) and \(\neg p\) for each propositional variable in the clause. Then, we construct cliques out of each disjunction in the CNF. Finally, we connect each \(p\) with \(\neg p\). Now, if we can find a vertex cover of this graph with size \(2k\), we get the satisfiability of the 3-CNF clause with \(k\) disjunctive clauses.</p> <ul> <li>If \(F\) has a satisfying assignment, take out exactly one literal with value \(1\) out of each disjunctive clause and construct a VC out of the remaining literals. It can be shown that the vertex cover will have size \(2k\).</li> <li>If there is a vertex cover, then we can drop at most 1 node from each disjunctive clause. Also, as the size if \(2k\) we can drop exactly 1 node from each clause. Assign these dropped nodes with a value of \(1\). Now, since we have a true value in each clause, the assignment satisfies the expression.</li> </ul> <h3 id="np-completeness-1">NP-Completeness</h3> <p>As we mentioned before, we consider \(P_{sat}\) or \(3\text{-}SAT\) as the hardest problem. That is, for every \(Q \in NP\), \(Np \leq_P P_{sat}\).</p> <p>We show this by reducing non-deterministic Turing Machines to \(P_{sat}\). To prove that a problem is NP-complete, we show</p> <ul> <li>That the problem lies in \(NP\). This step is very important as there are problems that are more difficult than \(NP\).</li> <li>Convert the 3-SAT problem (or any other known NP-complete problem) to an instance of the given problem.</li> </ul> <p>We list out some problems in NP-complete set.</p> <ul> <li>3-SAT</li> <li>Vertex Cover</li> <li>Clique in a graph</li> <li>\(k\)-coloring</li> <li>Min-cut and Max-flow</li> <li>Travelling Salesman Problem</li> <li>Hamiltonian Cycle in a graph</li> <li>Partitioning of a set of numbers such that the partitions have the same sum</li> <li>Knapsack problem</li> </ul> <p>The good news about \(NP\)-complete problems is that there are many heuristics and approximations such as LAs Vegas and Monte Carlo that work well for most of the above problems.</p> <hr/> <h4 id="end-of-course">END OF COURSE</h4> <hr/>]]></content><author><name></name></author><category term="Notes"/><summary type="html"><![CDATA[An introductory course to Automata theory. The first half covers DFAs, NFAs, and their various properties. Relations of regularity of languages and DFAs/NFAs and proofs of non-regularity of languages. The second half of the notes covers pushdown automata, context free grammar and their relation with deterministic PDAs. Briefly touches upon Turing machines.]]></summary></entry><entry><title type="html">DiBS Notes</title><link href="https://sudhansh6.github.io/blog/dbms/" rel="alternate" type="text/html" title="DiBS Notes"/><published>2022-01-06T00:00:00+00:00</published><updated>2022-01-06T00:00:00+00:00</updated><id>https://sudhansh6.github.io/blog/dbms</id><content type="html" xml:base="https://sudhansh6.github.io/blog/dbms/"><![CDATA[<h1 id="lecture-1">Lecture 1</h1> <blockquote> <p><code class="language-plaintext highlighter-rouge">03/01/2022</code></p> </blockquote> <h1 id="chapter-1-introduction">~Chapter 1: Introduction</h1> <ul> <li><strong>Embedded databases</strong> - Databases which don’t have high amount of concurrent access, but is mostly used by a single user. These databases are implemented by SQLite in general.</li> <li> <p>Motivation for Database systems -</p> <ul> <li>Atomicity</li> <li>Concurrency</li> <li>Security</li> <li>…</li> </ul> </li> </ul> <h2 id="data-models">Data Models</h2> <p>A collection tools for describing the data, relationships in the data, semantics and other constraints.</p> <p>We start using the relational models that are implemented using SQL. Then, we shall study Entity-Relationship data model. These are used for database design. We will briefly touch upon Object-based data models. Finally, we shall see Semi-structured data model as a part of XML.</p> <p>There are also other models like Network model and Hierarchical model (old) etc.</p> <h2 id="relational-model">Relational Model</h2> <p>All the data is stored in various tables. A <strong>relation</strong> is nothing but a table. Back in the 70’s, Ted Codd (Turing Award 1981) formalized the Relational Model. According to his terminology, a table is same as a <em>relation</em>, a column is also called an <em>attribute</em>, and the rows of the table are called as <em>tuples</em>. The second major contribution he made was introducing the notion of operations. Finally, he also established a low-level database engine that could execute these operations.</p> <p>Some more terminology - <strong>Logical Schema</strong> is the overall logical structure of the database. It is analogous to the type information of a variable in a program. A <strong>physical schema</strong> is the overall physical structure of the database. An <strong>instance</strong> is the actual content of the database at a particular point in time. It is analogous to the value of a variable. The notion of <strong>physical data independence</strong> is the ability to modify the physical schema without changing the logical schema.</p> <h3 id="data-definition-language-ddl">Data Definition Language (DDL)</h3> <p>It is the specification notation for defining the database schema. DDL compiler generates a set of table templates stored in a <em>data dictionary</em>. A data dictionary contains metadata (data about data) such as database schema, integrity constraints (primary key) and authorization.</p> <h3 id="data-manipulation-language-dml">Data Manipulation Language (DML)</h3> <p>It is the language for accessing and updating the data organized by the appropriate data model. It is also known as a <em>query language</em>. There are basically two types of data-manipulation languages - <strong>Procedural DML</strong> requires a user to specify what data is needed and how to get that data; <strong>Declarative DML</strong> requires a user to specify what data is need without specifying how to get those data. Declarative/non-procedural DMLs are usually easier to learn.</p> <h3 id="sql-query-language">SQL Query Language</h3> <p>SQL query language is <strong>non-procedural</strong>! It is declarative. SQL is <strong>not</strong> a Turing machine equivalent language. There are extensions which make it so. SQL does not support actions such as input from the users, typesetting, communication over the network and output to the display. A query takes as input several tables and always returns a single table. SQL is often used embedded within a higher-level language.</p> <p><strong>Database Design</strong> involves coming up with a Logical design and Physical design.</p> <p>A <strong>Database Engine</strong> accepts these queries and parses them. It is partitioned into modules that deal with each of the responsibilities of the overall system. The functional components of a database system can be divided into</p> <ul> <li> <p>Storage manager - Actually stores the data. It takes the logical view and maps it to the physical view. It is also responsible to interact with the OS file manager for efficient storing, retrieving and updating of data. It has various components such as authorization and integrity manager, transaction manager, file manager and buffer manager. It implements several data structures as a part of the physical system implementation - data files, data dictionary and indices.</p> </li> <li> <p>Query processor - It includes DDL interpreter, DML compiler (query to low-level instructions along with query optimization) and the query evaluation engine.</p> <p>Query processing involves parsing and translation, optimization, and evaluation. Statistics of the data are also used in optimization.</p> </li> <li> <p>Transaction management - A <strong>transaction</strong> is a collection of operations that performs a single logical function in a database application. The <strong>transaction management component</strong> ensures that the database remains in a consistent state despite system failure. The <strong>concurrency control manager</strong> controls the interaction among the concurrent transactions to ensure the consistency of the data.</p> </li> </ul> <h1 id="lecture-2">Lecture 2</h1> <blockquote> <p><code class="language-plaintext highlighter-rouge">04-01-22</code></p> </blockquote> <h3 id="database-architecture">Database Architecture</h3> <p>There are various architectures such as centralized databases, client-server, parallel databases and distributed databases.</p> <h1 id="chapter-2-intro-to-relational-model">~Chapter 2: Intro to Relational Model</h1> <h3 id="attributes">Attributes</h3> <p>The set of allowed values for each attribute is called the <strong>domain</strong> of the attribute. Attribute values are required to be <em>atomic</em> - indivisible. Todd realized that having sets or divisible attributes complicates the algebra. The special value <strong><em>null</em></strong> is a member of every domain that indicates the value is unknown. The null values causes complications in the definition of many operations.</p> <p>Relations are <strong>unordered</strong>. The order of tuples is irrelevant for the operations logically.</p> <p><strong>Database Schema</strong> - The logical structure of the database.</p> <h3 id="keys">Keys</h3> <p><em>K</em> is a <strong>superkey</strong> of the relation <em>R</em> if values for <em>K</em> are sufficient to identify a unique tuple of each possible relation \(r(R)\). Superkey \(K\) is a <strong>candidate key</strong> if \(K\) is minimal. One of the candidate keys is selected to be the <strong>primary key</strong>. A <strong>foreign key</strong> constraint ensures that the value in one relation must appear in another. There is a notion of <em>referencing</em> relation and a <em>referenced</em> relation.</p> <h3 id="relational-query-languages">Relational Query Languages</h3> <p>Pure languages include Relational algebra, Tuple relational calculus and Domain relational calculus. These three languages are equivalent in computing power.</p> <h1 id="lecture-3">Lecture 3</h1> <blockquote> <p><code class="language-plaintext highlighter-rouge">06/01/2022</code></p> </blockquote> <h2 id="relational-algebra">Relational Algebra</h2> <p>An algebraic language consisting of a set of operations that take one or two relations as input and produces a new relation as their result. It consists of six basic operators -</p> <ul> <li>select \(\sigma\)</li> <li>project \(\Pi\)</li> <li>union \(\cup\)</li> <li>set difference \(-\)</li> <li>Cartesian product \(\times\)</li> <li>rename \(\rho\)</li> </ul> <p>We shall discuss each of them in detail now.</p> <h3 id="select-operation">Select Operation</h3> <p>The <strong>select</strong> operation selects tuples that <u>satisfy a given predicate</u>. So, it’s more like <code class="language-plaintext highlighter-rouge">where</code> rather than <code class="language-plaintext highlighter-rouge">select</code> in SQL. The notation is given by \(\sigma_p(r)\).</p> <h3 id="project-operation">Project Operation</h3> <p>A unary operation that returns its argument relation, with certain attributes left out. That is, it gives a subset of attributes of tuples. By definition, it should only return the attributes. However, in most cases we can return modified attributes. The notation is given by \(\Pi_{attr_1, attr_2, ...}(r)\)</p> <h3 id="composition-of-relation-operations">Composition of Relation Operations</h3> <p>The result of a relational-algebra is a relation and therefore we different relational-algebra operations can be grouped together to form <u>relational-algebra expressions</u>.</p> <h3 id="cartesian-product-operation">Cartesian-product Operation</h3> <p>It simply takes the cartesian product of the two tables. Then, we can use the select condition to select the relevant (rational) tuples.</p> <p>The <strong>join</strong> operation allows us to combine a select operation and a Cartesian-Product operation into a single operation. The join operation \(r \bowtie_\theta s = \sigma_\theta (r \times s)\). Here \(\theta\) represents the predicate over which join is performed.</p> <h3 id="union-operation">Union operation</h3> <p>This operation allows us to combine two relations. The notation is \(r \cup s\). For this operation to be vald, we need the following two conditions -</p> <ul> <li>\(r, s\) must have the same <strong>arity</strong> (the same number of attributes in a tuple).</li> <li>The attribute domains must be <u>compatible</u>.</li> </ul> <blockquote> <p>Why second?</p> </blockquote> <h3 id="set-intersection-operation">Set-Intersection Operation</h3> <p>This operator allows us to find tuples that are in both the input relations. The notations is \(r \cap s\).</p> <h3 id="set-difference-operation">Set Difference Operation</h3> <p>It allows us to find the tuples that are in one relation but not in the other.</p> <h3 id="the-assignment-operation">The assignment Operation</h3> <p>The assignment operation is denoted by \(\leftarrow\) and works like the assignment in programming languages. It is used to define temporary relation variables for convenience. With the assignment operation, a query can be written as a sequential program consisting of a series of assignments followed by an expression whose value is displayed as the result of the query.</p> <h3 id="the-rename-operation">The rename Operation</h3> <p>The expression \(\rho_x(E)\) is used to rename the expression \(E\) under the name \(x\). Another form of the rename operator is given by \(\rho_{x(A1, A2, ...)}(E)\).</p> <blockquote> <p>Difference between rename and assignment? Is assignment used to edit tuples in a relation?</p> </blockquote> <p>Are these set of relational operators enough for Turing completeness? No! Check <a href="https://www.quora.com/Turing-Completeness/Why-is-relational-algebra-not-Turing-complete#:~:text=Relational%20algebra%20clearly%20doesn't,analysis%20such%20as%20query%20optimizers.">this</a> link for more info.</p> <h3 id="aggregate-functions">Aggregate Functions</h3> <p>We need functions such as <code class="language-plaintext highlighter-rouge">avg</code>, <code class="language-plaintext highlighter-rouge">min</code>, <code class="language-plaintext highlighter-rouge">max</code>, <code class="language-plaintext highlighter-rouge">sum</code> and <code class="language-plaintext highlighter-rouge">count</code> to operate on the multiset of values of a column of a relation to return a value. Functions such as <code class="language-plaintext highlighter-rouge">avg</code> and <code class="language-plaintext highlighter-rouge">sum</code> cannot be written using FOL or the relations we defined above. Functions such as <code class="language-plaintext highlighter-rouge">min</code> and <code class="language-plaintext highlighter-rouge">max</code> can be written using a series of queries but it is impractical. The other way of implementing this is to use the following</p> <div style="text-align:center;"> $$ \Pi_{mark}(marks) - \Pi_{m1.mark}(\sigma_{m1.mark &gt; m2.mark} \\ (\rho_{m1}(marks) \times \rho_{m2}(marks))) $$ </div> <p>However, this definitive expression is very inefficient as it turns a linear operation to a quadratic operation.</p> <p><strong>Note.</strong> The aggregates <strong>do not</strong> filter out the duplicates! For instance, consider $\gamma_{count(course_id)}(\sigma_{year = 2018}(section))$. What if a course has two sections? It is counted twice.</p> <h3 id="group-by-operation">Group By Operation</h3> <p>This operation is used to group tuples based on a certain attribute value.</p> <h2 id="equivalent-queries">Equivalent Queries</h2> <p>There are more ways to write a query in relation algebra. Queries which are <u>equivalent</u> need not be <u>identical</u>.</p> <p>In case of SQL, the database optimizer takes care of optimizing equivalent queries.</p> <h1 id="chapter-3-basic-sql">~Chapter 3: Basic SQL</h1> <h2 id="domain-types-in-sql">Domain Types in SQL</h2> <ul> <li><code class="language-plaintext highlighter-rouge">char(n)</code> - Fixed length character string, with user-specified length \(n\). We might need to use the extra spaces in the end in the queries too!</li> <li><code class="language-plaintext highlighter-rouge">varchar(n)</code> - Variable length strings</li> <li>…</li> </ul> <h2 id="create-table-construct">Create Table Construct</h2> <p>An SQL relation is defined using the create table command -</p> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">create</span> <span class="k">table</span> <span class="n">r</span>
	<span class="p">(</span><span class="n">A_1</span><span class="p">,</span> <span class="n">D_1</span><span class="p">,</span> <span class="n">A_2</span><span class="p">,</span> <span class="n">D_2</span><span class="p">,</span> <span class="p">...,</span> <span class="n">A_n</span><span class="p">,</span> <span class="n">D_n</span><span class="p">)</span>
</code></pre></div></div> <h2 id="integrity-constraints-in-create-table">Integrity Constraints in Create Table</h2> <p>Types of integrity constraints</p> <ul> <li>primary key \((A_1, A_2, A_3, ...)\)</li> <li>Foreign key \((A_m, ..., A_n)\) references r</li> <li>not <code class="language-plaintext highlighter-rouge">null</code></li> </ul> <p>SQL prevents any update to the database that violates an integrity constraint.</p> <h1 id="lecture-4">Lecture 4</h1> <blockquote> <p><code class="language-plaintext highlighter-rouge">10-01-22</code></p> </blockquote> <h2 id="basic-query-structure">Basic Query Structure</h2> <ul> <li>A typical SQL query has the form:</li> </ul> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">select</span> <span class="n">A1</span><span class="p">,</span> <span class="n">A2</span><span class="p">,</span> <span class="p">...,</span> <span class="n">An</span>
<span class="k">from</span> <span class="n">r1</span><span class="p">,</span> <span class="n">r2</span><span class="p">,</span> <span class="p">...,</span> <span class="n">rm</span>
<span class="k">where</span> <span class="n">P</span>
</code></pre></div></div> <p>where, \(A_i\) are attributes, \(r_i\) are relations, and \(P\) has conditions/predicates. The result of an SQL query is a relation. SQL is case-insensitive in general.</p> <ul> <li>We shall be using PostgreSQL for the rest of the course.</li> <li>SQL names are usually case insensitive. Some databases are case insensitive even in string comparison!</li> </ul> <h3 id="select-clause">select clause</h3> <ul> <li>To force the elimination of duplicates, insert the keyword <code class="language-plaintext highlighter-rouge">distinct</code> after select. Duplicates come from <ol> <li>Input itself is a multiset</li> <li>Joining tables</li> </ol> <p>Removing duplicates imposes an additional overhead to the database engine. Therefore, it was ubiquitously decides to exclude duplicates removal in SQL.</p> </li> <li> <p>The keyword <code class="language-plaintext highlighter-rouge">all</code> specifies that duplicates should not be removed.</p> </li> <li>SQL allows renaming relations and attributes using the <code class="language-plaintext highlighter-rouge">as</code> clause. We can skip <code class="language-plaintext highlighter-rouge">as</code> in some databases like Oracle. Also, some databases allow queries with no <code class="language-plaintext highlighter-rouge">from</code> clause.</li> </ul> <h3 id="from-clause">from clause</h3> <p>If we write <code class="language-plaintext highlighter-rouge">select * from A, B</code>, then the Cartesian product of <code class="language-plaintext highlighter-rouge">A</code> and <code class="language-plaintext highlighter-rouge">B</code> is considered. This usage has some corner cases but are rare.</p> <p>### as clause</p> <p>It can be used to rename attributes as well as relations.</p> <h3 id="self-join">Self Join</h3> <p>How do we implement various levels of recursion without loops and only imperative statements? Usually, <code class="language-plaintext highlighter-rouge">union</code> is sufficient for our purposes. However, this is infeasible in case of large tables or higher levels of hierarchy.</p> <h3 id="string-operations">String operations</h3> <p>SQL also includes string operations. The operator <code class="language-plaintext highlighter-rouge">like</code> uses patterns that are describes using two special character - <code class="language-plaintext highlighter-rouge">percent %</code> - Matches any substring and <code class="language-plaintext highlighter-rouge">underscore _</code> matches any character (Use <code class="language-plaintext highlighter-rouge">\</code> as the escape character). Some databases even fully support regular expressions. Most databases also support <code class="language-plaintext highlighter-rouge">ilike</code> which is case-insensitive.</p> <h3 id="set-operations">Set operations</h3> <p>These include <code class="language-plaintext highlighter-rouge">union</code>, <code class="language-plaintext highlighter-rouge">intersect</code> and <code class="language-plaintext highlighter-rouge">except</code> (set difference). To retain the duplicates we use <code class="language-plaintext highlighter-rouge">all</code> keyword after the operators.</p> <h3 id="null-values">null values</h3> <p>It signifies an unknown value or that a value does not exist. The result of any arithmetic expression involving <code class="language-plaintext highlighter-rouge">null</code> is <code class="language-plaintext highlighter-rouge">null</code>. The predicate <code class="language-plaintext highlighter-rouge">is null</code> can be used to check for null values.</p> <h1 id="lecture-5">Lecture 5</h1> <blockquote> <p><code class="language-plaintext highlighter-rouge">11-01-22</code></p> </blockquote> <h3 id="aggregate-functions-1">Aggregate Functions</h3> <p>The <code class="language-plaintext highlighter-rouge">having</code> clause can be used to select groups which satisfies certain conditions. Predicates in the <code class="language-plaintext highlighter-rouge">having</code> clause are applied after the formation of groups whereas predicates in the <code class="language-plaintext highlighter-rouge">where</code> clause are applied before forming the groups.</p> <h2 id="nested-subqueries">Nested subqueries</h2> <p>SQL provides a mechanism for the nesting of subqueries. A subquery is a select-from-where expression that is nested within another query. The nesting can be done in the following ways -</p> <ul> <li><code class="language-plaintext highlighter-rouge">from</code> clause - The relation can be replaced by any valid subquery</li> <li><code class="language-plaintext highlighter-rouge">where</code> clause - The predicate can be replaced with an expression of the form <code class="language-plaintext highlighter-rouge">B &lt;operation&gt; (subquery)</code> where <code class="language-plaintext highlighter-rouge">B</code> is an attribute and <code class="language-plaintext highlighter-rouge">operation</code> will be defined later.</li> <li><strong>Scalar subqueries</strong> - The attributes in the <code class="language-plaintext highlighter-rouge">select</code> clause can be replaced by a subquery that generates a single value!</li> </ul> <h3 id="subqueries-in-the-from-clause">subqueries in the <code class="language-plaintext highlighter-rouge">from</code> clause</h3> <p>the <code class="language-plaintext highlighter-rouge">with</code> clause provides a way of defining a temporary relation whose definition is available only to the query in which the <code class="language-plaintext highlighter-rouge">with</code> clause occurs. For example, consider the following</p> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">max_budget</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="k">as</span> 
	<span class="p">(</span><span class="k">select</span> <span class="k">max</span><span class="p">(</span><span class="n">budget</span><span class="p">))</span>
	<span class="k">from</span> <span class="n">department</span><span class="p">)</span>
<span class="k">select</span> <span class="n">department</span><span class="p">.</span><span class="n">name</span> <span class="k">from</span> <span class="n">department</span><span class="p">,</span> <span class="n">max_budget</span>
<span class="k">where</span> <span class="n">department</span><span class="p">.</span><span class="n">budget</span> <span class="o">=</span> <span class="n">max_budget</span><span class="p">.</span><span class="n">value</span>
</code></pre></div></div> <p>We can write more complicated queries. For example, if we want all departments where the total salary is greater than the average of the total salary at all departments.</p> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">dept_total</span><span class="p">(</span><span class="n">dept_name</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span> <span class="k">as</span>
	<span class="p">(</span><span class="k">select</span> <span class="n">dept_name</span><span class="p">,</span> <span class="k">sum</span><span class="p">(</span><span class="n">salary</span><span class="p">)</span> <span class="k">from</span> <span class="n">instructor</span> <span class="k">group</span> <span class="k">by</span> <span class="n">dept_name</span><span class="p">)</span>
		<span class="n">dept_total_avg</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="k">as</span>
		<span class="p">(</span><span class="k">select</span> <span class="k">avg</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="k">from</span> <span class="n">dept_total</span><span class="p">)</span>
    <span class="k">select</span> <span class="n">dept_name</span>
    <span class="k">from</span> <span class="n">dept_total</span><span class="p">,</span> <span class="n">dept_total_avg</span>
    <span class="k">where</span> <span class="n">dept_total</span><span class="p">.</span><span class="n">value</span> <span class="o">&gt;</span> <span class="n">dept_total_avg</span><span class="p">.</span><span class="n">value</span>
</code></pre></div></div> <h3 id="subqueries-in-the-where-clause">subqueries in the <code class="language-plaintext highlighter-rouge">where</code> clause</h3> <p>We use operations such as <code class="language-plaintext highlighter-rouge">in</code> and <code class="language-plaintext highlighter-rouge">not in</code>. We can also check the set membership of a subset of attributes in the same order. There is also a <code class="language-plaintext highlighter-rouge">some</code> keyword that returns a True if at least one tuple exists in the subquery that satisfies the condition. Similarly we have the <code class="language-plaintext highlighter-rouge">all</code> keyword. There is also the <code class="language-plaintext highlighter-rouge">exists</code> clause which returns True if the tuple exists in the subquery relation. For example, if we want to find all courses taught in both the Fall 2017 semester and in the spring 2018 semester. We can use the following</p> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">select</span> <span class="n">course_id</span> <span class="k">from</span> <span class="n">section</span> <span class="k">as</span> <span class="n">S</span>
<span class="k">where</span> <span class="n">semester</span> <span class="o">=</span> <span class="s1">'Fall'</span> <span class="k">and</span> <span class="nb">year</span> <span class="o">=</span> <span class="mi">2017</span> <span class="k">and</span>
	<span class="k">exists</span> <span class="p">(</span><span class="k">select</span> <span class="o">*</span> <span class="k">from</span> <span class="n">section</span> <span class="k">as</span> <span class="n">T</span>
			<span class="k">where</span> <span class="n">semester</span> <span class="o">=</span> <span class="s1">'Spring'</span> <span class="k">and</span> <span class="nb">year</span> <span class="o">=</span> <span class="mi">2018</span>
			<span class="k">and</span> <span class="n">S</span><span class="p">.</span><span class="n">course_id</span> <span class="o">=</span> <span class="n">T</span><span class="p">.</span><span class="n">course_id</span><span class="p">)</span>
</code></pre></div></div> <p>Here, <code class="language-plaintext highlighter-rouge">S</code> is the correlation name and the inner query is the correlated subquery. Correspondingly, there also is a <code class="language-plaintext highlighter-rouge">not exists</code> clause.</p> <p>The <code class="language-plaintext highlighter-rouge">unique</code> construct tests whether a subquery has any duplicate tuples in its result. It evaluates to True if there are no duplicates.</p> <h3 id="scalar-subquery">Scalar Subquery</h3> <p>Suppose we have to list all the departments along with the number of instructors in each department. Then, we can do the following</p> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">select</span> <span class="n">dept_name</span><span class="p">,</span> 
	<span class="p">(</span><span class="k">select</span> <span class="k">count</span><span class="p">(</span><span class="o">*</span><span class="p">)</span> <span class="k">from</span> <span class="n">instructor</span>
	<span class="k">where</span> <span class="n">department</span><span class="p">.</span><span class="n">dept_name</span> <span class="o">=</span> <span class="n">instructir</span><span class="p">.</span><span class="n">dept_name</span> <span class="k">as</span> <span class="n">num_instructors</span>
	<span class="p">)</span> <span class="k">from</span> <span class="n">department</span><span class="p">;</span>
</code></pre></div></div> <p>There would be a <strong>runtime error</strong> if the subquery returns more than one result tuple.</p> <h2 id="modification-of-the-database">Modification of the database</h2> <p>We can</p> <ul> <li> <p>delete tuples from a given relation using <code class="language-plaintext highlighter-rouge">delete from</code>. It deletes all tuples without a <code class="language-plaintext highlighter-rouge">where</code> clause. We need to be careful while using delete. For example, if we want to delete all instructors whose salary is less than the average salary of instructors. We can implement this using a subquery in the <code class="language-plaintext highlighter-rouge">where</code> clause. The problem here is that the average salary changes as we delete tuples from instructor. The solution for this problem is - we can compute average first and then delete without recomputation. This modification is usually implemented.</p> </li> <li> <p>insert new tuples into a give relation using <code class="language-plaintext highlighter-rouge">insert into &lt;table&gt; values &lt;A1, A2, ..., An&gt;</code>. The <code class="language-plaintext highlighter-rouge">select from where</code> statement is evaluated fully before any of its results are inserted into the relation. This is done to prevent the problem mentioned in <code class="language-plaintext highlighter-rouge">delete</code>.</p> </li> <li> <p>update values in some tuples in a given relation using <code class="language-plaintext highlighter-rouge">update &lt;table&gt; set A1 = ... where ...</code>. We can also use a <code class="language-plaintext highlighter-rouge">case</code> statement to make non-problematic sequential updates. For example,</p> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">update</span> <span class="n">instructor</span>
	<span class="k">set</span> <span class="n">salary</span> <span class="o">=</span> <span class="k">case</span>
					<span class="k">when</span> <span class="n">salary</span> <span class="o">&lt;=</span> <span class="mi">1000</span> <span class="k">then</span> <span class="n">salary</span> <span class="o">*</span><span class="mi">1</span><span class="p">.</span><span class="mi">05</span>
					<span class="k">else</span> <span class="n">salary</span><span class="o">*</span><span class="mi">1</span><span class="p">.</span><span class="mi">03</span>
                <span class="k">end</span>
</code></pre></div> </div> </li> </ul> <p><strong><code class="language-plaintext highlighter-rouge">coalesce</code></strong> takes a series of arguments and returns the first non-null value.</p> <h1 id="lecture-6">Lecture 6</h1> <blockquote> <p><code class="language-plaintext highlighter-rouge">13-01-22</code></p> </blockquote> <h1 id="chapter-4-intermediate-sql">~Chapter 4: Intermediate SQL</h1> <p><strong>Join operations</strong> take two relations and return as a result another relation. There are three types of joins which are described below.</p> <h3 id="natural-join">Natural Join</h3> <p>Natural join matches tuples with the same values for <strong>all common attributes</strong>, and retains only one copy of each common column.</p> <blockquote> <p>Can’t do self-join using this?</p> </blockquote> <p>However, one must be beware of natural join because it produces unexpected results. For example, consider the following queries</p> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">-- Correct version</span>
<span class="k">select</span> <span class="n">name</span><span class="p">,</span> <span class="n">title</span> <span class="k">from</span> <span class="n">student</span> <span class="k">natural</span> <span class="k">join</span> <span class="n">takes</span><span class="p">,</span> <span class="n">course</span>
<span class="k">where</span> <span class="n">takes</span><span class="p">.</span><span class="n">course_id</span> <span class="o">=</span> <span class="n">course</span><span class="p">.</span><span class="n">course_id</span>
<span class="c1">-- Incorrect version</span>
<span class="k">select</span> <span class="n">name</span><span class="p">,</span> <span class="n">title</span>
<span class="k">from</span> <span class="n">student</span> <span class="k">natural</span> <span class="k">join</span> <span class="n">takes</span> <span class="k">natural</span> <span class="k">join</span> <span class="n">course</span>
</code></pre></div></div> <p>The second query omits all pairs where the student takes a course in a department other than the student’s own department due to the attribute department name. Sometimes, we don’t realize some attributes are being equated because all the common attributes are equated.</p> <h3 id="outer-join">Outer join</h3> <p>One can lose information with inner join and natural join. Outer join is an extension of the join operation that avoids loss of information. It computes the join and then adds tuples from one relation that do not match tuples in the other relation to the result of the join. Outer join uses <code class="language-plaintext highlighter-rouge">null</code> to fill the incomplete tuples. We have variations of outer join such as left-outer join, right-outer join, and full outer join. Can outer join be expressed using relational algebra? Yes, think about it. In general, \((r ⟖ s) ⟖ t \neq r ⟖ (s ⟖t)\).</p> <p><strong>Note.</strong> \((r ⟖ s) ⟕ t \neq r ⟖ (s⟕t)\). Why? Consider the following</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>r | X | Y | s | Y | Z | t | Z | X | P |
  | 1 | 2 |   | 2 | 3 |   | 3 | 4 | 7 |
  | 1 | 3 |   | 3 | 4 |   | 4 | 1 | 8 |
-- LHS				-- RHS
| X | Y | Z | P |	| X | Y | Z | P |
| 1 | 2 | 3 | - |	| 4 | 2 | 3 | 7 |
| 1 | 3 | 4 | 8 |	| 1 | 3 | 4 | 8 |
</code></pre></div></div> <h2 id="views">Views</h2> <p>In some cases, it is not desirable for all users to see the entire logical model. For example, if a person wants to know the name and department of instructors without the salary, then they can use</p> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">create</span> <span class="k">view</span> <span class="n">v</span> <span class="k">as</span> <span class="k">select</span> <span class="n">name</span><span class="p">,</span> <span class="n">dept</span> <span class="k">from</span> <span class="n">instructor</span>
</code></pre></div></div> <p>A view provides a mechanism to hide certain data from the view of certain users. The view definition is not the same as creating a new relation by evaluating the query expression. Rather, a view definition causes the saving of an expression; the expression is substituted into queries using the view.</p> <p>One view may be used in the expression defining another view. A view relation \(v_1\) is said to <em>depend directly</em> on a view relation \(v_2\) if \(v_2\) is used in the expression defining \(v_1\). It is said to <em>depend on</em> \(v_2\) if there is a path of dependency. A <em>recursive</em> view depends on itself.</p> <h3 id="materialized-views">Materialized views</h3> <p>Certain database systems allow view relations to be physically stored. If relations used in the query are updated, the materialized view result becomes out of date. We need to maintain the view, by updating the view whenever the underlying relations are updated. Most SQL implementations allow updates only on simple views.</p> <h2 id="transactions">Transactions</h2> <p>A transaction consists of a sequence of query and/or update statements and is atomic. The transaction must end with one of the following statements -</p> <ul> <li><strong>Commit work</strong> - Updates become permanent</li> <li><strong>Rollback work</strong> - Updates are undone</li> </ul> <h2 id="integrity-constraints">Integrity Constraints</h2> <ul> <li><code class="language-plaintext highlighter-rouge">not null</code></li> <li><code class="language-plaintext highlighter-rouge">primary key (A1, A2, ..., Am)</code></li> <li><code class="language-plaintext highlighter-rouge">unique (A1, A2, ..., Am)</code></li> <li><code class="language-plaintext highlighter-rouge">check (P)</code></li> </ul> <h3 id="check-clause"><code class="language-plaintext highlighter-rouge">check</code> clause</h3> <p>The <strong>check(P)</strong> clause specifies a predicate P that must be satisfied by every tuple in a relation.</p> <h3 id="cascading-actions">Cascading actions</h3> <p>When a referential-integrity constraint is violated, the normal procedure is to reject the action that caused the violation. We can use <code class="language-plaintext highlighter-rouge">on delete cascade</code> or <code class="language-plaintext highlighter-rouge">on update cascade</code>. Other than cascade, we can use <code class="language-plaintext highlighter-rouge">set null</code> or <code class="language-plaintext highlighter-rouge">set default</code>.</p> <h1 id="lecture-7">Lecture 7</h1> <blockquote> <p><code class="language-plaintext highlighter-rouge">17-01-22</code></p> </blockquote> <p>Continuing the previous referential-integrity constraints. Suppose we have the command</p> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">create</span> <span class="k">table</span> <span class="n">person</span><span class="p">(</span>
	<span class="n">ID</span> <span class="nb">char</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span>
	<span class="n">name</span> <span class="nb">char</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span>
	<span class="n">mother</span> <span class="nb">char</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span>
	<span class="n">father</span> <span class="nb">char</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span>
	<span class="k">primary</span> <span class="k">key</span> <span class="n">ID</span><span class="p">,</span>
	<span class="k">foreign</span> <span class="k">key</span> <span class="n">father</span> <span class="k">references</span> <span class="n">person</span><span class="p">,</span>
	<span class="k">foreign</span> <span class="k">key</span> <span class="n">mother</span> <span class="k">references</span> <span class="n">person</span>
<span class="p">)</span>
</code></pre></div></div> <p>How do we insert tuples here without violating the foreign key constraints? We can initially insert the name attributes and then the father and mother attributes. This can be done by inserting <code class="language-plaintext highlighter-rouge">null</code> in the mother/father attributes. Is there any other way of doing this? We can insert tuples by using the acyclicity among the tuples using topological sorting. There is also a third way which is supported by SQL. In this method, we can ask the database to defer the foreign key checking till the end of the transaction.</p> <h3 id="complex-check-conditions">Complex check conditions</h3> <p>The predicate in the check clause can be an arbitrary predicate that can include a subquery <strong>(?)</strong> For example,</p> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">check</span> <span class="p">(</span><span class="n">time_slot_id</span> <span class="k">in</span> <span class="p">(</span><span class="k">select</span> <span class="n">time_slot_id</span> <span class="k">from</span> <span class="n">time_slot</span><span class="p">))</span>
</code></pre></div></div> <p>This condition is similar to a foreign key constraint. We have to check this condition not only when the ‘section’ relation is updated but also when the ‘time_slot’ relation is updated. Therefore, <u>it is not currently supported by any database!</u></p> <h3 id="built-in-data-types-in-sql">Built-in Data Types in SQL</h3> <p>In addition to the previously mentioned datatypes, SQL supports <code class="language-plaintext highlighter-rouge">date</code>s, <code class="language-plaintext highlighter-rouge">interval</code>s, <code class="language-plaintext highlighter-rouge">timestamp</code>s, and <code class="language-plaintext highlighter-rouge">time</code>. Whenever we subtract <code class="language-plaintext highlighter-rouge">date</code> from a <code class="language-plaintext highlighter-rouge">date</code> or <code class="language-plaintext highlighter-rouge">time</code> from <code class="language-plaintext highlighter-rouge">time</code>, we get an <code class="language-plaintext highlighter-rouge">interval</code>.</p> <p>Can we store files in our database? Yes! We can store large objects as</p> <ul> <li><code class="language-plaintext highlighter-rouge">blob</code> - Binary large object - Large collection of uninterpreted binary data (whose interpretation is left to the application outside of the database system).</li> <li><code class="language-plaintext highlighter-rouge">clob</code> character large object - Large collection of</li> </ul> <p>Every database has its own limit for the maximum file size.</p> <h3 id="index-creation">Index Creation</h3> <p>An <strong>index</strong> on an attribute of a relation is a data structure that allows the database system to find those tuples in the relation that have a specified value for that attribute efficiently, without scanning through all the tuples of the relation. We create an index with the <code class="language-plaintext highlighter-rouge">create index</code> command</p> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">create</span> <span class="k">index</span> <span class="o">&lt;</span><span class="n">name</span><span class="o">&gt;</span> <span class="k">on</span> <span class="o">&lt;</span><span class="n">relation</span><span class="o">-</span><span class="n">name</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">attribute</span><span class="p">):</span>
</code></pre></div></div> <p>Every database automatically creates an index on the primary key.</p> <h3 id="authorization">Authorization</h3> <p>We can assign several forms of authorization to a database</p> <ul> <li><strong>Read</strong> - allows reading, but no modification of data</li> <li><strong>Insert</strong> - allows insertion of new data, but not modification of existing data</li> <li><strong>Update</strong> - allows modification, but not deletion of data</li> <li><strong>Delete</strong> - allows deletion of data</li> </ul> <p>We have more forms on the schema level</p> <ul> <li><strong>Index</strong> - allows creation and deletion of indices</li> <li><strong>Resources</strong>, <strong>Alteration</strong></li> <li><strong>Drop</strong> - allows deleting relations</li> </ul> <p>Each of these types of authorizations is called a <strong>privilege</strong>. These privileges are assigned on specified parts of a database, such as a relation, view or the whole schema.</p> <p>The <code class="language-plaintext highlighter-rouge">grant</code> statement is used to confer authorization.</p> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">grant</span> <span class="o">&lt;</span><span class="n">privilege</span> <span class="n">list</span><span class="o">&gt;</span> <span class="k">on</span> <span class="o">&lt;</span><span class="n">relation</span> <span class="k">or</span> <span class="k">view</span><span class="o">&gt;</span> <span class="k">to</span> <span class="o">&lt;</span><span class="k">user</span> <span class="n">list</span><span class="o">&gt;</span>
<span class="c1">-- Revoke statement to revoke authorization</span>
<span class="k">revoke</span> <span class="k">select</span> <span class="k">on</span> <span class="n">student</span> <span class="k">from</span> <span class="n">U1</span><span class="p">,</span> <span class="n">U2</span><span class="p">,</span> <span class="n">U3</span>
</code></pre></div></div> <ul> <li><code class="language-plaintext highlighter-rouge">&lt;user list&gt;</code> can be a user-id, <strong>public</strong> or a <em>role</em>. Granting a privilege on a view does no imply granting any privileges on the underlying relations.</li> <li><code class="language-plaintext highlighter-rouge">&lt;privilege-list&gt;</code> may be <strong>all</strong> to revoke all privileges the revokee may hold.</li> <li>If <code class="language-plaintext highlighter-rouge">&lt;revoke-list&gt;</code> includes <strong>public</strong>, all users lost the privilege except those granted it explicitly.</li> <li>If the same privilege was granted twice to the same user by different grantees, the user may retain the privilege after the revocation. All privileges that depend on the privilege being revoked are also revoked.</li> </ul> <p>One of the major selling points of Java was a <em>garbage collector</em> that got rid of <code class="language-plaintext highlighter-rouge">delete</code>/<code class="language-plaintext highlighter-rouge">free</code> and automatically freed up unreferenced memory. This action is done via a <em>counter</em> which keeps a count of the variables that are referencing a memory cell. SQL uses a similar counter for keeping track of permissions of various objects. However, this approach fails in case of cycles in the dependency graph. For instance, consider the following situation</p> <p><img src="/assets/img/Databases/image-20220117101819769.png" alt="image-20220117101819769"/></p> <p>This problem does not occur in case of programming languages. The solution to this problem is <strong><em><code class="language-plaintext highlighter-rouge">TODO</code></em></strong>.</p> <p>What about garbage collection when the program is huge? Is it efficient? Currently, many optimizations, like <em>incremental garbage collection</em>, have been implemented to prevent freezing of a program for garbage collection. Even after this, Java is not preferred for real-time applications. However, programmers prefer Java because of the ease of debugging and writing programs.</p> <h3 id="roles">Roles</h3> <p>A <strong>role</strong> is a way to distinguish among various users as far as what these users can access/update in the database.</p> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">create</span> <span class="n">a</span> <span class="k">role</span> <span class="o">&lt;</span><span class="n">name</span><span class="o">&gt;</span>
<span class="k">grant</span> <span class="o">&lt;</span><span class="k">role</span><span class="o">&gt;</span> <span class="k">to</span> <span class="o">&lt;</span><span class="n">users</span><span class="o">&gt;</span>
</code></pre></div></div> <p>There are a couple more features in authorization which can be looked up in the textbook.</p> <p>We can also give authorization on views.</p> <h3 id="other-authorization-features">Other authorization features</h3> <ul> <li> <p>references privilege to create foreign key</p> <p><code class="language-plaintext highlighter-rouge">grant reference (dept_name) on department to Mariano</code></p> </li> <li> <p>transfer of privileges</p> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">grant</span> <span class="k">select</span> <span class="k">on</span> <span class="n">department</span> <span class="k">to</span> <span class="n">Amit</span> <span class="k">with</span> <span class="k">grant</span> <span class="k">option</span><span class="p">;</span>
<span class="k">revoke</span> <span class="k">select</span> <span class="k">on</span> <span class="n">department</span> <span class="k">from</span> <span class="n">Amit</span><span class="p">,</span> <span class="n">Satoshi</span> <span class="k">cascade</span><span class="p">;</span>
<span class="k">revoke</span> <span class="k">select</span> <span class="k">on</span> <span class="n">deparment</span> <span class="k">from</span> <span class="n">Amit</span><span class="p">,</span> <span class="n">Satoshi</span> <span class="k">restrict</span><span class="p">;</span>
</code></pre></div> </div> </li> </ul> <h1 id="lecture-8">Lecture 8</h1> <blockquote> <p><code class="language-plaintext highlighter-rouge">18-01-22</code></p> </blockquote> <h1 id="-chapter-5-advanced-sql">~ Chapter 5: Advanced SQL</h1> <p>Programming languages with automatic garbage collection cannot clean the data in databases. That is, if you try using large databases, then your system may hang.</p> <h2 id="jdbc-code">JDBC code</h2> <p><code class="language-plaintext highlighter-rouge">DriverManager.getConnection("jdbc:oracle:thin:@db_name")</code> is used to connect to the database. We need to close the connection after the work since each connection is a process on the server, and the server can have limited number of processes. In Java we check the <code class="language-plaintext highlighter-rouge">null</code> value using <code class="language-plaintext highlighter-rouge">wasNull()</code> function (not intuitive).</p> <p>Prepared statements are used to take inputs from the user without SQL injection. We can also extract metadata using JDBC.</p> <h2 id="sql-injection">SQL injection</h2> <p>The method where hackers insert SQL commands into the database using SQL queries. This problem is prevented by using <code class="language-plaintext highlighter-rouge">prepared statement</code>s.</p> <p>This lecture was cut-short, and hence has less notes.</p> <h1 id="lecture-9">Lecture 9</h1> <blockquote> <p><code class="language-plaintext highlighter-rouge">20-01-22</code></p> </blockquote> <h2 id="functions-and-procedures">Functions and Procedures</h2> <p>Functions and procedures allow ‘business logic’ to be stored in the database and executed from SQL statements.</p> <p>We can define a function using the following syntax</p> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">create</span> <span class="k">function</span> <span class="o">&lt;</span><span class="n">name</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">params</span><span class="p">)</span>
	<span class="k">returns</span> <span class="o">&lt;</span><span class="n">datatype</span><span class="o">&gt;</span>
	<span class="k">begin</span>
		<span class="p">...</span>
	<span class="k">end</span>
</code></pre></div></div> <p>You can return scalars or relations. We can also define external language routines in other programming languages. These procedures can be more efficient than the ones defined in SQL. We can declare external language procedures and functions using the following.</p> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">create</span> <span class="k">procedure</span> <span class="o">&lt;</span><span class="n">name</span><span class="o">&gt;</span><span class="p">(</span><span class="k">in</span> <span class="n">params</span><span class="p">,</span> <span class="k">out</span> <span class="n">params</span> <span class="p">(</span><span class="o">?</span><span class="p">))</span>
<span class="k">language</span> <span class="o">&lt;</span><span class="n">programming</span><span class="o">-</span><span class="k">language</span><span class="o">&gt;</span>
<span class="k">external</span> <span class="n">name</span> <span class="o">&lt;</span><span class="n">file_path</span><span class="o">&gt;</span>
</code></pre></div></div> <p>However, there are security issues with such routines. To deal with security problems, we can</p> <ul> <li><strong>sandbox techniques</strong> - using a safe language like Java which cannot access/damage other parts of the database code.</li> <li>run external language functions/procedures in a separate process, with no access to the database process’ memory.</li> </ul> <h2 id="triggers">Triggers</h2> <p>When certain actions happen, we would like the database to react and do something as a response. A <strong>trigger</strong> is a statement that is executed automatically by the system as a side effect of a modification to the database. To design a trigger mechanism, we must specify the conditions under which the trigger is to be executed and the actions to be taken when the trigger executes. The syntax varies from database to database and the user must be wary of it.</p> <p>The SQL:1999 syntax is</p> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">create</span> <span class="k">trigger</span> <span class="o">&lt;</span><span class="n">name</span><span class="o">&gt;</span> <span class="k">after</span> <span class="p">[</span><span class="k">update</span><span class="p">,</span> <span class="k">insert</span><span class="p">,</span> <span class="k">delete</span><span class="p">]</span> <span class="k">of</span> <span class="o">&lt;</span><span class="n">relation</span><span class="o">&gt;</span> <span class="k">on</span> <span class="o">&lt;</span><span class="n">attributes</span><span class="o">&gt;</span>
<span class="k">referencing</span> <span class="k">new</span> <span class="k">row</span> <span class="k">as</span> <span class="n">nrow</span>
<span class="k">referencing</span> <span class="k">old</span> <span class="k">row</span> <span class="k">as</span> <span class="n">orow</span>
<span class="p">[</span><span class="k">for</span> <span class="k">each</span> <span class="k">row</span><span class="p">]</span>
	<span class="p">...</span>
</code></pre></div></div> <p>If we do not want the trigger to be executed for every row update, then we can use statement level triggers. This ensures that the actions is executed for all rows affected by a transaction. We use <code class="language-plaintext highlighter-rouge">for each</code> instead of <code class="language-plaintext highlighter-rouge">for each row</code> and we reference tables instead of rows.</p> <p>Triggers need not be used to update materialized views, logging, and many other typical use cases. Use of triggers is not encouraged as they have a risk of unintended execution.</p> <h2 id="recursion-in-sql">Recursion in SQL</h2> <p>SQL:1999 permits recursive view definition. Why do we need recursion? For example, if we want to find which courses are a prerequisite (direct/indirect) for a specific course, we can use</p> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="k">recursive</span> <span class="n">rec_prereq</span><span class="p">(</span><span class="n">course_id</span><span class="p">,</span> <span class="n">prereq_id</span><span class="p">)</span> <span class="k">as</span> <span class="p">(</span>
	<span class="k">select</span> <span class="n">course_id</span><span class="p">,</span> <span class="n">prereq_id</span> <span class="k">from</span> <span class="n">prereq</span>
	<span class="k">union</span>
	<span class="k">select</span> <span class="n">rec_prereq</span><span class="p">.</span><span class="n">course_id</span><span class="p">,</span> <span class="n">prereq</span><span class="p">.</span><span class="n">prereq_id</span><span class="p">,</span>
	<span class="k">from</span> <span class="n">rec_prereq</span><span class="p">,</span> <span class="n">prereq</span>
	<span class="k">where</span> <span class="n">rec_prereq</span><span class="p">.</span><span class="n">prereq_id</span> <span class="o">=</span> <span class="n">prereq</span><span class="p">.</span><span class="n">course_id</span>
<span class="p">)</span> <span class="k">select</span> <span class="o">*</span> <span class="k">from</span> <span class="n">rec_prereq</span><span class="p">;</span>
</code></pre></div></div> <p>This example view, <code class="language-plaintext highlighter-rouge">rec_prereq</code> is called the <em>transitive closure</em> of the <code class="language-plaintext highlighter-rouge">prereq</code> relation. Recursive views make it possible to write queries, such as transitive closure queries, that cannot be written without recursion or iteration. The alternative to recursion is to write a procedure to iterate as many times as required.</p> <p>The final result of recursion is called the <strong>fixed point</strong> of the recursive view. Recursive views are required to be <strong>monotonic</strong>. This is usually achieved using <code class="language-plaintext highlighter-rouge">union</code> without <code class="language-plaintext highlighter-rouge">except</code> and <code class="language-plaintext highlighter-rouge">not in</code>.</p> <h2 id="advanced-aggregation-features">Advanced Aggregation Features</h2> <h3 id="ranking">Ranking</h3> <p>Ranking is done in conjunction with an order by specification. Can we implement ranking with the knowledge we have currently? Yes, we can use count() to check how many tuples are ahead of the current tuple.</p> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">select</span> <span class="o">*</span><span class="p">,</span>  <span class="p">(</span><span class="k">select</span> <span class="k">count</span><span class="p">(</span><span class="o">*</span><span class="p">)</span> <span class="k">from</span> <span class="n">r</span> <span class="k">as</span> <span class="n">r2</span> <span class="k">where</span> <span class="n">r2</span><span class="p">.</span><span class="n">t</span> <span class="o">&gt;</span> <span class="n">r1</span><span class="p">.</span><span class="n">t</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span> <span class="k">from</span> <span class="n">r</span> <span class="k">as</span> <span class="n">r1</span>
</code></pre></div></div> <p>However, this is \(\mathcal O(n^2)\). Also, note that the above query implements <em>sparse rank</em>. <em>Dense rank</em> can be implemented using the <code class="language-plaintext highlighter-rouge">unique</code> keyword. Rank in SQL can be implemented using <code class="language-plaintext highlighter-rouge">rank() over ([order by A desc])</code>.</p> <p>Ranking can be done within partitions within the dataset. This is done using <code class="language-plaintext highlighter-rouge">partition by</code>. The whole query is given by</p> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">select</span> <span class="n">ID</span><span class="p">,</span> <span class="n">dept_name</span><span class="p">,</span> <span class="n">rank</span><span class="p">()</span> <span class="n">over</span>
	<span class="p">(</span><span class="k">partition</span> <span class="k">by</span> <span class="n">dept_name</span> <span class="k">order</span> <span class="k">by</span> <span class="n">GPA</span> <span class="k">desc</span><span class="p">)</span>
<span class="k">from</span> <span class="n">dept_grades</span>
<span class="k">order</span> <span class="k">by</span> <span class="n">dept_name</span><span class="p">,</span> <span class="n">dept_rank</span>
</code></pre></div></div> <p><u>Multiple rank clauses can occur in a single select clause!</u> Ranking is done after applying <code class="language-plaintext highlighter-rouge">group by</code> clause/aggregation. Finally, if we want only the top few ranks, we can use <code class="language-plaintext highlighter-rouge">limit</code>. However, this method is restrictive as we can’t select top-n in each partition and it is inherently non-deterministic. This is because ties are broken arbitrarily. It is usually better to select directly using the rank attribute by embedding the relation in an outer query.</p> <p>Ranking has other function such as</p> <ul> <li><code class="language-plaintext highlighter-rouge">percent_rank</code> gives percentile</li> <li><code class="language-plaintext highlighter-rouge">cume_dist</code> gives fraction</li> <li><code class="language-plaintext highlighter-rouge">row_number</code> (non-deterministic)</li> </ul> <p>SQL:1999 permits the user to specify <code class="language-plaintext highlighter-rouge">nulls first</code> or <code class="language-plaintext highlighter-rouge">nulls last</code>.</p> <p>For a given constant \(n\), the function <code class="language-plaintext highlighter-rouge">ntile(n)</code> takes the tuples in each partition in the specified order, and divides them into \(n\) buckets with equal number of tuples.</p> <h2 id="windowing">Windowing</h2> <p>Here are the examples of window specifications</p> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">between</span> <span class="k">rows</span> <span class="n">unbounded</span> <span class="k">preceding</span> <span class="k">and</span> <span class="k">current</span>
<span class="k">rows</span> <span class="n">nbounded</span> <span class="k">preceding</span>
<span class="k">range</span> <span class="k">between</span> <span class="mi">10</span> <span class="k">preceding</span> <span class="k">and</span> <span class="k">current</span> <span class="k">row</span>
<span class="k">range</span> <span class="n">interval</span> <span class="mi">10</span> <span class="k">day</span> <span class="k">preceding</span>
<span class="c1">-- Given a relation transaction</span>
<span class="c1">-- where value is positive for a deposite and </span>
<span class="c1">-- negative for a withdrawal, find total balance</span>
<span class="c1">-- of each account after each transaction on it</span>
<span class="k">select</span> <span class="n">account_number</span><span class="p">,</span> <span class="n">date_time</span><span class="p">,</span> 
	<span class="k">sum</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="n">over</span> 
		<span class="p">(</span><span class="k">partition</span> <span class="k">by</span> <span class="n">account_number</span>
        <span class="k">order</span> <span class="k">by</span> <span class="n">date_time</span>
        <span class="k">rows</span> <span class="n">unbounded</span> <span class="k">preceding</span><span class="p">)</span>
   	<span class="k">as</span> <span class="n">balance</span>
<span class="k">from</span> <span class="n">transaction</span>
<span class="k">order</span> <span class="k">by</span> <span class="n">account_number</span><span class="p">,</span> <span class="n">date_time</span>
</code></pre></div></div> <p>We can perform windowing within partitions.</p> <h1 id="lecture-10">Lecture 10</h1> <blockquote> <p><code class="language-plaintext highlighter-rouge">24-01-22</code></p> </blockquote> <p>We will cover one last concept in SQL and then move on to ER models.</p> <h2 id="olap">OLAP</h2> <p>OLAP stands for Online Analytical Processing. It allows interactive analysis of data, allowing data to be summarized and viewed in different ways in an online fashion. Data that can be modeled as dimension attributes and measure attributes are called <strong>multidimensional data</strong>. <strong>Measure attributes</strong> measure some value that can be aggregated upon. <strong>Dimension attributes</strong> define the dimension on which measure attributes are viewed.</p> <p>Items are often represented using <strong>cross-tabulation</strong> (cross-tab), also referred to as a <strong>pivot table</strong>. The dimension attributes form the row and column headers. The measure attributes are mentioned in each individual cell. Similarly, we can create a <strong>data cube</strong> which is a multidimensional generalization of a cross-tab. We can represent cross-tabs using relations. These can be used in SQL with <code class="language-plaintext highlighter-rouge">null</code> representing the total aggregates (despite the confusion).</p> <p>The <code class="language-plaintext highlighter-rouge">cube</code> operation in SQL computes the union of <code class="language-plaintext highlighter-rouge">group by</code>’s on every subset of the specified attributes. The function <code class="language-plaintext highlighter-rouge">grouping()</code> can be applied on an attribute to check if the <code class="language-plaintext highlighter-rouge">null</code> value represents ‘all’ or not. It returns 1 if the value is a null value representing all. The <code class="language-plaintext highlighter-rouge">rollup</code> construct generates union on every prefix of a specified list of attributes. It can be used to generate aggregates at multiple levels of a hierarchy.</p> <h3 id="olap-operations">OLAP Operations</h3> <ul> <li><strong>Pivoting</strong> - Changing the dimensions used in a cross-tab</li> <li><strong>Slicing</strong> - Creating a cross-tab for fixed values only. Sometimes called <strong>dicing</strong> when values for multiple dimensions are fixed.</li> <li><strong>Rollup</strong> - Moving from finer-granularity data to a coarser granularity.</li> <li><strong>Drill down</strong> - Opposite of rollup.</li> </ul> <p>Early OLAP systems precomputed all possible aggregates in order to provide online response. Since this is infeasible, it suffices to precompute some aggregates and compute others on demand from pre-computed aggregates.</p> <h1 id="chapter-6-database-design-using-the-er-model">~Chapter 6: Database Design using the ER Model</h1> <p>How do we design schemas for a database? Is there any systematic way? We shall study this in the following chapter. The entity-relationship model proves useful in modelling the data.</p> <p>When we design a database, we initially characterize the data needs of the database users. Then, we choose a data model to translate the requirements into a conceptual schema. The conceptual schema is designed using the ER model, and the implementation can be done in different ways such as the relation model. We do this in the final step where we move from an abstract data model to the implementation in the database.</p> <p>Why do we care about good design? A bad design can have <em>redundancy</em> - repeats information which might cause data inconsistency and <em>incompleteness</em> which might make certain aspects of the enterprise difficult or impossible to model.</p> <h2 id="er-model">ER Model</h2> <p><strong>Entity</strong> is a thing or an object in the enterprise that is distinguishable from other objects. It is described by a set of attributes. A <strong>relationship</strong> is an association among several entities. These models are represented graphically using the ER diagram.</p> <h3 id="entity-sets">Entity sets</h3> <p>An <strong>entity set</strong> is a set of entities of the same type that share the same properties. For example, it can be a set of all persons (each of which is an entity). A subset of the attributes form a primary key of the entity set.</p> <p>Entity sets can be represented graphically using rectangles and attributes listed inside it. The primary keys are underlined.</p> <h3 id="relationship-sets">Relationship sets</h3> <p>A <strong>relationship set</strong> is a mathematical relation among \(n \geq 2\) entities, each taken from entity sets.</p> \[\{(e_1, e_2, \dots, e_n \vert e_1 \in E_1, e_2 \in E_2, \dots, e_n \in E_n\}\] <p>where \((e_1, e_2, \dots, e_n)\) is a relationship. We draw a line between the related entities to represent relationships. Relationship sets are represented using diamonds.</p> <p>An attribute can also be associated with a relationship set. This is shown using a rectangle with the attribute name inside connected to the relationship set diamond with a dotted line.</p> <h3 id="roles-1">Roles</h3> <p>The entity sets of a relationship need not be distinct. In such a case, we assign ‘roles’ to the entity sets.</p> <h3 id="degree-of-a-relationship-set">Degree of a relationship set</h3> <p>The degree of a relationship set is defined as the number of entities associated with the relationship set. Most relationship sets are binary. We can’t represent all ternary relations as a set of binary relations.</p> <p>There are no null values in the ER model. This becomes an issue in case of ternary relationships. Such problems are prevented in binary relationships. For example, think about the ER model of people and their parents. If someone has only one parent, then it is difficult to represent this using a ternary relationship between people, fathers and mothers. Instead, we could have two separate father and mother relationships. Binary relationships also provide the flexibility of mapping multiple entities to the same entity between two entity sets. While this is also possible in ternary relationships, we have more options in case of binary relationships.</p> <p>Does ternary relationship convey more information than binary relationship in any case? Yes, that is why we can’t represent all ternary relations as a set of binary relations. For instance, think about the instructor, project and student mapping. There are many combinations possible here which can’t be covered using binary relationships.</p> <h3 id="complex-attributes">Complex attributes</h3> <p>So far, we have considered atomic attributes in the relation model. The ER model does not impose any such requirement. We have <strong>simple</strong> and <strong>composite</strong> attributes. A composite attribute can be broken down into more attributes. For instance, we can have first and last name in name. We can have <em>single-valued</em> and <em>multi-valued</em> attributes. We can also have <em>derived</em> attributes. Multivalued attributes are represented inside curly braces <code class="language-plaintext highlighter-rouge">{}</code>.</p> <h3 id="mapping-cardinality-constraints">Mapping cardinality constraints</h3> <p>A mapping cardinality can be one-to-one, one-to-many, many-to-one or many-to-many.</p> <h1 id="lecture-11">Lecture 11</h1> <blockquote> <p><code class="language-plaintext highlighter-rouge">25-01-22</code></p> </blockquote> <p>We express cardinality constraints by drawing either a directed line \((\to)\), signifying ‘one’, or an undirected line \((-)\), signifying ‘many’, between the relationship set and the entity set.</p> <p>Let us now see the notion of participation.</p> <p><strong>Total participation</strong> - every entity in the entity set participates in at least one relationship in the relationship set. This is indicated using a double line in the ER diagram.</p> <p><strong>Partial participation</strong> - some entities may not participate in any relationship in the relationship set.</p> <p>We can represent more complex constraints using the following notation. A line may have an associated minimum and maximum cardinality, shown in the form ‘l..h’. A minimum value of 1 indicates total participation. A maximum value of 1 indicates that the entity participates in at most one relationship. A maximum value of * indicates no limit.</p> <p>How do we represent cardinality constraints in Ternary relationships? We allow at most one arrow out of a ternary (or greater degree) relationship to indicate a cardinality constraint. For instance, consider a ternary relationship R between A, B and C with arrows to B, then it indicates that each entity in A is associated with at most one entity in B for an entity in C.</p> <p>Now, if there is more than one arrow, the understanding is ambiguous. For example, consider the same setup from the previous example. If there are arrows to B and C, it could mean</p> <ul> <li>Each entity in A is associated with a unique entity from B and C, or</li> <li>Each pair of entities from (A, B) is associated with a unique C entity, and each pair (A, C) is associated with a unique entity in B.</li> </ul> <p>Due to such ambiguities, more than one arrows are typically not used.</p> <h3 id="primary-key-for-entity-sets">Primary key for Entity Sets</h3> <p>By definition, individual entities are distinct. From the database perspective, the differences are expressed in terms of their attributes. A key for an entity is a set of attributes that suffice to distinguish entities from each other.</p> <h3 id="primary-key-for-relationship-sets">Primary key for Relationship Sets</h3> <p>To distinguish among the various relationships of a relationship set we use the individual primary keys of the entities in the relationship set. That is, for a relationship set \(R\) involving entity sets \(E_1, E_2, \dots, E_n\), the primary key is given by the union of the primary keys of \(E_1, E_2, \dots, E_n\). If \(R\) is associated with any attributes, then the primary key includes those too. The choice of the primary key for a relationship set depends on the mapping cardinality of the relationship set.</p> <p><strong>Note.</strong> In one-to-many relationship sets, the primary key of the <strong>many</strong> side acts as the primary key of the relationship set.</p> <h3 id="weak-entity-sets">Weak Entity Sets</h3> <p>Weak entity set is an entity set whose existence depends on some other entity set. For instance, consider the section and course entity set. We cannot have a section without a course - an existence dependency. What if we use a relationship set to represent this? This is sort of redundant as both section and course have the course ID as an attribute. Instead of doing this, we can say that section is a weak entity set identified by course.</p> <p>In ER diagrams, a weak entity set is depicted via a double rectangle. We underline the discriminator of a weak entity set with a dashed line, and the relationship set connecting the weak entity set (using a double line) to the identifying strong entity set is depicted by a double diamond. The primary key of the strong entity set along with the discriminators of the weak entity set act as a primary key for the weak entity set.</p> <p>Every weak entity set must be associated with an <strong>identifying entity set</strong>. The relationships associating the weak entity set with the identifying entity set is called the <strong>identifying relationship</strong>. Note that the relational schema we eventually create from the weak entity set will have the primary key of the identifying entity set.</p> <h3 id="redundant-attributes">Redundant Attributes</h3> <p>Sometimes we often include redundant attributes while associating two entity sets. For example, the attribute <code class="language-plaintext highlighter-rouge">course_id</code> was redundant in the entity set section. However, when converting back to tables, some attributes get reintroduced.</p> <h2 id="reduction-to-relation-schemas">Reduction to Relation Schemas</h2> <p>Entity sets and relationship sets can be expressed uniformly as <em>relation schemas</em> that represent the content of the database. For each entity set and relationship set there is a unique schema that is assigned the name of the corresponding entity set or relationship set. Each schema has a number of columns which have unique names.</p> <ul> <li>A strong entity set reduces to a schema with the same attributes.</li> <li>A weak entity set becomes a table that includes a column for the primary key of the identifying strong entity set.</li> <li>Composite attributes are flattened out by creating separate attribute for each component attribute.</li> <li>A multivalued attribute \(M\) of an entity \(E\) is represented by a separate schema \(EM\). Schema \(EM\) has attributes corresponding to the primary key of \(E\) and an attribute corresponding to multivalued attribute \(M\).</li> <li>A many-to-many relationship set is represented as a schema with attributes for the primary keys of the two participating entity sets, and any descriptive attributes of the relationships set.</li> <li>Many-to-one and one-to-many relationship sets that are total on the many-side can be represented by adding an extra attribute to the ‘many’ side. If it were not total, null values would creep up. It is better to model such relationships as many-to-many relationships so that the model needn’t be changed when the cardinality of the relationship is changed in the future.</li> </ul> <h3 id="extended-er-features">Extended ER Features</h3> <p><strong>Specialization</strong> - Overlapping and Disjoint; Total and partial.</p> <p>How do we represent this in the schema? Form a schema for the higher-level entity and for the lower-level entity set. Include the primary key of the higher level entity set and local attributes in that of the local one. However, the drawback of such a construction is that we need to access two relations (higher and then lower) to get information.</p> <p><strong>Generalization</strong> - Combine a number of entity sets that share the same features into a higher-level entity set.</p> <p><strong>Completeness constraint</strong> specifies whether or not an entity in the higher-level entity set must belong to at least on of the lower-level entity sets within a generalization (total and partial concept). Partial generalization is the default.</p> <p><strong>Aggregation</strong> can also be represented in the ER diagrams.</p> <ul> <li>To represent aggregation, create a schema containing - primary key of the aggregated relationship, primary key of the associated entity set, and any descriptive attributes.</li> </ul> <blockquote> <p>I don’t understand aggregation</p> </blockquote> <h3 id="design-issues">Design issues</h3> <p><img src="/assets/img/Databases/image-20220126214411806.png" alt="image-20220126214411806"/></p> <h1 id="lecture-12">Lecture 12</h1> <blockquote> <p><code class="language-plaintext highlighter-rouge">27-01-22</code></p> </blockquote> <h3 id="binary-vs-non-binary-relationships">Binary vs. Non-Binary Relationships</h3> <p>We had discussed this previously in <a href="#degree-of-a-relationship-set">this</a> section. In general, any non-binary relationship can be represented using binary relationships by creating an artificial entity set. We do this by replacing \(R\) between entity sets \(A, B, C\) by an entity set \(E\), and three relationship sets \(R_i\) relating \(E\) and \(i \in \{A, B, C\}\). We create an identifying attribute for E and add any attributes of \(R\) to \(E\). For each relationship \((a_i, b_i, c_i)\) in \(R\), we</p> <ul> <li>create a new entity \(e_i\) in the entity set \(E\)</li> <li>add \((e_i, j_i)\) to \(R_j\) for \(j \in \{A, B, C\}\)</li> </ul> <p><img src="/assets/img/Databases/image-20220215211541849.png" alt="image-20220215211541849"/></p> <p>We also need to translate constraints (which may not be always possible). There may be instances in the translated schema that cannot correspond to any instance of \(R\). We can avoid creating an identifying attribute for \(E\) by making it a weak entity set identified by the three relationship sets.</p> <h3 id="er-design-decisions">ER Design Decisions</h3> <p><strong>Important Points</strong></p> <ul> <li>A weak entity set can be identified by multiple entity sets.</li> <li>A weak entity set can be identified by another weak entity set (indirect identification).</li> <li>In SQL, the value in a foreign key attribute can be null (the attribute of the relation having the fks constraint).</li> </ul> <h3 id="uml">UML</h3> <p>The <strong>Unified Modeling Language</strong> has many components to graphically model different aspects of an entire software system. The ER diagram notation we studied was inspired from the UML notation.</p> <h1 id="chapter-7-functional-dependencies">~Chapter 7: Functional Dependencies</h1> <p>When programmers usually skip the design phase, they run into problems with their relational database. We shall briefly mention these problems and see the motivation for this chapter.</p> <p>A good relational design does not have repetition of information, and no unnecessary null values. The only way to avoid the repetition of information is to decompose a relation to different schemas. However, all decompositions are not <strong>lossless</strong>.</p> <h1 id="lecture-13">Lecture 13</h1> <blockquote> <p><code class="language-plaintext highlighter-rouge">31-01-22</code></p> </blockquote> <p>The term <strong>lossy decomposition</strong> does not imply loss of tuples but rather the loss of information (relation) among the tuples. How do we formalise this idea?</p> <h2 id="lossless-decomposition---1">Lossless Decomposition - 1</h2> <p>Let \(R\) be a relations schema and let \(R_1\) and \(R_2\) form a decomposition of \(R = R_1 \cup R_2\). A decomposition if lossless if there is no loss of information by replacing \(R\) with the two relation schemas \(R_1, R_2\). That is,</p> \[\pi_{R_1}(r) \bowtie \pi_{R_2}(r) = r\] <p>Note that this relations must hold for all <strong>instances</strong> to call the decomposition lossless. And, conversely a decomposition is lossy if</p> \[r \subset \pi_{R_1}(r) \bowtie \pi_{R_2}(r)\] <p>We shall see the sufficient condition in a <a href="#lossless-decomposition---2">later section</a>.</p> <h2 id="normalization-theory">Normalization theory</h2> <p>We build the theory of functional/multivalued dependencies to decide whther a particular relation is in a “good” form.</p> <h2 id="functional-dependencies">Functional Dependencies</h2> <p>An instance of a relations that satisfies all such real-world constriants is called a <strong>legal instance</strong> of the relation. <u>A functional dependency is a generalization of the notion of a key</u>.</p> <p>Let \(R\) be a relation schema and \(\alpha, \beta \subseteq R\). The functional dependency \(\alpha \to \beta\) holds on \(R\) iff for any legal relations \(r(R)\) whenever two tuples \(t_1, t_2\) of \(r\) agree on the attributes \(\alpha\), they also agree on the attributes \(\beta\). That is,</p> \[\alpha \to \beta \triangleq t_1[\alpha] = t_2[\alpha] \implies t_1[\beta] = t_1[\beta]\] <h3 id="closure-properties">Closure properties</h3> <p>If \(A \to B\) and \(B \to C\) Then \(A \to C\). The set of <strong>all</strong> functional dependencies logically implied by a functional dependency set \(F\) is the <strong>closure</strong> of \(F\) denoted by \(F^+\).</p> <h3 id="keys-and-functional-dependencies">Keys and Functional Dependencies</h3> <p>\(K\) is a superket for relation schema \(R\) iff \(K \to R\). \(K\) is a candidate key for \(R\) iff</p> <ul> <li>\(K \to R\) and</li> <li>for no \(A \subset K\), \(A \to R\)</li> </ul> <p>Functional dependencies allow us to express constraints that cannot be expressed using super keys.</p> <h3 id="use-of-functional-dependencies">Use of functional dependencies</h3> <p>We use functional dependencies to test relations to see if they are legal and to specify constraints on the set of legal relations.</p> <p><strong>Note.</strong> A specific instance of a relation schema may satisfy a functional dependency even if that particular functional dependency does not hold across all legal instances.</p> <h2 id="lossless-decomposition---2">Lossless Decomposition - 2</h2> <p>A decomposition of \(R\) into \(R_1\) and \(R_2\) is lossless decomposition if at least one of the following dependecnies is in \(F^+\)</p> <ul> <li> \[R_1 \cap R_2 \to R_1\] </li> <li> \[R_1 \cap R_2 \to R_2\] </li> </ul> <p>The above functional dependencies are a necessary condition only if all constraints are functional dependencies.</p> <h2 id="dependency-preservation">Dependency Preservation</h2> <p>Testing functional dependency constrinats each time the database is updated can be costly. If testing a functional dependency can be done by considering just one relation, then the cost of testing this constraint is low. A decomposition that makes it computaitonally hard to enforce functional dependencies is sat to be <strong>not dependency preserving</strong>.</p> <h1 id="lecture-14">Lecture 14</h1> <blockquote> <p><code class="language-plaintext highlighter-rouge">01-02-22</code></p> </blockquote> <h2 id="boyce-codd-normal-form">Boyce-Codd Normal Form</h2> <p>There are a few designs of relational schema which prevent redundancies and have preferable properties. One such design format is BCNF.</p> <p>A relation schema \(R\) is in BCNF with respect to a set \(R\) of functional dependencies if <strong>for all</strong> functional dependencies in \(F^+\) of the form \(\alpha \to \beta\) where \(\alpha, \beta \subseteq R\), at least one of the following holds</p> <ul> <li>\(\alpha \to \beta\) is trivial (\(\beta \subseteq \alpha\))</li> <li>\(\alpha\) is a superkey for \(R\).</li> </ul> <p>Let \(R\) Be a schema \(R\) That is not in BCNF. Let \(\alpha \to \beta\) Be the FD that causes a violation of BCNF. Then, to convert \(R\) to BCNF we decompose it to</p> <ul> <li> \[\alpha \cup \beta\] </li> <li> \[R - (\beta - \alpha)\] </li> </ul> <p><strong><em>Example.</em></strong> Consider the relation \(R= (A, B, C)\) with \(F \{A \to B, B \to C\}\). Suppose we have the following decompositions</p> <ul> <li> \[R_1 = (A, B), R_2 = (B, C)\] <p>This decompositions is lossless-join and also dependency preserving. Notice that it is dependency preserving even though we have the \(A \to C\) constraint. This is because \(A \to C\) is implied from the other two constraints.</p> </li> <li> \[R = (A, B), R_2 = (A, C)\] <p>This decomposition is lossless but is not dependency preserving.</p> </li> </ul> <h3 id="bcnf-and-dependency-preservation">BCNF and Dependency Preservation</h3> <p><u>It is not always possible to achieve both BCNF and dependency preservation</u>.</p> <h2 id="third-normal-form">Third Normal Form</h2> <p>This form is useful when you are willing to allow a small amount of data redundancy in exchange for dependency preservation.</p> <p>A relations \(R\) Is in third normal form (3NF) if <strong>for all</strong> \(\alpha \to \beta \in F^+\) <strong>at least</strong> one of the following holds</p> <ul> <li>\(\alpha \to \beta\) is trivial</li> <li>\(\alpha\) is a super key for \(R\)</li> <li>Each attribute \(A\) In \(\beta - \alpha\) is contained in a candidate key for \(R\).</li> </ul> <p>There are 1NF and 2NF forms but they are not very important. <u>If a relation is in BCNF, then it is in 3NF.</u></p> <h3 id="redundancy-in-3nf">Redundancy in 3NF</h3> <p>Consider \(R\) which is in 3NF \(R = (J, K, L)\) and \(F = \{JK \to L, L \to K \}\). Then, we can have the following instance</p> <table> <thead> <tr> <th>J</th> <th>K</th> <th>L</th> </tr> </thead> <tbody> <tr> <td>p1</td> <td>q1</td> <td>k1</td> </tr> <tr> <td>p2</td> <td>q1</td> <td>k1</td> </tr> <tr> <td>p3</td> <td>q1</td> <td>k1</td> </tr> <tr> <td>null</td> <td>q2</td> <td>k2</td> </tr> </tbody> </table> <h3 id="3nf-and-dependency-preservation">3NF and Dependency Preservation</h3> <p>It is always possible to obtain a 3NF design without sacrificing losslessness or dependency preservation. However, we may have to use null values (like above) to represent some of the possible meaningful relationships among data items.</p> <h3 id="goals-of-normalisation">Goals of Normalisation</h3> <p>A “good” schema consists of lossless decompositions and preserved dependencies. We can use 3NF and BCNF (preferable) for such purpose.</p> <p>There are database schemas in BCNF that do not seem to be sufficiently normalised. <em>Multivalued dependencies, Insertion anomaly, …</em></p> <h2 id="functional-dependency-theory">Functional Dependency Theory</h2> <h3 id="closure-of-a-set-of-functional-dependencies">Closure of a set of functional dependencies</h3> <p>We can compute \(F^+\) from \(F\) by repeatedly applying <strong>Armstrong’s Axioms</strong></p> <ul> <li><strong>Reflexive rule</strong> - If \(\beta \subseteq \alpha\), then \(\alpha \to \beta\)</li> <li><strong>Augmentation rule</strong> - If \(\alpha \to \beta\), then \(\gamma\alpha \to \gamma\beta\)</li> <li><strong>Transitivity rule</strong> - If \(\alpha \to \beta\) and \(\beta \to \gamma\) then \(\alpha \to \gamma\)</li> </ul> <p>It is trivial to see that these rules are <strong>sound</strong>. However, showing that these rules are <strong>complete</strong> is much more difficult.</p> <p>Additional rules include (can be derived from above)-</p> <ul> <li><strong>Union rule</strong> - If \(\alpha \to \beta\) and \(\alpha \to \gamma\), then \(\alpha \to \beta\gamma\)</li> <li><strong>Decomposition rule</strong> - If \(\alpha \to \beta\gamma\), then \(\alpha \to \beta\)</li> <li><strong>Pseudo-transitivity rule</strong> - If \(\alpha \to \beta\) and \(\gamma\beta \to \delta\), then \(\alpha \gamma \to \delta\)</li> </ul> <h3 id="closure-of-attribute-sets">Closure of Attribute Sets</h3> <p>Given a set of attributes \(\alpha\), define the <strong>closure</strong> of \(\alpha\) <strong>under</strong> \(F\) (denoted by \(\alpha^+\)) as the set of attributes that are functionally determined by \(\alpha\) under \(F\). We use the following procedure to compute the closure of A</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>result := A
while (change) do
	for each beta to gamma in F do
		begin
			if beta in result then result = result union gamma
    end
</code></pre></div></div> <p>The time complexity of this algorithm is \(\mathcal O(n^3)\) where \(n\) is the number of attributes.</p> <p>There are several uses of the attribute closure algorithm</p> <ul> <li>To test if \(\alpha\) is a superkey, we compute \(\alpha\) and check if it contains all attributes of the relation</li> <li>To check if a functional dependency \(\alpha \to \beta\) holds, see if \(\beta \subseteq \alpha^+\)</li> <li>For computing the closure of \(F\). For each \(\gamma \subseteq R\), we find \(\gamma\) and for each \(S \subset \gamma^+\), we output a functional dependency \(\gamma \to S\).</li> </ul> <h3 id="canonical-cover">Canonical Cover</h3> <p>A <strong>Canonical cover</strong> of a functional dependency set \(F\) is the minimal set of functional dependencies such that its closure is \(F^+\).</p> <p>An attribute of a functional dependency in \(F\) is <strong>extraneous</strong> if we can remove it without changing \(F^+\). Removing an attribute from the left side of a functional dependency will make it a stronger constraint.</p> <h1 id="lecture-15">Lecture 15</h1> <blockquote> <p><code class="language-plaintext highlighter-rouge">05-02-22</code></p> </blockquote> <h3 id="extraneous-attributes">Extraneous attributes</h3> <p>Removing an attribute from the left side of a functional dependency makes it a stronger constraint. Attribute A is extraneous in \(\alpha\) if</p> <ul> <li> \[A \in \alpha\] </li> <li>\(F\) logically implies \((F - \{\alpha \to \beta\}) \cup \{(\alpha - A) \to \beta\}\)</li> </ul> <p>To test this, consider \(\gamma = \alpha - \{A\}\). Check if \(\gamma \to \beta\) can be inferred from \(F\). We do this by computing \(\gamma^+\) using the dependencies in \(F\), and if it includes all attributes in \(\beta\) then \(A\) is extraneous in \(\alpha\).</p> <p>On the other hand, removing an attribute from the right side of a functional dependency could make it a weaker constraint. Attribute A is extraneous in \(\beta\) if</p> <ul> <li> \[A \in \beta\] </li> <li> <p>The set of functional dependencies</p> <p>\((F - \{\alpha \to \beta\}) \cup \{\alpha \to ( \beta - A)\}\) logically implies \(F\).</p> </li> </ul> <p>To test this, consider \(F’ = (F - \{\alpha \to \beta\}) \cup \{\alpha \to ( \beta - A)\}\) and check if \(\alpha^+\) contains A; if it does, then \(A\) is extraneous in \(\beta\).</p> <h2 id="canonical-cover-revisited">Canonical Cover Revisited</h2> <p>A <strong>canonical cover</strong> for \(F\) is a set of dependencies \(F_c\) such that</p> <ul> <li>\(F\)(\(F_c\)) logically implies all dependencies in \(F_c\)(\(F\))</li> <li>No functional dependency in \(F_c\) contains an extraneous attribute</li> <li><u>Each left side of functional dependency in $$F_c$$ is unique</u></li> </ul> <p>To compute a canonical cover for \(F\) do the following</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Fc = F
repeat
	Use the union rule to replace any dependencies in Fc of the form
		alpha -&gt; beta and alpha -&gt; gamma with
    alpha -&gt; beta gamma
	Find a functional dependency alpha to beta 
	in Fc with an extraneous attribute 
	in alpha or in beta
	Delete extraneous attribute if found
until Fc does not change
</code></pre></div></div> <h2 id="dependency-preservation---3">Dependency Preservation - 3</h2> <p>Let \(F_i\) be the set of dependencies \(F^+\) that include only the attribtues in \(R_i\). A decomposition is <strong>dependency preserving</strong> if \((F_1 \cup \dots \cup F_n)^+ = F^+\). However, we can’t use this definition to test for dependency preserving as it takes exponential time.</p> <p>We test for dependency preservation in the following way. To check if a dependency \(\alpha \to \beta\) is preserved in a decomposition, apply the following test</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>result = alpha
repeat
	for each Ri in the decomposition
		t = (result cap Ri)^+ cap Ri
		result = result \cup t
until result does not change
</code></pre></div></div> <p>If the result contains all attributes in \(\beta\), then the functional dependency \(\alpha \to \beta\) is preserved. This procedure takes polynomial time.</p> <h2 id="testing-for-bcnf">Testing for BCNF</h2> <p>To check if a non-trivial dependency \(\alpha \to \beta\) cause a violation of BCNF, compute \(\alpha^+\) and verify that it includes all attributes of \(R\). Another simpler method is to check only the dependencies in the given set \(F\) for violations of BCNF rather than checking all dependencies in \(F^+\). If none of the dependencies in \(F\) cause a violation, then none of the dependencies in \(F^+\) will cause a violation. <em>Think.</em></p> <p>However, the simplified test using only \(F\) is incorrect when testing a relation in a decomposition of \(R\). For example, consider \(R = (A, B, C, D, E)\), with \(F = \{ A \to B, BC \to D\}\) and the decomposition \(R_1 = (A, B), R_2 = (A, C, D, E)\). Now, neither of the dependencies in \(F\) contain only attributes from \((A, C, D, E)\) so we might be misled into thinking \(R_2\) satisfies BCNF.</p> <p>Therefore, testing decomposition requires the restriction of \(R^+\) to that particular set of tables. If one wants to the use the original set of dependencies \(F\), then they must check that \(\alpha^+\) either includes no attributes of \(R_i - \alpha\) or includes all attributes of \(R_i\) for every set of attributes \(\alpha \subseteq R\). If a condition \(\alpha \to \beta \in F^+\) violates BCNF, then the dependency \(\alpha \to (\alpha^+ - \alpha) \cap R_i\) can be shown to hold on \(R_i\) and violate BCNF.</p> <p>In conclusion, the BCNF decomposition algorithm is given by</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>result = R
done = false
compute F+
while (not done) do
	if (there is a schema Ri in result that is not in BCNF)
		let alpha to beta be a nontrivial functional dependency
      that holds on Ri such that alpha to Ri
      is not in F+
      and alpha cap beta is null
 		result = {(result - Ri),(Ri - beta),(alpha, beta)}
 	else done = true
		
</code></pre></div></div> <p>Note that each \(R_i\) is in BCNF and decomposition is lossless-join.</p> <h2 id="3nf">3NF</h2> <p>The main drawback of BCNF is that is may not be dependency preserving. Through 3NF, we allow some redundancy to acquire dependency preserving along with lossless join.</p> <p>To test for 3NF, we only have to check the FDs in \(F\) and not all the FDs in \(F^+\).We use attribute closure to check for each dependency \(\alpha \to \beta\), if \(\alpha\) is a super key. If \(\alpha\) is not a super key, we need to check if each attribute in \(\beta\) is contained in a candidate key of \(R\).</p> <p>However, this test is shown to be NP-hard, but the decomposition into third normal form can be done in polynomial time.</p> <blockquote> <p>Doesn’t decomposition imply testing? No, one relation can have many 3NF decompositions.</p> </blockquote> <h3 id="3nf-decomposition-algorithm">3NF Decomposition Algorithm</h3> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Let Fc be a canconical cover for F;
i = 0;
/* initial schema is empty */
for each FD alpha to beta in Fc do
	if none of the schemas Rj (j &lt;= i) contains alpha beta
		then begin
			i = i + 1
			Ri = alpha beta
		end
/* Here, each of the FDs will be contained in one of the Rjs */
if none of the schemas Rj (j &lt;= i) contains a candidate key for R
  then begin
    i = i + 1
    Ri = any candidate key for R
  end
/* Here, there is a relation contianing the candidate key of R */
/* Optionally remove redundant relations */
repeat
  if any schema Rj is contained in another schema Rk
    then delete Rj
      Rj = Ri;
      i = i - 1
  return (R1, ..., Ri)
</code></pre></div></div> <p>Guaranteeing that the above set of relations are in 3NF is the easy part. However, proving that the decomposition is lossless is difficult.</p> <h3 id="comparison-of-bcnf-and-3nf">Comparison of BCNF and 3NF</h3> <p>3NF has redundancy whereas BCNF may not be dependency preserving. The bigger problem is 3Nf allows certain function dependencies which are not super key dependencies. However, none of the SQL implementations today support such FDs.</p> <h2 id="multivalued-dependencies">Multivalued Dependencies</h2> <p>Let \(R\) be a relation schema and let \(\alpha, \beta \subseteq R\) . The multivalued dependency</p> \[\alpha \to\to \beta\] <p>holds on \(R\) if in any legal relation \(r(R)\), for all pairs for tuples \(t_1, t_2\) in \(r\) such that \(t_1[\alpha] = t_2[\alpha]\), there exists tuples \(t_3\) and \(t_4\) in \(r\) such that</p> \[t_1[\alpha] = t_2[\alpha] = t_3[\alpha] = t_4[\alpha] \\ t_3[\beta] = t_1[\beta] \\ t_3[R - \beta] = t_2[R - \beta] \\ t_4[\beta] = t_2[\beta] \\ t_4[R - \beta] = t_1[R - \beta]\] <p>Intuitively, it means that the relationship between \(\alpha\) and \(\beta\) is independent of the remaining attributes in the relation. The tabular representation of these conditions is given by</p> <p><img src="/assets/img/Databases/image-20220217224504065.png" alt="image-20220217224504065"/></p> <p>The definition can also be mentioned in a more intuitive manner. Consider the attributes of \(R\) that are partitioned into 3 nonempty subsets \(W, Y, Z\). We say that \(Y \to\to Z\) iff for all possible relational instances \(r(R)\),</p> \[&lt;y_1, z_1, w_1&gt; \in r \text{ and } &lt; y_1, z_2, w_2 &gt; \in r \\ \implies \\ &lt;y_1, z_1, w_2 &gt; \in r \text{ and } &lt;y_1, z_2, w_1 &gt; \in r\] <p><strong>Important Points</strong>-</p> <ul> <li>If \(Y \to\to Z\) then \(Y \to\to W\)</li> <li>If \(Y \to Z\) then \(Y \to\to Z\)</li> </ul> <blockquote> <p>why?</p> </blockquote> <p>The closure \(D^+\) of \(D\) is the set of all functional and multivalued dependencies logically implied by \(D\). We are not covering the reasoning here.</p> <h2 id="fourth-normal-form">Fourth Normal Form</h2> <p>A relation schema \(R\) is in 4NF rt a set \(D\) of functional and multivalued dependencies if for all multivalued dependencies in \(D^+\) in the form \(\alpha \to\to \beta\), where \(\alpha, \beta \subseteq R\), at least one of the following hold</p> <ul> <li>\(\alpha \to\to \beta\) is trivial</li> <li>\(\alpha\) is a super key for schema \(R\)</li> </ul> <p><u>If a relation is in 4NF, then it is in BCNF.</u> That is, 4NF is stronger than BCNF. Also, 4NF is the generalisation of BCNF for multivalued dependencies.</p> <h3 id="restriction-of-mvds">Restriction of MVDs</h3> <p>The restriction of \(D\) to \(R_i\) is the set \(D_i\) consisting of</p> <ul> <li>All functional dependencies in \(D^+\) that include only attributes of \(R_i\)</li> <li>All multivalued dependencies of the form \(\alpha \to \to (\beta \cap R_i)\) where \(\alpha \in R_i\) and \(\alpha \to\to \beta \in D^+\).</li> </ul> <h3 id="4nf-decomposition-algorithm">4NF Decomposition Algorithm</h3> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>result = {R};
done = false;
compute D+
Let Di denote the restriction of D+ to Ri
while(not done)
	if (there is a schema Ri in result not in 4NF)
		let alpha to to beta be a nontrivial MVD that holds
		on Ri such that  alpha to Ri is not in Di and 
		alpha cap beta is null
		result = {result - Ri, Ri - beta, (alpha, beta)}
	else done = true
</code></pre></div></div> <p>This algorithm is very similar to that of BCNF decomposition.</p> <h1 id="lecture-16">Lecture 16</h1> <blockquote> <p><code class="language-plaintext highlighter-rouge">07-02-22</code></p> </blockquote> <h2 id="further-normal-forms">Further Normal Forms</h2> <p><strong>Join dependencies</strong> generalise multivalued dependencies and lead to <strong>project-join normal form (PJNF)</strong> also known as <strong>5NF</strong>. A class of even more general constraints leads to a normal form called <strong>domain-key normal form</strong>. There are hard to reason with and no set of sound and complete set of inference rules exist.</p> <h2 id="overall-database-design-process">Overall Database Design Process</h2> <p>We have assumed \(R\) is given. In real life, we can get it based on applications through ER diagrams. However, one can consider \(R\) to be generated from a single relations containing all attributes that are of interest (called <strong>universal relation</strong>). Normalisation breaks this \(R\) into smaller relations.</p> <p>Some aspects of database design are not caught by normalisation. For example, a <strong>crosstab</strong>, where values for on attribute become column names, is not captured by normalisation forms.</p> <h2 id="modeling-temporal-data">Modeling Temporal Data</h2> <p><strong>Temporal data</strong> have an associated time interval during which the data is valid. A <strong>snapshot</strong> is the value of the data at a particular point in time. Adding a temporal component results in functional dependencies being invalidated because the attribute values vary over time. A <strong>temporal functional dependency</strong> \(X \xrightarrow{\tau} Y\) holds on schema \(R\) if the functional dependency \(X \to Y\) holds on all snapshots for all legal instances \(r(R)\).</p> <p>In practice, database designers may add start and end time attributes to relations. SQL standard [start, end). In modern SQL, we can write</p> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">period</span> <span class="k">for</span> <span class="n">validtime</span> <span class="p">(</span><span class="k">start</span><span class="p">,</span> <span class="k">end</span><span class="p">)</span>
<span class="k">primary</span> <span class="k">key</span> <span class="p">(</span><span class="n">course_id</span><span class="p">,</span> <span class="n">validtime</span> <span class="k">without</span> <span class="k">overlaps</span><span class="p">)</span>
</code></pre></div></div> <h1 id="chapter-8-complex-data-types">~Chapter 8: Complex Data Types</h1> <p>Expected to read from the textbook.</p> <ul> <li>Semi-Structured Data</li> <li>Object Orientation</li> <li>Textual Data</li> <li>Spatial Data</li> </ul> <h2 id="semi-structured-data">Semi-Structured Data</h2> <p>Many applications require storage of complex data, whose schema changes often. The relational model’s requirement of atomic data types may be an overkill. JSON (JavaScript Object Notation) and XML (Extensible Markup Language) are widely used semi-structured data models.</p> <p><strong>Flexible schema</strong></p> <ul> <li><strong>Wide column</strong> representation allow each tuple to have a different set of attributes and can add new attributes at any time</li> <li><strong>Sparse column</strong> representation has a fixed but large set of attributes but each tuple may store only a subset.</li> </ul> <p><strong>Multivalued data types</strong></p> <ul> <li>Sets, multi-sets</li> <li>Key-value map</li> <li>Arrays</li> <li>Array database</li> </ul> <h3 id="json">JSON</h3> <p>It is a verbose data type widely used in data exchange today, There are efficient data storage variants like BSON</p> <h3 id="knowledge-representation">Knowledge Representation</h3> <p>Representation of human knowledge is a long-standing goal of AI. <strong>RDF: Resource Description Format</strong> is a simplified representation for facts as triples of the form (subject, predicate, object). For example, (India, Population, 1.7B) is one such form. This form has a natural graph representation. There is a query language called SparQL for this representation. <strong>Linked open data</strong> project aims to connect different knowledge graphs to allow queries to span databases.</p> <p>To represent n-ary relationships, we can</p> <ul> <li>Create an artificial entity and link to each of the n entities</li> <li>Use <strong>quads</strong> instead of triples with context entity</li> </ul> <h2 id="object-orientation">Object Orientation</h2> <p><strong>Object-relational data model</strong> provides richer type system with complex data types and object orientation. Applications are often written in OOP languages. However, the type system does not match relational type system and switching between imperative language and SQL is cumbersome.</p> <p>To use object-orientation with databases, we could build an <strong>object-relational database</strong>, adding object-oriented features to a relational database. Otherwise, we could automatically convert data between OOP and relational model specified by <strong>object-relational mapping</strong>. <strong>Object-oriented database</strong> is another option that natively supports object-oriented data and direct access from OOP. The second method is widely used now.</p> <h3 id="object-relational-mapping">Object-Relational Mapping</h3> <p>ORM systems allow</p> <ul> <li>specification of mapping between OOP objects and database tuples</li> <li>Automatic modification of database</li> <li>Interface to retrieve objects satisfying specified conditions</li> </ul> <p>ORM systems can be used for websites but not for data-analytics applications!</p> <h2 id="textual-data">Textual Data</h2> <p><strong>Information retrieval</strong> basically refers to querying of unstructured data. Simple model of keyword queries consists of fetching all documents containing all the input keywords. More advanced models rank the relevance of documents.</p> <h3 id="ranking-using-tf-idf">Ranking using TF-IDF</h3> <p>Term is a keyword occurring in a document query. The <strong>term frequency</strong> \(TF(d, t)\) is the relevance of a term \(t\) to a document \(d\). It is defined by</p> \[TF(d, t) = \log( 1+ n(d, t)/n(d))\] <p>where \(n(d, t)\) is the number of occurrences of term \(t\) in document \(d\) and \(n(d)\) is the number of terms in the document \(d\).</p> <p>The <strong>inverse document frequency</strong> \(IDF(t)\) is given by</p> \[IDF(t) = 1/n(t)\] <p>This is used to give importance to terms that are rare. <strong>Relevance</strong> of a document \(d\) to a set of terms \(Q\) can be defined as</p> \[r(d, Q) = \sum_{t \in Q} TF(d, t)*IDF(t)\] <p>There are other definitions that take <strong>proximity</strong> of words into account and <strong>stop words</strong> are often ignored.</p> <h1 id="lecture-17">Lecture 17</h1> <blockquote> <p><code class="language-plaintext highlighter-rouge">08-02-22</code></p> </blockquote> <p>The TF-IDF method in search engine was did not work out as web designers added repeated occurrences of words on their website to increase the relevance. There were plenty of shady things web designers could do in order to increase the page relevance. To prevent this problem, Google introduced the model of <strong>PageRank</strong>.</p> <h3 id="ranking-using-hyperlinks">Ranking using Hyperlinks</h3> <p>Hyperlinks provide very important clues to importance. Google’s PageRank measures the popularity/importance based on hyperlinks to pages.</p> <ul> <li>Pages hyperlinked from many pages should have higher PageRank</li> <li>Pages hyperlinked from pages with higher PageRank should have higher PageRank</li> </ul> <p>This model is formalised by a <strong>random walk</strong> model. Let \(T[i, j]\) be the probability that a random walker who is on page \(i\) will click on the link to page \(j\). Then, PageRank[j] for each page \(j\) is defined as</p> \[P[j] = \delta/N + (1 - \delta)*\sum_{i = 1}^n(T(i, j)*P(j))\] <p>where \(N\) is the total number of pages and \(\delta\) is a constant usually set to \(0.15\). As the number of pages are really high, some sort of bootstrapping method (Monte Carlo simulation) is used to approximate the PageRank. PageRank also can be fooled using mutual link spams.</p> <h3 id="retrieval-effectiveness">Retrieval Effectiveness</h3> <p>Measures of effectiveness</p> <ul> <li><strong>Precision</strong> - what % of returned results are actually relevant.</li> <li><strong>Recall</strong> - what percentage of relevant results were returned</li> </ul> <h2 id="spatial-data">Spatial Data</h2> <p>Not covered</p> <h1 id="chapter-9-application-development">~Chapter 9: Application Development</h1> <h2 id="http-and-sessions">HTTP and Sessions</h2> <p>The HTTP protocol is <strong>connectionless</strong>. That is, once the server replied to a request, the server closes the connection with the client, and forgets all about the request. The motivation to this convention is that it reduces the load on the server. The problem however is authentication for every connection. Information services need session information to acquire user authentication only once per session. This problem is solved by <strong>cookies</strong>.</p> <p>A <strong>cookie</strong> is a small piece of text containing identifying information</p> <ul> <li>sent by server to browser on first interaction to identify session</li> <li>sent by browser to the server that created the cookie on further interactions (part of the HTTP protocol)</li> <li>Server saved information about cookies it issued, and can use it when serving a request. E.g, authentication information, and user preferences</li> </ul> <p>Cookies can be stored permanently or for a limited time.</p> <p><strong>Java Servlet</strong> defines an API for communication between the server and app to spawn threads that can work concurrently.</p> <h2 id="web-services">Web Services</h2> <p>Web services are basically URLs on which we make a request to obtain results.</p> <p>Till HTML4, local storage was restricted to cookies. However, this was expanded to any data type in HTML5.</p> <h2 id="http-and-https">HTTP and HTTPS</h2> <p>The application server authenticates the user by the means of user credentials. What if a hacker scans all the packets going to the server to obtain a user’s credentials? So, HTTPS was developed to encrypt the data sent between the browser and the server. How is this encryption done? The server and the browser need to have a common key. Turns out, there are crypto techniques that can achieve the same.</p> <p>What if someone creates a middleware that simulates a website a user uses? This is known as <strong>man in the middle attack</strong>. How do we know we are connected to the authentic website? The basic idea is to have a <strong>public key</strong> of the website and send data encrypted via this public key. Then, the website uses its own <strong>private key</strong> to decrypt the data. This conversion is reversible. As in, the website encrypts the data using its own private key which can be decoded by the user using the public key.</p> <p>How do we get public keys for millions of websites out there? We use <strong>digital certificates</strong>. Let’s say we have a website’s public key and that website has the public key of the user (via their website). The website then encrypts the user’s public key using its private key to generate a digital certificate. This digital certificate can be advertised on the user’s website to allow other users to check the authenticity of the user’s website. Now, another user can obtain this certificate, decrypt it using the first website’s private key, and verify the authenticity of the user’s webpage. These verifications are maintained as a hierarchical structure to maintain digital certificates of millions of websites.</p> <h2 id="cross-site-scripting">Cross Site Scripting</h2> <p>In cross site scripting, the user’s session for one website is used in another website to execute actions at the server of the first website. For example, suppose a bank’s website, when logged in, allows the user to transfer money by visiting the link <code class="language-plaintext highlighter-rouge">xyz.com/?amt=1&amp;to=123</code>. If another website has a similar link (probably for displaying an image), then it can succeed in transferring the amount if the user is still logged into the bank. This vulnerability is called called <strong>cross-site scripting (XSS)</strong> or <strong>cross-site request forgery (XSRF/CSRF)</strong>. <strong>XSRF</strong> tokens are a form of cookies that are used to check these cross-site attacks (CORS from Django).</p> <h1 id="lecture-18">Lecture 18</h1> <blockquote> <p><code class="language-plaintext highlighter-rouge">14-02-22</code></p> </blockquote> <h2 id="application-level-authorisation">Application Level Authorisation</h2> <p>Current SQL standard does not allow fine-grained authorisation such as students seeing their own grades but not others. <strong>Fine grained (row-level) authorisation</strong> schemes such as Oracle Virtual Private Database (VPD) allows predicates to be added transparently to all SQL queries.</p> <h1 id="chapter-10-big-data">~Chapter 10: Big Data</h1> <p>Data grew in terms of volume (large amounts of data), velocity (higher rates of insertions) and variety (many types of data) in the recent times. This new generation of data is known as <strong>Big Data</strong>.</p> <p>Transaction processing systems (ACID properties) and query processing systems needed to be made scalable.</p> <h2 id="distributed-file-systems">Distributed File Systems</h2> <p>A distributed file system stores data across a large collection of machines, but provides a single file-system view. Files are replicated to handle hardware failure, and failures were to be detected and recovered from.</p> <h3 id="hadoop-file-system-architecture">Hadoop File System Architecture</h3> <p>A single namespace is used for an entire cluster. Files are broken up into blocks (64 MB) and replicated on multiple <em>DataNodes</em>. A client finds the location of blocks from <em>NameNode</em> and accesses the data from <em>DataNodes</em>.</p> <p>The key idea of this architecture is using large block sizes for the actual file data. This way, the metadata would be reduced and the <em>NameNode</em> can store the <em>DataNodes</em> info in a much more scalable manner.</p> <p>Distributed file systems are good for <u>millions of large files</u>. However, distributed file systems have very high overheads and poor performance with billions of smaller tuples. Data coherency also needs to be ensured (write-once-read-many access model).</p> <h2 id="sharding">Sharding</h2> <p>It refers to partitioning data across multiple databases. Partitioning is usually done on some <strong>partitioning attributes</strong> known as <strong>partitioning keys</strong> or <strong>shard keys</strong>. The advantage to this is that it scales well and is easy to implement. However, it is not transparent (manually writing all routes and queries across multiple databases), removing load from an overloaded database is not easy, and there is a higher change of failure. Sharding is used extensively by banks today.</p> <h2 id="key-value-storage-systems">Key Value Storage Systems</h2> <p>These systems store large numbers of small sized records. Records are partitioned across multiple machines, and queries are routed by the system to appropriate machine. Also, the records are replicated across multiple machines to ensure availability. Key-value stores ensure that updates are applied to all replicas to ensure consistency.</p> <p>Key-value stores may have</p> <ul> <li><u>uninterpreted bytes</u> with an associated key</li> <li><u>Wide-column</u> with associated key</li> <li>JSON</li> </ul> <p><strong>Document stores</strong> store semi-structured data, typically JSON. Key-value stores support <code class="language-plaintext highlighter-rouge">put</code>, <code class="language-plaintext highlighter-rouge">get</code> and <code class="language-plaintext highlighter-rouge">delete</code>. Some systems also support <strong>range queries</strong> on key values. Document stores also support queries on non-key attributes. <u>Key value stores are not full database systems</u>. They have no/limited support for transactional updates and applications must manage query processing on their own. These systems are therefore known as <strong>NoSQL</strong> systems.</p> <h2 id="parallel-and-distributed-databases">Parallel and Distributed Databases</h2> <p><strong>Replication</strong> to ensure availability. <strong>Consistency</strong> implemented using majority protocols. <strong>Network partitions</strong> involve a network can break into two or more parts, each with active systems that can’t talk to other parts. In presence of partitions, cannot guarantee both availability and consistency - <strong>Brewer’s CAP</strong> theorem. Traditional database systems choose consistency, and most web applications choose availability.</p> <h1 id="lecture-19">Lecture 19</h1> <blockquote> <p><code class="language-plaintext highlighter-rouge">15-02-22</code></p> </blockquote> <h2 id="mapreduce-paradigm">MapReduce Paradigm</h2> <p>The goal here is to be able to run many queries/scripts across a large number of machines. <code class="language-plaintext highlighter-rouge">Map</code> and <code class="language-plaintext highlighter-rouge">Reduce</code> have similar functionalities as seen in Python. Programmers realised many operations can be reduced to a sequence of map and reduce actions (popular in functional programming).</p> <p>Google formalised the notion of map-reduce for web-crawling and other web-development needs as map-reduce workers. This paradigm was used along with distributed file systems.</p> <p>The default input for the map operations is a line.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>map(k, v) -&gt; list(k1, v1)
reduce(k1, list(v1)) -&gt; v2
</code></pre></div></div> <p>However, map-reduce code for database queries was large. So, the developers at Facebook came up with Hive which converts SQL queries to map-reduce queries.</p> <h2 id="algebraic-operations">Algebraic Operations</h2> <p>We shall study these as a part of <strong>Spark</strong>.</p> <h1 id="lecture-20">Lecture 20</h1> <blockquote> <p><code class="language-plaintext highlighter-rouge">17-02-22</code></p> </blockquote> <h2 id="algebraic-operations-in-spark">Algebraic Operations in Spark</h2> <p><strong>Resilient Distributed Dataset (RDD)</strong> abstraction is a collection of records that can be stored across multiple machines. RDDs can be created by applying algebraic operations on other RDDs. This is a generalisation to RA where the operators can be any piece of code. <u>RDDs can be lazily computed when needed.</u> As in, the tree is executed only on specific functions such as <code class="language-plaintext highlighter-rouge">saveAsTextFile()</code> or <code class="language-plaintext highlighter-rouge">collect()</code>.</p> <p>Spark makes use of Java Lambda expressions with the following syntax.</p> <div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">s</span> <span class="o">-&gt;</span> <span class="nc">ArrayasList</span><span class="o">(</span><span class="n">s</span><span class="o">.</span><span class="na">split</span><span class="o">(</span><span class="s">" "</span><span class="o">)).</span><span class="na">iterate</span><span class="o">()</span>
</code></pre></div></div> <p>RDDs in Spark can be typed in programs, but not dynamically.</p> <h2 id="streaming-data">Streaming Data</h2> <p>Streaming data refers to data that arrives in a continuous fashion in contrast to <strong>data-at-rest</strong>.</p> <p>Approaches to querying streams-</p> <ul> <li><strong>Windowing</strong> - Break up stream into windows and queries are run on windows.</li> <li><strong>Continuous Queries</strong> - Queries written e.g. in SQL, output partial result based on stream seen so far; query results are updated continuously.</li> <li><strong>Algebraic operators on streams</strong> - Operators are written in an imperative language.</li> <li><strong>Pattern Matching</strong> - <em>Complex Even Processing (CEP)</em> systems. Queries specify patterns, system detects occurrences of patterns and triggers actions.</li> <li><strong>Lambda architecture</strong> - Split the stream into two, one output goes to stream processing system and the other to a database for storage.</li> </ul> <p>There are stream extensions to SQL - Tumbling window, Hopping window, Sliding window and Sessions windows.</p> <h3 id="publish-subscribe-systems">Publish Subscribe Systems</h3> <p><strong>Public-subscribe (pub-sub)</strong> systems provide convenient abstraction for processing streams. For example, Apache Kafka</p> <h2 id="graph-databases">Graph Databases</h2> <p>A <strong>graph data model</strong> can be seen as a generalisation of the ER model. Every entity can be seen as a node, and every binary relationship is an edge. Higher degree relationships can be expressed as multiple binary relationships.</p> <p>Check out <em>Neo4J</em>. Query languages for graph databases make it easy for graph traversal.</p> <h1 id="lecture-21">Lecture 21</h1> <blockquote> <p><code class="language-plaintext highlighter-rouge">28-02-22</code></p> </blockquote> <h3 id="parallel-graph-processing">Parallel graph processing</h3> <p>Two popular approaches have been devised for parallel processing on very large graphs</p> <ul> <li>Map-reduce and algebraic frameworks</li> <li><strong>Bulk synchronous processing (BSP)</strong></li> </ul> <h3 id="bulk-synchronous-processing">Bulk Synchronous Processing</h3> <p>Each vertex of a graph has data associated with it. The vertices are partitioned across multiple machines, and state of the nodes are kept in-memory. Now, in each step (<em>superstep</em>)</p> <ul> <li>Nodes process received messages</li> <li>Update their state</li> <li>Send further messages or vote to halt</li> <li>Computation ends when all nodes vote to halt, and there are no pending messages</li> </ul> <p>The method is synchronous as the computation is done in steps. However, this method is not fault tolerant as all the computations need to be recomputed in case of a failure. Checkpoints can be created for restoration.</p> <h1 id="chapter-11-data-analytics">~Chapter 11: Data Analytics</h1> <ul> <li><strong>Data Analytics</strong> - The processing of data to infer patterns, correlations, or models for prediction.</li> <li>Data often needs to be <strong>extracted</strong> from various source formats, <strong>transformed</strong> to a common schema, and <strong>loaded</strong> into the <u>data warehouse</u>. (ETL)</li> <li><strong>Data mining</strong> extends techniques developed by ML onto large datasets</li> <li>A <strong>data warehouse</strong> is a repository of information gathered from multiple sources, stored under a unified schema at a single site. It also permits the study of historical trends. The common schema is <u>optimised for querying and not transactions</u>. The schema is most often <strong>denormalized</strong> (faster query time).</li> <li>Data in warehouses can be stored as <strong>fact tables</strong> or <strong>dimension tables</strong>. The attributes of fact tables can be usually viewed as <strong>measure attributes</strong> (aggregated upon) or <strong>dimension attributes</strong> (small ids that are foreign keys to dimension tables).</li> <li>A fact table branching out to multiple dimension schema is a <strong>star schema</strong>. A <strong>snowflake schema</strong> has multiple levels of dimension tables (can have multiple fact tables).</li> <li>A <strong>data lake</strong> refers to repositories which allow data to be stored in multiple formats without schema integration. Basically, data is just dumped for future use.</li> <li>Data warehouses often use <strong>column-oriented storage</strong>.</li> </ul> <h1 id="chapter-12-physical-storage-systems">~Chapter 12: Physical Storage Systems</h1> <p>The performance of a database engine depends on the way data is stored underneath. The storage hierarchy typically used is as follows</p> <p><img src="/assets/img/Databases/image-20220312223422611.png" alt="image-20220312223422611"/></p> <p>Tertiary storage is used for data archives in today’s world. Data is read as a cache-line from the main memory (lookahead sorta). Similarly, to account for even higher latency of the flash memory, we read one page at a time.</p> <h2 id="storage-interfaces">Storage Interfaces</h2> <p>The way we interface with the storage also has a great impact on the performance. We have the following standards</p> <ul> <li>SATA (Serial ATA) - Supports upto 6 Gbps (v3)</li> <li>SAS (Serial Attached SCSI) - Supports upto 12 Gbps (v3)</li> <li>NVMe (Non-Volatile Memory Express) works with PCIe connecters and gives upto 24 Gbps.</li> </ul> <h1 id="lecture-22">Lecture 22</h1> <blockquote> <p><code class="language-plaintext highlighter-rouge">03-03-22</code></p> </blockquote> <p>A large number of disks are connected by a high-speed network to a number of servers in a <strong>Storage Area Network (SAN)</strong>. The <strong>Network Attached Storage (NAS)</strong> provides a file system interface using a network file system protocol like FTP. SAN can be connected to multiple computers and gives a view of a local disk. It has fault tolerance and replication. A NAS pretends to be a file system unlike SAN.</p> <h2 id="magnetic-disks">Magnetic Disks</h2> <p>The surface of the platter is divided into 50k-100k circular <strong>tracks</strong>. Each track is divided into 500-1000 (on inner tracks) or 1000-2000 (on outer tracks) <strong>sectors</strong>. A <strong>cylinder</strong> is a stack of platters.</p> <p>The performance of a disk is measured via its <strong>access time</strong> which involves seek time and rotational latency, <strong>I/O operations per second (IOPS)</strong>, <strong>Mean/Annualized time to failure (MTTF)</strong> and <strong>data-transfer rate</strong>. We can tune the performance by changing parameters such as <strong>Disk block size</strong> and <strong>Sequential/Random access pattern</strong>. MTTF decreases as disk ages.</p> <p><strong><em>Note.</em></strong> Suppose the MTTF of a single disk is \(t\). How do we calculate the average failing time of a disk in a set of \(n\) disks? The probability that a disk fails in a given hour is \(1/t\). The probability that one of the disks in \(n\) fails is \(1 - (1 - 1/t)^n\). However, if \(t\) is large, it is simply \(n/t\). That is, on an average a disk fails in every \(t/n\) hours in a set of \(n\) disks.</p> <p>In a random access pattern, every request requires a <strong>seek</strong>. This method results in lower transfer rates. Current disks allow up to 50-200 IOPS.</p> <h2 id="flash-storage">Flash storage</h2> <p>A <strong>NAND flash</strong> is widely used for storage in contrast to a <strong>NOR flash</strong>. A page can only be written once, and it must be erased to allow rewriting. Flash storage does page-at-a-time read. If we try for a byte read, then the control lines take up a lot of storage, and the capacity goes down.</p> <p>A <strong>solid state disk</strong> uses standard block-oriented disk interfaces, but store data on multiple flash storage devices internally. We can use SSD using the SATA interface. An erase in flash storage happens in unit of <strong>erase block</strong>, and <strong>remapping</strong> of logical page addresses to physical page addresses avoids waiting for erase. The remapping is carried out by <strong>flash translation layer</strong>. After 100000 to 1000000 erases, the erase block becomes unreliable and cannot be use due to <strong>wear leveling</strong>.</p> <p>A SLC tolerates about \(10^6\) erases. A QLC has 4 voltage levels (2 bits can be stored in 1 physical bit). These are much less tolerant to erases (about \(10^3\) erases). <strong>Wear leveling</strong> normalises the erases in a region of the flash storage by storing cold data in the part where a lot of erases have been done.</p> <p>The performance of an SSD is measured through the data transfer rates. SSDs also support parallel reads. <strong>Hybrid disks</strong> combine small amount of flash cache with large magnetic disks.</p> <p>Recently, Intel has come up with the 3D-XPoint memory technology which is shipped as Intel Optane. It allows lower latencies than flash SSDs.</p> <h3 id="raid">RAID</h3> <p><strong>Redundant Arrays of Independent Disks</strong> is a set of disk organization techniques that manage a large number of disks <u>providing a view of a single disk.</u> The idea is that some disk out of a set of <em>N</em> disks will fails much higher than the chance that a specific single disk will fail. We expect <u>high capacity, high speed, and high reliability</u> from this system.</p> <p>In a way, we improve the reliability of the storage system using redundancy. For example, the simplest way to do this is <strong>mirroring</strong> (or shadowing) where we just duplicate all disks. <u>The **mean time to data loss** depends on the mean time to failure and the mean time to repair</u>. For example, if the MTTF is 100000 hours and the mean time to repair is 10 hours, then we get the mean time to data loss as \(500\times 10^6\) hours. How do we get this? The probability that one of the disk fails is \(2*10^{-5}\). Now, what is the probability that the other disk fails within the repair time? It is \(2* 10^{-4}\). Now, at this point we have data loss. Therefore, the mean time to data loss would be \(2.5 *10^8\) for one disk. As we have two disks, we get \(5 * 10^8\). Data loss occurs when both disks fail.</p> <p>The two main goals of parallelism in a disk system are to load balance multiple small accesses to increase throughput and parallelise large accesses to reduce the response time. We do this via bit-level stripping or <strong>block-level striping</strong>. In block level striping, with n disks, block \(i\) of a file goes to disk to disk(\(i\%n\)) + 1. Now, requests for the same file can run in parallel increasing the transfer rate.</p> <ul> <li>RAID level 0 : Block-striping; non-redundant. Used in high-performance applications where data loss is not critical.</li> <li>RAID level 1: Mirrored disks with block striping. Popular for best write performance and applications such as storing log files in a database system.</li> </ul> <p>RAID also <strong>parity blocks</strong> that stores the XOR of bits from the block of each disk. Parity block \(j\) stores XOR of bits from block \(j\) of each disk. This helps in recovery of data in case of a single disk failure (XOR the parity bit with the remaining blocks on various disks). Parity blocks are often spread across various disks for obvious reasons.</p> <ul> <li> <p>RAID level 5 - Block-interleaved Distributed Parity. This is nice but writes are slower. The cost of recovery is also high. <em>Think</em>.</p> </li> <li> <p>RAID level 6 - It has a P + Q redundancy scheme where 2 error correction blocks are stored instead of a single parity block. Two parity blocks guard against multiple(2) disk failures.</p> </li> </ul> <p>There are other RAID levels which are not used in practice.</p> <h1 id="lecture-23">Lecture 23</h1> <blockquote> <p><code class="language-plaintext highlighter-rouge">07-03-22</code></p> </blockquote> <p><strong>Software RAID</strong> vs. <strong>Hardware RAID</strong>. Copies are written sequentially to guard against corruption in case of power failure. There are couple of hardware issues</p> <ul> <li><strong>Latent sector failures</strong> - Data successfully written earlier gets damaged which can result in data loss even if only one disk fails.</li> <li><strong>Data scrubbing</strong> - Continuous scans for latent failures, and recover from copy/parity.</li> <li><strong>Hot swapping</strong> - Replacement of disk while the system is running without powering it down. This reduces the time to recovery, and some hardware RAID systems support this.</li> </ul> <h1 id="chapter-13-data-storage-structures">~Chapter 13: Data Storage Structures</h1> <h2 id="file-organization">File Organization</h2> <p>The database is stored as a collection of <em>files</em>. Each file is a sequence of <em>records</em>, and each record is a sequence of fields. We will assume the following</p> <ul> <li>Fixed record size</li> <li>Each file has records of one particular type only</li> <li>Different files are used for different relations</li> <li>Records are smaller than a disk block</li> </ul> <h3 id="fixed-length-records">Fixed length records</h3> <p>We store the records contiguously, and access a record based on the index and the offset. There might be fragmentation at the end of the block. How do we handle deleted records? We shall link all the free records on a free list.</p> <h3 id="variable-length-records">Variable length records</h3> <p>Strings are typically variable sized. Each record has variable length attributes represented by fixed size (offset, length) with the actual data stored after all fixed length attributes. Null values are represented by null-value bitmap. How do we structure these records in a block?</p> <h3 id="slotted-page-structure">Slotted Page Structure</h3> <p>A slotted page header contains -</p> <ul> <li>number of record entries</li> <li>end of free space in the block</li> <li>location and size of each record</li> </ul> <p>The records are stored contiguously after the header. Disk pointers point to the header and not directly to the record.</p> <h3 id="storing-large-objects">Storing Large Objects</h3> <p>Records were assumed to be smaller than pages. Otherwise, we store the records as files. In Postgres, the large attribute is automatically broken up into smaller parts.</p> <h2 id="organisation-of-records-in-files">Organisation of Records in Files</h2> <p>Records can be stored as</p> <ul> <li><strong>Heap</strong> - Record can be placed anywhere in the file where there is space. We maintain a hierarchical free space map of two levels usually.</li> <li><strong>Sequential</strong> - Store records in sorted sequential order, based on the value of the search key of each record.</li> <li><strong>B+ tree file organization</strong></li> <li><strong>Hashing</strong></li> </ul> <p>Some databases also support <strong>multi-table clustering file organisation</strong> that allows records of different relations to be stored in the same file.</p> <h2 id="metadata-and-partitioning">Metadata and Partitioning</h2> <p>The <strong>data dictionary</strong> or <strong>system catalog</strong> stored <strong>metadata</strong> such as</p> <ul> <li>names of relations</li> <li>names, types and lengths of attributes of each relation</li> <li>names and definitions of views</li> <li>integrity constraints</li> </ul> <h1 id="lecture-24">Lecture 24</h1> <blockquote> <p><code class="language-plaintext highlighter-rouge">08-03-22</code></p> </blockquote> <h3 id="partitioning">Partitioning</h3> <p><strong>Table partitioning</strong> - Records in a relation can be partitioned into smalled relations that are stored separately - <strong>Horizontal partitioning</strong>. Store each attribute of a relation separately - <strong>vertical partitioning</strong>. Also known as <strong>columnar representation</strong> or <strong>column oriented storage</strong>. This is a good idea for data analytics but not for transaction processing. The benefits of this representation include</p> <ul> <li>Reduced IO if only some attributes are accessed</li> <li>Improved CPU cache performance</li> <li>Improved Compression</li> <li>Vector Processing on modern CPU architectures</li> </ul> <p>The disadvantages are</p> <ul> <li>Tuple reconstruction is difficult</li> <li>Tuple deletion and updates are difficult</li> <li>Cost of decompression</li> </ul> <p>Some databases support a hybrid model which has both row and column representation.</p> <p><strong>Note.</strong> ORC and Parquet use file formats with columnar storage inside file. These are log file formats.</p> <h2 id="storage-access">Storage Access</h2> <p>Blocks are units of both storage allocation and data transfer. At the disk layer, a page is the physical unit. <strong>Buffer</strong> - The portion of the main memory to store copies of the disk blocks.</p> <h3 id="buffer-manager">Buffer Manager</h3> <p><strong>Pinned block</strong> - A memory block that is not allowed to be written back to the disk. A <strong>pin</strong> is done before reading/writing data from a block. An <strong>unpin</strong> done when read/write is complete. Multiple concurrent pin/unpin operations are possible. There are also <strong>shared and exclusive locks</strong> on buffer.</p> <h3 id="buffer-replacement-policies">Buffer Replacement Policies</h3> <p>Most OS replace the block using the LRU strategy. However, this is not suitable in many database operations. Therefore, a database system can query plan to predict future references. There are <strong>toss-immediate</strong> and <strong>MRU</strong> strategies too.</p> <h1 id="chapter-14-indexing">~Chapter 14: Indexing</h1> <p>A <strong>search key</strong> is a set of attributes used to look up records in a file. An <strong>index file</strong> consists of records (called <strong>index entries</strong>) of the form \(search-key \mid pointer\). These files are usually much smaller than the original file. We have two basic kinds of indices</p> <ul> <li><strong>Ordered indices</strong> - SEarch keys are stored in a sorted order</li> <li><strong>Hash indices</strong> - search keys are distributed uniformly across “buckets” using a “hash function”.</li> </ul> <h2 id="index-evaluation-metrics">Index Evaluation Metrics</h2> <ul> <li>Access types supported by the indices. These include searching for records with a specified value or records falling in a specified range of values.</li> <li>Access time</li> <li>Insertion time</li> <li>Deletion time</li> <li>Space overhead</li> </ul> <h2 id="ordered-indices">Ordered Indices</h2> <p>A <strong>clustering index</strong> in a sequentially ordered file, is the index whose search key specifies the sequential order of the file. It is also called as the <strong>primary index</strong> that is not to be confused with primary key. A <strong>secondary index/nonclustering</strong> is an index whose search key specifies an order different from the sequential order of the file.</p> <p>An index sequential file is a sequential file ordered on a search key, with a clustering index on the search key.</p> <h3 id="dense-index-files">Dense index Files</h3> <p>A <strong>dense index</strong> is an index for which there is a record in the index-file for every search-key value in the file. Also, every index-record made with a dense index need not be mapped to an index as we use the following structure.</p> <p><img src="/assets/img/Databases/image-20220407153333197.png" alt="image-20220407153333197"/></p> <p>A <strong>sparse index</strong> on the other hand contains index records for only some search-key values. To locate a record with a search-key value \(K\), we first find an index record with largest search-key value \(&lt; K\). Then, we search the file sequentially starting at the record to which the index record points. For unclustered index, we create a sparse index on top of a dense index (multilevel index).</p> <h1 id="lecture-25">Lecture 25</h1> <blockquote> <p><code class="language-plaintext highlighter-rouge">10-03-22</code></p> </blockquote> <p>Sparse indices take less space and have less maintenance overhead in comparison to dense indices. However, they are generally slower than dense indices.</p> <p><strong>Note.</strong> Secondary indices have to be dense.</p> <p>We use <strong>lexicographic ordering</strong> for composite search keys.</p> <h2 id="b-tree">B\(^+\)-Tree</h2> <p>We will ignore duplicate keys for now. The number of children for every node lies within a certain specified range for that tree. In a \(B^+\)-Tree we have \(n\) pointers and \(n-1\) values separating them. A pointer between values \(a\) and \(b\) will point to values \(c\) that satisfy \(a \leq c &lt; b\). It is not necessary for the internal nodes to be full.</p> <p>Formally, a \(B^+\)-tree is a rotted tree satisfying the following properties</p> <ul> <li>All paths from the root to a leaf are of the same length.</li> <li>Each node that is not a root or a leaf has between \(\lceil{n/2}\rceil\) and \(n\) children.</li> <li>A lead node has between \(\lceil (n - 1)/2 \rceil\) and \(n - 1\) values.</li> <li>If a root is not a leaf, it has at least 2 children, and if a root is a lead, it can have between \(0\) and \(n - 1\) values.</li> </ul> <p>A typical node looks like \(P_! \mid K_1 \mid \dots \mid K_{n - 1} \mid P_n\). Here \(K_i\) are the search-key values and \(P_i\) are pointers to children or records (buckets of records). Also, \(K_1 &lt; \dots &lt; K_{n - 1}\).</p> <h3 id="leaf-nodes">Leaf nodes</h3> <p>For \(i = 1, \dots, n - 1\), pointer \(P_i\) points to a file record with search-key value \(K_i\).</p> <p>Pointers help us keep the nodes logically close but they need not be physically close. The non-lead levels of the \(B^+\) tree form a hierarchy of sparse indices. The level below root has at least \(2* \lceil n/2 \rceil\) values, the next level has \(2* \lceil n/2 \rceil* \lceil n/2 \rceil\), and so on. So if there are \(K\) search key values in the file, the tree height is no more than \(\lceil \log_{\lceil n/1 \rceil} K\rceil\).</p> <h3 id="queries-on-b-trees">Queries on \(B^+\)-trees</h3> <p><strong>Range queries</strong> finds all records with search key values in a given range. These are implemented as iterators.</p> <p>To handle non-unique keys, create a composite key that indexes into the duplicate values. Search for an index can be implemented as a range query. If the index is clustering, then all accesses are sequential. However, if the index if non-clustering, each record access may need an I/O operation.</p> <h3 id="insertion-on-b-trees">Insertion on \(B^+\)-trees</h3> <p>Insertion is easy when the nodes are not full. However, when nodes are full, we would have to split the nodes. We split a node through the parent, by adding a splitting value in the parent node. We do this recursively, and if the root gets full, we create a new root. We insert from leaves because the leaves hold the pointers to records.</p> <p><img src="/assets/img/Databases/image-20220407164819276.png" alt="image-20220407164819276"/></p> <p>The above image gives the formal algorithm.</p> <h3 id="deletion-on-b-trees">Deletion on \(B^+\)-trees</h3> <p>We need to ensure that there are at least a minimum number of values in each node. The complexity of the updates is of the order \(\mathcal O( \log_{\lceil n/2 \rceil}K)\). The height of the tree decreases when a node has very few children. Note that a deleted value can still appear as a separator in the tree after the deletion. Also, the average node occupancy depends on the insertion order (2/3rds with random and 1/2 with insertion in sorted order).</p> <h1 id="lecture-26">Lecture 26</h1> <blockquote> <p><code class="language-plaintext highlighter-rouge">14-03-22</code></p> </blockquote> <p>If we allow non-unique keys, we can store a key with multiple pointers. However, the complexity comes in terms of deletion. Worst case complexity may be linear.</p> <h3 id="b-tree-file-organisation">\(B^+\)-Tree file Organisation</h3> <p>Leaf nodes in a \(B^+\) tree file organisation store records, instead of pointers. As records are larger than pointers, the maximum number of records that can be stored in a lead node is less than the number of pointers in a non-leaf node. To improve space utilisation, we can involve more sibling nodes in redistribution during splits and merges. Involving 2 siblings in redistribution results in each node having at least \(\lfloor 2n/3 \rfloor\) entries.</p> <p>Record relocation and secondary indices - If a record moves, all secondary indices that store record pointers have to be updated. Therefore, node splits in \(B^+\) tree file organisation become very expensive. The solution to this is use a search key of the \(B^+\) tree file organisation instead o record pointer in a secondary index. For example, consider students database sorted using roll numbers with names as a secondary index. If the records move, we would need to update all the “name” index pointers. So what we do is, make the “name” index pointers point to the “roll number” index pointers instead of the records directly. Since “roll number” is a clustered index, no relocation of secondary indices is required.</p> <h3 id="indexing-strings">Indexing Strings</h3> <p>How do we use variable length strings as keys? We use <strong>prefix compression</strong> along with variable fanout (?). In the internal nodes, we can use simplified separators.</p> <h2 id="bulk-loading-and-bottom-up-build">Bulk Loading and Bottom-Up Build</h2> <p>Inserting entries one-at-a-time into a \(B^+\)-tree requires \(\geq\) 1 I/O per entry assuming leaves don’t fit in the memory.</p> <ul> <li>Sort entries first, and insert in a sorted order. This will have much improved I/O performance.</li> <li>Build a \(B^+\)tree <strong>bottom-up</strong>. AS before sort the entries, and then create tree layer-by-layer starting with the leaf level.</li> </ul> <p>However, the above two methods expect a bulk insertion. What do we do if we have a sudden burst of inserts? We will look at alternatives later.</p> <h3 id="b-tree-index-files">B-Tree Index Files</h3> <p>Similar to \(B^+\)-tree but B-tree allows search-key values to appear only once and eliminates redundant storage of search keys. The pointers to the records are stored in the internal nodes too! The problem with this approach is that the tree becomes taller. There is minimal advantage too.</p> <p>Indexing on flash has a few issues, as writes are no in-place and it eventually requires a more expensive erase.</p> <p>A key idea is to use large node size to optimise disk access, but structure data within a node using a tree with small node size, instead of using an array for faster cache access (so that all nodes fit inside a single cache line).</p> <h2 id="hashing">Hashing</h2> <h3 id="handling-bucket-overflows">Handling bucket overflows</h3> <p><strong>Overflow chaining</strong> - The overflow buckets of a given bucket are chained together in a linked list. The above scheme is called <strong>closed addressing</strong> or <strong>open/closed hashing</strong>.</p> <p>Overflow can happen due to insufficient buckets or skewness in the data.</p> <p>Hashing is not used widely on disks but is used in-memory.</p> <p><strong>Covering indices</strong> - Attributes that are added to index to prevent the control from fetching the entire record.</p> <p>Some databases allow creation of indices on foreign keys.</p> <p>Indices over tuples can be problematic for a few queries due to lexicographic ordering.</p> <h1 id="lecture-27">Lecture 27</h1> <blockquote> <p><code class="language-plaintext highlighter-rouge">15-03-22</code></p> </blockquote> <h2 id="write-optimised-indices">Write Optimised Indices</h2> <p>Performance of \(B^+\) trees can be poor for write intensive workloads. This is because we require one I/O per leaf, assuming all internal nodes are in memory. There are two approaches to reducing cost of writes</p> <ul> <li>Log-structured merge tree</li> <li>Buffer tree</li> </ul> <h3 id="log-structured-merge-lsm-tree">Log Structured Merge (LSM) Tree</h3> <p>Consider only insert queries for now. Records are first inserted into in-memory L0 tree. When the in-memory tree is full, we move the records to the disk in the L1 tree. \(B^+\)-tree is constructed using bottom-up by merging the existing L1 tree with records from L0 tree. The goal is to minimise random I/O.</p> <p>The benefits are that inserts are done using sequential I/O operations and the leaves are full avoiding space wastage. The drawbacks are that queries have to search multiple trees and the entire context of each level is copied multiple times. <strong>Bloom filters</strong> avoid lookups in most trees. The idea is to use hash functions and bitmaps.</p> <p>How about deletes? They will now incur a lot of I/O. We do a logical delete by inserting a new delete entry. Updates are handled as inserts followed by deletes.</p> <p>LSM trees were introduced for disk-based indices. These are useful to minimise erases with flash-based indices.</p> <h3 id="buffer-tree">Buffer Tree</h3> <p>Each internal node of \(B^+\)-tree has a buffer to store inserts. The inserts are moved to lower levels when the buffer is full. With a large buffer, many records are moved to lower level at each time. Therefore, per record I/O decreases.</p> <p>The benefits are less overhead on queries, and it can be used with any tree index structure. However, they have more random I/O than LSM trees.</p> <h2 id="spatial-and-temporal-indices">Spatial and Temporal Indices</h2> <p>A <strong>k-d tree</strong> is a structure used for indexing multiple dimensions. Each level of k-d tree partitions the space into two, and we cycle through the dimensions at each level. Range queries do not have \(\log\) complexity bounds in this index structure.</p> <p>Queries can mix spatial (contains, overlaps) and non-spatial conditions.</p> <p>The <strong>k-d-B</strong> tree extends the k-d tree to allow multiple child nodes for each internal node. This is well suited for secondary storage.</p> <p>Each node in a <strong>quadtree</strong> is associated with a rectangular region of space. Similarly, we can cut across more dimensions in each level.</p> <h3 id="r-tree">R-tree</h3> <p>The motivation behind this structure was to store objects in the spatial domain in a single leaf. We try to create minimally overlapping bounding boxes for all the objects and create a structure similar to a \(B^+\)-tree. Multiple paths may need to be searched, but the performance is good in practice.</p> <p>Suppose we want to insert a new object that overlaps with many bounding boxes. We choose the box which overlaps the least, or the box which has the lowest change in size on the addition. Now, insertion is done via the <strong>clustering algorithm</strong>. The clustering is also done via some heuristics such as minimum overlap of bounding boxes. Greedy heuristics are often used.</p> <h1 id="lecture-28">Lecture 28</h1> <blockquote> <p><code class="language-plaintext highlighter-rouge">17-03-22</code></p> </blockquote> <h3 id="indexing-temporal-data">Indexing Temporal Data</h3> <p>A time interval has a start and an end time. A query may ask for all tuples that are valid at a point in time or during a time interval. We can use a spatial index called an <strong>R-tree</strong> for indexing.</p> <h1 id="chapter-15-query-processing">~Chapter 15: Query Processing</h1> <p>Database engines often apply optimisations based on statistics over data which are approximate. An annotated expression specifying a detailed execution strategy is called an <strong>evaluation plan</strong>.</p> <p><strong>Query optimisation</strong> chooses an evaluation plan with the lowest cost (a metric based on approximated statistics).</p> <h2 id="measures-of-query-cost">Measures of Query Cost</h2> <p>Many factors contribute to time cost such as disk access, CPU, and network communication. Cost can be measured on <strong>response time</strong> or <strong>total resource consumption</strong>. As estimating the time is more difficult, we often resort to resource consumption for optimisation. This metric is also useful is shared databases. For our purposes, we will just consider costs related to I/O time.</p> <p>Now, the disk cost is estimated as the sum of average seeks, blocks read, and blocks written. For simplicity we just use the <strong>number of block transfers from disk</strong> and the <strong>number of seeks</strong>. Then, we get \(b \times t_T + S\times t_S\). On a high end magnetic disk, \(t_S = 4ms, t_T = 0.1ms\) and on a SSD, \(t_S = 20-90\mu s, t_T = 2-10 \mu s\) for 4KB blocks.</p> <p>We assume no data is available in the buffer.</p> <h2 id="selection-operation">Selection Operation</h2> <p><code class="language-plaintext highlighter-rouge">A1</code>- <strong>Linear Search</strong> - Assume that file is stored sequentially.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cost = b/2*t_T + 1*t_S
</code></pre></div></div> <p>We do not consider binary search as it requires a lot more (random) accesses and access time is high in disks.</p> <h3 id="selection-using-indices">Selection using Indices</h3> <p><code class="language-plaintext highlighter-rouge">A2</code> - <strong>Clustering index, Equality on key</strong> - Retrieve a single record that satisfied the corresponding equality condition.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cost = (h_i + 1)*(t_T + t_S)
</code></pre></div></div> <p>Here, <code class="language-plaintext highlighter-rouge">h_i</code> is the height of the index (in \(B^+\)-tree?), and since we are doing random I/O for each case, we need to add both seek and transfer time.</p> <p><code class="language-plaintext highlighter-rouge">A3</code>-<strong>Clustering index, equality on non-key</strong> - Retrieve multiple records. Records will be on consecutive blocks. Let \(b\) be the number of blocks containing matching records.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cost = h_i*(t_T + t_S) + t_S + t_T*b
</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">A4</code>-<strong>Secondary index, equality on key/non-key</strong></p> <p>If the search-key is a candidate key, then</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cost = (h_i + 1)*(t_T + t_S)
</code></pre></div></div> <blockquote> <p>Why?</p> </blockquote> <p>Otherwise, each of <code class="language-plaintext highlighter-rouge">n</code> matching records may b on a different block</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cost = (h_i + n)*(t_T + t_S)
</code></pre></div></div> <p>It might be cheaper to scan the whole relation as sequential access is easier than random I/O.</p> <p><code class="language-plaintext highlighter-rouge">A5</code>-<strong>Clustering index, comparison</strong></p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cost = linear_cost for &lt;
		 = index_equality_cost + linear_cost
</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">A6</code>-<strong>Non-clustering index, comparison</strong></p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cost = cost + cost_records (I/O)
</code></pre></div></div> <p>The difference between clustering and non-clustering indices is that we would have to fetch records in case of non-clustering indices in order to read the non-clustering index attribute. This is not the case in case of a clustering index.</p> <p>Let me write my understanding of all this</p> <blockquote> <p>Indices are just files with pointers. Basically, scanning through indices is faster than scanning through a sequence of entire records, so we use indices. Instead of storing indices sequentially, we use \(B^+\) trees so that its faster. We can’t do this with records directly because records are big and they may not reside in a single file (I think).</p> <p>Now, clustering indices are indices whose order is same as the order of the records. So, once we fetch a record for an index, all records corresponding to the next indices will be in a sequence. Therefore, we won’t have additional seek time.</p> <p>However, this is not the case for non-clustering indices. If we want records corresponding to the next indices of the current index, we’d have additional seek time as the records may lie in different blocks.</p> </blockquote> <h3 id="implementation-of-complex-selections">Implementation of Complex Selections</h3> <p>How do we implement conjunctions? If all the attributes in the conjunction are indexed, then it is straightforward. We will just take the intersection of all results. Otherwise, test all the other conditions after fetching the records into the memory buffer.</p> <p>Also, as we discussed before, we can use a composite index.</p> <p>Disjunctions are a slightly different. If we have all indexed attributes, we just take the union. Otherwise, we just have to do a linear scan. Linear scan is also the best way in most cases for negation.</p> <h2 id="bitmap-index-scan">Bitmap Index Scan</h2> <p>We have seen that index scans are useful when less number of records match in the case of secondary indices. If more records match, we should prefer a linear scan. How do we decide the method beforehand? The <strong>bitmap index scan</strong> algorithm is used in PostgreSQL.</p> <p>We create a bitmap in memory with a bit for each page in the relation. A record ID is just the page ID and the entry number. We initially do an index scan to find the relevant pages, and mark these pages as 1 in the bitmap. After doing this, we just do a linear scan fetching only pages with bit set to 1.</p> <p>How is the performance better? It is same as index scan when only a few bits are set, and it is same as a linear scan when most bits are set. Random I/O is avoided in both cases.</p> <h2 id="sorting">Sorting</h2> <p>For relations that fit in memory, we can use quicksort. Otherwise, we use <strong>external sort merge</strong>.</p> <p><img src="/assets/img/Databases/image-20220407235807034.png" alt="image-20220407235807034"/></p> <p><img src="/assets/img/Databases/image-20220407235757873.png" alt="image-20220407235757873"/></p> <h1 id="lecture-29">Lecture 29</h1> <blockquote> <p><code class="language-plaintext highlighter-rouge">21-03-22</code></p> </blockquote> <h2 id="join-operation">Join Operation</h2> <h3 id="nested-loop-join">Nested Loop Join</h3> <p>Requires no indices and can be used with any kind of join condition. It is very expensive though, as it is quadratic in nature. Most joins can be done in linear time in one of the relations, as most joins are foreign key joins. In the worst case, there would memory enough to hold only one block of each relation. The estimated cost then is, <code class="language-plaintext highlighter-rouge">n_r*b_s + b_r</code> block transfers and <code class="language-plaintext highlighter-rouge">n_r + b_r</code> seeks.</p> <h3 id="block-nested-loop-join">Block Nested-Loop Join</h3> <p>We first do block matching and then tuple matching. Asymptotically, this looks same as the above method but it decreases the I/O cost as the number of seeks come down.</p> <h3 id="indexed-nested-loop-join">Indexed Nested-Loop Join</h3> <p>An index is useful in equi-join or natural join. For each tuple \(t_r\) in the outer relation \(r\), we use the index to look up tuples in \(s\) satisfy the join condition with tuple \(t_r\). In the worst case, the buffer has space for only one page of \(r\), and for each tuple in \(r\), we perform an index lookup on \(s\). Therefore, the cost of the join is <code class="language-plaintext highlighter-rouge">b_r(t_T + t_S) + n_r*C</code>, where \(c\) is the cost of traversing index and fetching all matching \(s\) tuples for one tuple of \(r\). The second term is the dominating term. We should use the fewer tuples relations as the outer relation.</p> <h3 id="merge-join">Merge Join</h3> <p>Sort both relations on their join attribute, and merge the sorted relations. Cost is <code class="language-plaintext highlighter-rouge">(b_r + b_s)*t_T + (ceil(b_r/b_b) + ceil(b_S/b_b))*t_S</code> along with the cost of sorting.</p> <p><strong>Hybrid merge-join</strong> - If one relation is sorted, an the other has a secondary \(B^+\)-tree on the join attribute, then we can merge the sorted relation with the leaf entries of the \(B^+\)-tree. Then we sort the result on the addresses of the unsorted relation’s tuples. Finally, we scan the unsorted relation in physical address order and merge with the previous result, to replace addresses by actual tuples.</p> <h3 id="hash-join">Hash Join</h3> <p>The goal in the previous methods was to simplify the relations so that they fit in the memory. Along with this, we can also parallelise our tasks.</p> <p>In this method, we hash on the join attributes and then merge each of the partitions. It is applicable for equi-joins and natural joins.</p> <p><img src="/assets/img/Databases/image-20220408003107650.png" alt="image-20220408003107650"/></p> <p>The value \(n\) and the hash function \(h\) are chosen such that each \(s_i\) fits in the memory. Typically, \(n\) is chosen as \(\lceil b_s/M \rceil *f\) where \(f\) is a <strong>fudge factor</strong>. The probe relation need not fit in memory. We use <strong>recursive partitioning</strong> if number of partitions is greater than number of pages in the memory.</p> <p><strong>Overflow resolution</strong> can be done in the build phase. Partition \(s_i\) is further partitioned using a different hash function. <strong>Overflow avoidance</strong> performs partitioning carefully to avoid overflows during the build phase. Both methods fail with a high number of duplicates.</p> <p>Cost of hash join is <code class="language-plaintext highlighter-rouge">(3(b_r + b_s) + 4n_h)*t_T + 2t_T(ceil(b_r/b_b) + ceil(b_s/b_b))</code>. Recursive partitioning adds a factor of \(\log_{\lfloor M/bb\rfloor - 1}(b_s/M)\). If the entire build can be kept in the memory, then no partitioning is required and cost estimate goes down to \(b_r + b_s\).</p> <p>Can we not build an entire index on \(s\) instead of hash join? Building an on-disk index is very expensive on disk. Indices have to be maintained which is an overhead.</p> <p><strong>Hybrid Hash-join</strong> keeps the first partition of the build relation in memory. This method is most useful when \(M \gg \sqrt b_s\).</p> <h3 id="complex-joins">Complex Joins</h3> <p>Similar methods to that of selection can be used here. That is conjunction of \(n\) conditions requires intersections of the result of \(n\) joins. In disjunction, we take the union of the join results. This method works for sets but not for multi-sets! For multi-sets, we can make sets out of the records.</p> <h3 id="joins-on-spatial-data">Joins on Spatial Data</h3> <p>There is no simple sort order for spatial joins. Indexed nested loops join with spatial indices such as R-trees, quad-trees and k-d-B-trees. Nearest neighbour joins can be done with tiling.</p> <h2 id="other-operations">Other operations</h2> <p><strong>Duplicate elimination</strong> can be implemented via hashing or sorting. An optimisation is to delete duplicates during run generation as well as at intermediate merge steps. <strong>Projection</strong> can be done by performing projection on each tuple. <strong>Aggregation</strong> can implemented similar to duplicate elimination. Sorting and hashing can be used to bring tuples in the same group together, and then the aggregate functions can be applied on each group.</p> <h1 id="lecture-30">Lecture 30</h1> <blockquote> <p><code class="language-plaintext highlighter-rouge">22-03-22</code></p> </blockquote> <h2 id="set-operations-1">Set Operations</h2> <p>These are fairly straightforward using merge-join after sorting or hash-join.</p> <h2 id="outer-join-1">Outer Join</h2> <p>During merging, for every tuple \(t_r\) from \(r\) that do not match any tuple in \(s\), output \(t_r\) padded with nulls.</p> <h2 id="evaluation-of-expressions">Evaluation of Expressions</h2> <p>We have two method to evaluate an entire expression tree</p> <ul> <li><strong>Materialisation</strong> - Generate results of an expression whose inputs are relations or are already computed, materialize (store) it on disk</li> <li><strong>Pipelining</strong> - Pass on tuples to parent operations even as an operation is being executed</li> </ul> <h3 id="materialisation">Materialisation</h3> <p>We evaluate one operation at a time, and store each temporary result on the disk. this method is always applicable, but the cost is high. The overall cost is the sum of costs of individual operations and the cost of writing intermediate results to the disk.</p> <p><strong>Double buffering</strong> - Use two output buffers for each operation, when one is full write it to disk while the other is getting filled.</p> <h3 id="pipelining">Pipelining</h3> <p>We evaluate several operations simultaneously, passing the results of one operation on to the next. However, this is not always possible in case of aggregation, sorts and hash-joins. It is executed in two ways -</p> <ul> <li><strong>Demand driven</strong> - In lazy evaluation, the system repeatedly requests next tuple from the top level operation. The operation has to maintain states. Pull model.</li> <li><strong>Producer driven</strong> - In eager pipelining the operators produce tuples eagerly and pass them up to their parents. Push model.</li> </ul> <h2 id="blocking-operations">Blocking Operations</h2> <p>They cannot generate any output until all the input is consumed. For example, sorting, aggregation, etc. They often have two sub-operations, and we can treat them as separate operations. All operations in a <strong>pipeline</strong> stage run concurrently.</p> <h2 id="query-processing-in-memory">Query Processing in Memory</h2> <p>In early days, memory was the bottleneck. So, engineers had to reduce the I/O. Query was compiled to machine code, and compilation usually avoids many overheads of interpretations to speed up query processing. This was often done via generation of Java byte code with JIT compilation. Column oriented storage was preferred as it allowed vector operations, and cache conscious algorithms were used.</p> <h1 id="lecture-31">Lecture 31</h1> <blockquote> <p><code class="language-plaintext highlighter-rouge">24-03-22</code></p> </blockquote> <h3 id="cache-conscious-algorithms">Cache conscious algorithms</h3> <p>The goal is to minimise the cache misses.</p> <ul> <li><strong>Sorting</strong> - We can use runs that are as large as L3 cache to avoid cache misses during sorting of a run. Then merge runs as usual in merge sort.</li> <li><strong>Hash-join</strong> - We first create partitions such that build + probe partitions fit in memory. Then, we sub partition further such that sub partition and index fit in L3 cache. This speeds up probe phase.</li> <li>Lay out attributes of tuples to maximise cache usage. Store often accessed attributes adjacent to each other.</li> <li>Use multiple threads for parallel query processing. Cache miss leads to stall of one thread, but others can proceed.</li> </ul> <h1 id="chapter-16-query-optimisation">~Chapter 16: Query Optimisation</h1> <p>As we have seen before, there are multiple ways to evaluate a given query. The cost difference can be magnanimous in some cases. A plan is evaluated on cost formulae, statistical information and statistical estimation of intermediate results. Most databases support <code class="language-plaintext highlighter-rouge">explain &lt;query&gt;</code> that gives the details of the evaluation plan.</p> <h2 id="generating-equivalent-expressions">Generating Equivalent Expressions</h2> <p>Two queries are equivalent in the (multi)set version if both of them generate the same (multi)set of tuples on <strong>every legal database instance</strong>. Note that we ignore the order of tuples in relational algebra.</p> <ul> <li> <p>Conjunctive selection operations can be deconstructed into a sequence of individual selections</p> \[\sigma_{\theta_1 \land \theta_2}(E) \equiv \sigma_{\theta_1} (\sigma_{\theta_2}(E))\] </li> <li> <p>Selection operations are commutative</p> \[\sigma_{\theta_1} (\sigma_{\theta_2}(E)) \equiv \sigma_{\theta_2} (\sigma_{\theta_1}(E))\] </li> <li> <p>Only the last in a sequence of project operations is needed, the others can be omitted.</p> \[\Pi_{L_1}(\dots(\Pi_{L_n}(E))\dots) \equiv \Pi_{L_1}(E)\] </li> <li> <p>Selections can be combined with Cartesian products and theta joins.</p> \[\begin{align} \sigma_{\theta}(E_1 \times E_2) &amp;\equiv E_1 \bowtie_\theta E_2 \\ \sigma_{\theta_1}(E_1 \bowtie_{\theta_2} E_2) &amp; \equiv E_1 \bowtie_{\theta_1 \land \theta_2} E_2 \end{align}\] </li> <li> <p><strong>Theta-join and natural joins</strong> operations are <u>commutative</u> as well as <u>associative</u>. However, order will not be the same in SQL.</p> <p>sc \((E_1 \bowtie_{\theta_1} E_2)\bowtie_{\theta_2 \land \theta_3} E_3 \equiv(E_1 \bowtie_{\theta_1 \land \theta_3} E_2)\bowtie_{\theta_2 } E_3\)</p> <p>where \(\theta_2\) contains attributes only from \(E_2\) and \(E_3\).</p> </li> <li> \[\sigma_{\theta_1 \land \theta_2} (E_1 \bowtie_\theta E_2) \equiv (\sigma_{\theta_1}(E_1)) \bowtie_\theta (\sigma_{\theta_2}(E_2))\] </li> <li> <p>Projection distributes over join. Throw out useless attributes before joining.</p> <p><img src="/assets/img/Databases/image-20220416151913983.png" alt="image-20220416151913983"/></p> </li> <li> <p>We also have the usual set operations equivalences. Selection operation distributes over \(\cup, \cap, -\).</p> </li> <li> <p>We can also come up with rules involving left outer join (⟖), aggregations and group by’s.</p> \[\sigma_\theta(E_1 ⟕ E_2) \equiv (\sigma_\theta(E_1) ⟕ E_2)\] <p>where \(\theta\) does not involve attributes from \(E_2\) that are not in \(E_1\). If it involves only the attributes from \(E_2\) and is <u>null rejecting</u>, we can convert the left outer join to inner join.</p> </li> <li></li> <li> \[_A\gamma_{count(A)}(s_1 \bowtie_{s_1.A = s_2.A}s_2) \equiv \Pi_{A, c_1 \times c_2}(_A\gamma_{count(A)}(s_1) \bowtie_{s_1.A = s_2.A} {_A}\gamma_{count(A)}(s_2))\] </li> <li> \[\sigma_\theta({_A}\gamma_{agg(B)}(E)) \equiv {_A}\gamma_{agg(B)}(\sigma_\theta(E))\] <p>where \(\theta\) uses only attributes from the grouping attributes.</p> </li> </ul> <p>There were 300 rules in SQL server in 2008!</p> <h1 id="lecture-32">Lecture 32</h1> <blockquote> <p><code class="language-plaintext highlighter-rouge">28-03-22</code></p> </blockquote> <p>Note that left/right outer join is not commutative! An optimiser has to consider the cost not just the size. Sometimes, more tuples might be faster due to indices. Associativity is some times helpful in join when the join result of, say, \(r2, r3\) is much larger than that of \(r1, r2\). In that case, we compute the smaller join first. One must also beware about the overhead of applying all these transformations.</p> <p>There are other optimisations such as detecting duplicate sub-expressions and replacing them by one copy. Dynamic Programming is also put to use. The algorithms for transformation of evaluation plans must also be taken into account. Practical query optimisers either enumerate all plans and choose the best plan using cost, or they use heuristics to choose a plan.</p> <h3 id="cost-based-optimisation">Cost based optimisation</h3> <p>If we have \(r_1 \bowtie \dots \bowtie r_n\), we have \((2(n - 1))!/(n - 1)!\). We use dynamic programming to store the least-cost join order. Using dynamic programming, we are bringing down factorial order to an exponential order \(3^n\). The cost of each join is evaluated by interchanging selection and join operations based on indices. Further optimisation is done by only considering <strong>left-deep join trees</strong> where the rhs of a join is a relation and not an intermediate join. After this, the time complexity is \(\mathcal O(n2^n)\) and space complexity is \(\mathcal O(2^n)\).</p> <p>How about sort orders? Certain sort orders can make subsequent operations cheaper. However, we don’t consider this much. The Volcano project also considers physical equivalence rules.</p> <h3 id="heuristic-optimisation">Heuristic Optimisation</h3> <p>Heuristic optimisation transforms the query-tree by using a set of rules that typically improve execution performance. Nested subqueries hinder optimisation techniques.</p> <p>System-R used heuristics for aggregates. We also need to check <u>optimisation cost budget</u> and <u>plan caching</u>. As some applications use the same query repeatedly, we can try and use the same evaluation plan based on a heuristic on statistics.</p> <h2 id="statistics-for-cost-estimation">Statistics for Cost Estimation</h2> <p>We consider \(n_r\) (no. of tuples), \(b_r\) (no. of blocks), \(I_r\) (size of a tuple), \(f_r\) (blocking factor \(b_r = \lceil n_r/f_r\rceil\)) and \(V(A, r)\) (no. of distinct values). Histograms are used to compute statistics.</p> <h1 id="lecture-33">Lecture 33</h1> <blockquote> <p><code class="language-plaintext highlighter-rouge">29-03-22</code></p> </blockquote> <h3 id="selection-size-estimation">Selection size estimation</h3> <ul> <li> \[\sigma_{A = v}(r) \approx n_r/V(A, r)\] </li> <li>Assuming, \(\min\) and \(\max\) are available - \(\sigma_{A \leq v}(r) = \begin{cases} 0 &amp;&amp; v &lt; \min(A, r) \\ n_r \cdot \frac{v - \min(A, r)}{\max(A, r) - \min{A, r}} \end{cases}\)</li> </ul> <p>These estimates are refined using updates in the histograms. Similarly, we can derive size estimates for complex selections.</p> <h3 id="join-size-estimation">Join size estimation</h3> <ul> <li>If \(R \cap S = \phi\), then \(r \bowtie s = r \times s\).</li> <li>If \(R \cap S\) is a key in \(R\), then a tuple of \(s\) will join with at most one tuples from \(r\) -&gt; \(r \bowtie s \leq s\).</li> <li>If \(R \cap S\) in \(S\) is a foreign key in \(S\) referencing \(R\), then \(r \bowtie s = s\).</li> <li>If the common attribute is not a key, then the size is \((n_r*n_s)/V(A, s)\) if every tuple in \(R\) produces a tuple in the join.</li> </ul> <p>Similarly, we have other size estimations.</p> <p>For projection, we have \(\Pi_A(r) = V(A, r)\), and for aggregation we have \({_G}\gamma_A(r) = V(G, r)\). There are estimates for set operations too!</p> <p>In summary, these estimates work well in practice, but the errors are multiplied across multiple queries. In worst cases, they might hamper the performance.</p> <h2 id="additional-optimisations">Additional Optimisations</h2> <h3 id="optimising-nested-subqueries">Optimising Nested Subqueries</h3> <p>SQL treats the nested subquery as a function with a few parameters - This evaluation is known as <strong>correlated evaluation</strong>. The parameters to the function are known as <strong>correlation variables</strong>. This method is inefficient because a large number of call may be made for the nested query that results in unnecessary random I/O.</p> <p>However, every nested subquery in SQL can be written in terms of joins. SQL optimisers try to do this. One must be beware of duplicates during this conversion. The (left)<strong>semijoin</strong> operator ⋉ is defined as - A tuple \(r_i\) appears \(n\) times in \(r ⋉_\theta s\) if it appears \(n\) times in \(r\), and there is atleast on matching tuple \(s_i\) in \(s\). This operator is often used by optimisers to maintain the duplicate count. Similarly, for <code class="language-plaintext highlighter-rouge">not exists</code>, we have <strong>anti semijoin</strong> \(\bar ⋉\).</p> <p><strong>Decorrelation</strong> is the process of replacing a nested query by a query with a join/semi-join. This process is a bit non-trivial in case of scalar subqueries. Note that relational algebra can’t deal with exceptions.</p> <h3 id="materialised-views">Materialised views</h3> <p>The values of the view are computed and stored. The re-computation during updates is expensive. Therefore, we adopt <u>incremental view maintenance</u>. The changes to a relation or expressions are referred to as its <strong>differential</strong>.</p> <p>To explain the above, consider a materialised view of a join. For a new insert, we find the corresponding matching tuples for join and add them. Similarly for deletes. We can do this due to distributivity of \(\bowtie\) and \(\cup\).</p> <p>Project is a more difficult operation due to duplicates. Therefore, we maintain a count for how many times the set of attributes occur. Aggregates can also be done in a similar way.</p> <p>To handle expressions, the optimiser might have to change the evaluation plan. For example, the tree structure in join order may not be efficient if indices are present during insertions.</p> <h1 id="lecture-34">Lecture 34</h1> <blockquote> <p><code class="language-plaintext highlighter-rouge">28-03-22</code></p> </blockquote> <p>We had discussed about view maintenance, but how do we use materialised views? A query optimiser can replace sub-expressions with appropriate views if the user writes the queries only in terms of relations. Sometimes, the opposite can also be useful.</p> <p>Materialised view selection and index selection are done based on typical system <strong>workload</strong>. Commercial database systems provide <u>tuning</u> tools that automate this process.</p> <h3 id="top-k-queries">Top-K queries</h3> <p>The query optimiser should consider that only the top-k results are required from a huge relation. This can be done via indexed nested loops join with the relation that is being used for sorting as the outer relation. There are other alternatives too.</p> <h3 id="multi-query-optimisation">Multi-query Optimisation</h3> <p>Multiple queries with common sub-routines can be done in parallel.</p> <h3 id="parametric-query-optimisation">Parametric Query Optimisation</h3> <p>The evaluation plan can change based on the input parameters to the queries. To optimise this, we divide the range of the parameter into different partitions and choose a good evaluation plan for each partition.</p> <h1 id="chapter-17-transactions">~Chapter 17: Transactions</h1> <p>A <strong>transaction</strong> is a <em>unit</em> of program execution. It access and possible updates various data items. It also guarantees some well-defined robustness properties. To discuss transactions, we move to a level below queries where each <em>atomic</em> instruction is performed. We need to ensure correctness during failures and concurrency.</p> <p>In OS, we have seen that mutexes are used for concurrency. However, we need a higher level of concurrency in databases.</p> <p><strong>ACID guarantees</strong> refer to Atomicity (Failures), Consistency (Correctness), Isolation (Concurrency) and Durability (Failures). There is a notion of <u>consistent state</u> and <u>consistent transaction</u>. Durability refers to persistence in case of failures. Atomicity refers to all-or-nothing for each update. Partial updates are reversed using logs. Two concurrent transactions must execute as if they are unaware of the other in isolation. In conclusion, ACID transactions are a general systems abstraction.</p> <p>Concurrency increases processor and disk utilisation. It also reduces the average response time. Isolated refers to concurrently executing actions but showing as if they were occurring serially/sequentially.</p> <h2 id="serialisability">Serialisability</h2> <p>A schedule is <strong>serialisable</strong> if it is equivalent to a serial schedule. We are assuming that transactions that are run in isolation are atomic, durable and preserve consistency.</p> <p><strong>Conflict serialisable</strong> schedules are a subset of serialisable schedules that detect or prevent conflict and avoid any ill effects. To understand these, we will consider <code class="language-plaintext highlighter-rouge">read</code>s and <code class="language-plaintext highlighter-rouge">write</code>s.</p> <p><strong>Conflicting instructions</strong> - Instructions form two transactions <strong>conflict</strong> only if one or both <em>update</em> the <em>same shared</em> item. For example, <code class="language-plaintext highlighter-rouge">write A</code> in T1 conflicts with <code class="language-plaintext highlighter-rouge">read A</code> in T2. These are similar to RAW, WAW, etc conflicts seen in Architecture course.</p> <p>We can swap the schedules of non-conflicting schedules and obtain a serial schedule. Such schedules are conflict serialisable. Conflict equivalence refers to the equivalence between the intermediate schedules obtained while swapping. More formally,</p> <p><img src="/assets/img/Databases/image-20220416193446900.png" alt="image-20220416193446900"/></p> <p>We are skipping <strong>view equivalence</strong>. There are other notions of serialisability (considering a group of operations).</p> <h3 id="testing-for-conflict-serialisability">Testing for Conflict Serialisability</h3> <p>A <strong>precedence graph</strong> is a directed graph where vertices are transaction IDs and edges represent conflicting instructions with arrows showing the temporal order. Then, we can perform topological sorting to check for serialisability. A schedule is serialisability iff its precedence graph is acyclic.</p> <h1 id="lecture-35">Lecture 35</h1> <blockquote> <p><code class="language-plaintext highlighter-rouge">04-04-22</code></p> </blockquote> <p>We shall discuss a series of concepts in isolation now.</p> <h3 id="recoverable-schedules">Recoverable Schedules</h3> <p>If a transaction \(T_i\) reads a data item previously written by a transaction \(T_j\), then the commit operation of \(T_j\) appears before the commit operation of \(T_i\). These schedules are recoverable.</p> <h3 id="cascading-rollbacks">Cascading rollbacks</h3> <p>A single transaction failure leads to a series of transaction rollbacks. That is, uncommitted transactions must be rolled back.</p> <h3 id="cascadeless-schedules">Cascadeless Schedules</h3> <p>Cascading rollbacks cannot occur in these schedules. For each pair of transactions \(T_i\) and \(T_j\) such that \(T_j\) reads a data item previously written by \(T_i\), the commit operation \(T_i\) appears before the read operation of \(T_j\). That is, they allow reading of committed values only and disallow <em>dirty reads</em>. Every cascadeless schedule is recoverable.</p> <h3 id="weak-levels-of-isolation">Weak levels of Isolation</h3> <p>Some applications can tolerate schedules that are not serialisable. For example, in statistics we only want approximations. Ideally, we’d like serialisable, recoverable and preferably cascadable.</p> <p>There are levels of isolation defined in SQL-92 like - read committed, read uncommitted, repeatable read, and serialisable. Most often, databases run in read committed mode.</p> <h3 id="concurrency-control-mechanisms">Concurrency Control Mechanisms</h3> <p>We have a ton of theory for implementing whatever we have discussed. There are locking schemes, timestamp schemes, optimistic/lazy schemes and multi-versions (similar to master-slave mechanism in parallel cores of architecture).</p> <h2 id="transactions-in-sql">Transactions in SQL</h2> <p>We have predicate operations in SQL. A tuple might fail a predicate before a transaction, but passes it after the transaction has completed. Some databases lock the matched tuples for consistency, but that does not always work. That is, we need “predicate locking”, not just key-based locks that locks all <em>possible</em> matching tuples. Phantom reads refer to not matching tuples that are just added.</p> <p>In SQL, a transaction begins implicitly. <strong>commit work</strong> commits current transaction and begins a new one. <strong>rollback work</strong> causes current transaction to abort. Isolation levels can be set at database level or at the start of a transaction.</p> <h1 id="chapter-18-concurrency-control">~Chapter 18: Concurrency Control</h1> <h2 id="lock-based-protocols">Lock based protocols</h2> <p>A lock is a mechanism to control concurrent access to a data item. Items can be locked in two modes</p> <ul> <li><strong>exclusive</strong> (X) mode - Data item can be both read as well as written. <code class="language-plaintext highlighter-rouge">lock-X</code></li> <li><strong>shared</strong> (S) mode - Data item can only be read. <code class="language-plaintext highlighter-rouge">lock-S</code></li> </ul> <p>These requests are made implicitly using a concurrency control manager. Not that X lock can’t be obtained when a S lock is held on an item.</p> <p>A <strong>locking protocol</strong> is a set of rules followed by all transactions while requesting and releasing locks. They enforce serialisability by restricting the set of possible schedules. To handle <strong>deadlocks</strong>, we need to roll back some transactions. <strong>Starvation</strong> is also possible if concurrency control manager is badly designed. This occurs because X-locks can’t be granted when S-lock is being used.</p> <h3 id="two-phase-locking-protocol">Two-Phase Locking Protocol</h3> <p>This protocol ensures conflict-serialisable schedules. We have two phases</p> <ul> <li>Phase 1: Growing phase. A transaction can obtain locks but not release them</li> <li>Phase 2: Shrinking phase. It’s the opposite of the above.</li> </ul> <p>The transactions can be serialised in the order of their lock points (the point where a transaction has acquired its final lock). However, this protocol does not ensure protection from deadlocks. It also does not ensure recoverability. There are extensions that ensure recoverability from cascading roll-back.</p> <ul> <li><strong>Strict two-phase locking</strong> - A transaction must hold all its exclusive locks till it commits/aborts.</li> <li><strong>Rigorous two-phase locking</strong> - A transaction must hold all locks till commit/abort.</li> </ul> <p>We mostly use the second protocol.</p> <p>Two-phase locking is not necessary condition for serialisability. That is, there are conflict serialisable schedules that cannot be obtained if the two-phase locking protocol is used.</p> <p>Given a locking protocol, a schedule \(S\) is <strong>legal</strong> under a locking protocol if it can be generated by a set of transactions that follow the protocol. A protocol <strong>ensures</strong> serialisability if all legal schedules under that protocol are serialisable.</p> <p>In the two-phase locking protocol. we can upgrade (S to X) in the growing phase and downgrade (X to S) in the shrinking phase.</p> <h1 id="lecture-36">Lecture 36</h1> <blockquote> <p><code class="language-plaintext highlighter-rouge">05-04-22</code></p> </blockquote> <h2 id="implementation-of-locking">Implementation of Locking</h2> <p>A <strong>lock manager</strong> can be implemented as a separate process. The lock manager maintains an in-memory data-structure called a <strong>lock table</strong> to record granted locks and pending requests. A lock table is implemented as a hash table with queues.</p> <h2 id="graph-based-protocols">Graph-Based Protocols</h2> <p>They impose a partial ordering \(\to\) on the set \(D = \{d_1, \dots, d_n\}\) of all the data items. If \(d_i \to d_j\), then any transaction accessing both \(f_i\) and \(f_j\) must access \(d_i\) before accessing \(d_j\).</p> <p>A tree protocol ensures conflict serialisability as well as freedom from deadlock. However, it does not guarantee recoverability and it has other issues.</p> <h2 id="deadlocks">Deadlocks</h2> <p>There are other deadlock prevention strategies like</p> <ul> <li><strong>wait-die</strong> - non-preemptive. Older transaction may wait for younger one to release the data item, and the younger transaction never wait for older ones. They are rolled back instead.</li> <li><strong>wound-wait</strong> - preemptive. Older transaction <em>wounds</em> (forces rollback) of a younger transaction instead of waiting for it.</li> </ul> <p>In both the schemes, a rolled back transaction restarts with its original timestamp.</p> <ul> <li>Time-out based schemes</li> </ul> <h3 id="deadlock-recovery">Deadlock Recovery</h3> <p>There are two ways for rollback</p> <ul> <li>Total rollback</li> <li>Partial rollback - Roll back victim transaction only as far as necessary to release locks that another transaction in cycle is waiting for.</li> </ul> <p>A solution for starvation is that the oldest transaction in the deadlock set is never chosen as victim of rollback.</p> <h2 id="multiple-granularity">Multiple Granularity</h2> <p>A lock table might be flooded with entries when a transaction requires coarser granularity. The levels of granularity we use are database, area, file and record. What if we only use coarse granularities? The problem is that it’s not effective in terms of concurrency.</p> <p>We use <strong>intention locks</strong> to take care of hierarchy of granularities.</p> <h3 id="intention-lock-modes">Intention Lock Modes</h3> <p>In addition to S and X, we have</p> <ul> <li><strong>Intention-shared</strong> IS - Indicates explicit locking at a lower level of the tree but only with shared locks.</li> <li><strong>Intention-exclusive</strong> IX - Indicates explicit locking at a lower level with exclusive or shared locks.</li> <li><strong>Shared and intention exclusive</strong> SIX - The subtree rooted by that node is locked explicitly in shared mode and explicit locking is being done at a lower level with exclusive-mode locks.</li> </ul> <p>Intention locks allow a higher level node to be locked in S or X mode without having to check all descendent nodes. That is, to get a lock at the bottom level, we need to start taking intention locks from the root. Also, we have the following <strong>compatibility matrix</strong>.</p> <p><img src="/assets/img/Databases/image-20220417153625206.png" alt="image-20220417153625206"/></p> <p>The query engine decides all the locks based on the input queries. It follows adaptive lock granularity when it can’t decide. There is also a notion of <strong>lock granularity escalation</strong> in adaptive locking where the query engine shifts to a coarser granularity in case there are too many locks at a particular level.</p> <p>Now, we discuss locking in the case of predicate reads. Consider an insert. You can lock the entire relation to ensure consistency, but when someone inserts a new record there won’t be any lock on it. So, we use the following rules.</p> <p><img src="/assets/img/Databases/image-20220417155825429.png" alt="image-20220417155825429"/></p> <p>Note that one also locks the metadata in two-phase locking scheme that helps it ensure serialisability.</p> <h2 id="phantom-phenomenon">Phantom Phenomenon</h2> <p>A transaction \(T_1\) performs a predicate read, and a transaction \(T_2\) inserts a matching tuple while \(T_1\) is active but after predicate read. As a result, some of these schedules are not serialisable.</p> <h3 id="handling-phantoms">Handling Phantoms</h3> <p>If the conflict is at the data level, locking the metadata will prevent insertion and deletion in the relation. However, this provides very low concurrency for insertions and deletions.</p> <h3 id="index-locking-to-prevent-phantoms">Index Locking to prevent Phantoms</h3> <p>Every relation must have at least one index. A transaction \(T_i\) that performs a lookup must lock all the index leaf nodes that it accesses in \(S\)-mode. That is, it locks a range. A transaction \(T_j\) that inserts, updates or deletes a tuple \(t_i\) in a relation \(r\) must update all indices to \(r\). It can’t acquire X-lock in the locked range of \(T_i\). So phantom reads won’t occur when the rules of two-phase locking protocol must be observed. The key idea here is that, tuples in the matching range will be sequential do to the index.</p> <h3 id="next-key-locking-to-prevent-phantoms">Next-Key Locking to prevent Phantoms</h3> <p>This method provides higher concurrency. It locks all values that satisfy index lookup, and also lock the next key value in the index.</p> <p>Note that the above locks are done in the \(B^+\) trees.</p> <h1 id="lecture-37">Lecture 37</h1> <blockquote> <p><code class="language-plaintext highlighter-rouge">07-04-22</code></p> </blockquote> <h2 id="timestamp-ordering-protocol">Timestamp Ordering Protocol</h2> <p>The timestamp-ordering protocol guarantees serialisability since all the arcs in the precedence graph are of the form having nodes with edges from smaller timestamp to larger timestamp. This protocol ensures freedom from deadlock as no transaction ever waits. However, the schedule may not be cascade free and may not even be recoverable.</p> <p>To make it recoverable, we have the following solutions</p> <ul> <li>All the writes are done at the end of the timestamp. A transaction that aborts is restarted with a new timestamp.</li> <li>Limited form of locking - wait for data to be committed before reading it</li> <li>Use commit dependencies to ensure responsibility.</li> </ul> <h2 id="thomas-write-rule">Thomas’ Write Rule</h2> <p>Modified version of the TSO in which obsolete <strong>write</strong> operations may be ignored under certain circumstances. When a transaction items to write to a data item Q which will be rewritten by another transaction, then the original write is considered as obsolete. \(TS(T) &lt; W_\text{timestamp}(Q)\). So, rather than rolling back the original transaction as the TSO does, we ignore the write operation in the original transaction. In this way, Thomas’ Write Rules allows greater potential concurrency. It allows some view serialisable schedules that are not conflict-serialisable.</p> <p>The rule comes into the picture in case of <strong>blind writes</strong> - A write is done without a preceding read.</p> <h2 id="validation-based-protocol">Validation Based Protocol</h2> <p>It uses timestamps, but they are not pre-decided. The validation is performed at commit time to detect any out-of-serialisation order reads/writes. It is also known as <strong>optimistic concurrency control</strong> since transaction executes fully in the hope that all will go well during validation. This is done in three phases</p> <ul> <li>Read and execution phase. Writes are done to temporary variables.</li> <li>Validation phase</li> <li>Write phase</li> </ul> <p>Each transaction has 3 timestamps corresponding to start of execution, validation phase, and write phase. The validation time stamps are used in the protocol. In validation, we check that for all \(T_i, T_j\) such that \(TS(T_i) &lt; TS(T_j)\), one of the following must hold</p> <ul> <li> \[finishTS(T_i) &lt; startTS(T_j)\] </li> <li>\(startTS(T_j) &lt; finishTS(T_i) &lt; validationTS(T_j)\) and the set of data items written by \(T_i\) does not intersect with the set of data items read by \(T_j\).</li> </ul> <p>This is when the validation succeeds.</p> <h2 id="multiversion-concurrency-control">Multiversion Concurrency Control</h2> <p>Multiversion schemes keep old versions of data item to increase concurrency. There are variants such as</p> <ul> <li>Multiversion Timestamp Ordering</li> <li>Multiversion Two-Phase Locking</li> <li>Snapshot isolation</li> </ul> <p>The key ideas are that</p> <ul> <li>Each successful write results in the creation of a new version that labeled using timestamps.</li> <li>When a read operation is issued, we select the appropriate timestamp based on the timestamp of transaction issuing read and return the value of the selected version.</li> </ul> <h3 id="multiversion-timestamp-ordering">Multiversion Timestamp ordering</h3> <p>Each data item \(Q\) has a sequence of versions \(&lt; Q_1, \dots, Q_n&gt;\) each of which have</p> <ul> <li>Content</li> <li>Write timestamp</li> <li>Read timestamp</li> </ul> <p>If \(T\) issues a read or write, let \(Q_k\) be the version with the highest <u>write</u> timestamp that has a value less than the timestamp of \(T\). Then for a read, we return the value from \(Q_k\), and for a write we overwrite if both the timestamps are equal. We roll back \(T\) if \(TS(T) &lt; R\_timestamp\). Otherwise, we simply create a new entry.</p> <p>Like the basic TSP, recoverability is not ensured.</p> <h3 id="multiversion-two-phase-locking">Multiversion Two-Phase Locking</h3> <p>Differentiates between read-only transactions and update transactions. Update transactions follow rigorous two-phase locking. Read of a data item returns the latest version of the item. The first write of \(Q\) by \(T\) results in creation of a new version \(Q_i\) and the timestamp is updated after the completion of the transaction. After the transaction \(T\) completes, \(TS(T_i) = \texttt{ts-counter} + 1\) and \(W\_timestamp(Q) = TS(T_i)\) for all versions of \(Q\) that it creates. Then, the <code class="language-plaintext highlighter-rouge">ts-counter</code> is incremented. All of this must be done atomically.</p> <p>In read only transactions, <code class="language-plaintext highlighter-rouge">ts-counter</code> is assigned to the timestamp. As a result, only serialisable schedules are produced.</p> <p>The issues with multiversion schemes are they increase storage overhead and there are issues with keys constraint checking and indexing with multiple versions.</p> <h2 id="snapshot-isolation">Snapshot Isolation</h2> <p>A transaction \(T\) executing with snapshot isolation</p> <ul> <li>Takes snapshot of the committed data at start</li> <li>Always reads/modified data in its own snapshot</li> <li>Updates of concurrent transactions are not visible to \(T\)</li> <li>Writes of \(T\) are complete when it commits</li> </ul> <p>So, <strong>first committer wins</strong> rule is being used. <strong>Serialisable snapshot isolation (SSI)</strong> is an extension that ensures serialisability. However, there are some anomalies in this.</p> <h1 id="lecture-38">Lecture 38</h1> <blockquote> <p><code class="language-plaintext highlighter-rouge">11-04-22</code></p> </blockquote> <h1 id="chapter-19">~Chapter 19:</h1> <p>A transaction failure can occur as a result of</p> <ul> <li>logical errors - internal error condition in the transaction. These can be somewhat prevented by <code class="language-plaintext highlighter-rouge">assert</code> statements.</li> <li>system error - database must terminate the transaction due to errors like deadlock.</li> </ul> <p><strong>System crash</strong> - Occurs due to a power failure, hardware or software failure. A <strong>failstop assumption</strong> refers to the assumptions that non-volatile storage contents are not corrupted by a system crash. A <strong>disk failure</strong> destroys disk storage.</p> <p>Logging helps in recovery. To recover from failure, we first find inconsistent blocks by</p> <ul> <li>We compare two copies of every disk block which is expensive, or</li> <li>Use logs sort of mechanism</li> </ul> <p>and then overwrite the inconsistent blocks. We also need to ensure atomicity despite failures.</p> <h2 id="log-based-recovery">Log-Based Recovery</h2> <p>A <strong>log</strong> is a sequence of log records that keep information of update activities on the database. When transaction \(T\) starts, it registers itself by writing \((T start)\) log record. Before \(T\) executes \(write(X)\), it writes a log record \((T, X, V_1, V_2)\). Upon finishing the last statement, the log record \((T commit)\) is written. There are two approaches using log</p> <ul> <li>Immediate database modification - write to buffer which will write to disk when before the transaction commits. Log record is written before database item is written.</li> <li>Deferred database modification - writes are done only after commit. Not used frequently.</li> </ul> <p><u>A transaction is said to have committed when its commit log record is output to stable storage.</u> Also, the log records are interleaved for concurrent transactions.</p> <h2 id="concurrency-control-and-recovery">Concurrency Control and Recovery</h2> <p>We assume that if a transaction \(T\) has modified an item, no other transaction can modify the same item until \(T\) has committed or aborted. This is equivalent to <em>strict two phase locking</em>.</p> <ul> <li>\(undo(T_i)\) restores the value of all data items updated by \(T_i\) to their old values, going backwards from the last log record for \(T_i\). For each restoration, we add a log record of \((T_i, X, V)\). When undo of a transaction is complete, a log record \((T_i abort)\) is written out.</li> <li>\(redo(T_i)\) sets the value of all data items updated by \(T_i\) to the new values, going forward from the first log record of \(T_i\). The log is unchanged here.</li> </ul> <h2 id="recovering-from-failure">Recovering from Failure</h2> <p>When recovering from failure,</p> <ul> <li>Transaction \(T_i\) needs to be undone if the log contains the record \((T_i start)\) but does not contain \((T_i commit)\) or \((T_i abort)\)</li> <li>It needs to be redone if it contains \((T_i start)\) and \((T_i commit)\) or \((T_i abort)\).</li> </ul> <p>Note that the second step is wasteful in some cases. We recovered before, and we are doing it again. This is known as <strong>repeating history</strong>.</p> <h3 id="checkpoints">Checkpoints</h3> <p>Processing the entire log can be slow. We streamline recovery procedures by periodically performing checkpointing.</p> <ul> <li>Output all log records currently residing in the main memory onto stable storage</li> <li>Output all modified buffer blocks to the disk</li> <li>Write a log record \((checkpoint L)\) onto stable storage where \(L\) is a list of all transactions active at the time of checkpoint</li> <li>All updates are stopped while doing checkpointing.</li> </ul> <p>The log records before a checkpoint are not needed!</p> <h1 id="lecture-39">Lecture 39</h1> <blockquote> <p><code class="language-plaintext highlighter-rouge">12-04-22</code></p> </blockquote> <p>## Recovery Algorithm</p> <p><img src="/assets/img/Databases/image-20220417183018051.png" alt="image-20220417183018051"/></p> <p><img src="/assets/img/Databases/image-20220417183027590.png" alt="image-20220417183027590"/></p> <p><img src="/assets/img/Databases/image-20220417183036363.png" alt="image-20220417183036363"/></p> <h2 id="log-record-buffering">Log Record Buffering</h2> <p>Log records are buffered in main memory, instead of being output directly to stable storage. When the buffer is full, a <strong>log force</strong> operation is performed.</p> <p>As we had said, before a block of data in the main memory is output to the database, all log records pertaining to data in that block must have been output to stable storage. This rule is called as <strong>write-ahead logging</strong> or WAL rule. Strictly speaking, this is only required for undo transactions.</p> <h2 id="database-buffering">Database Buffering</h2> <p>The recovery algorithm supports the <strong>no-force policy</strong> - updated blocks need not be written to disk when transaction commits. However, <strong>force policy</strong> is a more expensive commit. The recovery algorithm also supports the <strong>steal policy</strong> - blocks containing updates of uncommitted transactions can be written to disk, even before the transaction commits.</p> <p>No updates should be in progress on a block when it is output to disk. It can be ensured by acquiring exclusive locks on the block before writing a data item. Locks can be released once the write is completed. Such locks held for short durations are called <strong>latches</strong>.</p> <p>In summary, we acquire latch, do log flush, write block to disk and finally release the latch.</p> <p>The <strong>dual paging</strong> problem refers to the extra I/O that is done when fetching a page from swap to buffer and then moving it to the disk. This can be prevented by letting the OS pass the control to the database when it needs to evict a page from the buffer. The database outputs the page to the database instead of the swap space, and release the page from the buffer.</p> <h2 id="fuzzy-checkpointing">Fuzzy Checkpointing</h2> <p>to avoid long interruption of normal processing during checkpointing, we allow updates to happen during checkpointing. We permit transactions to proceed with their actions once we note the list \(M\) of modified buffer blocks. We store a pointer to the <strong>checkpoint</strong> record in a fixed position <strong>last_checkpoint</strong> on disk once the all modified buffer blocks in \(M\) are output to disk. During recovery, we use this last checkpoint.</p> <h2 id="failure-with-loss-of-nonvolatile-storage">Failure with Loss of Nonvolatile Storage</h2> <p>Technique similar to checkpointing used to deal with the loss of non-volatile storage. That is, we periodically <strong>dump</strong> the entire content of the database to stable storage. No transaction may be active during the dump procedure. We perform the following -</p> <ul> <li>output all log records from main memory to storage</li> <li>output all buffer blocks onto the disk</li> <li>copy the contents of the database to stable storage</li> <li>output a record \((dump)\) to lon on stable storage.</li> </ul> <p>There are versions of <strong>fuzzy dump</strong> and <strong>online dump</strong>.</p> <h2 id="remote-backup-systems">Remote Backup Systems</h2> <p>We need to <strong>detect failure</strong> at the backup site using heartbeat messages and perform <strong>transfer of control</strong> to take control at the backup site. The log records are copied at the backup before, and recovery can be initiated. Once the primary site goes back up, we give back the control.</p> <p>The <strong>time to recover</strong> is very important to reduce delay in takeover. Therefore, the backup sire periodically processed the redo log records, performs a checkpoint, and can then delete earlier parts of the log.</p> <p>A <strong>hot-spare</strong> configuration permits very fast takeover - backup continually processes redo logs as they arrive and when the failure is detected, the backup rolls back incomplete transactions and is ready to process new transactions. An alternative to remote system backup is to use distributed systems.</p> <p>We have the following levels of durability</p> <ul> <li><strong>One safe</strong> - Commit as soon as transaction’s commit log record is written at primary.</li> <li><strong>Two-very safe</strong> - Commit when transaction’s commit log record is written at primary and backup.</li> <li><strong>Two-safe</strong> - Proceed as in two-very-safe is both primary and backup are active.</li> </ul> <p>We also need to reduce latency for communication. We add a <strong>near site</strong> backup close to the primary site. Log records are replicated both at near site and remote backup site. If primary fails, remote backup site gets latest log records, which it may have missed, from near site.</p> <hr/> <h4 id="end-of-course">END OF COURSE</h4> <hr/>]]></content><author><name></name></author><category term="Notes"/><summary type="html"><![CDATA[An introductory course for design and programming of database systems. Covers the entity-relationship (ER) approach to data modelling, the relational model of database management systems (DBMSs) and the use of query languages such as SQL. Briefly discusses query processing and the role of transaction management.]]></summary></entry></feed>