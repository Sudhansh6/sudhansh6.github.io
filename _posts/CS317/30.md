# Lecture 30

> `22-03-22`

## Set Operations

These are fairly straightforward using merge-join after sorting or hash-join. 

## Outer Join

During merging, for every tuple $$t_r$$ from $$r$$ that do not match any tuple in $$s$$, output $$t_r$$ padded with nulls. 

## Evaluation of Expressions

We have two method to evaluate an entire expression tree

- **Materialisation** - Generate results of an expression whose inputs
  are relations or are already computed, materialize (store) it on disk
- **Pipelining** - Pass on tuples to parent operations even as an
  operation is being executed

### Materialisation

We evaluate one operation at a time, and store each temporary result on the disk. this method is always applicable, but the cost is high. The overall cost is the sum of costs of individual operations and the cost of writing intermediate results to the disk.

**Double buffering** - Use two output buffers for each operation, when one is full write it to disk while the other is getting filled. 

### Pipelining

We evaluate several operations simultaneously, passing the results of one operation on to the next. However, this is not always possible in case of aggregation, sorts and hash-joins. It is executed in two ways -

- **Demand driven** - In lazy evaluation, the system repeatedly requests next tuple from the top level operation. The operation has to maintain states. Pull model.
- **Producer driven** - In eager pipelining the operators produce tuples eagerly and pass them up to their parents. Push model.

## Blocking Operations

They cannot generate any output until all the input is consumed. For example, sorting, aggregation, etc. They often have two sub-operations, and we can treat them as separate operations. All operations in a **pipeline** stage run concurrently. 

## Query Processing in Memory

In early days, memory was the bottleneck. So, engineers had to reduce the I/O. Query was compiled to machine code, and compilation usually avoids many overheads of interpretations to speed up query processing. This was often done via generation of Java byte code with JIT compilation. Column oriented storage was preferred as it allowed vector operations, and cache conscious algorithms were used. 

