# Lecture 9

**Note.** $$n$$-digit arithmetic deals with $$n$$ significant digits and not $$n$$ places after the decimal.

## Order of the fixed point iteration method

Summarizing the last lecture we have

- If we have a function $$g(x)$$ whose roots are to be found, we can convert it to a fixed point problem by appropriately constructing a $$f(x)$$.
- If we construct $$f(x)$$ such that it’s derivative is non-zero at the root, then the fixed point iteration method is <u>linear</u>.
- Otherwise, if the derivative is zero, then the fixed point iteration method is quadratic or higher. For example, we constructed such a $$f(x)$$ which mirrored the Newton-Raphson method.
- In the Newton-Raphson method itself, if the root is a simple zero of $$g$$, the method has quadratic convergence. However, if it is not a simple zero if $$g$$ then the method may not have a quadratic convergence.

Can we modify NR to overcome the limitation of multiplicity of the zero?

## Modified Newton-Raphson

For a given $$g(x)$$, we define a function $$\mu$$


$$
\mu(x) = \frac{g(x)}{g'(x)}
$$


If $$x = p$$ is a xero of $$g$$ with multiplicity $$m$$, we have


$$
\mu(x) = (x - p)\frac{q(x)}{mq(x) + (x - p)q'(x)}
$$


Notice that $$x = p$$ is a simple root of  $$\mu$$. Further, assume $$g, q$$ are continuous. Then, if $$g(x)$$ has no other zero in a neighborhood of $$x = p$$ then $$\mu(x)$$ will also not have any other zero in that neighborhood. We can now apply Newton-Raphson method to $$\mu(x)$$.

The fixed point iteration is given by


$$
\begin{align}
f(x) &= x - \frac{\mu(x)}{\mu'(x)} \\
&= x - \frac{g(x)/g'(x)}{(g'(x)^2 - g(xg''(x)))/g'(x)^2} \\
&= x - \frac{g(x)g'(x)}{g'(x)^2 - g(x)g''(x)}
\end{align}
$$


This iteration will converge to $$p$$ with at least the quadratic order of convergence. The only theoretical drawback with this method is that we now need to compute $$g’’(x)$$ at each step. Computationally, the denominator of the formula involves cancelling two nearly equal terms ($$x = p$$ is a root of both $$g, g’$$). 

Note that if $$x = p$$ is a simple zero, the modified Newton-Raphson still bodes well. It’s just that there are a lot more calculations in the modified NR method.

## An other methods?

There are many methods other than the 4 we considered so far. Suppose that $$\{p_n\}$$ converges to $$p$$ linearly. For large enough $$n$$, we have $$(p_{n + 1} - p)^2 \approx (p_n - p)(p_{n + 2} - p)$$ which further gives


$$
p \approx p_n - \frac{(p_{n + 1} - p_n)^2}{p_{n + 2} - 2p_{n + 1} + p_n} = \hat p_n
$$


This is called **Aitken’s** $$\mathbf{\Delta^2}$$**-method** of accelerating convergence. So, if we have a sequence $$\{p_n\}$$ converging to $$p$$ linearly, we can come up with an alternate sequence $$\{\hat p_n\}$$ using the original sequence that converges faster.

This brings us to the end of the second theme of our course - *Equations in one variable*.

