<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Modulo Compressed Sensing | Sudhansh</title> <meta name="author" content="Sudhansh Peddabomma"> <meta name="description" content="An introduction to recovery methods for measurements using fixed dynamic range sensors."> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%91%BE&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://sudhansh6.github.io/blog/Modulo-Compressed-Sensing/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?6185d15ea1982787ad7f435576553d64"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/">Sudhansh</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">Articles</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects</a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"></a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/challenges/">Challenges</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/misc/">Miscellaneous</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Modulo Compressed Sensing</h1> <p class="post-meta">January 6, 0001</p> <p class="post-tags"> <a href="/blog/0001"> <i class="fa-solid fa-calendar fa-sm"></i> 0001 </a>   ·   <a href="/blog/category/research"> <i class="fa-solid fa-tag fa-sm"></i> Research</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <h2 id="compressed-sensing">Compressed Sensing</h2> <p>Recover a high dimensional vector \(x\) with a very few non-zero values. Plethora of algorithms</p> <h3 id="sensors-and-measurements">Sensors and Measurements</h3> <ul> <li> <p>Sensors have Finite Dynamic Range</p> </li> <li> <p>Loss of information due to clipping. One potential approach to fix this is to wrap around the signal.</p> <p><img src="/assets/img/0001-01-01-Modulo-Compressed-Sensing/image-20210610112718042.png" alt="image-20210610112718042">​</p> </li> </ul> <p>This is where Modulo comes in.</p> <h3 id="why-cant-we-scale-the-signal">Why can’t we scale the signal?</h3> <p>There is an inherent quantization step involved during measurements. Therefore, scaling down and scaling back up will have the same resolution.</p> <ul> <li>Quantization error is proportional to the maximum value of the input signal.</li> </ul> <h1 id="modulo-compressed-sensing">Modulo Compressed Sensing</h1> <p>Typically, the real world sensors have a <strong>finite</strong> dynamic range. They have a <strong>clipping</strong> effect where the measurements become <strong>saturated</strong> once the values cross the range of the sensor. High dynamic range systems are affected by <em>high quantization noise</em>. To counter this problem, a new approach for measurements called <strong>self-reset analog to digital converters (SR-ADCs)</strong> have been proposed.</p> <p>These sensors fold the amplitudes back into the dynamic range of the ADCs using the modulo arithmetic. However, these systems encounter loss due to the modulo operation. The <em>transfer</em> function of the SR_ADC with parameter \(\lambda\) is given by</p> <div style="text-align: center;"> $$ \mathcal M_\lambda = 2\lambda \left( \left[ \left[ \frac{t}{2\lambda} + \frac{1}{2} \right]\right] - \frac{1}{2}\right) $$ </div> <p>Here, \([[t]] \triangleq t = \lfloor t \rfloor\). Now, we need to consider how we shall sample the values. A sampling theory called <em>unlimited sampling framework</em> was developed which provides sufficient conditions on the sampling rate for guaranteeing the recovery of band-limited signals from the folded samples. SR-ADC is applied individually to multiple linear measurements of the images, and is termed as modulo compressed sensing.</p> <p><strong>Note.</strong> The measured values may lie <em>outside</em> the dynamic range due to <strong>sensor noise</strong>.</p> <p>Let us concretely define the problem. Let \(x \in \mathbb{R}^N\) denote an \(s\)-sparse vector (\(||x||_0 \leq s\)) with \(s &lt; \frac{N}{2}\). We obtain \(m\) <em>projections</em> of \(x\) as follows:</p> <div style="text-align: center;"> $$ z_i = [[ \langle a_i, x \rangle ]], i = 1,2, \cdots, m $$ </div> <p>Usually, \(m \leq N\) in the compressed sensing paradigm. Stacking these projections, we get</p> <div style="text-align: center;"> $$ z = [[y]] = [[Ax]] $$ </div> <p>The non-linearity introduced by the modulo operation along with the undetermined compressive measurements could lead to an indeterminate system.</p> <blockquote> <p>\(\mathbf{P_0}\): Any real valued vector \(y \in \mathbb{R}^m\) can be uniquely decomposed as \(y = z + v\) where \(z \in [0, 1)^m\) and \(v \in \mathbb{Z}^m\) denote the fractional and integral part of \(y\) respectively. The following optimization problem is defined as \(P_0\)</p> </blockquote> <div style="text-align: center;"> $$ \arg \min_{x,v} \|x\|_0 \\ \text{ subject to } Ax = z + v; v \in \mathbb Z^m $$ </div> <blockquote> <ul> <li>Notice that \(v\) is the integral part and not \(z\), which may be confusing.</li> <li>The optimization equation does not oblige \(z\) to belong to \([0, 1)^m\). In fact, this condition is implicitly taken care when we impose minimality over \(z\).</li> <li>The \(\|w_0\|\) condition comes due to the sparsity of \(w\).</li> <li>Any \(s'\) sparse solution to \(P_0\) such that \(s' \leq s\) is also \(s\) sparse.</li> </ul> </blockquote> <h2 id="identifiability">Identifiability</h2> <blockquote> <p><strong>Lemma.</strong> Any vector \(x\) satisfying \(\|x\|_0 \leq s &lt; \frac{N}{2}\) is a unique solution to the optimization problem \(P_0\) iff any \(2s\) columns of matrix \(A\) are linearly independent of all \(v \in \mathbb Z^m\)</p> </blockquote> <hr> <p><strong>Proof.</strong></p> <p>(\(\rightarrow\)) Suppose a set of \(2s\) columns of \(A\), say \(S\), are not linearly independent. That is,</p> <div align="center"> $$ Ay = w \in \mathbb{Z}^m \text{ where } y\in \mathbb{R}^n \text{ has support } S $$ </div> <p>Consider a vector \(x\) defined from \(y\) whose support is the first \(s\) columns of \(S\). Similarly, define \(x_1\) whose support is the remaining \(s\) columns of \(S\). Let \(Ax = z + v\) where \(z \in (0, 1)^m\) and \(v \in \mathbb{Z}^m\). We have</p> <div align="center"> $$ Ax_1 = Ay - Ax = w - (z + v) $$ </div> <p>Therefore, \(-x_1\) and \(x\) are both solutions of \(P_0\). This is a contradiction. This proves sufficiency.</p> <p>(\(\leftarrow\)) Let \(z \in (0, 1)^m\) and \(v, v_1 \in \mathbb{Z}^m\) such that \(Ax = z + v\) and \(Ax_1 = z + v_1\) where \(\|x\|_0, \|x_1\|_0 \leq s\). Now, the size of the support of \(x - x_1\) is at most \(2s\). Consequently,</p> <div align="center"> $$ A(x - x_1) = v - v_1 \in \mathbb{Z}^m $$ </div> <p>This is a contradiction as any \(2s\) columns of \(A\) are linearly independent of all \(v \in \mathbb{Z}^m\). This proves necessity.</p> <hr> <blockquote> <p><strong><em>Corollary.</em></strong> Any vector \(x\) satisfying \(\|x\|_0 \geq \frac{N}{2}\) is a unique solutions to \(P_0\) iff columns of \(A\) are linearly independent. Consequently, the minimum number of measurements required for unique recovery is m = \(N + 1\) (not \(N\), see below)</p> </blockquote> <h2 id="conditions-for-recovery">Conditions for recovery</h2> <h3 id="signals-in-spacial-domain">Signals in spacial domain</h3> <p>To compare the modulo-CS problem to the standard CS problem, we state the two necessary conditions for modulo-CS recovery.</p> <p>The following two conditions are necessary for recovering any vector \(x\) satisfying \(\|x\|_0 \leq s\) as a unique solution to \(P_0\):</p> <ul> <li>\(m \geq 2s + 1\), and</li> <li>Any \(2s\) columns of \(A\) are linearly independent.</li> </ul> <p>\(m = 2s\) is necessary and sufficient for unique sparse recovery in the standard CS setup. We now show \(m = 2s + 1\) measurements is sufficient for unique recovery.</p> <blockquote> <p><strong>Theorem.</strong> For any \(N \geq 2s + 1\), there exists a matrix \(A \in \mathbb{R}^{m \times N}\) with \(m = 2s + 1\) rows such that every \(s\)-sparse \(x \in \mathbb{R}^N\) can be uniquely recovered from its modulo measurements \(z = [[Ax]]\)</p> </blockquote> <hr> <p><strong>Proof.</strong> We define the following</p> <ol> <li>\(\mathcal{V} = \{v \vert v \in \mathbb{Z}^m\}\) denotes the <em>countably</em> infinite set of all integer vectors.</li> <li>\(\mathcal{G} = \{T \vert T \subset [N], \vert T\vert = 2s\}\) denotes the set of all index sets on \([N]\) whose cardinality is \(2s\).</li> </ol> <p>Let \(A\) be a matrix for which at least one \(s\)- sparse vector \(x\) <strong>cannot</strong> be recovered from \(z = [[Ax]]\) via \((P_0)\). Our aim is to show the set of all such matrices is of <a href="#appendix1"><strong>Lebesgue measure zero</strong></a>.</p> <p>For a given \(u \in \mathcal{V}\) and \(S \in \mathcal{G}\), construct \(B(u, S) = \begin{bmatrix}u&amp;A_S\end{bmatrix}\). If \(det(B(u, S))\) equals \(0\), then \(A\) is not linearly independent of \(\mathbb{Z}^m\). This function is a non-zero polynomial of the entries of \(A_s\), and therefore the set of matrices which satisfy this condition have Lebesgue measure zero.</p> <p>Now, consider \(\cup_{S \in \mathcal{G}}\cup_{u \in \mathcal{V}} \{ A \vert det(B(u, S)) = 0 \}\), This set is of Lebesgue measure zero (why?). Therefore, any matrix \(A\) chosen outside this set will ensure that any \(s\)-sparse vector \(x\) can be recovered from \(y = [[Ax]]\).</p> <hr> <ul> <li>If the entries of \(A\) are drawn independently from any continuous distribution, \(A\) lies outside the set of Lebesgue measure 0 described in the above theorem.</li> <li>Integer matrices cannot be used as candidate measurement matrices for modulo CS (why?)</li> </ul> <h3 id="signals-in-temporal-domain">Signals in Temporal domain</h3> <p><strong>Unlimited Sampling Theorem</strong> - A band-limited signal can be recovered from modulo samples provided that a certain sampling density criterion is satisfied. This criterion must be independent of the ADC threshold.</p> <blockquote> <p><strong>Theorem.</strong> Let \(f(t)\) be a function with no frequencies higher than \(\Omega\)(rad/s), then a sufficient condition for recovery of \(f(t)\) from its modulo samples \(y_k = \mathcal M_\lambda(f(t)), t = kT, k \in \mathbb Z\) is,</p> <div align="center"> $$ T \leq \frac{1}{2\Omega e} $$ </div> </blockquote> <p>The above guarantees the recovery of the signal. Now, we discuss the conditions for unique recovery. There is a one-to-one mapping between a band-limited function and its modulo samples provided that the sampling rate is higher than the <em>Nyquist Rate</em>, \(T &lt; \pi/\Omega\).</p> <blockquote> <p><strong>Theorem.</strong> Let \(f(t)\) be a finite-energy function with no frequencies higher than \(\Omega\) (rad/s). Then the function \(f(t)\) is <em>uniquely</em> determined by its modulo samples \(y_k = \mathcal M_\lambda(f(t_k))\) taken on grid \(t = kT_\epsilon, k \in \mathbb Z\) where</p> <div align="center"> $$ 0 &lt; T_\epsilon &lt; \frac{\pi}{\Omega + \epsilon}, \epsilon &gt; 0 $$ </div> </blockquote> <h2 id="convex-relaxation">Convex Relaxation</h2> <p>Replacing the \(l_0\)-norm in \(P_0\) with the \(l_1\)-norm, we obtain the optimization problem:</p> <div align="center"> $$ \mathbf{P_1} :\arg \min_{x, v} \|x\|_1 \\ \text{ subject to } Ax = z + v; v \in \mathbb{Z}^m $$ </div> <h3 id="integer-range-space-property">Integer Range Space Property</h3> <p>A matrix \(A\) is said to satisfy the <em>IRSP</em> of <em>order</em> \(s\) if, for all sets \(S \subset [N]\) with \(\vert S\vert \leq s\),</p> <div align="center"> $$ \|u_S\|_1 &lt; \|u_{S^c}\|_1 $$ </div> <p>holds for every \(u \in \mathbb{R}^N\) with \(Au = v \in \mathbb{Z}^m\).</p> <blockquote> <p><strong>Theorem.</strong> Every \(s\)-sparse \(x\) is the unique solution of \((P_1)\) iff the matrix \(A\) satisfies the IRSP of order s.</p> </blockquote> <hr> <p><strong>Proof.</strong></p> <p>(\(\rightarrow\)) Consider a fixed index set \(S\) with \(\vert S\vert \leq s\), and suppose that every \(x\) supported on \(S\) is a unique minimizer of \((P_1)\). Then, for any \(u\) such that \(Au = v \in \mathbb Z^m\), the vector \(u_S\) is the unique minimizer of \((P_1)\). But, \(A(u_S + u_{S^c}) \in \mathbb Z^m\). This means that \(u_{S^c}\) is also a solution of \((P_1)\) for \([[Au_S]] = y\). Consequently, (we are talking about \(l_1\)-norm not \(l_0\)-norm)</p> <div align="center"> $$ \|u_S\|_1 &lt; \|u_{S^c}\|_1 $$ </div> <p>(\(\leftarrow\)) Suppose IRSP holds with respect to the set \(S\). Consider \(x\) supported on \(S\) and another vector \(x^1\) that result in the same modulo measurements with respect to \(A\). Let \(u = x - x^1\), the vector \(Au \in \mathbb Z^m\). Due to the IRSP,</p> <div align="center"> $$ \|u_S\|_1 &lt; \|u_{S^c}\|_1 $$ </div> <p>Hence,</p> <div align="center"> $$ \begin{align} \|x\|_1 &amp;\leq \|x - x^1_S\|_1 + \|x^1_S\|_1 \\ &amp;= \|u_S\|_1 + \|x^1_S\|_1 \\ &amp;&lt; \|u_{S^c}\|_1 + \|x^1_S\|_1 \\ &amp;= \|-x^1_{S^c}\|_1 + \|x_S^1\|_1 = \|x^1\|_1\end{align} $$ </div> <p>Thus proving uniqueness.</p> <hr> <h2 id="mixed-linear-integer-program-milp">Mixed Linear Integer Program (MILP)</h2> <p>The \(l_1\)-norm can be re-written as a linear function using two positive vectors \(x^+\) and \(x^-\), where \(x = x^+ - x^-\). This leads to the MILP formulation</p> <div align="center"> $$ \min_{x^+, x^-, v} \mathbf{1}^T(x^+ + x^-) \\ \text{ subject to } \\ \begin{bmatrix}A&amp;-A&amp;-I\end{bmatrix}\begin{bmatrix}x^+ \\ x^- \\ v\end{bmatrix} = z; \\ v\in \mathbb Z^m; x^+, x^- \geq 0 $$ </div> <p>This is efficiently solved using <a href="https://towardsdatascience.com/the-branch-and-bound-algorithm-a7ae4d227a69" rel="external nofollow noopener" target="_blank">branch-and-bound algorithm</a>.</p> <h4 id="appendix---lebesgue-measure"><a name="appendix1">Appendix - Lebesgue Measure</a></h4> <p>Lebesgue measure is an extension of the classical notions of length, area and volume to more complicated sets. Given an open set \(S \equiv \sum_k (a_k, b_k)\) containing disjoint intervals, the Lebesgue measure is defined by</p> <div align="center"> $$ \mu_L(S) = \sum_k(b_k - a_k) $$ </div> <p>Refer to this <a href="https://math.unl.edu/~gmeisters1/papers/Measure/measure.pdf" rel="external nofollow noopener" target="_blank">document</a> for more details regarding this topic.</p> <p>Let \(A \subseteq \mathbb{R}\). \(A\) is said to be of <strong>measure zero</strong> if for any \(\epsilon &gt; 0\), there exists a sequence of open intervals \((I_n)_{n \in \mathbb{N}}\) such that,</p> <div align="center"> $$ A \subseteq \bigcup\limits^\infty_{n = 1}I_n \text{ and } \sum_{n = 1}^\infty l(I_n) &lt; \epsilon $$ </div> <p>where, \(l((a, b)) = b - a\). For example, \(\mathbb{Q}\) is of measure zero.</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/Lattices-in-Cryptography/">Lattices in Cryptography and Quantum Computers</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/GANs-for-Compressed-Sensing/">Generative Adversarial Networks for Compressed Sensing</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/Object-Detection/">Object Detection</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/Low-Rank-Tensor-Recovery/">Low Rank Tensor Recovery for Joint Probability Distribution</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/Machine-Learning-Cheatsheet/">Machine Learning Cheatsheet</a> </li> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2024 Sudhansh Peddabomma. Last updated: March 17, 2024. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?9b43d6e67ddc7c0855b1478ee4c48c2d" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-0K9MLG0V24"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-0K9MLG0V24");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>