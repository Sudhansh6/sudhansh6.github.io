<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Brains and AI | Sudhansh Peddabomma</title> <meta name="author" content="Sudhansh Peddabomma"> <meta name="description" content="The primary motivation for AI stems from our brains. How has our research in cognitive science shaped the modern AI systems?"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%91%BE&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://sudhansh6.github.io/blog/brains-and-ai/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?6185d15ea1982787ad7f435576553d64"></script> <script src="/assets/js/chat.js?e73db4280bae3cbae4d78219277155b9"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/">Sudhansh Peddabomma</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">Articles</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects</a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"></a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/challenges/">Challenges</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/misc/">Miscellaneous</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Brains and AI</h1> <p class="post-meta">January 17, 2025</p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/category/notes"> <i class="fa-solid fa-tag fa-sm"></i> Notes</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <h1 id="distributed-representations-of-words-and-phrases-and-their-compositionality"><a href="https://arxiv.org/abs/1310.4546" rel="external nofollow noopener" target="_blank">Distributed Representations of Words and Phrases and their Compositionality</a></h1> <p>Presented by <a href="https://www.linkedin.com/in/joycelyn-yiu" rel="external nofollow noopener" target="_blank">Joycelyn Yiu</a></p> <p>What are distribution representations of words? Since symbols have no internal structure, researchers tries to represent words with vectors such that words that are similar to each other are closer in the vector space and vice versa.</p> <p>The inspiration for this idea comes from 1980’s, to convey semantics of language to machines. These representations can capture patterns and relationships between words like synonyms and grammar rules. How do we capture these patterns in practice?</p> <h3 id="skip-gram-model">Skip-Gram model</h3> <p>The skip gram model is a method that teaches a computer to understand the meaningful of words by reading large pieces of text. It basically learns the word relationships by predicting the surrounding words for a given word.</p> <p>In essence, from the training text, we compute the probability of <em>context</em> words occurring after a <em>center</em> word. How do you learn a distribution over words?</p> <p>The authors of the paper replaced softmax with a simpler one called <strong>Noise Contrastive Estimation NCE)</strong> that improved training and quality of representations.</p> <p>This model typically does not work well for rare words.</p> <p>In addition to the vanilla model, they added extension to represent phrases. Let us delve into each of these contributions.</p> <h2 id="method">Method</h2> <h3 id="hierarchical-softmax">Hierarchical softmax</h3> <p>The authors introduced hierarchical softmax that brought down the number of evaluations to \(\log_2(W)\) nodes rather than the typical \(W\) output nodes (where \(w\) is the number of words in the vocabulary).</p> <blockquote> <p>Is this used in LLMs? LLMs have become ubiquitous because of their parallelizability, and this takes it away to some extent.</p> </blockquote> <h3 id="negative-sampling">Negative Sampling</h3> <p>Introduced by Guzman and Hyvarinen, NCE tries to differentiate data from noise using logistic regression.</p> <h3 id="subsampling-of-frequent-words">Subsampling of Frequent Words</h3> <p>Common words like “the”, “a”, etc. occur frequently in text and do not provide a lot of information as compared to rare words. To counter this imbalance, the authors introduced a frequency based discard probability for the words to subsample the words. This improves the training speed and the accuracy of rare words.</p> <h3 id="learning-phrases">Learning phrases</h3> <p>The simple addition the authors did was to create new tokens for phrases like “The New York Times” - increasing the vocabulary size potentially making it unscalable. However, iteratively training the model considering longer phrases seemed to obtain a decent performance according to the authors.</p> <p>These techniques can be added to any underlying neural network model.</p> <h2 id="experiments">Experiments</h2> <p>The authors noticed that the representations posses a linear structure that allowed vector arithmetic. This potentially is a consequence of the training objective - the word vectors are in a linear relationship with the inputs to softmax non-linearity.</p> <h1 id="attention-is-all-you-need"><a href="https://arxiv.org/abs/1706.03762" rel="external nofollow noopener" target="_blank">Attention is all you need</a></h1> <p>Presented by <a href="https://www.linkedin.com/in/hansenlillemark" rel="external nofollow noopener" target="_blank">Hansen Jin Lillemark</a></p> <p>What is intelligence? We represented words with high-dimensional vectors, and we seemed to have cracked natural language? How does the brain understand and represent concepts?</p> <p>Language is one of the easiest avenues to test our algorithms of artificial intelligence. We have stored a lot of data in the past few decades, and this set up a good foundation to train models here.</p> <p>Transformers, inspired from some brain mechanisms, have become the go-to mechanism for most of the ML applications. It starts off with the language modeling task where the task is to predict the next word \(x_t\) give the previous words in the sentence. This very general task was first introduced by Shannon to define information and entropy.</p> <p>Domains like mathematics have deterministic distributions whereas reasoning usually has a flatter distribution. Another issue with language is that it keeps changing with time, and the models need to be dynamic enough to maintain this.</p> <h2 id="method-1">Method</h2> <p>Continuing from the Word2Vec paper, we represent words with vector embeddings.</p> <blockquote> <p>The embedding size is essentially like PCA - decomposing meanings into a low-dimensional space. Although there are over hundred thousand words, we are representing them in 500 dimensions?</p> </blockquote> <blockquote> <p>Can we create different similarity kernels to create different meanings? This effect is achieved through multi-head attention.</p> </blockquote> <blockquote> <p>Different language to language translation is possible with LLMs. Is there an inherent universal language?</p> </blockquote> <blockquote> <p>LLMs are able to reason well in some scenarios. Try asking it a novel puzzle and see how it does. However, it struggles with math. Is there something we are missing?</p> </blockquote> <blockquote> <p>Decoder inference is still sequential… Training seems more efficient but inference…</p> </blockquote> <h1 id="bias-variance-tradeoff">Bias-Variance Tradeoff</h1> <p>This topic seems like a thing of the past. We have built very large models around large amounts of data, and everything seems to work. So, why worry about bias or variance? Bias is solved by large models and variance is solved by large data. If all’s good in the world, then why don’t we have zero loss?</p> <blockquote> <p>Recap: The bias-variance trade-off. When low complexity models cannot inherently capture the complexity of the data, they have a <em>bias</em> or they <em>underfits</em> the training data. It can arise from a poor architecture or features engineered from the data. On the other end, complex models with large amount of parameters may fit the training data really well, but they tend to perform poorly on the test loss. This error, called <em>variance error</em>, occurs due to <em>overfitting</em>. in these cases, models are said to not generalize well across different data distributions. This trade-off between bias and variance is still present at the core of modern models.</p> </blockquote> <p>To counter these problems, early approaches involved <strong>regularizing</strong> models to prefer solutions with “simple” patterns - ones that have low-norm weights even in over-parameterized models. There are modern theoretical frameworks such as the <a href="https://arxiv.org/abs/1806.07572" rel="external nofollow noopener" target="_blank">Neural Tangent Kernels (NTK)</a> that show that over-parameterized networks behave like kernel machines and converge to smooth solutions due to regularization. That is, interpolating regularized solutions seems to generalize well.</p> <p>I also mentioned <em>poor model architecture</em> as a source of these errors. Over-parameterized models can often be replaced with models designed with a good <strong>inductive bias</strong> - models that leverage the structures in the data to generate structured solutions. For example, CNNs leveraged that images have spatial-features, and replaced fully-connected layers with convolutional kernels that greatly reduced the number of parameters.</p> <blockquote> <p><em>Model architectures</em> designed with inductive bias are the best kind of models. Attention is also a product of such design philosophies.</p> </blockquote> <p>So far, we have</p> <ul> <li>Maybe over-parameterization works but we need to have appropriate regularization tricks such as dropout and weight decay</li> <li>Adaptive optimizers, early stopping, large batch training all seem to make sense</li> </ul> <p>In 2018, <a href="https://arxiv.org/abs/1812.11118" rel="external nofollow noopener" target="_blank">Belkin et al.</a>, showed that test loss follows a “double descent” curve - it peaks at a critical model complexity, then decreases. This phenomenon has been seen to occur in CNNs, Transformers, and linear models with high dimensional features. The take away message is that more complexity does not mean worse generalization in the modern architectures.</p> <p><img src="/assets/img/BrainsAI/17377675747647.jpg" alt=""></p> <p>How does data fit in all this? More the amount of data, the simpler the model becomes - we have seen that the inner layers of LLMs require sparse changes in the weights to fine-tune to different datasets (LoRA). It maybe seen as if large datasets prevent overfitting since larger models are able to absorb the noise in the data without harming the underlying signal.</p> <p>In 2019, <a href="https://arxiv.org/abs/1906.11300" rel="external nofollow noopener" target="_blank">Bartlett et al.</a>, showed that models can memorize noisy data but still generalize if noise is structured or data has low intrinsic dimensions. High-dimensional mode old can separate signal from noise via implicit regularization. At the core of some of the large models we have built, we made a rather huge assumption - the noise in the data is Gaussian. The MSE loss is nothing but a negative likelihood over Gaussian noise. These assumptions must be carefully considered while building models for different applications.</p> <p>So what do we make of all this? It’s new information that we didn’t have before while designing models. Maybe it’s because of this the model scaling laws are working.</p> <h1 id="benign-overfitting-in-linear-regression"><a href="https://arxiv.org/abs/1906.11300" rel="external nofollow noopener" target="_blank">Benign overfitting in linear regression</a></h1> <p>The ultimate goal of machine learning is how to train a model that fits to a given data. We are approaching this by reducing the empirical training risk/error through a loss function. There is a mis-match between what are doing and the goal we are trying to achieve - reducing the test loss or generalize well to new data. Let us understand this better.</p> <p>A model’s ability to fit a wide variety of functions or patterns in the data is a known as its <em>capacity</em>. As we have increased the models’ capacity, we seemed to have the cross the peak in the double descent curve - they are over-fitting but it seems to be benign. That is, they seem to have zero training risk and the test risk approaches the best possible value. Why do we think this is benign? As the model capacity increases, the test loss seems to be decreasing even more. So how do we reach this benign overfitting region?</p> <p>The authors tested this with linear regression and significant over-parameterization. For a linear regression model the minimum norm solution is given by</p> \[\hat \theta = X^T = (XX^T)^{-1}y \; X\theta = y\] <p>The authors define the excess risk of the estimator as</p> \[T(\theta) := \mathbb E_{x, t} [(y - x^T \theta)^2 - (y - X^T \theta^*)^2]\] <p>How do you over-parameterize a linear regression model? The authors consider the number of eigenvectors of the covariance of the data. They consider quantities from the PCA theory. They concluded that if the decay of the eigenvalues of the covariance is sharp, then we can reach the benign overfitting region.</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/data-systems-for-ml/">Data Systems for Machine Learning</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/NumAn/">Numerical Analysis Notes</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/ipl/">IPL Notes</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/dbms/">DiBS Notes</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/ai-agents/">AI Agents</a> </li> </div> <script>document.querySelectorAll("#table-of-contents a").forEach(function(e){e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substring(1);document.querySelectorAll(".content-section").forEach(function(e){e.classList.add("hidden")});var n=document.getElementById(t);n&&n.classList.remove("hidden")})});</script> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2025 Sudhansh Peddabomma. Last updated: February 15, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?9b43d6e67ddc7c0855b1478ee4c48c2d" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-0K9MLG0V24"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-0K9MLG0V24");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <div class="chat-toggle-container"> <button id="chat-toggle-btn" class="chat-toggle-btn"> <i class="fas fa-comments"></i> </button> </div> <div id="chat-window" class="chat-window"> <div class="chat-header"> <h5 class="mb-0">Talk to my AI</h5> <button id="close-chat" class="btn-close"> <i class="fas fa-times"></i> </button> </div> <div id="chat-messages" class="chat-messages"></div> <div class="chat-input-container"> <input type="text" id="chat-input" class="form-control" placeholder="Type a message..."> <button id="send-btn" class="btn btn-primary"> <i class="fas fa-paper-plane"></i> </button> </div> </div> </body> </html>