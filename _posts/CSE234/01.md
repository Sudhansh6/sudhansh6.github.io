# Background 
## DL Computation
The idea is to concatenate composable layers 

$$
    \theta^{(t + 1)} = f(\theta^{(t)}, \nabla_L(\theta^{(t)}, D^{(t)}) 
$$

A **model** is a parameterized function that describes how we map inputs to predictions. The parameters are optimized using optimization methods like **SGD**, Newton methods, etc. A **loss function** guides the model to give feedback on how well the model is performing.

Having these basic definitions, we will build abstractions to map all the models being used today. It is not possible to build systems to support all models. A quick refresher of important models

- **CNNs** - Learnable filters to convolute across images to learn spatial features. The top 3 breakthrough architectures were - AlexNet, ResNet, U-Net. What are the important components in CNNs?
    - Convolution (1D, 2D, 3D) 
    - Matmul 
    - Softmax
    - Element-wise operations - ReLU, add, sub, pooling, normalization, etc.

- **Recurrent Neural Networks** - Many problems in nature are many-to-many. RNNs maintain an internal state that is updated as a sequence is processed. Arbitrary inputs and outputs can be generated, and any neural network can be used in the RNN architecture. The top 3 breakthrough architectures were - Bidirectional RNNs, LSTMs, GRU. What are the important components in RNNs?
    - Matmul 
    - Element-wise non-linear - ReLU, Sigmoid, Tanh 
    - Underlying MLP
  RNNs have a problem of forgetting ($$0.9*0.9*… \approx 0$$). Additionally, they lack **parallelizability** - both forward and backward passes have $$O(sequence length)$$.
  
- **Transformers** (Attention + MLP) - Treat representations of each element in the sequences as queries to access and incorporate information from a set of values. Transformers have an encoder part (BERT most famous) and a decoder part (GPT most famous). Along with these, DiT is one of the top 3 models. What are the important components in Transformers?
    - Attention - Matmul, softmax, Normalization
    - MLP
    - Layernorm, GeLU, etc.

- **Mixture of Experts** - Voting from many experts is better than one expert. Latest LLMs are mostly MoEs - Grok, Mixtral, Deepseek-v3. A router (Matmul, softmax) is the novel component in MoE - it makes system design difficult.

## Machine Learning Systems
As mentioned before, the three pillars for the systems are data, model and compute. The foal is to express as manny as models as possible using one set of programming interface by connecting math primitives. 

### Computational Dataflow Graph
A representation to show data flow in programs. A **node** represents the computation (operator) and an **edge** represents the data dependency (data flowing direction). A node can also represent the input/output tensor of the operator.

### Example: Deep learning with TensorFlow v1
```python
import tinyflow as tf

x = tf.placeholder(tf.float32, [None, 784]) # Forward declaration 
cross_entropy = tf.reduce_mean(-tf.reduce_sum(y *tf.log(y), reduction_indices=[1])) # Loss function declaration 
W_grad = tf.gradients(cross_entropy, [W])[0] # Automatic differentiation
train_step = tf.assign(W, W - learning_rate*W_grad) # SGD update rule 

for i in range(1000):
        sess.run(train_step, feed_dict={x, y}) # Real-execution happens here
```

![](assets/img/2025-01-06-data-systems-for-ml/17364786998993.jpg)

This DAG representation opens up all possibilities of optimizations. However, creating such a graph doesn’t allow flexibility - once a graph is defined, it cannot be changed based on the input. 

### Example: PyTorch 
PyTorch also uses computational graphs, but it creates it on the fly. Previously, we had defined the graph and then executed it. Symbolic declaration vs imperative programming. Define-then-run vs Define-and-run. C++ vs Python. 

What are the pros and cons?

|  | Good | Bad |
|---|---|---|
| Symbolic | Easy to optimize, much more efficient (can be 10x faster) | The way of programming can be counter-intuitive, hard to debug and less flexible |
| Imperative | More flexible, easy to program and debug | Less efficient and more difficult to optimize |

How does TensorFlow work in Python then? Tensorflow has Python as the interface language. 

Apart from these two famous frameworks, there were more like Caffe, DyNet, mxnet (has ability to switch between both), etc. Recently, Jax (derived from Tensorflow) has been getting more popular. 

### Just-in-time (JIT) compilation
Ideally, we want define-and-run during development and define-then-run during deployment. However do we combine both? PyTorch introduced a deploy mode through a decorator `torch.compile()`. So is there an issue with JIT? It creates only static graphs, and cannot work with conditionals or loops in the code. 

### Static vs Dynamic models
![](assets/img/2025-01-06-data-systems-for-ml/17364797895738.jpg)
Static graphs are defined and optimized only once. The execution follows a defined computation. On the other hand, dynamic graphs depend on the input. It is difficult to express complex flow-control logic and debug. The implementation is also difficult. 

As seen above, LSTMs are trying to replace the dynamics in the natural language problem.

**How to handle dynamics?** 
- Just do Define-and-run and forget about JIT - most popular unforunately :(
- Introduce Control Flow Ops - 
    - Example: Switch and Merge. This can be added a computational primitive in the graph and introduce dynamics in the graph.
    - These ideas are natural across all programming languages - conditionals and loops. However, the problem with this approach is that graphs becomes complex, and more importantly, how does we do back propagation? What is the gradient of “switch”? TensorFlow team has been working on this. 
- Piecewise compilation and guards - This approach is better adopted than control flow. 
    - Case 1: A graph accepting input shapes of $$[x, c1, c2]$$ where $$x$$ is variable. The solution is to compile for different values of $$x$$ (powers of 2).
