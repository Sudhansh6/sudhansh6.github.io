<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>AI Agents | Sudhansh Peddabomma</title> <meta name="author" content="Sudhansh Peddabomma"> <meta name="description" content="Everyone is talking about agents. But what is an agent? Is it just a buzzword being thrown around? This article talks deeply about this issue along with the technical ideas associated."> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link href="/assets/css/bootstrap-toc.min.css?6f5af0bb9aab25d79b2448143cbeaa88" rel="stylesheet"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%91%BE&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://sudhansh6.github.io/blog/ai-agents/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?6185d15ea1982787ad7f435576553d64"></script> <script src="/assets/js/chat.js?e73db4280bae3cbae4d78219277155b9"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/">Sudhansh Peddabomma</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">Articles</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects</a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"></a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/challenges/">Challenges</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/misc/">Miscellaneous</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="row"> <div class="col-sm-3"> <nav id="toc-sidebar" class="sticky-top"></nav> </div> <div class="col-sm-9"> <div class="post"> <header class="post-header"> <h1 class="post-title">AI Agents</h1> <p class="post-meta">January 6, 2025</p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/category/notes"> <i class="fa-solid fa-tag fa-sm"></i> Notes</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <h1 id="introduction">Introduction</h1> <p>The content on this article is based on the <a href="https://github.com/pearls-lab/ai-agents-course" rel="external nofollow noopener" target="_blank">course</a> by <a href="https://prithvirajva.com" rel="external nofollow noopener" target="_blank">Prof. Prithviraj</a> at UC San Diego. This <a href="https://www.kaggle.com/whitepaper-agents" rel="external nofollow noopener" target="_blank">whitepaper</a> about AI Agents by Google is also a good read.</p> <h2 id="what-is-an-agent">What is an agent?</h2> <p>Agent is an entity with <em>agency</em>. <a href="https://minecraft.wiki/w/Agent" rel="external nofollow noopener" target="_blank">A Minecraft agent?</a>. Agents see applications within the workspaces in the form of workflow automations, household or commercial robotics, software development and personal assistants. Generally, the theme is that <em>agents</em> take actions.</p> <p>Historically, the use of agents started in the early 1900s in the field of control theory. They were used for dynamic control of flight systems, and in 1940s it expanded to flight guidance, etc. By the 1950s the concepts of MDPs and dynamic programming were being expanded to many use cases. Surprisingly, one of the first natural language chatbots, Eliza, was created as a psychotherapist simulator in the 1960s! Finally, reinforcement learning became a field of study in the 1990s for sequential decision making.</p> <h2 id="sequential-decision-making">Sequential Decision Making</h2> <p>These tasks are different from other ML problems like classification. A model that has an accuracy of 99% at each step, has a cumulative accuracy of ~30% after 120 steps!</p> <p>These problems are formalized as a Markov Decision Process - an <strong>agent</strong> performs <strong>actions</strong> in an <strong>environment</strong>, and in turn receives <strong>rewards</strong> as feedback. These configurations are distinguished as <strong>states</strong>, and the whole process can be seen as sequential decision making.</p> <p>The core components of an agent, often agreed on, are</p> <ul> <li> <strong>Grounding</strong> - Language is anchored to <em>concepts</em> in the world. Language can be grounded to different forms of information systems - images, actions and cultural norms. <ul> <li>Agency (ability to act) - At each state, an agent needs to have multiple choices to act. <em>If an agent has to select what tools to use but there’s always only one tool, is that agency?</em> The action space has to be well-defined to look for agency. Although there is a single tool call, different parameters for the tool call can probably be considered as different actions. Actions can be defined as something the agent does and changes the environment. The distinction between an agent and environment is not very clear in many cases. Although, our approximations mostly serve us well.</li> <li>Planning (Long horizon)</li> <li>Memory - <ul> <li>Short-term - What is the relevant information around the agent that it needs to use to act now</li> <li>Long term - What information has the agent already gathered that it can retrieve to take an action</li> </ul> </li> <li>Learning (from feedback) - Doesn’t necessarily always mean <em>backpropagation</em>.</li> </ul> </li> <li> <strong>Additional</strong> - <ul> <li>Embodiment (physically acting in the real-world). <em>Embodied hypothesis</em> - embodiment is necessary for AGI.</li> <li>Communication - Can the agent communicate its intentions to other agents. Very necessary pre-requisite for multi-agent scenarios.</li> <li>World Modeling - Given the state of the world and an actions, predict the next state of the world. Is <a href="https://deepmind.google/technologies/veo/veo-2/" rel="external nofollow noopener" target="_blank">Veo</a>/<a href="https://sora.com" rel="external nofollow noopener" target="_blank">Sora</a> a world model? It is an attempt for world model since they have no verifiability. <a href="https://deepmind.google/discover/blog/genie-2-a-large-scale-foundation-world-model/" rel="external nofollow noopener" target="_blank">Genie</a> is another such attempt. So is <a href="https://genesis-embodied-ai.github.io" rel="external nofollow noopener" target="_blank">Genesis</a> - this is much better if it works.</li> <li>Multi-modality - The clean text on the internet is only a few terabytes, and our models have consumed it (took use 2 decades though). YouTube has 4.3 Petabytes of new videos a day. CERN generates 1 Petabyte a day (modalities outside vision and language). Some people believe this form of scaling is the way to go. There are more distinctions -</li> </ul> </li> </ul> <table> <thead> <tr> <th>Model</th> <th>AI System</th> <th>Agent</th> </tr> </thead> <tbody> <tr> <td>GPT-4</td> <td>ChatGPT</td> <td>ChatGPT computer use</td> </tr> <tr> <td>Forward passes of a neural net</td> <td>Mixing models together</td> <td>Has agency</td> </tr> </tbody> </table> <p>It is important to remember that not every use case needs an agent and most use cases just need models or AI systems. <em>Occam’s razor</em>.</p> <h1 id="simulated-environments-and-reality">Simulated Environments and Reality</h1> <p>Why do we need simulations? Most tasks have many ways of completing them. There is no notion of <em>global</em> optimal solutions ahead of time but usually known once the task is complete.</p> <p>The agent needs to explore to find many solutions to compare and see what is the most efficient. However, exploration in the read world is expensive - wear and tear of robots, excessive compute, danger to humans, etc.</p> <p>Simulations offer an easy solution to these problems. Assign a set of rules, and let a world emerge. One of the early examples of this is <a href="https://en.wikipedia.org/wiki/Conway%27s_Game_of_Life" rel="external nofollow noopener" target="_blank">Conway’s Game of Life</a> which theorized that complicated behaviors can emerge by just a few rules.</p> <p>From an MDP perspective, a simulation contains \(&lt;S, A, T&gt;\) where</p> <ul> <li>\(S\) is the set of all states. It consists of propositions that are true/false. Example: You are in a house, door is open, knife in drawer</li> <li>\(A\) is the set of all actions. Example: Take knife from drawer, walk through door</li> <li>\(T\) is the transition matrix - (You are in the house, you walk out of the door) -&gt; You are outside the house.</li> </ul> <p>A simulation need not have an explicit reward.</p> <h2 id="sim2real-transfer">Sim2Real Transfer</h2> <p>The ability of an agent trained in simulation transfer to reality is dependent on how good the model extrapolates out of distribution. With the current stage of agents, the simulation is made as close to reality as possible to reduce the Sim2Real gap.</p> <p>How do we measure closeness to reality? The tasks in the real world have different types of complexities -</p> <ol> <li>Cognitive complexity - Problems that requires long chains of <em>reasoning</em> - puzzles, math problems or moral dilemmas</li> <li>Perceptive complexity - Requires high levels of vision and/or precise motor skills - bird watching, threading a needle, Where’s Waldo</li> </ol> <p>Examples of simulations -</p> <ol> <li>Grid world - low cognitive and almost zero perceptive. However, this idea can arbitrarily scale to test algorithms for their generalization potential in controllable settings.</li> <li>Atari - low perceptive, medium cognitive. Atari games became very popular in 2013, when Deepmind released their <a href="https://arxiv.org/pdf/1312.5602" rel="external nofollow noopener" target="_blank">Deep Q-Net</a> paper that achieved human level skills on these games.</li> <li> <a href="https://en.wikipedia.org/wiki/Zork" rel="external nofollow noopener" target="_blank">Zork</a>, <a href="https://www.nethack.org" rel="external nofollow noopener" target="_blank">NetHack</a> - low perceptive, high cognitive. These are configurations or worlds that you purely interact with text. The worlds are actually so complex that there is no agent that is able to finish the challenge!</li> <li> <a href="https://cs.stanford.edu/people/jcjohns/clevr/" rel="external nofollow noopener" target="_blank">Clevr simulation</a> - medium perceptive, low cognitive - This simulation generates images procedurally with certain set of objects and has reasoning questions for each image.</li> <li> <a href="https://ai2thor.allenai.org" rel="external nofollow noopener" target="_blank">AI2 THOR</a> - medium perceptive, medium cognitive. Worlds with ego-centric views for robotics manipulation and navigation simulations</li> <li> <a href="https://arxiv.org/pdf/2407.18901" rel="external nofollow noopener" target="_blank">AppWorld</a> - medium perceptive, medium cognitive. A bunch of different apps that you would generally use in daily life. The agents can access apps, and the simulation also has human simulators. This simulation is one that is closest to reality in the discussed so far!</li> <li> <a href="https://www.minecraft.net/en-us" rel="external nofollow noopener" target="_blank">Minecraft</a> - medium perceptive, high cognitive. A voxel based open-world game that lets players take actions similar to early-age humans.</li> <li> <a href="https://mujoco.org" rel="external nofollow noopener" target="_blank">Mujoco</a> - high perceptive, low cognitive. It is a free and open source physics engine to aid the development of robotics.</li> <li> <a href="https://ai.meta.com/research/publications/habitat-a-platform-for-embodied-ai-research/" rel="external nofollow noopener" target="_blank">Habitat</a> - high perceptive, medium cognitive. A platform for research in embodied AI that contains indoor-world ego-centric views similar to AI2 THOR, but with much better graphics. They have recently added sound in the environment too!</li> <li> <p>High perceptive, high cognitive - Real world, and whoever gets this simulation right, wins the race to AGI. It requires people to sit down and enumerate all kinds of rules. Game Engines like Unreal and Unity are incredibly complex, and are the closest we’ve gotten.</p> <p>Some researchers try to “learn” the simulations from real-world demonstrations.</p> </li> </ol> <p>In each of these simulators, think of the complexity and reward sparsity in the environment. It is easy to build a simulator that gives rewards at a goal state than the one that gives a reward for each action. There are some open-lines of research in this domain -</p> <ol> <li>Which dimensions of complexity transfer more easily? Curriculum learning</li> <li>Can you train on lower complexity and switch to a higher complexity?</li> <li>Can we learn the world model holy grail?</li> </ol> <h2 id="how-to-make-simulations">How to make simulations?</h2> <p>As we’ve seen, simulations can range from games to real-world replications with physics involved. Most simulations are not designed keeping AI in mind. However, with the current state of AI, this is an important factor to keep in mind.</p> <p>Classical environments like in Zork/AI2 Thor/Mujoco have something known as <strong>PDDLs</strong>. Some simulations are built through AI, like <em>AI Dungeon</em> that spins up worlds for role-play games.</p> <h3 id="planning-domain-definition-language-pddl">Planning Domain Definition Language (PDDL)</h3> <p>Standard encoding for classic planning tasks. Many specific languages for creating simulations have similarities with PDDL.</p> <p>A PDDL Task consists of the following</p> <ul> <li>Objects - things in the world that interest us</li> <li>Predicates - Properties of objects that we are interested in, can be true or false</li> <li>Initial state - The state of the world that we start in</li> <li>Goal specification - Things that we want to be true</li> <li>Actions/Operators - Ways of changing the state of the world.</li> </ul> <p>These are split across two files - domain and problem <code class="language-plaintext highlighter-rouge">.pddl</code> files.</p> <p>Classic symbolic planners read PDDLs and give possible solutions. Checkout the <a href="https://planning.wiki/ref/planners/atoz" rel="external nofollow noopener" target="_blank">Planning.wiki</a>. In many cases these planners are used over reinforcement learning due to lack of algorithmic guarantees.</p> <p>There were other attempts</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/NumAn/">Numerical Analysis Notes</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/data-systems-for-ml/">Data Systems for Machine Learning</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/ipl/">IPL Notes</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/dbms/">DiBS Notes</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/automata/">Automata Notes</a> </li> </div> <script>document.querySelectorAll("#table-of-contents a").forEach(function(e){e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substring(1);document.querySelectorAll(".content-section").forEach(function(e){e.classList.add("hidden")});var n=document.getElementById(t);n&&n.classList.remove("hidden")})});</script> </div> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2025 Sudhansh Peddabomma. Last updated: January 22, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="/assets/js/bootstrap-toc.min.js?c82ff4de8b0955d6ff14f5b05eed7eb6"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?9b43d6e67ddc7c0855b1478ee4c48c2d" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-0K9MLG0V24"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-0K9MLG0V24");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <div class="chat-toggle-container"> <button id="chat-toggle-btn" class="chat-toggle-btn"> <i class="fas fa-comments"></i> </button> </div> <div id="chat-window" class="chat-window"> <div class="chat-header"> <h5 class="mb-0">Talk to my AI</h5> <button id="close-chat" class="btn-close"> <i class="fas fa-times"></i> </button> </div> <div id="chat-messages" class="chat-messages"></div> <div class="chat-input-container"> <input type="text" id="chat-input" class="form-control" placeholder="Type a message..."> <button id="send-btn" class="btn btn-primary"> <i class="fas fa-paper-plane"></i> </button> </div> </div> </body> </html>