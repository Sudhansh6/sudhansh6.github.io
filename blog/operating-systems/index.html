<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Operating System Notes | Sudhansh Peddabomma</title> <meta name="author" content="Sudhansh Peddabomma"> <meta name="description" content="Basic concepts of Operating Systems like process abstraction, process execution mechanism, inter-process mechanism, memory management, paging, memory allocation and free space management algorithms, threads and concurrency, locks, condition variables, semaphores, I/O and filesystems, etc."> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link href="/assets/css/bootstrap-toc.min.css?6f5af0bb9aab25d79b2448143cbeaa88" rel="stylesheet"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%91%BE&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://sudhansh6.github.io/blog/operating-systems/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?6185d15ea1982787ad7f435576553d64"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/">Sudhansh Peddabomma</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">Articles</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects</a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"></a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/challenges/">Challenges</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/misc/">Miscellaneous</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="row"> <div class="col-sm-3"> <nav id="toc-sidebar" class="sticky-top"></nav> </div> <div class="col-sm-9"> <div class="post"> <header class="post-header"> <h1 class="post-title">Operating System Notes</h1> <p class="post-meta">September 30, 2021</p> <p class="post-tags"> <a href="/blog/2021"> <i class="fa-solid fa-calendar fa-sm"></i> 2021 </a>   ·   <a href="/blog/category/notes"> <i class="fa-solid fa-tag fa-sm"></i> Notes</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <h1 id="lecture-1---introduction">Lecture 1 - Introduction</h1> <h2 id="what-is-an-operating-system">What is an operating system?</h2> <p>An operating system is a <strong>middleware</strong> between user programs and system hardware.</p> <table> <thead> <tr> <th style="text-align: center">User Programs</th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><strong>OS</strong></td> </tr> <tr> <td style="text-align: center"> <strong>Hardware</strong>: CPU, Memory, Disk, I/O</td> </tr> </tbody> </table> <p>An operating system manages hardware: CPU, Main Memory, IO devices (disk, network, card, mouse, keyboard, etc.)</p> <h2 id="what-happens-when-you-run-a-program-background">What happens when you run a program? (Background)</h2> <p>A compiler translated high level programs into an <strong><em>executable</em></strong> (“.c” to “a.out”)</p> <p>The executable contains instructions that the CPU can understand and the program’s data (all numbered with addresses).</p> <p>Instructions run on CPU: hardware implements an <strong><em>Instruction Set Architecture</em></strong> (ISA).</p> <p>CPU also consists of a few registers, e.g.,</p> <ul> <li>Pointer to current instruction (PC)</li> <li>Operands of the instructions, memory addresses</li> </ul> <p>To run an exe, the CPU does the following:</p> <ol> <li>Fetches instruction ‘pointed at’ by PC from memory</li> <li>Loads data required by the instructions into registers</li> <li>Decodes and executes the instruction</li> <li>Stores the results to memory</li> </ol> <p>Most recently used instructions and data are in CPU <strong>cache</strong> (instruction cache and data cache) for faster access.</p> <h2 id="what-does-the-os-do">What does the OS do?</h2> <h3 id="os-manages-cpu">OS manages CPU</h3> <p>It initializes program counter (PC) and other registers to begin execution. OS provides the <strong>process abstraction</strong>.</p> <p><strong><em>Process:</em></strong> A running program</p> <p>OS creates and manages processes. Each process has the illusion of having the complete CPU, i.e., OS <strong><em>virtualizes</em></strong> CPU. It <em>timeshares</em> the CPU between processes. It also enables coordination between processes.</p> <h3 id="os-manages-memory">OS manages memory</h3> <p>It loads the program executable (code, data) from disk to memory. It has to manage code, data, stack, heap, etc. Each process thinks it has a dedicated memory space for itself, numbers code, and data starting from 0 (<strong>virtual addresses</strong>).</p> <p>The operating system abstracts out the details of the actual placement in memory, translates from virtual addresses to real physical addresses.</p> <p>Hence, the process does not have to worry about where its memory is allocated in the physical space.</p> <h3 id="os-manages-devices">OS manages devices</h3> <p>OS helps in reading/writing files from the disk. OS has code to manage disk, network card, and other external devices: <strong><em>device drivers</em></strong>.</p> <p><strong><em>Device driver:</em></strong> Talks the language of the hardware devices.</p> <p>It issues instructions to devices (fetching data from a file). It also responds to interrupt events from devices (pressing a key on the keyboard).</p> <p>The persistent (ROM) data is organised as a <strong><em>file system</em></strong> on the disk.</p> <h2 id="design-goals-of-an-operating-system">Design goals of an operating system</h2> <ul> <li> <strong>Convenience</strong>, <strong>abstraction of hardware</strong> resources for user programs.</li> <li> <strong>Efficiency</strong> of usage of CPU, memory, etc.</li> <li> <strong>Isolation</strong> between multiple processes.</li> </ul> <h2 id="history-of-operating-systems">History of operating systems</h2> <p>OS started out as a library to provide common functionality across programs. Later, it evolved from procedure calls to <strong><em>system calls</em></strong>.</p> <p>When a system call is made to run OS code, the CPU executes at a <em>higher privilege level</em>.</p> <p>OS evolved from running a single program to executing <em>multiple processes concurrently</em>.</p> <h1 id="lecture-2---the-process-abstraction">Lecture 2 - The Process Abstraction</h1> <p>An operating system provides <strong>process abstraction</strong>. That is, when you execute a program, the OS creates a <em>process</em>. It timeshares CPU across multiple processes (virtualizing CPU). An OS also has a <strong><em>CPU scheduler</em></strong> that picks one of the many active processes to execute on a CPU. This scheduler has 2 components.</p> <ol> <li> <strong>Policy</strong> - It decides which process to run on the CPU</li> <li> <strong>Mechanism</strong> - How to “context-switch” between processes</li> </ol> <h2 id="what-constitutes-a-process">What constitutes a process?</h2> <p>Every process has a <strong><em>unique identifier (PID)</em></strong> and a <strong><em>memory image</em></strong> - the fragments of the program present in the memory. As mentioned earlier, a memory image has 4 components (code, data, stack, and heap).</p> <p>When a process is running, a process also has a <strong><em>CPU context</em></strong> (registers). This has components such as program counter, current operands, and stack pointer. These basically store the state of the process.</p> <p>A process also has <strong><em>File descriptors</em></strong> - pointers to open files and devices.</p> <h2 id="how-does-an-os-create-a-process">How does an OS create a process?</h2> <p>Initially, the OS allocates and creates a memory image. It loads the code and data from the disk executable. Then, it makes a runtime stack and heap.</p> <p>After this, the OS opens essential files (<code class="language-plaintext highlighter-rouge">STD IN</code>, <code class="language-plaintext highlighter-rouge">STD OUT</code>, <code class="language-plaintext highlighter-rouge">STD ERR</code>). Then the CPU registers are initialized, and the PC points to the first instruction.</p> <h2 id="states-of-a-process">States of a process</h2> <ul> <li> <p>A process that is currently being executed in the CPU is <strong>Running</strong>.</p> </li> <li> <p>Processes that are waiting to be scheduled are <strong>Ready</strong>. These are not yet executed.</p> </li> <li> <p>Some processes may be in the <strong>Blocked</strong> state. They are suspended and not ready to run. These processes may be waiting for some event, e.g., waiting for input from the user. They are unblocked once an <em>interrupt is issued</em>.</p> </li> <li> <p><strong>New</strong> processes are being created and are yet to run.</p> </li> <li> <p><strong>Dead</strong> processes have finished executing and are terminated.</p> <table> <thead> <tr> <th style="text-align: center"><img src="/assets/img/Operating%20Systems/image-20210726215935642.png" alt="image-20210726215935642"></th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><em>Process State Transitions</em></td> </tr> </tbody> </table> </li> </ul> <p>When one process is blocked, another process can be executed to utilize the resources effectively. Here is a simple example reflecting this situation.</p> <table> <thead> <tr> <th style="text-align: center"><img src="/assets/img/Operating%20Systems/image-20210726220829735.png" alt="image-20210726220829735"></th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><em>Example: Process States</em></td> </tr> </tbody> </table> <h2 id="os-data-structures">OS data structures</h2> <p>An operating system maintains a data structure of all active processes. One such structure is the <strong><em>process control block (PCB)</em></strong>. Information about each process is stored in a PCB.</p> <p>Different Operating Systems might use other names for this structure. PCB is the generic name. All the processes running on the system are stored in a list of PCBs.</p> <p>A PCB has the following components of a process:</p> <ul> <li>Process identifier</li> <li>Process state</li> <li>Pointers to other related processes (parent)</li> <li>CPU context of the process (saved when the process is suspended)</li> <li>Pointers to memory locations</li> <li>Pointers to open files</li> </ul> <h1 id="lecture-21---xv6-introduction-and-x86-background">Lecture 21 - xv6 introduction and x86 background</h1> <p>xv6 is a simple OS used for teaching OS concepts. We shall be using the x86 version of the OS.</p> <p>An OS enables users to run the processed stored in memory on the CPU.</p> <ul> <li>It loads the process code/data in main memory.</li> <li>CPU fetches, decodes, executes instructions in program code.</li> <li>It fetches the process data from memory to CPU registers for faster access during instruction execution (We studied in Arch that memory access is expensive).</li> <li>Recently fetched code/data is stored in the CPU in the form of cache for future access.</li> </ul> <h2 id="memory-image-of-a-process">Memory Image of a process</h2> <p>The memory image of a process consists of</p> <ul> <li>Compiled code (CPU instructions)</li> <li>Global/static variables (memory allocated at compile time)</li> <li>Heap (dynamic memory allocation via, <code class="language-plaintext highlighter-rouge">malloc</code>, <code class="language-plaintext highlighter-rouge">new</code> etc) that grows (up) on demand.</li> <li>Stack (temporary storage during function calls, e.g., local variables) that usually grows “up” towards lower addresses. It shrinks “down” as memory is freed (exiting function call).</li> <li>Other things like shared libraries.</li> </ul> <p>Every instruction/data has an address, used by the CPU to fetch/store (<em>Virtual addresses</em> managed by OS). Consider the following example</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">int</span> <span class="o">*</span><span class="n">iptr</span> <span class="o">=</span> <span class="n">malloc</span><span class="p">(</span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">))</span>
</code></pre></div></div> <p>Here, <code class="language-plaintext highlighter-rouge">iptr</code> itself is on stack but it points to 4 bytes (size of <code class="language-plaintext highlighter-rouge">int</code>) in the heap.</p> <h2 id="x86-registers">x86 registers</h2> <p>Registers are a small space for data storage with the CPU. Every CPU architecture has its set of registers used during computation. The names of these registers vary across different architectures. These are the common types of registers:</p> <ul> <li>General purpose registers - stores data during computations (<code class="language-plaintext highlighter-rouge">eax, ebx, ecx, edx, esi, edi</code>).</li> <li>Pointers to stack locations - base of stack (<code class="language-plaintext highlighter-rouge">ebp</code>) and top of stack (<code class="language-plaintext highlighter-rouge">esp</code>).</li> <li>Program counter or instruction pointer (<code class="language-plaintext highlighter-rouge">eip</code>) - Next instruction to execute.</li> <li>Control registers - Hold control information or metadata of a process (e.g., <code class="language-plaintext highlighter-rouge">cr3</code> has pointer to page table of the process). A page table helps the OS to keep track of the memory of the process.</li> <li>Segment registers (<code class="language-plaintext highlighter-rouge">cs, ds, es, fs, gs, ss</code>) - information about segments (related to memory of process).</li> </ul> <h2 id="x86-instructions">x86 Instructions</h2> <p>Every CPU can execute a set of instructions defined in its ISA. The compiled code is written using this ISA so that the CPU can execute these instructions. Here are some common instructions used:</p> <ul> <li>Load/store - <code class="language-plaintext highlighter-rouge">mov src, dst</code> (AT&amp;T syntax - using <code class="language-plaintext highlighter-rouge">src</code> before <code class="language-plaintext highlighter-rouge">dst</code>) <ul> <li> <code class="language-plaintext highlighter-rouge">mov %eax, %ebx</code> - copy contents of <code class="language-plaintext highlighter-rouge">eax</code> to <code class="language-plaintext highlighter-rouge">ebx</code> </li> <li> <code class="language-plaintext highlighter-rouge">mov (%eax), %ebx</code> - copy contents at the address in <code class="language-plaintext highlighter-rouge">eax</code> into <code class="language-plaintext highlighter-rouge">ebx</code> </li> <li> <code class="language-plaintext highlighter-rouge">mov 4(%eax), %ebx</code> - copy contents stores at offset of 4 bytes from address stored at <code class="language-plaintext highlighter-rouge">eax</code> into <code class="language-plaintext highlighter-rouge">ebx</code> </li> </ul> </li> <li>Push/pop on stack - changes <code class="language-plaintext highlighter-rouge">esp</code> <ul> <li> <code class="language-plaintext highlighter-rouge">push %eax</code> - push contents of <code class="language-plaintext highlighter-rouge">eax</code> onto stack, update <code class="language-plaintext highlighter-rouge">esp</code> </li> <li> <code class="language-plaintext highlighter-rouge">pop %eax</code> - pop top of stack onto <code class="language-plaintext highlighter-rouge">eax</code>, update <code class="language-plaintext highlighter-rouge">esp</code> </li> </ul> </li> <li> <code class="language-plaintext highlighter-rouge">jmp</code> sets <code class="language-plaintext highlighter-rouge">eip</code> to a specified address</li> <li> <code class="language-plaintext highlighter-rouge">call</code> to invoke a function, <code class="language-plaintext highlighter-rouge">ret</code> to return from a function</li> <li>Variants of above (<code class="language-plaintext highlighter-rouge">movw, pushl</code>) for different register sizes.</li> </ul> <h2 id="privilege-levels">Privilege Levels</h2> <p>x86 CPUs have multiple privilege levels called <strong><em>rings</em></strong> (0 to 3). Ring 0 has the highest privilege and OS code runs at this level. Ring 3 has the lowest privilege and user code runs at this level.</p> <p>There are two types of instructions - privileged and unprivileged. <strong>Privileged</strong> instructions perform sensitive operations which ideally should not be performed by user programs. These can be executed by the CPU only when running at the highest privilege level (ring 0) .</p> <p>For example, writing into <code class="language-plaintext highlighter-rouge">cr3</code> register (setting page table) is a privileged instruction. We don’t want a user manipulating memory of another process. instructions to access I/O devices is also privileged.</p> <p>Unprivileged instructions can be run at lower privilege levels.</p> <blockquote> <p><span style="color:red">Even ring 0?</span></p> </blockquote> <p>For example, user code running at a lower privilege level can store a value into a general purpose register.</p> <p>When a user required OS services (system calls), the CPU moves to higher privilege level and executes OS code that contains privileged instructions. User code cannot invoke privileged instructions directly.</p> <h2 id="function-calls-and-the-stack">Function calls and the stack</h2> <p>Local variables and arguments are stored on stack for the duration of a function call. When a function is called:</p> <ul> <li>Arguments are pushed onto the stack.</li> <li> <code class="language-plaintext highlighter-rouge">call function</code> - pushes the return address on stack and jumps to function. That is, <code class="language-plaintext highlighter-rouge">eip</code> shifts from top of stack to function implementation.</li> <li>Local variables are allocated on stack</li> <li>Function code is executed</li> <li> <code class="language-plaintext highlighter-rouge">ret</code> - instruction pops return address, <code class="language-plaintext highlighter-rouge">eip</code> goes back to the old value.</li> </ul> <blockquote> <p><span style="color:red">What exactly is happening above?</span></p> </blockquote> <p>In this way, stack acts as a temporary storage for function calls.</p> <p>Before making a function call, we may have to store values of some registers. This is because, registers can get clobbered during a function call.</p> <ul> <li>Some registers are saved on stack by <strong>caller</strong> before invoking the function (<em>caller save registers</em>). The function code (<em>callee</em>) can freely change them, and the caller restores them later.</li> <li>Some registers are saved by <strong>callee</strong>, and are restored after function ends (<em>callee save registers</em>). Caller expects them to have same value on return.</li> <li>Return value stored in <code class="language-plaintext highlighter-rouge">eax</code> register by callee (one of caller save registers)</li> </ul> <p>All of the above is automatically done by the C compiler (C calling convention). Every language has a calling convention that decides which registers have to be classified as caller and callee.</p> <blockquote> <p>Caller and Callee both store the registers?</p> </blockquote> <p>Timeline of a function call is as follows (<em>Note.</em> Stack grows up from higher to lower addresses):</p> <ul> <li>Caller save registers are pushed (<code class="language-plaintext highlighter-rouge">eax, ecx, edx</code>)</li> <li>Arguments of the function are pushed in reverse order onto the stack</li> <li>The return address or the old <code class="language-plaintext highlighter-rouge">eip</code> is pushed on stack by the <code class="language-plaintext highlighter-rouge">call</code> instruction</li> <li>The old <code class="language-plaintext highlighter-rouge">ebp</code> is also pushed onto the stack</li> <li>Set <code class="language-plaintext highlighter-rouge">ebp</code> to the current top of the stack (base of new “stack frame” of the function)</li> <li>Push local variables and callee save registers (<code class="language-plaintext highlighter-rouge">ebx, esi, edi</code>). <code class="language-plaintext highlighter-rouge">esp</code> automatically goes up as you push things onto the stack.</li> <li>The function is executed.</li> <li>After the function execution, the current stack frame is popped to restore the old <code class="language-plaintext highlighter-rouge">ebp</code>.</li> <li>The return address is popped and <code class="language-plaintext highlighter-rouge">eip</code> is restored by the <code class="language-plaintext highlighter-rouge">ret</code> instruction.</li> </ul> <p><img src="/assets/img/Operating%20Systems/Peek%202021-07-31%2000-30.gif" alt="function stack"></p> <p>Stack pointers: <code class="language-plaintext highlighter-rouge">ebp</code> stores the address of base of the current stack frame and <code class="language-plaintext highlighter-rouge">esp</code> stores the address of current top of stack. This way, function arguments are accessible from looking under the stack base pointer.</p> <h2 id="c-vs-assembly-for-os-code">C vs. assembly for OS code</h2> <p>Most of xv6 is in C! The assembly code is automatically generated by the compiler (including all the stack manipulations for function calls).</p> <p>However, small parts of the OS are in assembly language. This is because, the OS needs more controls over what needs to be done in some situations. For example, the logic of switching from stack of one process to stack of another cannot be written in a high-level language.</p> <p>Therefore, basic understanding of x86 assembly language is required to follow some nuances of xv6 code.</p> <h2 id="more-on-cpu-hardware">More on CPU hardware</h2> <p>Some aspects of CPU hardware that are not relevant to studying OS:</p> <ul> <li>CPU cache - CPU stores recently fetched instructions and data in multiple levels of cache. The operating system has no visibility or control intro the CPU cache.</li> <li>Hyper-threading - A CPU core can run multiple processed concurrently via hyper-threading. From an OS perspective, 4-core CPU with 2 hyper-threads per core, and 8-core CPU with no hyper-threading will look the same, even though the performance may differ. The OS will schedule processes in parallel on the 8 available processors.</li> </ul> <h1 id="lecture-22-processes-in-xv6">Lecture 22: Processes in xv6</h1> <h2 id="the-process-abstraction">The process abstraction</h2> <p>The OS is responsible for concurrently running multiple processes (on one or more CPU cores/processors)</p> <ul> <li>Create, run, terminate a process</li> <li>Context switch from one process to another</li> <li>Handle any events (e.g., system calls from process)</li> </ul> <p>OS maintains all information about an active process in a process control block (PCB)</p> <ul> <li>Set of PCBs of all active processes is a critical kernel data structure</li> <li>Maintained as part of kernel memory (part of RAM that stores kernel code and data, more on this later)</li> </ul> <p>PCB is known by different names in different OS</p> <ul> <li> <code class="language-plaintext highlighter-rouge">structproc</code> in xv6</li> <li> <code class="language-plaintext highlighter-rouge">task_struct</code> in Linux</li> </ul> <h2 id="pcb-in-xv6-struct-proc">PCB in xv6: struct proc</h2> <p>The different states of a process in xv6 (<code class="language-plaintext highlighter-rouge">procstate</code>) are given by <code class="language-plaintext highlighter-rouge">UNUSED, EMBRYO (new), SLEEPING (blocked), RUNNABLE (ready), RUNNING, ZOMBIE (dead)</code></p> <p>The <code class="language-plaintext highlighter-rouge">struct proc</code> has</p> <ul> <li>Size of the process</li> <li>Pointer to the apge table</li> <li>Bottom of the kernel stack for this process</li> <li>Process state</li> <li>Process ID</li> <li>Parent process</li> <li>Pointer to folder in which process is running</li> <li>Some more stuff which we will study later</li> </ul> <h3 id="kernel-stack">Kernel Stack</h3> <p>Register state (CPU context) is saved on user stack during the function calls to restore/resume later. Likewise, the CPU context is stored on <strong><em>kernel stack</em></strong> when process jumps into OS to run kernel code.</p> <p>We use a separate stack because the OS does not trust the user stack. It is a separate area of memory per process within the kernel, not accessible by regular user code. It is linked from <code class="language-plaintext highlighter-rouge">struct proc</code> of a process.</p> <h3 id="list-of-open-files">List of open files</h3> <p>Array of pointers to open files (<code class="language-plaintext highlighter-rouge">struct file</code> has info about the open file)</p> <ul> <li>When user opens a file, a new entry is created in this array, and the index of that entry is passed as a file descriptor to user</li> <li>Subsequent read/write calls on a file use this file descriptor to refer to the file</li> <li> <p>First 3 files (array indices 0,1,2) open by default for every process: standard input, output and error</p> </li> <li>Subsequent files opened by a process will occupy later entries in the array</li> </ul> <h3 id="page-table">Page table</h3> <p>Every instruction or data item in the memory image of process has an address. Page table of a process maintains a mapping between the virtual addresses and physical addresses.</p> <h2 id="process-table-ptable-in-xv6">Process table (<code class="language-plaintext highlighter-rouge">ptable</code>) in xv6</h2> <p>It has a lock for protection. It is an array of all processes. Real kernels have dynamic-sized data structures. However, xv6 being a dummy OS, has a static array.</p> <p>A CPU scheduler in the OS loops over all runnable processes, picks one, and sets it running on the CPU.</p> <h2 id="process-state-transtition-examples">Process state transtition examples</h2> <p>A process that needs to sleep will set its state to <code class="language-plaintext highlighter-rouge">SLEEPING</code> and invoke scheduler.</p> <p>A process that has run for its fair share will set itself to <code class="language-plaintext highlighter-rouge">RUNNABLE</code> and invoke Scheduler. The Scheduler will once again find another <code class="language-plaintext highlighter-rouge">RUNNABLE</code> process and set it to <code class="language-plaintext highlighter-rouge">RUNNING</code>.</p> <h1 id="live-session-1">Live Session 1</h1> <ul> <li> <em>Real memory</em> is less than <em>virtual memory</em>. It is easier to let the process think it has the whole memory rather than telling it how much memory it exactly has.</li> <li>Memory for Global variables and Function variables is allocated once! We don’t know how many times each function will be called. Therefore, we just assign it once and use the allocated space for repeated calls.</li> <li>We have <em>caller</em> and <em>callee</em> registers for storing existing computations in the registers before a function call. We can’t have only one set (callee or caller) store all these values due to some subtle reasons. A caller save register would have to pass some arguments. A callee save register would have to return some arguments. To avoid all this, we have a separate set of caller and callee registers.</li> <li>“Only one process can run on a core at any time”. Basically that the OS sees the processor as two different cores in hyper-threading. Therefore, it can run a <em>single</em> process on a <em>core</em>.</li> <li> <em>xv6</em> is primarily written in C. If we need an OS to compile and run a program, how do we run xv6? Whenever you boot a system with an OS, you use an existing OS to build the binaries for the needed OS. Then, you run the binary to run the OS. To answer the chicken and egg problem, someone might’ve written an OS in assembly code initially.</li> <li>OS keeps track of locations of memory images using <strong>page tables</strong>.</li> <li>Virtual addresses of an array will be contiguous, but the OS may not allocate contiguous memory.</li> <li>When we print the address of a pointer, we get the <strong>virtual address</strong> of the variable. Exposing the real address is a security risk.</li> </ul> <h1 id="lecture-3---process-api">Lecture 3 - Process API</h1> <p>We will discuss the API that the OS provides to create and manage processes.</p> <h2 id="what-is-the-api">What is the API?</h2> <p>So, the API refers to the functions available to write user programs. The API provided by the OS is a set of <strong>system calls</strong>. Recall, a system call is like a function call, but it runs at a higher privilege level. System calls can perform sensitive operations like access to hardware. Some “blocking” system calls cause the process to be blocked and unscheduled (e.g., <code class="language-plaintext highlighter-rouge">read</code> from disk).</p> <h2 id="do-we-have-to-rewrite-programs-for-each-os">Do we have to rewrite programs for each OS?</h2> <p>No, we don’t. This is possible due to the <strong><em>POSIX API</em></strong>. This is a standard set of system calls that OS must implement. Programs written to the POSIX API can run on any POSIX compatible OS. Almost every modern OS has this implemented, which ensures program portability. Program language libraries hide the details of invoking system calls. This way, the user does not have to worry about explicitly invoking system calls.</p> <p>For ex, the <code class="language-plaintext highlighter-rouge">printf</code> function in the C library calls the <code class="language-plaintext highlighter-rouge">write</code> system call to write to the screen.</p> <h2 id="process-related-system-calls-in-unix">Process related system calls (in Unix)</h2> <p>The most important system call to create a process is the <strong><code class="language-plaintext highlighter-rouge">fork()</code></strong> system call. It creates a new <strong>child</strong> process. All processes are created by forking from a parent. The <strong><code class="language-plaintext highlighter-rouge">init</code></strong> process is the ancestor of all processes. When the OS boots up, it creates the <code class="language-plaintext highlighter-rouge">init</code> process.</p> <p><strong><code class="language-plaintext highlighter-rouge">exec()</code></strong> makes a process execute a given executable. <strong><code class="language-plaintext highlighter-rouge">exit()</code></strong> terminates a process, and <strong><code class="language-plaintext highlighter-rouge">wait()</code></strong> causes a parent to block until a child terminates. Many variants of the above system calls exist with different arguments.</p> <h2 id="what-happens-during-a-fork">What happens during a fork?</h2> <p>A new process is created by making a copy of the parent’s memory image. This means the child’s code is exactly the same as the parent’s code. The new process is added to the <a href="#os-data-structures">OS process list</a> and scheduled. Parent and child start execution just after the fork statement (with different return values).</p> <p>Note that parent and child execute and modify the memory data independently (the memory images being a copy of one another does not propagate).</p> <p>The return values for <code class="language-plaintext highlighter-rouge">fork()</code> are set as follows:</p> <ul> <li> <code class="language-plaintext highlighter-rouge">0</code> for the child process</li> <li> <code class="language-plaintext highlighter-rouge">&lt; 0</code> if <code class="language-plaintext highlighter-rouge">fork</code> failed</li> <li> <code class="language-plaintext highlighter-rouge">PID of the child</code> in the parent</li> </ul> <h2 id="terminating-child-processes">Terminating child processes</h2> <p>A process can be terminated in the following situations</p> <ul> <li>The process calls <code class="language-plaintext highlighter-rouge">exit()</code> (<code class="language-plaintext highlighter-rouge">exit()</code> is called automatically when the end of main is reached)</li> <li>OS terminated a misbehaving process</li> </ul> <p>The processes are not immediately deleted from the process list upon termination. They exist as zombies. These are cleared out when a parent calls <code class="language-plaintext highlighter-rouge">wait(NULL)</code>. A zombie child is then cleaned up or “reaped”.</p> <p><code class="language-plaintext highlighter-rouge">wait()</code> <strong>blocks the parent</strong> until the child terminates. There are some non-blocking ways to invoke wait.</p> <p>What if the parent terminates before its child? <code class="language-plaintext highlighter-rouge">init</code> process adopts orphans and reaps them. Dark, right? If the <code class="language-plaintext highlighter-rouge">init</code> process does not do this, zombies will eat up the system memory. Why do we need zombies? (Too many brains in the world). There are subtle reasons for this, which are out of scope for this discussion.</p> <h2 id="what-happens-during-exec">What happens during exec?</h2> <p>After forking, the parent and the child are running the same code. This is not useful! A process can run <code class="language-plaintext highlighter-rouge">exec()</code> to <strong>load</strong> another executable to its memory image. This allows a child to run a different program from the parent. There are variants of <code class="language-plaintext highlighter-rouge">exec()</code>, e.g., <code class="language-plaintext highlighter-rouge">execvp()</code>, to pass command-line arguments to the new executable.</p> <h2 id="case-study-how-does-a-shell-work">Case study: How does a shell work?</h2> <p>In a basic OS, the <code class="language-plaintext highlighter-rouge">init</code> process is created after the initialization of hardware. The <code class="language-plaintext highlighter-rouge">init</code> spawns a lot of new processes like <code class="language-plaintext highlighter-rouge">bash</code>. <strong><code class="language-plaintext highlighter-rouge">bash</code></strong> is a shell. A shell reads user commands, forks a child, execs the command executable, waits for it to finish, and reads the next command.</p> <p>Standard commands like <code class="language-plaintext highlighter-rouge">ls</code> are all executables that are simply <code class="language-plaintext highlighter-rouge">exec</code>‘ed by the shell.</p> <h2 id="more-funky-things-about-the-shell">More funky things about the shell</h2> <p>A shell can manipulate the child in strange ways. For example, you can redirect the output from a command to a file.</p> <div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>prompt <span class="o">&gt;</span> <span class="nb">ls</span> <span class="o">&gt;</span> foo.txt
</code></pre></div></div> <p>This is done via spawning a child, rewires its standard output to a file, and then calls the executable.</p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">close</span><span class="p">(</span><span class="n">STDOUT_FILENO</span><span class="p">);</span>
<span class="n">open</span><span class="p">(</span><span class="s">"./p4.output"</span><span class="p">,</span> <span class="n">O_CREAT</span><span class="o">|</span><span class="n">O_WRONLY</span><span class="o">|</span><span class="n">O_TRUNC</span><span class="p">,</span> <span class="n">S_IRWXU</span><span class="p">);</span>
</code></pre></div></div> <p>We can similarly modify the input for a process.</p> <h1 id="lecture-23---system-calls-for-process-management-in-xv6">Lecture 23 - System calls for process management in xv6</h1> <h2 id="process-system-calls-shell">Process system calls: Shell</h2> <p>When xv6 boots up, it starts the init process (the first user process). Init forks shell, which prompts for input. This shell process is the main screen that we see when we run xv6.</p> <p>Whenever we run a command in the shell, the shell creates a new child process, executes it, waits for the child to terminate, and repeats the whole process again. Some commands have to be executed by the parent process itself and <strong>not by the child</strong>. For example, <code class="language-plaintext highlighter-rouge">cd</code> command should change the parent’s (shell) current directory, not of the child. Such commands are directly executed by the shell itself without forking a new process.</p> <h2 id="what-happens-on-a-system-call">What happens on a system call?</h2> <p>All the system calls available to the users are defined in the user library header <strong>‘user.h’</strong>. This is equivalent to a C library header (xv6 doesn’t use a standard C library). System call implementation invokes a special <strong>trap</strong> instruction called <strong><code class="language-plaintext highlighter-rouge">int</code></strong> in x86. All the system calls are defined in “usys.S”.</p> <p>The trap (int) instruction causes a jump to kernel code that handles the system call. Every system call is associated with a number which is moved into <code class="language-plaintext highlighter-rouge">eax</code> to let the kernel run the applicable code. We’ll learn more about this later, so don’t worry about this now.</p> <h2 id="fork-system-call">Fork system call</h2> <p>Parent allocates new process in <code class="language-plaintext highlighter-rouge">ptable</code>, copies parent state to the child. The child process set is set to runnable, and the scheduler runs it at a later time. Here is the implementation of <code class="language-plaintext highlighter-rouge">fork()</code></p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">int</span>
<span class="nf">fork</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span>
<span class="p">{</span>
    <span class="kt">int</span> <span class="n">i</span><span class="p">,</span> <span class="n">pid</span><span class="p">;</span>
    <span class="k">struct</span> <span class="n">proc</span> <span class="o">*</span><span class="n">np</span><span class="p">;</span>
    <span class="k">struct</span> <span class="n">proc</span> <span class="o">*</span><span class="n">curproc</span> <span class="o">=</span> <span class="n">myproc</span><span class="p">();</span>
    <span class="c1">// Allocate process.</span>
    <span class="k">if</span><span class="p">((</span><span class="n">np</span> <span class="o">=</span> <span class="n">allocproc</span><span class="p">())</span> <span class="o">==</span> <span class="mi">0</span><span class="p">){</span>
        <span class="k">return</span> <span class="err">−</span><span class="mi">1</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="c1">// Copy process state from proc.</span>
    <span class="k">if</span><span class="p">((</span><span class="n">np</span><span class="err">−</span><span class="o">&gt;</span><span class="n">pgdir</span> <span class="o">=</span> <span class="n">copyuvm</span><span class="p">(</span><span class="n">curproc</span><span class="err">−</span><span class="o">&gt;</span><span class="n">pgdir</span><span class="p">,</span> <span class="n">curproc</span><span class="err">−</span><span class="o">&gt;</span><span class="n">sz</span><span class="p">))</span> <span class="o">==</span> <span class="mi">0</span><span class="p">){</span>
        <span class="n">kfree</span><span class="p">(</span><span class="n">np</span><span class="err">−</span><span class="o">&gt;</span><span class="n">kstack</span><span class="p">);</span>
        <span class="n">np</span><span class="err">−</span><span class="o">&gt;</span><span class="n">kstack</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
        <span class="n">np</span><span class="err">−</span><span class="o">&gt;</span><span class="n">state</span> <span class="o">=</span> <span class="n">UNUSED</span><span class="p">;</span>
        <span class="k">return</span> <span class="err">−</span><span class="mi">1</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="n">np</span><span class="err">−</span><span class="o">&gt;</span><span class="n">sz</span> <span class="o">=</span> <span class="n">curproc</span><span class="err">−</span><span class="o">&gt;</span><span class="n">sz</span><span class="p">;</span>
    <span class="n">np</span><span class="err">−</span><span class="o">&gt;</span><span class="n">parent</span> <span class="o">=</span> <span class="n">curproc</span><span class="p">;</span>
    <span class="o">*</span><span class="n">np</span><span class="err">−</span><span class="o">&gt;</span><span class="n">tf</span> <span class="o">=</span> <span class="o">*</span><span class="n">curproc</span><span class="err">−</span><span class="o">&gt;</span><span class="n">tf</span><span class="p">;</span>
    <span class="c1">// Clear %eax so that fork returns 0 in the child.</span>
    <span class="n">np</span><span class="err">−</span><span class="o">&gt;</span><span class="n">tf</span><span class="err">−</span><span class="o">&gt;</span><span class="n">eax</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="k">for</span><span class="p">(</span><span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">NOFILE</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span>
        <span class="k">if</span><span class="p">(</span><span class="n">curproc</span><span class="err">−</span><span class="o">&gt;</span><span class="n">ofile</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="n">np</span><span class="err">−</span><span class="o">&gt;</span><span class="n">ofile</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">filedup</span><span class="p">(</span><span class="n">curproc</span><span class="err">−</span><span class="o">&gt;</span><span class="n">ofile</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
    <span class="n">np</span><span class="err">−</span><span class="o">&gt;</span><span class="n">cwd</span> <span class="o">=</span> <span class="n">idup</span><span class="p">(</span><span class="n">curproc</span><span class="err">−</span><span class="o">&gt;</span><span class="n">cwd</span><span class="p">);</span>
    <span class="n">safestrcpy</span><span class="p">(</span><span class="n">np</span><span class="err">−</span><span class="o">&gt;</span><span class="n">name</span><span class="p">,</span> <span class="n">curproc</span><span class="err">−</span><span class="o">&gt;</span><span class="n">name</span><span class="p">,</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">curproc</span><span class="err">−</span><span class="o">&gt;</span><span class="n">name</span><span class="p">));</span>
    <span class="c1">// Set new pid</span>
    <span class="n">pid</span> <span class="o">=</span> <span class="n">np</span><span class="err">−</span><span class="o">&gt;</span><span class="n">pid</span><span class="p">;</span>
    <span class="n">acquire</span><span class="p">(</span><span class="o">&amp;</span><span class="n">ptable</span><span class="p">.</span><span class="n">lock</span><span class="p">);</span>
    <span class="c1">// Set Process state to runnable</span>
    <span class="n">np</span><span class="err">−</span><span class="o">&gt;</span><span class="n">state</span> <span class="o">=</span> <span class="n">RUNNABLE</span><span class="p">;</span>
    <span class="n">release</span><span class="p">(</span><span class="o">&amp;</span><span class="n">ptable</span><span class="p">.</span><span class="n">lock</span><span class="p">);</span>
    <span class="c1">// Fork system call returns with child pid in parent</span>
    <span class="k">return</span> <span class="n">pid</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div> <h2 id="exec-system-call">Exec system call</h2> <p>The source code is a little bit complicated. The key steps include</p> <ul> <li>Copy new executable into memory, replacing the existing memory image</li> <li>Create new stack, heap</li> <li>Switch process page table to use the new memory image</li> <li>Process begins to run new code after system call ends</li> </ul> <h2 id="exit-system-call">Exit system call</h2> <p>Exiting a process cleans up the state and passes abandoned children to <code class="language-plaintext highlighter-rouge">init</code>. It marks the current process as a zombie and invokes the scheduler.</p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">void</span>
<span class="nf">exit</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span>
<span class="p">{</span>
    <span class="k">struct</span> <span class="n">proc</span> <span class="o">*</span><span class="n">curproc</span> <span class="o">=</span> <span class="n">myproc</span><span class="p">();</span>
    <span class="k">struct</span> <span class="n">proc</span> <span class="o">*</span><span class="n">p</span><span class="p">;</span>
    <span class="kt">int</span> <span class="n">fd</span><span class="p">;</span>
    <span class="k">if</span><span class="p">(</span><span class="n">curproc</span> <span class="o">==</span> <span class="n">initproc</span><span class="p">)</span>
        <span class="n">panic</span><span class="p">(</span><span class="s">"init exiting"</span><span class="p">);</span>
    <span class="c1">// Close all open files.</span>
    <span class="k">for</span><span class="p">(</span><span class="n">fd</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">fd</span> <span class="o">&lt;</span> <span class="n">NOFILE</span><span class="p">;</span> <span class="n">fd</span><span class="o">++</span><span class="p">){</span>
        <span class="k">if</span><span class="p">(</span><span class="n">curproc</span><span class="err">−</span><span class="o">&gt;</span><span class="n">ofile</span><span class="p">[</span><span class="n">fd</span><span class="p">]){</span>
            <span class="n">fileclose</span><span class="p">(</span><span class="n">curproc</span><span class="err">−</span><span class="o">&gt;</span><span class="n">ofile</span><span class="p">[</span><span class="n">fd</span><span class="p">]);</span>
            <span class="n">curproc</span><span class="err">−</span><span class="o">&gt;</span><span class="n">ofile</span><span class="p">[</span><span class="n">fd</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
        <span class="p">}</span>
    <span class="p">}</span>
    <span class="n">begin_op</span><span class="p">();</span>
    <span class="n">iput</span><span class="p">(</span><span class="n">curproc</span><span class="err">−</span><span class="o">&gt;</span><span class="n">cwd</span><span class="p">);</span>
    <span class="n">end_op</span><span class="p">();</span>
    <span class="n">curproc</span><span class="err">−</span><span class="o">&gt;</span><span class="n">cwd</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="n">acquire</span><span class="p">(</span><span class="o">&amp;</span><span class="n">ptable</span><span class="p">.</span><span class="n">lock</span><span class="p">);</span>
    <span class="c1">// Parent might be sleeping in wait().</span>
    <span class="n">wakeup1</span><span class="p">(</span><span class="n">curproc</span><span class="err">−</span><span class="o">&gt;</span><span class="n">parent</span><span class="p">);</span>
    <span class="c1">// Pass abandoned children to init.</span>
    <span class="k">for</span><span class="p">(</span><span class="n">p</span> <span class="o">=</span> <span class="n">ptable</span><span class="p">.</span><span class="n">proc</span><span class="p">;</span> <span class="n">p</span> <span class="o">&lt;</span> <span class="o">&amp;</span><span class="n">ptable</span><span class="p">.</span><span class="n">proc</span><span class="p">[</span><span class="n">NPROC</span><span class="p">];</span> <span class="n">p</span><span class="o">++</span><span class="p">){</span>
        <span class="k">if</span><span class="p">(</span><span class="n">p</span><span class="err">−</span><span class="o">&gt;</span><span class="n">parent</span> <span class="o">==</span> <span class="n">curproc</span><span class="p">){</span>
            <span class="n">p</span><span class="err">−</span><span class="o">&gt;</span><span class="n">parent</span> <span class="o">=</span> <span class="n">initproc</span><span class="p">;</span>
            <span class="k">if</span><span class="p">(</span><span class="n">p</span><span class="err">−</span><span class="o">&gt;</span><span class="n">state</span> <span class="o">==</span> <span class="n">ZOMBIE</span><span class="p">)</span>
                <span class="n">wakeup1</span><span class="p">(</span><span class="n">initproc</span><span class="p">);</span>
        <span class="p">}</span>
    <span class="p">}</span>
    <span class="c1">// Jump into the scheduler, never to return.</span>
    <span class="n">curproc</span><span class="err">−</span><span class="o">&gt;</span><span class="n">state</span> <span class="o">=</span> <span class="n">ZOMBIE</span><span class="p">;</span>
    <span class="c1">// Invoke the scheduler</span>
    <span class="n">sched</span><span class="p">();</span>
    <span class="n">panic</span><span class="p">(</span><span class="s">"zombie exit"</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div></div> <p>Remember, the complete cleanup happens only when a parent reaps the child.</p> <h2 id="wait-system-call">Wait system call</h2> <p>It must be called to clean up the child processes. It searches for dead children in the process table. If found, it cleans up the memory and returns the PID of the dead child. Otherwise, it sleeps until one dies.</p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">int</span>
<span class="nf">wait</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span>
<span class="p">{</span>
    <span class="k">struct</span> <span class="n">proc</span> <span class="o">*</span><span class="n">p</span><span class="p">;</span>
    <span class="kt">int</span> <span class="n">havekids</span><span class="p">,</span> <span class="n">pid</span><span class="p">;</span>
    <span class="k">struct</span> <span class="n">proc</span> <span class="o">*</span><span class="n">curproc</span> <span class="o">=</span> <span class="n">myproc</span><span class="p">();</span>
    <span class="n">acquire</span><span class="p">(</span><span class="o">&amp;</span><span class="n">ptable</span><span class="p">.</span><span class="n">lock</span><span class="p">);</span>
    <span class="k">for</span><span class="p">(;;){</span>
        <span class="c1">// Scan through table looking for exited children.</span>
        <span class="n">havekids</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
        <span class="k">for</span><span class="p">(</span><span class="n">p</span> <span class="o">=</span> <span class="n">ptable</span><span class="p">.</span><span class="n">proc</span><span class="p">;</span> <span class="n">p</span> <span class="o">&lt;</span> <span class="o">&amp;</span><span class="n">ptable</span><span class="p">.</span><span class="n">proc</span><span class="p">[</span><span class="n">NPROC</span><span class="p">];</span> <span class="n">p</span><span class="o">++</span><span class="p">){</span>
            <span class="k">if</span><span class="p">(</span><span class="n">p</span><span class="err">−</span><span class="o">&gt;</span><span class="n">parent</span> <span class="o">!=</span> <span class="n">curproc</span><span class="p">)</span>
                <span class="k">continue</span><span class="p">;</span>
            <span class="n">havekids</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
            <span class="k">if</span><span class="p">(</span><span class="n">p</span><span class="err">−</span><span class="o">&gt;</span><span class="n">state</span> <span class="o">==</span> <span class="n">ZOMBIE</span><span class="p">){</span>
                <span class="c1">// Found one.</span>
                <span class="n">pid</span> <span class="o">=</span> <span class="n">p</span><span class="err">−</span><span class="o">&gt;</span><span class="n">pid</span><span class="p">;</span>
                <span class="n">kfree</span><span class="p">(</span><span class="n">p</span><span class="err">−</span><span class="o">&gt;</span><span class="n">kstack</span><span class="p">);</span>
                <span class="n">p</span><span class="err">−</span><span class="o">&gt;</span><span class="n">kstack</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
                <span class="n">freevm</span><span class="p">(</span><span class="n">p</span><span class="err">−</span><span class="o">&gt;</span><span class="n">pgdir</span><span class="p">);</span>
                <span class="n">p</span><span class="err">−</span><span class="o">&gt;</span><span class="n">pid</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
                <span class="n">p</span><span class="err">−</span><span class="o">&gt;</span><span class="n">parent</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
                <span class="n">p</span><span class="err">−</span><span class="o">&gt;</span><span class="n">name</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
                <span class="n">p</span><span class="err">−</span><span class="o">&gt;</span><span class="n">killed</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
                <span class="n">p</span><span class="err">−</span><span class="o">&gt;</span><span class="n">state</span> <span class="o">=</span> <span class="n">UNUSED</span><span class="p">;</span>
                <span class="n">release</span><span class="p">(</span><span class="o">&amp;</span><span class="n">ptable</span><span class="p">.</span><span class="n">lock</span><span class="p">);</span>
                <span class="k">return</span> <span class="n">pid</span><span class="p">;</span>
            <span class="p">}</span>
        <span class="p">}</span>
        <span class="c1">// No point waiting if we don’t have any children.</span>
        <span class="k">if</span><span class="p">(</span><span class="o">!</span><span class="n">havekids</span> <span class="o">||</span> <span class="n">curproc</span><span class="err">−</span><span class="o">&gt;</span><span class="n">killed</span><span class="p">){</span>
            <span class="n">release</span><span class="p">(</span><span class="o">&amp;</span><span class="n">ptable</span><span class="p">.</span><span class="n">lock</span><span class="p">);</span>
        <span class="k">return</span> <span class="err">−</span><span class="mi">1</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="c1">// Wait for children to exit. (See wakeup1 call in proc_exit.)</span>
    <span class="n">sleep</span><span class="p">(</span><span class="n">curproc</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">ptable</span><span class="p">.</span><span class="n">lock</span><span class="p">);</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div> <h2 id="summary-of-process-management-system-calls-in-xv6">Summary of process management system calls in xv6</h2> <ul> <li>Fork - process marks new child’s <code class="language-plaintext highlighter-rouge">struct proc</code> as <code class="language-plaintext highlighter-rouge">RUNNABLE</code>, initializes child memory image and other states that are needed to run when scheduled</li> <li>Exec - process reinitializes memory image of user, data, stack, heap, and returns to run new code.</li> <li>Exit - process marks itself as <code class="language-plaintext highlighter-rouge">ZOMBIE</code>, cleans up some of its state, and invokes the scheduler</li> <li>Wait - parent finds any <code class="language-plaintext highlighter-rouge">ZOMBIE</code> child and cleans up all its state. IF no dead child is found, it sleeps (marks itself as <code class="language-plaintext highlighter-rouge">SLEEPING</code> and invokes scheduler).</li> </ul> <blockquote> <p>When do we call wait in the parent process?</p> </blockquote> <h1 id="lecture-4---mechanism-of-process-execution">Lecture 4 - Mechanism of process execution</h1> <p>In this lecture, we will learn how an OS runs a process. How it handles system calls, and how it context switches from one process to the other. We are going to understand the low-level mechanisms of these.</p> <h2 id="process-execution">Process Execution</h2> <p>The first thing the OS does is, it allocates memory and create a memory image. It also sets up the program counter and other registers. After the setup, the OS is out of the way, and the process executes directly on the CPU <strong>by itself</strong>.</p> <h2 id="a-simple-function-call">A simple function call</h2> <p>A function call translates to a <strong><code class="language-plaintext highlighter-rouge">jump</code></strong> instruction. A new stack frame is pushed onto the stack, and the stack pointer (SP) is updated. The old value of the PC (return value) is pushed to the stack, and the PC is updated. The stack frame contains return value, function arguments, etc.</p> <h2 id="how-is-a-system-call-different">How is a system call different?</h2> <p>The CPU hardware has multiple privilege levels. The <em>user mode</em> is used to run the user code. OS code like the system calls run in the <em>kernel mode</em>. Some instructions execute only in kernel mode.</p> <p>The kernel does not trust the user stack. It uses a separate kernel stack when in kernel mode. The kernel also does not trust the user-provided addresses. It sets up an <strong><em>Interrupt Descriptor Table (IDT)</em></strong> at boot time. The IDT has addresses of kernel functions to run for system calls and other events.</p> <h2 id="mechanism-of-a-system-call-trap-instruction">Mechanism of a system call: trap instruction</h2> <p>A special trap instruction is run when a system call must be made (usually hidden from the user by libc). The trap instruction initially moves the CPU to a high privilege level. The stack pointer is updated to switch to the kernel stack. Here, the context, such as old PC, registers, etc., is saved. Then, the address of the system call is looked up in the IDT, and the PC jumps to the trap handler function in the OS code.</p> <p>The trap instruction is executed on the hardware in the following cases -</p> <ul> <li>System call - Program needs OS service</li> <li>Program faults - Program does something illegal, e.g., access memory that it doesn’t have access to</li> <li>Interrupt events - External device needs the attention of OS, e.g., a network packet has arrived on the network card.</li> </ul> <p>In all of the cases, the mechanism is the same as described above. The IDT has many entries. The system calls/interrupts store a number in a CPU register before calling trap to identify which IDT entry to use.</p> <p>When the OS is done handling the syscall or interrupt, it calls a special instruction called <strong><code class="language-plaintext highlighter-rouge">return-from-trap</code></strong>. It undoes all the actions done by the trap instruction. It restores the context of CPU registers from the kernel stack. It changes the CPU privilege from kernel mode to user mode, and it restores the PC and jumps to user code after the trap call.</p> <p>The user process is unaware that it was suspended, and it resumes execution as usual.</p> <p>Before returning to the user mode, the OS checks if it has to switch back to the same process or another process. Why do we want to do this? Sometimes when the OS is in kernel mode, it cannot return back to the same process it left. For example, when the original process has exited, it must be terminated (e.g., due to a segfault) or when the process has made a blocking system call. Sometimes, the OS does not want to return back to the same process. Maybe the process has run for a long time, Due to the timesharing responsibility, the OS switches to another process. In such cases, OS is said to perform a <strong><em>context switch</em></strong> to switch from one process to another.</p> <h2 id="os-scheduler">OS scheduler</h2> <p>The OS scheduler is responsible for the context switching mechanism. It has two parts - A policy to pick which process to run and a mechanism to switch to that process. There are two different types of schedulers.</p> <p>A non-preemptive (cooperative) scheduler is polite. It switches only when a process is blocked or terminated. On the other hand, a preemptive (non-cooperative) schedulers can switch even when the process is ready to be continued. The CPU generates a <strong>periodic timer interrupt</strong> to check if a process has run for too long. After servicing an interrupt, a preemptive scheduler switches to another process.</p> <h2 id="mechanism-of-context-switch">Mechanism of context switch</h2> <p>Suppose a process A has moved from the user to kernel mode, and the OS decides it must switch from A to B. Now, the OS’s first job is saving the context (PC, registers, kernel stack pointer) of A on the kernel stack. Then, the kernel stack pointer is switched to B, and B’s context is restored from B’s kernel stack. This context was saved by the OS when it switched out of B in the past. Now, the CPU is running B in kernel mode, <code class="language-plaintext highlighter-rouge">return-from-trap</code> to switch to user mode of B.</p> <h2 id="a-subtlety-on-saving-context">A subtlety on saving context</h2> <p>The context (PC and other registers) of a process is saved on the kernel stack in two different scenarios.</p> <p>When the OS goes from user mode to kernel mode, user context (e.g., which instruction of user code you stopped at) is saved on the kernel stack by the trap instruction. This is later restored using the <code class="language-plaintext highlighter-rouge">return-from-trap</code> instruction. The other scenario where you store the context is during a context switch. The kernel context (e.g., where you stopped in the OS code) of process A is saved on the kernel stack of A by the context-switching code, and B’s context is restored.</p> <h1 id="live-session-2">Live Session 2</h1> <ul> <li> <p>As the shell user, you don’t have to call <code class="language-plaintext highlighter-rouge">fork</code>, <code class="language-plaintext highlighter-rouge">exec</code>, <code class="language-plaintext highlighter-rouge">wait</code> and <code class="language-plaintext highlighter-rouge">exit</code>. The shell automatically takes care of this.</p> </li> <li> <p>The stack pointer’s current location is stored in a general-purpose register before jumping from the user stack to the kernel stack.</p> </li> <li> <p>Why don’t we create an empty system image for a child process? Some instructions (in Windows) require the child to run the parent’s code. We can’t initialize an empty image. There are some advantages to copying the memory image of the parent into the child. The modern OSs utilize copy on demand.</p> <p>When a child is created, the PC points to the instruction after <code class="language-plaintext highlighter-rouge">fork()</code>. This prevents the OS from calling <code class="language-plaintext highlighter-rouge">fork()</code> recursively. <code class="language-plaintext highlighter-rouge">fork()</code> can return \(-1\) instead of the child’s PID if the process creation fails.</p> </li> <li> <p><code class="language-plaintext highlighter-rouge">wait()</code> reaps only a <strong>single</strong> child process. We need to call it again if we need to reap more children. With some variants of <code class="language-plaintext highlighter-rouge">wait()</code>, we can delete a specific child.</p> <p><code class="language-plaintext highlighter-rouge">wait()</code> is designed this way so that the parent knows which child has been reaped. This information is important for later instructions. Returning an array of variable size is not a feasible option.</p> </li> </ul> <h1 id="lecture-24---trap-handling">Lecture 24 - Trap Handling</h1> <p>What is a trap? In certain scenarios, the user programs have to <em>trap</em> into the OS/kernel code. The following events cause a user process to “trap” into the kernel (xv6 refers to these events as traps)</p> <ul> <li>System calls - requests by user for OS services</li> <li>Interrupts - External device wants attention</li> <li>Program fault - Illegal action by a program</li> </ul> <p>When any of the above events happen, the CPU executes the special <em><code class="language-plaintext highlighter-rouge">int</code></em> instruction. The user program is blocked. A trap instruction has a parameter <code class="language-plaintext highlighter-rouge">int n</code>, indicating the type of interrupt. For example, syscall has a different value for \(n\) from a keyboard interrupt.</p> <p>Before the trap instruction is executed, <code class="language-plaintext highlighter-rouge">eip</code> points to the user program instruction, and <code class="language-plaintext highlighter-rouge">esp</code> to user stack. When an interrupt occurs, the CPU executes the following step s as part of the <code class="language-plaintext highlighter-rouge">int n</code> instruction -</p> <ul> <li>Fetch the \(n\)th entry interrupt descriptor table (CPU knows the memory address of IDT)</li> <li>Save stack pointer (<code class="language-plaintext highlighter-rouge">esp</code>) to an internal register</li> <li>Switch <code class="language-plaintext highlighter-rouge">esp</code> to the kernel stack of the process (CPU knows the location of the kernel stack of the current process - <strong><em>task state segment</em></strong>)</li> <li>On the kernel stack, save the old <code class="language-plaintext highlighter-rouge">esp</code>, <code class="language-plaintext highlighter-rouge">eip</code>, etc.</li> <li>Load the new <code class="language-plaintext highlighter-rouge">eip</code> from the IDT, which points to the kernel trap handler.</li> </ul> <p>Now, the OS is ready to run the kernel trap handler code on the process’s kernel stack. Few details have been omitted above -</p> <ul> <li>Stack, code segments (<code class="language-plaintext highlighter-rouge">cs</code>, <code class="language-plaintext highlighter-rouge">ss</code>), and a few other registers are also saved.</li> <li>Permission check of CPU privilege levels in IDT entries. For example, a user code can invoke the IDT entry of a system call but not of a disk interrupt.</li> <li>Suppose an interrupt occurs when the CPU is already handling a previous interrupt. In that case, we don’t have to save the stack pointer again.</li> </ul> <h2 id="why-a-separate-trap-instruction">Why a separate trap instruction?</h2> <p>Why can’t we simply jump to kernel code, like we jump to the code of a function in a function call? The reasons are as follows -</p> <ul> <li>The CPU is executing the user code at a lower privilege level, but the OS code must run at a higher privilege.</li> <li>The user program cannot be trusted to invoke kernel code on its own correctly.</li> <li>Someone needs to change the CPU privilege level and give control to the kernel code.</li> <li>Someone also needs to switch to the secure kernel stack so that the kernel can start saving the state.</li> </ul> <h2 id="trap-frame-on-the-kernel-stack">Trap frame on the kernel stack</h2> <p><strong>Trap frame</strong> refers to the state pushed on the kernel stack during trap handling. This state includes the CPU context of where execution stopped and some extra information needed by the trap handler. The <code class="language-plaintext highlighter-rouge">int n</code> instruction pushes only the bottom few entries of the trap frame. The kernel code pushes the rest.</p> <h2 id="kernel-trap-handler-alltraps">Kernel trap handler (<code class="language-plaintext highlighter-rouge">alltraps</code>)</h2> <p>The IDT entries for all interrupts will set <code class="language-plaintext highlighter-rouge">eip</code> to point to the kernel trap handler <code class="language-plaintext highlighter-rouge">alltraps</code>. The <code class="language-plaintext highlighter-rouge">alltraps</code> assembly code pushes the remaining registers to complete the trap frame on the kernel stack. <code class="language-plaintext highlighter-rouge">pushal</code> pushes all the general-purpose registers. It also invokes the C trap handling function named <code class="language-plaintext highlighter-rouge">trap</code>. The top of the trap frame (current top of the stack - <code class="language-plaintext highlighter-rouge">esp</code>) is given as an argument to the C function.</p> <p>The convention of calling C functions is to push the arguments on to the stack and then call the function.</p> <h2 id="c-trap-handler-function">C trap handler function</h2> <p>The C trap handler performs different actions based on the kind of trap. For example, say we have to execute a system call. The function invokes <code class="language-plaintext highlighter-rouge">int n</code>. The system call number is taken from the register <code class="language-plaintext highlighter-rouge">eax</code> (whether fork, exec, etc.). The return value of the syscall is stored in <code class="language-plaintext highlighter-rouge">eax</code> after execution.</p> <p>Suppose we have an interrupt from a device; the corresponding device-related code is called. The trap number is different for different devices. A timer interrupt is a special hardware interrupt, and it is generated periodically to trap to the kernel. On a timer interrupt, a process <code class="language-plaintext highlighter-rouge">yield</code>s CPU to the scheduler. This interrupt ensures a process does not run for too long.</p> <h2 id="return-from-trap">Return from trap</h2> <p>The values from the kernel stack have to be popped. The return from trap instruction <code class="language-plaintext highlighter-rouge">iret</code> does the opposite of <code class="language-plaintext highlighter-rouge">int</code>. It pops the values and changes the privilege level back to a lower level. Then, the execution of the pre-trap code can resume.</p> <h2 id="summary-of-xv6-trap-handling">Summary of xv6 trap handling</h2> <ul> <li>System calls, program faults, or hardware interrupts cause the CPU to run <code class="language-plaintext highlighter-rouge">int n</code> instruction and “trap” to the OS.</li> <li>The trap instruction causes the CPU to switch <code class="language-plaintext highlighter-rouge">esp</code> to the kernel stack, <code class="language-plaintext highlighter-rouge">eip</code> to the kernel trap handling code.</li> <li>The pre-trap CPU state is saved on the kernel stack in the trap frame. This is done both by the <code class="language-plaintext highlighter-rouge">int</code> instruction and the <code class="language-plaintext highlighter-rouge">alltraps</code> code.</li> <li>The kernel trap handler handles the trap and returns to the pre-trap process.</li> </ul> <h1 id="lecture-25---context-switching">Lecture 25 - Context Switching</h1> <p>Before we understand context switching, we need to understand the concepts related to processes and schedulers in xv6. In xv6, every CPU has a attribute called a <strong>scheduler thread</strong>. It is a special process that runs the scheduler code. The scheduler goes over the list of processes and switches to one of the runnable processes. after running for sometime, the process switches back to the scheduler thread. This can happen in the following 3 ways -</p> <ul> <li>Process has terminated</li> <li>Process needs to sleep</li> <li>Process <em>yields</em> after running for a long time</li> </ul> <p>A context switch only happens when the process is already <strong>in the kernel mode</strong>.</p> <h2 id="scheduler-and-sched">Scheduler and sched</h2> <p>The scheduler switches to a user process in the <code class="language-plaintext highlighter-rouge">scheduler</code> function. User processes switch to the scheduler thread in the <code class="language-plaintext highlighter-rouge">sched</code> function (invoked from <code class="language-plaintext highlighter-rouge">exit</code>, <code class="language-plaintext highlighter-rouge">sleep</code>, <code class="language-plaintext highlighter-rouge">yield</code>).</p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">void</span>
<span class="nf">scheduler</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span>
<span class="p">{</span>
    <span class="k">struct</span> <span class="n">proc</span> <span class="o">*</span><span class="n">p</span><span class="p">;</span>
    <span class="k">struct</span> <span class="n">cpu</span> <span class="o">*</span><span class="n">c</span> <span class="o">=</span> <span class="n">mycpu</span><span class="p">();</span>
    <span class="n">c</span><span class="err">−</span><span class="o">&gt;</span><span class="n">proc</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="k">for</span><span class="p">(;;){</span>
        <span class="c1">// Enable interrupts on this processor.</span>
        <span class="n">sti</span><span class="p">();</span>
        <span class="c1">// Loop over process table looking for process to run.</span>
        <span class="n">acquire</span><span class="p">(</span><span class="o">&amp;</span><span class="n">ptable</span><span class="p">.</span><span class="n">lock</span><span class="p">);</span>
        <span class="k">for</span><span class="p">(</span><span class="n">p</span> <span class="o">=</span> <span class="n">ptable</span><span class="p">.</span><span class="n">proc</span><span class="p">;</span> <span class="n">p</span> <span class="o">&lt;</span> <span class="o">&amp;</span><span class="n">ptable</span><span class="p">.</span><span class="n">proc</span><span class="p">[</span><span class="n">NPROC</span><span class="p">];</span> <span class="n">p</span><span class="o">++</span><span class="p">){</span>
            <span class="k">if</span><span class="p">(</span><span class="n">p</span><span class="err">−</span><span class="o">&gt;</span><span class="n">state</span> <span class="o">!=</span> <span class="n">RUNNABLE</span><span class="p">)</span>
                <span class="k">continue</span><span class="p">;</span>
            <span class="c1">// Switch to chosen process. It is the process’s job</span>
            <span class="c1">// to release ptable.lock and then reacquire it</span>
            <span class="c1">// before jumping back to us.</span>
            <span class="n">c</span><span class="err">−</span><span class="o">&gt;</span><span class="n">proc</span> <span class="o">=</span> <span class="n">p</span><span class="p">;</span>
            <span class="n">switchuvm</span><span class="p">(</span><span class="n">p</span><span class="p">);</span>
            <span class="n">p</span><span class="err">−</span><span class="o">&gt;</span><span class="n">state</span> <span class="o">=</span> <span class="n">RUNNING</span><span class="p">;</span>
            <span class="n">swtch</span><span class="p">(</span><span class="o">&amp;</span><span class="p">(</span><span class="n">c</span><span class="err">−</span><span class="o">&gt;</span><span class="n">scheduler</span><span class="p">),</span> <span class="n">p</span><span class="err">−</span><span class="o">&gt;</span><span class="n">context</span><span class="p">);</span>
            <span class="n">switchkvm</span><span class="p">();</span>
            <span class="c1">// Process is done running for now.</span>
            <span class="c1">// It should have changed its p−&gt;state before coming back.</span>
            <span class="n">c</span><span class="err">−</span><span class="o">&gt;</span><span class="n">proc</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
        <span class="p">}</span>
        <span class="n">release</span><span class="p">(</span><span class="o">&amp;</span><span class="n">ptable</span><span class="p">.</span><span class="n">lock</span><span class="p">);</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div> <p>The <code class="language-plaintext highlighter-rouge">sched</code> function is as follows</p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">void</span>
<span class="nf">sched</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span>
<span class="p">{</span>
    <span class="kt">int</span> <span class="n">intena</span><span class="p">;</span>
    <span class="k">struct</span> <span class="n">proc</span> <span class="o">*</span><span class="n">p</span> <span class="o">=</span> <span class="n">myproc</span><span class="p">();</span>
    <span class="k">if</span><span class="p">(</span><span class="o">!</span><span class="n">holding</span><span class="p">(</span><span class="o">&amp;</span><span class="n">ptable</span><span class="p">.</span><span class="n">lock</span><span class="p">))</span>
    <span class="n">panic</span><span class="p">(</span><span class="s">"sched ptable.lock"</span><span class="p">);</span>
    <span class="k">if</span><span class="p">(</span><span class="n">mycpu</span><span class="p">()</span><span class="err">−</span><span class="o">&gt;</span><span class="n">ncli</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">panic</span><span class="p">(</span><span class="s">"sched locks"</span><span class="p">);</span>
    <span class="k">if</span><span class="p">(</span><span class="n">p</span><span class="err">−</span><span class="o">&gt;</span><span class="n">state</span> <span class="o">==</span> <span class="n">RUNNING</span><span class="p">)</span>
    <span class="n">panic</span><span class="p">(</span><span class="s">"sched running"</span><span class="p">);</span>
    <span class="k">if</span><span class="p">(</span><span class="n">readeflags</span><span class="p">()</span><span class="o">&amp;</span><span class="n">FL_IF</span><span class="p">)</span>
    <span class="n">panic</span><span class="p">(</span><span class="s">"sched interruptible"</span><span class="p">);</span>
    <span class="n">intena</span> <span class="o">=</span> <span class="n">mycpu</span><span class="p">()</span><span class="err">−</span><span class="o">&gt;</span><span class="n">intena</span><span class="p">;</span>
    <span class="n">swtch</span><span class="p">(</span><span class="o">&amp;</span><span class="n">p</span><span class="err">−</span><span class="o">&gt;</span><span class="n">context</span><span class="p">,</span> <span class="n">mycpu</span><span class="p">()</span><span class="err">−</span><span class="o">&gt;</span><span class="n">scheduler</span><span class="p">);</span>
    <span class="n">mycpu</span><span class="p">()</span><span class="err">−</span><span class="o">&gt;</span><span class="n">intena</span> <span class="o">=</span> <span class="n">intena</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div> <p>The high level view is</p> <p><img src="assets/image-20210813235433748.png" alt="image-20210813235433748"></p> <h2 id="when-does-a-process-call-sched">When does a process call <code class="language-plaintext highlighter-rouge">sched</code>?</h2> <p><strong>Yield</strong> - A timer interrupt occurs when a process has run for a long enough time.</p> <p><strong>Exit</strong> - The process has exit and set itself as zombie.</p> <p><strong>Sleep</strong> - A process has performed a blocking action and set itself to sleep.</p> <h2 id="struct-context"><code class="language-plaintext highlighter-rouge">struct context</code></h2> <p>This structure is saved and restored during a context switch. It is basically a set of registers to be saved when switching from one process to another. For example, we must save <code class="language-plaintext highlighter-rouge">eip</code> which signifies where the process has stopped. The context is pushed onto the kernel stack and the <code class="language-plaintext highlighter-rouge">struct proc</code> maintains a pointer to the context structure on the stack.</p> <p>Now, the obvious question is “what is the difference between this and the <a href="#trap-frame-on-the-kernel-stack">trap frame</a>?” We shall look into it now.</p> <h2 id="context-structure-vs-trap-frame">Context structure vs. Trap frame</h2> <p>The trapframe (<code class="language-plaintext highlighter-rouge">p -&gt; tf</code>) is saved when the CPU switches to the kernel mode. For example, <code class="language-plaintext highlighter-rouge">eip</code> in the trapframe is the <code class="language-plaintext highlighter-rouge">eip</code> value where the syscall was made in the user code. On the other hand, the context structure is saved when process switches to another process. For example, <code class="language-plaintext highlighter-rouge">eip</code> value when <code class="language-plaintext highlighter-rouge">swtch</code> is called. Both these structures reside on the kernel stack and <code class="language-plaintext highlighter-rouge">struct proc</code> has pointers to both of them. Although, they differ in the content they store. This sort of clears up the confusion in the <a href="#a-subtlety-on-saving-context">subtlety of memory storage</a> in the kernel stack.</p> <h2 id="swtch-function"> <code class="language-plaintext highlighter-rouge">swtch</code> function</h2> <p>This function is invoked both by the CPU thread and the process. It takes two arguments, the <strong>address of the pointer</strong> of the old context and the pointer of the new context. We are not sending the address of the new context, but the context pointer itself.</p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// When invoked from the scheduler: address of scheduler's context pointer, process context pointer</span>
<span class="n">swtch</span><span class="p">(</span><span class="o">&amp;</span><span class="p">(</span><span class="n">c</span> <span class="o">-&gt;</span> <span class="n">scheduler</span><span class="p">),</span> <span class="n">p</span> <span class="o">-&gt;</span> <span class="n">context</span><span class="p">);</span>
<span class="c1">// When invoked from sched: address of process context pointer, scheduler context pointer</span>
<span class="n">swtch</span><span class="p">(</span><span class="o">&amp;</span><span class="n">p</span> <span class="o">-&gt;</span> <span class="n">context</span><span class="p">,</span> <span class="n">mycpu</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">scheduler</span><span class="p">);</span>

</code></pre></div></div> <p>When a process/thread has invoked the <code class="language-plaintext highlighter-rouge">swtch</code>, the stack has caller save registers and the return address (<code class="language-plaintext highlighter-rouge">eip</code>). <code class="language-plaintext highlighter-rouge">swtch</code> does the following -</p> <ul> <li>Push the remaining (callee save) registers on the old kernel stack.</li> <li>Save the pointer to this context into the context structure pointer of the old process.</li> <li>Switch <code class="language-plaintext highlighter-rouge">esp</code> from the old kernel stack to the new kernel stack.</li> <li> <code class="language-plaintext highlighter-rouge">esp</code> now points to the saved context of new process. This is the primary step of a context switch.</li> <li>Pop the callee-save registers from the new stack.</li> <li>Return from the function call by popping the return address after the callee save registers.</li> </ul> <p>The assembly code of <code class="language-plaintext highlighter-rouge">swtch</code> is as follows -</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Context switch
void swtch(struct context **old, struct context *new);
Save the current registers on the stack, creating
a struct context, and save its address in *old.
Switch stacks to new and pop previously−saved registers.
.globl swtch
swtch:
movl 4(%esp), %eax
movl 8(%esp), %edx
# Save old callee−saved registers
pushl %ebp
pushl %ebx
pushl %esi
pushl %edi
# Switch stacks
# opposite order compared to MIPS
# movl src dst
movl %esp, (%eax)
movl %edx, %esp
# Load new callee−saved registers
popl %edi
popl %esi
popl %ebx
popl %ebp
ret
</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">eax</code> has the address of the pointer to the old context and <code class="language-plaintext highlighter-rouge">edx</code> has the pointer to the new context.</p> <blockquote> <p>Why address of pointer?</p> </blockquote> <h2 id="summary-of-context-switching-in-xv6">Summary of context switching in xv6</h2> <p>The old process, say P1, goes into the kernel mode and gives up the CPU. The new process, say P2, is ready to run. P1 switches to the CPU scheduler thread. The <strong>scheduler thread</strong> finds P2 and switches to it. Then, P2 returns from trap to user mode. The process of switching from one process/thread to another involves the following steps. All the register states (CPU context) on the kernel stack of the old process are saved. The context structure pointer of the old process is updated to this saved context. Then, <code class="language-plaintext highlighter-rouge">esp</code> moves from the old kernel stack to the new kernel stack. Finally, the register states are restored in the new kernel stack to resume the new process.</p> <h1 id="lecture-26---user-process-creation">Lecture 26 - User process creation</h1> <p>We know that the <code class="language-plaintext highlighter-rouge">init</code> process is created when xv6 boots up. The <code class="language-plaintext highlighter-rouge">init</code> process forks a shell process, and the shell is used to spawn any user process. The function <code class="language-plaintext highlighter-rouge">allocproc</code> is called during both <code class="language-plaintext highlighter-rouge">init</code> process creation and in fork system call.</p> <h2 id="allocproc"><code class="language-plaintext highlighter-rouge">allocproc</code></h2> <p>It iterates over the <code class="language-plaintext highlighter-rouge">ptable</code>, finds an unused entry, and marks it as an embryo. This entry is later marked as runnable after the process creation completes. It also allocates a new PID for the process. Then, <code class="language-plaintext highlighter-rouge">allocproc</code> has to allocate space on the kernel stack. To do this, we start from the bottom of the stack and find some free space. We leave room for the trap frame. Then, we push the return address of <code class="language-plaintext highlighter-rouge">trapret</code> and also the context structure with <code class="language-plaintext highlighter-rouge">eip</code> pointing to the function <code class="language-plaintext highlighter-rouge">forkret</code>. When the new process is scheduled, it begins execution at <code class="language-plaintext highlighter-rouge">forkret</code>, returns to <code class="language-plaintext highlighter-rouge">trapret</code>, and finally returns from the trap to the user space.</p> <p>The role of <code class="language-plaintext highlighter-rouge">allocproc</code> is to create a template kernel stack, and make the process look like it had a trap and was context switched out in the past. This is done so that the scheduler can switch to this process like any other.</p> <blockquote> <p>Where is kernel mode? The sp points to the kernel stack.</p> </blockquote> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">allocproc</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span>
<span class="p">{</span>
    <span class="k">struct</span> <span class="n">proc</span> <span class="o">*</span><span class="n">p</span><span class="p">;</span>
    <span class="kt">char</span> <span class="o">*</span><span class="n">sp</span><span class="p">;</span>
    <span class="n">acquire</span><span class="p">(</span><span class="o">&amp;</span><span class="n">ptable</span><span class="p">.</span><span class="n">lock</span><span class="p">);</span>
    <span class="k">for</span><span class="p">(</span><span class="n">p</span> <span class="o">=</span> <span class="n">ptable</span><span class="p">.</span><span class="n">proc</span><span class="p">;</span> <span class="n">p</span> <span class="o">&lt;</span> <span class="o">&amp;</span><span class="n">ptable</span><span class="p">.</span><span class="n">proc</span><span class="p">[</span><span class="n">NPROC</span><span class="p">];</span> <span class="n">p</span><span class="o">++</span><span class="p">)</span>
        <span class="k">if</span><span class="p">(</span><span class="n">p</span><span class="err">−</span><span class="o">&gt;</span><span class="n">state</span> <span class="o">==</span> <span class="n">UNUSED</span><span class="p">)</span>
            <span class="k">goto</span> <span class="n">found</span><span class="p">;</span>
    <span class="n">release</span><span class="p">(</span><span class="o">&amp;</span><span class="n">ptable</span><span class="p">.</span><span class="n">lock</span><span class="p">);</span>
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
    <span class="nl">found:</span>
        <span class="n">p</span><span class="err">−</span><span class="o">&gt;</span><span class="n">state</span> <span class="o">=</span> <span class="n">EMBRYO</span><span class="p">;</span>
        <span class="n">p</span><span class="err">−</span><span class="o">&gt;</span><span class="n">pid</span> <span class="o">=</span> <span class="n">nextpid</span><span class="o">++</span><span class="p">;</span>
        <span class="n">release</span><span class="p">(</span><span class="o">&amp;</span><span class="n">ptable</span><span class="p">.</span><span class="n">lock</span><span class="p">);</span>
        <span class="c1">// Allocate kernel stack.</span>
        <span class="k">if</span><span class="p">((</span><span class="n">p</span><span class="err">−</span><span class="o">&gt;</span><span class="n">kstack</span> <span class="o">=</span> <span class="n">kalloc</span><span class="p">())</span> <span class="o">==</span> <span class="mi">0</span><span class="p">){</span>
            <span class="n">p</span><span class="err">−</span><span class="o">&gt;</span><span class="n">state</span> <span class="o">=</span> <span class="n">UNUSED</span><span class="p">;</span>
            <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
        <span class="p">}</span>
        <span class="n">sp</span> <span class="o">=</span> <span class="n">p</span><span class="err">−</span><span class="o">&gt;</span><span class="n">kstack</span> <span class="o">+</span> <span class="n">KSTACKSIZE</span><span class="p">;</span>
        <span class="c1">// Leave room for trap frame.</span>
        <span class="n">sp</span> <span class="err">−</span><span class="o">=</span> <span class="k">sizeof</span> <span class="o">*</span><span class="n">p</span><span class="err">−</span><span class="o">&gt;</span><span class="n">tf</span><span class="p">;</span>
        <span class="n">p</span><span class="err">−</span><span class="o">&gt;</span><span class="n">tf</span> <span class="o">=</span> <span class="p">(</span><span class="k">struct</span> <span class="n">trapframe</span><span class="o">*</span><span class="p">)</span><span class="n">sp</span><span class="p">;</span>
        <span class="c1">// Set up new context to start executing at forkret,</span>
        <span class="c1">// which returns to trapret.</span>
        <span class="n">sp</span> <span class="err">−</span><span class="o">=</span> <span class="mi">4</span><span class="p">;</span>
        <span class="o">*</span><span class="p">(</span><span class="n">uint</span><span class="o">*</span><span class="p">)</span><span class="n">sp</span> <span class="o">=</span> <span class="p">(</span><span class="n">uint</span><span class="p">)</span><span class="n">trapret</span><span class="p">;</span>
        <span class="n">sp</span> <span class="err">−</span><span class="o">=</span> <span class="k">sizeof</span> <span class="o">*</span><span class="n">p</span><span class="err">−</span><span class="o">&gt;</span><span class="n">context</span><span class="p">;</span>
        <span class="n">p</span><span class="err">−</span><span class="o">&gt;</span><span class="n">context</span> <span class="o">=</span> <span class="p">(</span><span class="k">struct</span> <span class="n">context</span><span class="o">*</span><span class="p">)</span><span class="n">sp</span><span class="p">;</span>
        <span class="n">memset</span><span class="p">(</span><span class="n">p</span><span class="err">−</span><span class="o">&gt;</span><span class="n">context</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="k">sizeof</span> <span class="o">*</span><span class="n">p</span><span class="err">−</span><span class="o">&gt;</span><span class="n">context</span><span class="p">);</span>
        <span class="n">p</span><span class="err">−</span><span class="o">&gt;</span><span class="n">context</span><span class="err">−</span><span class="o">&gt;</span><span class="n">eip</span> <span class="o">=</span> <span class="p">(</span><span class="n">uint</span><span class="p">)</span><span class="n">forkret</span><span class="p">;</span>
        <span class="k">return</span> <span class="n">p</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div> <h2 id="init-process-creation"> <code class="language-plaintext highlighter-rouge">Init</code> process creation</h2> <p>The <code class="language-plaintext highlighter-rouge">userinit</code> function is called to create the <code class="language-plaintext highlighter-rouge">init</code> process. This is also done using the <code class="language-plaintext highlighter-rouge">allocproc</code> function. The trapframe of <code class="language-plaintext highlighter-rouge">init</code> is modified, and the process is set to be runnable. The <code class="language-plaintext highlighter-rouge">init</code> program opens <code class="language-plaintext highlighter-rouge">STDIN</code>, <code class="language-plaintext highlighter-rouge">STDOUT</code> and <code class="language-plaintext highlighter-rouge">STDERR</code> files. These are inherited by all subsequent processes as child inherits parent’s files. It then forks a child, execs shell executable in the child, and waits for the child to die. It also reaps dead children.</p> <h2 id="forking-a-new-process">Forking a new process</h2> <p>Fork allocates a new process via <code class="language-plaintext highlighter-rouge">allocproc</code>. The parent memory image and the file descriptors are copied. Take a look at the <a href="#fork-system-call">fork code</a> while you’re reading this. The trapframe of the child is copied from that of the parent. This allows the child execution to resume from the next instruction after <code class="language-plaintext highlighter-rouge">fork()</code>. Only the return value in <code class="language-plaintext highlighter-rouge">eax</code> is changed so that the child returns its PID. The state of the new child is set to runnable, and the parent returns normally from the trap/system call.</p> <h2 id="summary-of-new-process-creation">Summary of new process creation</h2> <p>New processes are created by marking a new entry in the <code class="language-plaintext highlighter-rouge">ptable</code> as runnable after configuring the kernel stack, memory image etc of the new process. The kernel stack of the new process is made to look like that of a process that had been context switched out in the past.</p> <h1 id="live-session-3">Live Session 3</h1> <ul> <li> <p>What is a scheduler thread? It is a kernel process that is a part of the OS. It always runs in kernel mode, and it is not a user -level process.</p> </li> <li> <p><code class="language-plaintext highlighter-rouge">int n</code> is a hardware instruction and is enabled by a <em>hardware descriptor language</em>. It is similar to, say, the <code class="language-plaintext highlighter-rouge">add</code> instruction. Why is it a hardware instruction? We don’t trust the software. As it is a hardware instruction, we can trust the CPU maker to bake the chip correctly.</p> </li> <li> <p>The <code class="language-plaintext highlighter-rouge">trapframe</code> has the user context, and the context structure has the kernel context. Every context switch is preceded by a trap instruction. A context switch only happens in the kernel mode. Now, what if a user process does not go to the kernel mode ever? The timer interrupt will take care of this. It will prompt the process to go into trap mode if the process has run for too long.</p> </li> <li> <p>In the <a href="#a-subtlety-on-saving-context">subtlety on saving context</a>, the first point refers to storing the trapframe. The second point refers to storing the context structure.</p> </li> <li> <p><code class="language-plaintext highlighter-rouge">forkret</code> is a small function that a program has to execute after a process has been created. This mainly involves the locking mechanism that will be discussed later. <code class="language-plaintext highlighter-rouge">fork</code> is a wrapper of <code class="language-plaintext highlighter-rouge">allocproc</code></p> </li> <li> <p><code class="language-plaintext highlighter-rouge">sched</code> is only called by the user processes in case of <code class="language-plaintext highlighter-rouge">sleep</code>, <code class="language-plaintext highlighter-rouge">exit</code>, and <code class="language-plaintext highlighter-rouge">yield</code>. <code class="language-plaintext highlighter-rouge">sched</code> stores the context of the current context onto the kernel stack. The <code class="language-plaintext highlighter-rouge">scheduler</code> function is called by the scheduler thread to switch to a new process. Both of these functions call the <code class="language-plaintext highlighter-rouge">swtch</code> function to switch the current process. Think of the CPU scheduler (scheduler thread) as an intermediate process that has to be executed when switching from process A to process B.</p> <p>Why do we need this intermediate process? Several operating systems make do without a scheduler thread. This is modular, and xv6 chose this methodology. The <code class="language-plaintext highlighter-rouge">scheduler</code> function simply uses the Round Robin algorithm.</p> </li> </ul> <h1 id="lecture-5---scheduling-policy">Lecture 5 - Scheduling Policy</h1> <p>What is a scheduling policy? It is a program that decides which program to run at a given time from the set of ready processes. The OS scheduler schedules the CPU requests (bursts) of processes. <strong>CPU burst</strong> refers to the CPU time used by a process in a continuous stretch. For example, if a process comes back after an I/O wait, it counts as a fresh CPU burst.</p> <p>Our goal is to maximize CPU utilization, and minimize the <strong>turnaround time</strong> of a process. The turnaround time of a process refers to the time between the process’s arrival and its completion. The scheduling policy must also minimize the average <strong>response time</strong>, from process arrival to the first scheduling. We should also treat all processes fairly and minimize the <strong>overhead</strong>. The amortized cost of a context switch is high.</p> <p>We shall discuss a few scheduling policies and their pros/cons below.</p> <h3 id="first-in-first-out-fifo">First-In-First-Out (FIFO)</h3> <p>Schedule the processes as an when they arrive in the CPU. The drawback of this method is the <strong>convoy effect</strong>. In this situation, a process takes high time to execute and effectively increases the turnaround time.</p> <h3 id="shortest-job-first-sjf">Shortest Job First (SJF)</h3> <p>This is provably optimal when all processes arrive together. Although, this is a non-preemptive policy. Short processes can still be stuck behind the long ones when the long process arrives first.</p> <h3 id="shortest-time-to-completion-first">Shortest Time-to-Completion First</h3> <p>This is a preemptive version of SJF. This policy preempts the running task is the remaining time to execute the process is more than that of the new arrival. This method is also called the Shortest Remaining Time First (SRTF).</p> <blockquote> <p>How do we know the running time/ time left of a process? We schedule processes in bursts! No, that’s wrong! See this</p> <p><img src="/assets/img/Operating%20Systems/image-20210823105421325.png" alt="image-20210823105421325"></p> </blockquote> <h3 id="round-robin-rr">Round Robin (RR)</h3> <p>Every process executes for a fixed quantum slice. The slice is big enough to amortize the cost of a context switch. This policy is also preemptive! It has a good response time and is fair. Although, it may have high turnaround times.</p> <h2 id="schedulers-in-real-systems">Schedulers in Real systems</h2> <p>Real schedulers are more complex. For example, Linux uses a policy called Multi-Level Feedback Queue (MLFQ). You maintain a set of queues and prioritize them. A process is picked from the highest priority queue. Processes in the same priority level are scheduled using a policy like RR. The priority of a queue decays with its age.</p> <h1 id="lecture-6---inter-process-communication-ipc">Lecture 6 - Inter-Process Communication (IPC)</h1> <p>In general, two processes do not share any memory with each other. Some processes might want to work together for a task, and they need to communicate information. The OS provides IPC mechanisms for this purpose.</p> <h2 id="types-of-ipc-mechanisms">Types of IPC mechanisms</h2> <h3 id="shared-memory">Shared Memory</h3> <p>Two processes can get access to the same region of the memory via <code class="language-plaintext highlighter-rouge">shmget()</code> system call.</p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">int</span> <span class="n">shmget</span><span class="p">(</span><span class="n">key_t</span> <span class="n">key</span><span class="p">,</span> <span class="kt">int</span> <span class="n">size</span><span class="p">,</span> <span class="kt">int</span> <span class="n">shmflg</span><span class="p">)</span>
</code></pre></div></div> <p>By providing the same key, two processes can get the same segment of memory.</p> <blockquote> <p>How do they know keys?</p> </blockquote> <p>Although, when realizing this idea, we need to consider some problematic scenarios. For example, we need to take care that one process is not overwriting another’s data.</p> <h3 id="signals">Signals</h3> <p>These are well-defined messages that can be sent to processes that are supported by the OS. Some signals have a fixed meaning. For example, a signal to terminate a process. Some signals can also be user-defined. A signal can be sent to a process by the OS or another process. For example, when you type <code class="language-plaintext highlighter-rouge">Ctrl + C</code>, the OS sends <code class="language-plaintext highlighter-rouge">SIGINT</code> signal to the running process.</p> <p>These signals are handled by a <strong>signal handler</strong>. Every process has a default code to execute for each signal. Some (Can’t edit the terminate signal) of these signal handlers can be overridden to do other things. Although, you cannot send messages/bytes in this method.</p> <h3 id="sockets">Sockets</h3> <p>Sockets can be used for two processes on the same machine or different machines to communicate. For example, TCP/UDP sockets across machines and Unix sockets in a local machine. Processes open sockets and connect them to each other. Messages written into one socket can be read from another. The OS transfers the data across socket buffers.</p> <h3 id="pipes">Pipes</h3> <p>These are similar to sockets but are <strong>half-duplex</strong> - information can travel only in one direction. A pipe system call returns two file descriptors. These are simply <strong>handles</strong> that can read and write into files (read handle and write handle). The data written in one file descriptors can be read through another.</p> <p>In regular pipes, both file descriptors are in the same process. How is this useful? When a parent forks a child process, the child process has access to the same pipe. Now, the parent can use one end of the pipe, and the child can use the other end.</p> <p><strong>Named pipes</strong> can be used to provide two endpoints a pipe to different processes. The pipe data is buffered in OS (kernel) buffers between write and read.</p> <h3 id="message-queues">Message Queues</h3> <p>This is an abstraction of a mailbox. A process can open a mailbox at a specified location and send/receive messages from the mailbox. The OS buffers messages between send and receive.</p> <h2 id="blocking-vs-non-blocking-communication">Blocking vs. non-blocking communication</h2> <p>Some IPC actions can block</p> <ul> <li>reading from a socket/pip that has no data, or reading from an empty message queue</li> <li>Writing to a full socket/pip/message queue</li> </ul> <p>The system calls to read/write have versions that block or can return with an error code in case of a failure.</p> <h1 id="lecture-7---introduction-to-virtual-memory">Lecture 7 - Introduction to Virtual memory</h1> <p>The OS provides a virtualized view of the memory to a user process. Why do we need to do this? Because the real view of memory is messy! In the olden days, the memory had only the code of one running process and the OS code. However, the contemporary memory structure consists of multiple active processes that timeshare the CPU. The memory of a single process need not be contiguous.</p> <p>The OS hides these messy details of the memory and provides a clean abstraction to the user.</p> <h2 id="the-abstraction-virtual-address-space">The Abstraction: (Virtual) Address Space</h2> <p>Every process assumes it has access to a large space of memory from address - to a MAX value. The memory of a process, as we’ve seen earlier, has code (and static data), heap (dynamic allocations), and stack (function calls). Stack and heap of the program grow during <strong>runtime</strong>. The CPU issues “loads” and “stores” to these virtual addresses. For example, when you print the address of a variable in a program, you get the virtual addresses!</p> <h2 id="translation-of-addresses">Translation of addresses</h2> <p>The OS performs the address translation from virtual addresses (VA) to physical addresses (PA) via a memory hardware called <strong>Memory Management Unit (MMU)</strong>. The OS provides the necessary information to this unit. The <em>CPU loads/stores to VA</em>, but the memory hardware accesses PA.</p> <h2 id="example-paging">Example: Paging</h2> <p>This is a technique used in all modern OS. The OS divides the virtual address space into fixed-size <strong>pages</strong>, and similarly, the physical memory is segmented into <strong>frames</strong>. To allocate memory, a <em>page</em> is mapped to a free physical frame. The <strong>page table</strong> stores the mappings from the virtual page number to the physical frame number for a process. The MMU has access to these page tables and uses them to translate VA to PA.</p> <h2 id="goals-of-memory-virtualization">Goals of memory virtualization</h2> <ul> <li>Transparency - The user programs should not be aware of the actual physical addresses.</li> <li>Efficiency - Minimize the overhead and wastage in terms of memory space and access time.</li> <li>Isolation and Protection - A user process should not be able to access anything outside its address space.</li> </ul> <h2 id="how-can-a-user-allocate-memory">How can a user allocate memory?</h2> <p>The OS allocates a set of pages to the memory image of the process. Within this image</p> <ul> <li>Static/global variables are allocated in the executable.</li> <li>Local variables of a function are allocated during runtime on the stack.</li> <li>Dynamic allocation with <code class="language-plaintext highlighter-rouge">malloc</code> on the heap.</li> </ul> <p>Memory allocation is done via system calls under the hood. For example, <code class="language-plaintext highlighter-rouge">malloc</code> is implemented by a C library that has algorithms for efficient memory allocation and free space management.</p> <p>When the program runs out of the initially allocated space, it <em>grows</em> the heap using the <code class="language-plaintext highlighter-rouge">brk/sbrk</code> system call. Unlike <code class="language-plaintext highlighter-rouge">fork</code>, <code class="language-plaintext highlighter-rouge">exec</code>, and <code class="language-plaintext highlighter-rouge">wait</code>, the programmer is discouraged from using these system calls directly in the user code.</p> <p>A program can also allocate a page-sized memory using the <code class="language-plaintext highlighter-rouge">mmap()</code> system call and get an <em>anonymous</em> (empty, will be discussed later) page from the OS.</p> <h2 id="a-subtlety-in-the-address-space-of-the-os">A subtlety in the address space of the OS</h2> <p>Where is the OS code run? OS is not a separate process with its own address space. Instead, the OS code is a part of the address space of every process. A process sees OS as a part of its code! In the background, the OS provides this abstraction. However, in reality, the page tables map the OS addresses to the OS code.</p> <p>Also, the OS needs memory for its data structures. How does it allocate memory for itself? For large allocation, the OS allocates itself a page. For smaller allocations, the OS uses various memory allocation algorithms (will be discussed later). <strong>Note.</strong> The OS cannot use <code class="language-plaintext highlighter-rouge">libc</code> and <code class="language-plaintext highlighter-rouge">malloc</code> in the kernel.</p> <blockquote> <p>Why?</p> </blockquote> <h1 id="live-session-4">Live Session 4</h1> <ul> <li>The scheduler/PC does not always know the running time of the processes. Therefore, we can’t implement SJF and SRTF in practice.</li> <li>The shared key is shared offline (say, via a command-line argument) in the shared memory IPC.</li> <li>Every process has a set of virtual addresses that it can use. <code class="language-plaintext highlighter-rouge">mmap()</code> is used to fetch the free virtual addresses. It is mainly used for allocating <em>large</em> chunks of memory (allocates pages). It can be used to get <em>general memory</em> and not specifically for heap. On the other hand, <code class="language-plaintext highlighter-rouge">brk</code> and <code class="language-plaintext highlighter-rouge">sbrk</code> grow the heap in <em>small</em> chunks. <code class="language-plaintext highlighter-rouge">malloc</code> uses these two system calls for expanding memory.</li> <li>Conceptually, sockets and message queues are the same. The two structures just have a different programming interface.</li> <li> <code class="language-plaintext highlighter-rouge">libc</code> and <code class="language-plaintext highlighter-rouge">malloc</code> can’t be used in the kernel because these are user-space libraries. The kernel has its own versions of these functions. Variants.</li> <li>The C library grows the heap. The OS grows the stack. This is because the heap memory is an abstraction provided by the C libraries. The C library gets a page of memory using <code class="language-plaintext highlighter-rouge">mmap()</code> and provides a small chunk of this page to the user when <code class="language-plaintext highlighter-rouge">malloc()</code> is called. Suppose the stack runs out of the allocated memory. In that case, the OS either allocates new memory and transfers all the content if required or terminates the process for using a lot of memory.</li> </ul> <h1 id="lecture-8---mechanism-of-address-translation">Lecture 8 - Mechanism of Address Translation</h1> <p>Suppose we have written a C program that initializes a variable and adds a constant to it. This code is converted into an assembly code, each instruction having an address. The virtual address space is set up by the OS during process creation.</p> <blockquote> <p>Can we use heap from an assembly code?</p> </blockquote> <p>The OS places the memory images in various chunks (need not be contiguous). However, we shall be considering a simplified version of an OS where the entire memory image is placed in a single chunk. We need the OS to access the physical memory given the virtual address. Also, the OS must detect an error if a program tries to access the memory that is outside the bounds.</p> <h2 id="who-performs-address-translation">Who performs address translation?</h2> <p>In this simple example, the OS can tell the hardware the base and the bound/size values. The MMU calculates PA from VA. The OS is <strong>not involved</strong> in every translation!</p> <p>Basically, the CPU provides a privileged mode of execution. The instruction set has privileged instructions to set translation information (e.g., base, bound). We don’t want the user programs to be able to set this information. Then, the MMU uses this information to perform translation on every memory access. The MMU also generates <em>faults</em> and <em>traps</em> to OS when an access is illegal.</p> <h2 id="role-of-os">Role of OS</h2> <p>What does the OS do? The OS maintains a free list of memory. It allocates spaces to process during creation and cleans up when done. The OS also maintains information of where space is allocated to each process in PCBs. This information is provided to the hardware for translation. Also, the information has to be <strong>updated on context switch</strong> in the MMU. Finally, the OS handles traps due to illegal memory access.</p> <h2 id="segmentation">Segmentation</h2> <p>The base and bound method is a very simple method to store the memory image. Segmentation is a generalized method to store each segment of the memory image separately. For example, the base/bound values of the heap, stack, etc., are stored in the MMU. However, segmentation is not popularly used. Instead, paging is used widely.</p> <p>Segmentation is suitable for sparse address spaces.</p> <blockquote> <p>Stack and heap grow in the physical address space?</p> </blockquote> <p>Although, segmentation uses variable-sized allocation, which leads to <strong>external fragmentation</strong> - small holes in the memory left unused.</p> <h1 id="lecture-9---paging">Lecture 9 - Paging</h1> <p>The memory image of a process is split into fixed-size chunks called <strong>pages</strong>. Each of these pages is mapped to a <strong>physical frame</strong> in the memory. This method avoids external fragmentation. Although, there might be <strong>internal fragmentation</strong>. This is because sometimes the process requires much less memory than the size of a page, but the OS allocates memory in fixed-size pages. However, internal fragmentation is a small problem.</p> <h2 id="page-table-1">Page Table</h2> <p>This is a data structure specific to a process that helps in VA-PA translation. This structure might be as simple as an array storing mappings from virtual page numbers (VPN) to physical frame numbers (PFN). This structure is stored as a part of the OS memory in PCB. The MMU has access to the page tables and uses them for address translation. The OS has to update the page table given to the MMU upon a context switch.</p> <h2 id="page-table-entry-pte">Page Table Entry (PTE)</h2> <p>The most straightforward page table is a linear page table, as discussed above. Each PTE contains PFN and a few other bits</p> <ul> <li>Valid bit - Is this page used by the process?</li> <li>Protection bits - Read/write permissions</li> <li>Present bit - Is this page in memory? (will be discussed later)</li> <li>Dirty bit - Has this page been modified?</li> <li>Accessed bit - Has this page been recently accessed?</li> </ul> <h2 id="address-translation-in-hardware">Address translation in hardware</h2> <p>A virtual address can be separated into VPN and offset. The most significant bits of the VA are the VPN. The page table maps VPN to PFN. Then, PA is obtained from PFN and offset within a page. The MMU stores the (physical) address of the start of the page table, not all the entries. The MMU has to walk to the relevant PTE in the page table.</p> <p>Suppose the CPU requests code/data at a virtual address. Now, the MMU has to access the physical memory to fetch code/data. As you can see, paging adds <em>overhead</em> to memory access. We can reduce this overhead by using a cache for VA-PA mappings. This way, we need not go to the page table for every instruction.</p> <h2 id="translation-lookaside-buffer-tlb">Translation Lookaside Buffer (TLB)</h2> <p>Ignore the name. Basically, it’s a cache of recent VA-PA mappings. To translate VA to PA, the MMU first looks up the TLB. If the TLB misses, the MMU has to walk the page table. TLB misses are expensive (in the case of multiple memory accesses). Therefore, a <strong>locality of reference</strong> helps to have a high hit rate. For example, a program may try to fetch the same data repeatedly in a loop.</p> <p><strong>Note.</strong> TLB entries become invalid on context switch and change of page tables.</p> <blockquote> <p>Page table can change without context switch?</p> </blockquote> <p>Also, this cache is not taken care of by the OS but by the architecture itself.</p> <h2 id="how-are-page-tables-stored-in-the-memory">How are page tables stored in the memory?</h2> <p>A typical page table has 2^20 entries in a 32-bit architecture (32 bit VA) and 4KB pages</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>2^32 (4GB RAM)/ 2^12 (4KB pages)
</code></pre></div></div> <p>If each PTE is 4 bytes, then page table is 4MB! How do we reduce the size of page tables? We can use large pages. Still, it’s a tradeoff.</p> <p>How does the OS allocate memory for such large tables? The page table is itself split into smaller chunks! This is a <strong>multilevel page table</strong>.</p> <h2 id="multilevel-page-tables">Multilevel page tables</h2> <p>A page table is spread over many pages. An “outer” page table or <strong>page directory</strong> tracks the PFNs of the page table pages. If a page directory can’t fit in a single page, we may use more than 2 levels. For example, 64-bit architectures use up to 7 levels!</p> <p>How is the address translation done in this case? The first few bits of the VA identify the outer page table entry. The next few bits are used to index into the next level of PTEs.</p> <p>What about TLB misses? We need to perform multiple access to memory required to access all the levels of page tables. This is a lot of overhead!</p> <h1 id="lecture-10---demand-paging">Lecture 10 - Demand Paging</h1> <p>The main memory may not be enough to store all the page tables of active processes. In such cases, the OS uses a part of the disk (<strong>swap space</strong>) to store pages that are not in active use. Therefore, physical memory is allocated on demand, and this is called demand paging.</p> <h2 id="page-fault">Page Fault</h2> <p>The present bit in the page table entry indicates if a page of a process resides in the main memory or not (swap). When translating from VA to PA, the MMU reads the present bit. If the page is present in the memory, the location is directly accessed. Otherwise, the MMU raises a trap to the OS - <strong>page fault</strong>. (<em>No fault happened, actually</em>).</p> <p>The page fault traps OS and moves CPU to kernel mode like any other system call. Then, the OS fetches the disk address of the page and issues a “read” to the disk. How does the OS know the location of pages on the disk? It keeps track of disk addresses (say, in a page table). The OS context switches to another process, and the current process is blocked.</p> <blockquote> <p>Suppose the CPU context switches from the MMU read from swap to another process. When it comes back to the process, the disk would have fetched the address from the swap. How does the MMU revert back to its previous state? The other process to which the CPU context switched will have used the MMU. -&gt; See the below paragraph</p> </blockquote> <p>Eventually, when the disk read completes, the OS updates the process’s page table and marks the process as ready. When the process is scheduled again, the OS <strong>restarts the instruction</strong> that caused the page fault.</p> <h2 id="summary---memory-access">Summary - Memory Access</h2> <p>The CPU issues a load to a VA for code/data. Before sending a request, the CPU checks its cache first. It goes to the main memory if the cache misses. <strong>Note.</strong> This is not the TLB cache.</p> <p>After the control reaches the main memory, the MMU looks up the TLB for VA. If TLB is hit, the PA is obtained, and the code/data is returned to the CPU. Otherwise, the MMU accesses memory, walks the page table (maybe multiple levels), and obtains the entry.</p> <ul> <li>If the present bit is set in PTE, the memory is accessed. Think about this point carefully. The frame may be present in physical memory or the swap.</li> <li>The MMU raises a page fault if the present bit is not set but is valid access. The OS handles page fault and restarts the CPU load instruction</li> <li>In the case of invalid page access, trap to OS for illegal access.</li> </ul> <h2 id="complications-in-page-faults">Complications in page faults</h2> <p>What does the OS do when servicing a page fault if there is no free page to swap in the faulting page? The OS must swap out an existing page (if modified, i.e., dirty) and then swap in the faulting page. However, this is too much work! To avoid this, the OS may proactively swap out pages to keep the list of free pages. Pages are swapped out based on the <strong>page replacement policy</strong>.</p> <h2 id="page-replacement-policies">Page Replacement policies</h2> <p>The optimal strategy would be to replace a page that is not needed for the longest time in the future. This is not practical. We can use the following policies -</p> <p><strong>FIFO Policy</strong> - Replace the page that was brought into the memory the earliest. However, this may be a popular page.</p> <p><strong>LRU/LFU</strong> - This is commonly used in practical OS. In this policy, we replace the page that was least recently (or frequently) used in the past.</p> <h2 id="example---page-replacement-policy">Example - Page Replacement Policy</h2> <p><img src="/assets/img/Operating%20Systems/image-20210827230153801.png" alt="image-20210827230153801"></p> <p>Suppose we can store only 3 frames in the physical memory, and there are 4 pages in the process. The set of accesses is also known as the <strong>reference string</strong>. Note that the initial few accesses are definitely missed, as the cache is empty - cold misses. The goal is to reduce the number of page faults, which leads to reading from the swap space and is slow.</p> <p><strong>Belady’s anomaly</strong> - The performance of the FIFO may get worse when the memory size increases.</p> <p>The LRU works better as it makes use of the locality of references.</p> <h3 id="how-is-lru-implemented">How is LRU implemented?</h3> <p>The OS is not involved in every memory access.</p> <blockquote> <p>Why?</p> </blockquote> <p>Therefore, the OS does not know which page is the LRU. There is some hardware help and some approximations which help the OS to find the LRU page. The MMU sets a bit in the PTE (<em>accessed</em> bit) when a page is accessed. The OS periodically looks at this bit to estimate pages that are active and inactive.</p> <blockquote> <p>How often does the OS check this? Going through all pages also takes time. Are interrupts used?</p> </blockquote> <p>The OS tries to find a page that does not have the access bit set to replace a page. It can also look for a page with the dirty bit not set to avoid swapping out to disk.</p> <blockquote> <p>If the dirty bit is set, using that page would involve writing to disk. Why?</p> </blockquote> <h1 id="lecture-11---memory-allocation-algorithms">Lecture 11 - Memory Allocation Algorithms</h1> <p>Let us first discuss the problems with variable/dynamic size allocation. This is done from the C library - allocates one or more pages from the kernel via <code class="language-plaintext highlighter-rouge">brk/sbrk</code> <code class="language-plaintext highlighter-rouge">mmap</code> system calls. The user may ask for variable-sized chunks of memory and can arbitrarily free the used memory. The C library and the kernel (for its internal data structures) must take care of all this.</p> <h2 id="variable-sized-allocation---headers">Variable sized allocation - Headers</h2> <p>Consider a simple implementation of <code class="language-plaintext highlighter-rouge">malloc</code>. An available chunk of memory is allocated on request. Every assigned piece has a header with info like chunk size, checksum/some magic number, etc. Why store size? We should know how much memory to free when <code class="language-plaintext highlighter-rouge">free</code> is called.</p> <h2 id="free-list">Free List</h2> <p>How is the free space managed? It is usually handled as a list. The library keeps track of the head of the list. The pointer to the next free chunk is embedded within the current head. Allocations happen from the head.</p> <h2 id="external-fragmentation">External Fragmentation</h2> <p>Suppose 3 allocations of size 100 bytes each happen. Then, the middle chunk pointed to by <code class="language-plaintext highlighter-rouge">sptr</code> is freed. How is the free list updated? It now has two non-contiguous elements. The free space may be scattered around due to fragmentation. Therefore, we cannot satisfy a request for 3800 bytes even though we have free space. This is the primary problem of variable allocation.</p> <p><strong>Note.</strong> The list is updated to account for the newly freed space. That is, the head is revised to point to <code class="language-plaintext highlighter-rouge">sptr</code>, and the list is updated accordingly. Don’t be under the false impression that we are missing out on free space.</p> <h2 id="splitting-and-coalescing">Splitting and Coalescing</h2> <p>Suppose we have a bunch of adjacent free chunks. These chunks may not be adjacent in the list. If we had started out with a big free piece, we might end up with small tangled chunks. We need an algorithm that merged all the contiguous free fragments into a bigger free chunk. We must also be able to split the existing free pieces to satisfy the variable requests.</p> <h3 id="buddy-allocation-for-easy-coalescing">Buddy allocation for easy coalescing</h3> <p>Allocate memory only in sizes of power of 2. This way, 2 adjacent power-of-2 chunks can be merged to form a bigger power-of-2 chunk. That is, buddies can be combined to form bigger pieces.</p> <h2 id="variable-size-allocation-strategies">Variable Size Allocation Strategies</h2> <p><strong>First Fit</strong> - Allocate the first chunk that is sufficient</p> <p><strong>Best Fit</strong> - Allocate the free chunk that is closest in size to the request.</p> <p><strong>Worst Fit</strong> - Allocate the free chunk that is farthest in size. Sounds odd? It’s better sometimes as the remaining free space in the chunk is large and is more usable. For example, the best fit might allocate a 20-byte chunk for a malloc(15), and the worst might give a 100-byte chunk for the same call. Now, the 85-byte free space is more usable than the 5-byte free space.</p> <blockquote> <p>Do we use this in the case of buddy allocation?</p> </blockquote> <h2 id="fixed-size-allocations">Fixed Size allocations</h2> <p>Fixed-size allocations are much simpler as they avoid fragmentation and various other problems. The kernel issues fix <strong>page-sized</strong> allocations. It maintains a free list of pages, and the pointer to the following free page is stored in the current free page itself. What about smaller allocations (e.g., PCB)? The kernel uses a <strong>slab allocator</strong>. It maintains <strong>object caches</strong> for each type of object. Within each cache, only fixed size allocation is done. Each cache is made up of one or more <em>slabs</em>. Within a page, we have fixed size allocations again.</p> <p>Fixed size memory allocators can be used in user programs too. <code class="language-plaintext highlighter-rouge">malloc</code> is a generic memory allocator, but we can use other methods too.</p> <h1 id="live-session-5">Live Session 5</h1> <ul> <li> <p><strong>Dirty bit</strong> -The MMU sets this bit (unlike the present bit and valid bit, which are set by the OS) when the page is recently swapped into the memory. The OS needs this while evicting pages from the memory.</p> <p>Basically, when you swap in a page frame from the disk to the main memory, you <strong>copy-paste</strong> the frame. When the page in the main memory is modified, it is not in sync with the page in the disk. At this point, the MMU <strong>sets</strong> the <strong>dirty bit</strong>.</p> </li> <li> <p>A page can be in</p> <ul> <li>Swap</li> <li>Main Memory</li> <li>Unallocated</li> </ul> <p>Now, note that all of the 4GB memory space need not be allocated.</p> <p>When the address is not allocated at all, the <strong>valid bit</strong> is <strong>unset</strong>. Whenever a virtual address is accessed, and consequently, the memory is allocated (allocated in the main memory), the <strong>valid bit</strong> is set. This memory allocation is triggered by a <strong>page fault</strong>. Initially, the newly allocated memory has the <strong>present bit set</strong> (since we just allocated the memory, we will use it). A page is swapped into the disk when not in active use, and the <strong>present bit</strong> is <strong>unset</strong>.</p> </li> <li> <p>Access bit is <strong>set</strong> whenever a page is accessed. The bit is unset periodically by the OS.</p> </li> <li> <p>The device driver maintains a queue to process multiple reads/writes to the disk.</p> </li> <li> <p>The OS code is mapped into the virtual address space of the processes. It has all the OS information, PCBs, etc. This way, there wouldn’t be much hassle during context switching. The page table of a process also has entries for the OS code.</p> <p>The OS memory inside the process memory can increase. If it takes too much space, the modern OS has some techniques to prevent the OS space from encroaching the process’s memory space.</p> <p>A PTE also has <strong>permission bits</strong> that prevent the user code from accessing the OS code. When the program has to access the OS code, the <strong>trap instruction</strong> switches us into a higher privilege level and moves us into the OS code.</p> <p>After we enter the kernel mode, we still cannot modify the OS code in any way we want. This is because we enter the kernel mode using thoroughly defined system calls.</p> <p>Remember, the <code class="language-plaintext highlighter-rouge">int n</code> instruction is run by the <strong>hardware</strong>.</p> </li> <li> <p>Every time the page table is updated, the TLB has to be updated too. This is done via special instructions.</p> </li> <li> <p>The user code runs natively on the CPU. The OS asks the CPU to execute the instructions sequentially. Then, the OS is out of the picture. All the memory fetches are done via the CPU.</p> <p>Now, you may think, when does the OS actually be involved in the memory access. The OS has to periodically check over the processes (maybe during access bit updates). Even when system calls are made, the OS has a play.</p> </li> <li> <p>There is a hardware register where the address of the page table is stored. The MMU accesses the page table using this address.</p> </li> </ul> <h1 id="lecture-27---virtual-memory--and-paging-in-xv6">Lecture 27 - Virtual Memory and paging in xv6</h1> <p>We have a 32-bits version on xv6; thereby, we have \(2^{32} =\) 4GB virtual address space for every process. The process address space is divided into pages (4KB by default). Every valid <strong>logical</strong> page used by the process is mapped to a physical frame by the OS (no demand paging). There is a single page table entry per page containing the physical frame number (<strong>PFN</strong>) and various flags/permissions for the page.</p> <h2 id="page-table-in-xv6">Page table in xv6</h2> <p>There can be up to \(2^{20}\) page table entries for a process with the properties we have described above. Each PTE has a 20-bit physical frame number and some flags</p> <ul> <li> <code class="language-plaintext highlighter-rouge">PTE_P</code> indicates if a page is present. If not set, access will cause a page fault.</li> <li> <code class="language-plaintext highlighter-rouge">PTE_W</code> indicates if writable. If not set, only reading is permitted</li> <li> <code class="language-plaintext highlighter-rouge">PTE_U</code> indicates if user page. If not set, only the kernel can access the page.</li> </ul> <p>Address translation is done via the page number (top 20 bits of a virtual address) to index into the page table, find the PFN, add a 12-bit offset (for navigating inside the frame).</p> <h2 id="two-level-page-table">Two-level page table</h2> <p>All the \(2^{20}\) entries can’t be stored contiguously. Therefore, the page table in xv6 has two levels. We have \(2^{10}\) <em>inner</em> page tables pages, each with \(2^{10}\) PTEs. The <em>outer</em> page director stores PTE-like references to the \(2^{10}\) inner page tables. The physical address of the outer page directory is stored in the CPU’s <code class="language-plaintext highlighter-rouge">cr3</code> register, which is used by the MMU during address translation.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>A virtual address ’la’ has a three−part structure as follows:
+−−−−−−−−10−−−−−−+−−−−−−−10−−−−−−−+−−−−−−−−−12−−−−−−−−−−+
| Page Directory | Page Table | Offset within Page |
| 	  Index	     |   Index    |					   |
+−−−−−−−−−−−−−−−−+−−−−−−−−−−−−−−−−+−−−−−−−−−−−−−−−−−−−−−+
\−−− PDX(va) −−/ \−−− PTX(va) −−/
</code></pre></div></div> <p>Therefore, we now have 32-bit virtual addresses.</p> <h2 id="process-virtual-address-space-in-xv6">Process virtual address space in xv6</h2> <p>The memory image of a process starting at address 0 has the following: code/data from the executable, <em>fixed</em>-size stack with <strong>guard page</strong> (to prevent overflowing), expandable heap. This is how the user part of the process is organized.</p> <p>The process space also has the kernel code/data beginning at the address <code class="language-plaintext highlighter-rouge">KERNBASE (2GB)</code>. This part contains kernel code/data, free pages maintained by the kernel, and some space reserved for the I/O devices.</p> <p>The page table of a process contains two sets of PTEs.</p> <ul> <li>The user entries map low virtual addresses to the physical memory sued by the process for its code/data/stack/heap.</li> <li>The kernel entries map high virtual addresses to physical memory containing OS code and data structures. These entries are identical across all processes.</li> </ul> <p>A process can only access memory mapped by its own page table.</p> <h2 id="os-page-table-mappings">OS page table mappings</h2> <p>The OS code/data structures are a part of the virtual address space of every process. The page table entries map high virtual addresses (2GB to 2GB + <code class="language-plaintext highlighter-rouge">PHYSTOP</code>) to OS code/data in physical memory (~0 to <code class="language-plaintext highlighter-rouge">PHYSTOP</code>). This part contains the kernel code/data, I/O devices, and primarily free pages. Note that there is only a single copy of OS code in memory, mapped into all process page tables.</p> <p>Can’t we directly access the OS code using its physical address? No. With paging and MMU, the physical memory can only be accessed by assigning a virtual address. During a trap, the same page table can be used to access the kernel. If the OS is not a part of the virtual address space, we would have had to use a new page table during trap which is cumbersome (?).</p> <p>Some of the aforementioned free pages in the OS memory are assigned to processes. Suppose a physical frame P is initially mapped into the kernel part of the address space at virtual address V ( we will have V = P + <code class="language-plaintext highlighter-rouge">KERNBASE</code>). When assigned to a user process, this piece of memory is assigned another virtual address U (&lt; <code class="language-plaintext highlighter-rouge">KERNBASE</code>). This is because a user cannot utilize this free page unless the PTE is in the userspace. Hence, the same frame P is mapped twice into the page table! The kernel and user access the same memory using different virtual addresses.</p> <blockquote> <p>What is going on above?</p> </blockquote> <p>Every byte of RAM can consume 2 bytes of virtual address space, so xv6 cannot use more than 2GB of RAM. Actual kernels deal with this better. For example, the kernel page is deleted when a user page is created.</p> <h2 id="maintaining-free-memory">Maintaining free memory</h2> <p>After bootup, RAM contains the OS code/data and free pages. The OS collects all the free pages into a free list called <code class="language-plaintext highlighter-rouge">run</code> to be assigned to the user processes. This free list is a linked list, and the pointer to the next free page is embedded within the previous free page.</p> <p>Any process that needs a free page uses <code class="language-plaintext highlighter-rouge">kalloc()</code> to get a free page. Memory is freed up using <code class="language-plaintext highlighter-rouge">kfree()</code>. We need to add the free page to the head of the free list and update the free list pointer. Take a look at the codes for this part.</p> <h2 id="summary-of-virtual-memory-in-xv6">Summary of virtual memory in xv6</h2> <p>xv6 only has virtual addressing, no demand paging. There is a 2 tier page table, outer <code class="language-plaintext highlighter-rouge">pgdir</code>, and inner pages tables. The process address space has</p> <ul> <li>User memory image at low virtual addresses</li> <li>Kernel code/data mapped at high virtual addresses.</li> </ul> <h1 id="lecture-28---memory-management-of-user-processes-in-xv6">Lecture 28 - Memory Management of user processes in xv6</h1> <p>The user process needs memory pages to build its address space. Every process requires memory for memory image and page table. The free list of the kernel allocates this memory using <code class="language-plaintext highlighter-rouge">kalloc</code>. The new virtual address space for a process is created during <code class="language-plaintext highlighter-rouge">init</code> process creation, <code class="language-plaintext highlighter-rouge">fork</code> system call, and <code class="language-plaintext highlighter-rouge">exec</code> system call. The existing virtual address space is modified using the <code class="language-plaintext highlighter-rouge">sbrk</code> system call (to expand heap). The page table is constructed in the following manner:</p> <ul> <li>We start with a single page for the outer page directory</li> <li>We allocate inner page tables as and when needed.</li> </ul> <h2 id="functions-to-build-page-table">Functions to build page table</h2> <p>Every page table begins setting up the kernel mappings in <code class="language-plaintext highlighter-rouge">setupkvm</code>. The outer <code class="language-plaintext highlighter-rouge">pgdir</code> is allocated. The kernel mappings defined in <code class="language-plaintext highlighter-rouge">kmap</code> are added to the page table by calling <code class="language-plaintext highlighter-rouge">mappages</code>. After <code class="language-plaintext highlighter-rouge">setupkvm</code>, user page table mappings are added.</p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// This table defines the kernel’s mappings, which are present in</span>
<span class="c1">// every process’s page table.</span>
<span class="k">static</span> <span class="k">struct</span> <span class="n">kmap</span> <span class="p">{</span>
    <span class="kt">void</span> <span class="o">*</span><span class="n">virt</span><span class="p">;</span>
    <span class="n">uint</span> <span class="n">phys_start</span><span class="p">;</span>
    <span class="n">uint</span> <span class="n">phys_end</span><span class="p">;</span>
    <span class="kt">int</span> <span class="n">perm</span><span class="p">;</span>
<span class="p">}</span> <span class="n">kmap</span><span class="p">[]</span> <span class="o">=</span> <span class="p">{</span>
    <span class="p">{</span> <span class="p">(</span><span class="kt">void</span><span class="o">*</span><span class="p">)</span><span class="n">KERNBASE</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span>	<span class="n">EXTMEM</span><span class="p">,</span> 	<span class="n">PTE_W</span><span class="p">},</span> <span class="c1">// I/O space</span>
    <span class="p">{</span> <span class="p">(</span><span class="kt">void</span><span class="o">*</span><span class="p">)</span><span class="n">KERNLINK</span><span class="p">,</span> <span class="n">V2P</span><span class="p">(</span><span class="n">KERNLINK</span><span class="p">),</span>	<span class="n">V2P</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> 	<span class="mi">0</span><span class="p">},</span> <span class="c1">// kern text + rodata</span>
    <span class="p">{</span> <span class="p">(</span><span class="kt">void</span><span class="o">*</span><span class="p">)</span><span class="n">data</span><span class="p">,</span>	<span class="n">V2P</span><span class="p">(</span><span class="n">data</span><span class="p">),</span>	<span class="n">PHYSTOP</span><span class="p">,</span> 	<span class="n">PTE_W</span><span class="p">},</span> <span class="c1">// kern data + memory</span>
    <span class="p">{</span> <span class="p">(</span><span class="kt">void</span><span class="o">*</span><span class="p">)</span><span class="n">DEVSPACE</span><span class="p">,</span> <span class="n">DEVSPACE</span><span class="p">,</span>	<span class="mi">0</span><span class="p">,</span> 	<span class="n">PTE_W</span><span class="p">},</span> <span class="c1">// more devices</span>
<span class="p">};</span>

<span class="c1">// Set up kernel part of a page table.</span>
<span class="n">pde_t</span><span class="o">*</span>
<span class="nf">setupkvm</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span>
<span class="p">{</span>
    <span class="n">pde_t</span> <span class="o">*</span><span class="n">pgdir</span><span class="p">;</span>
    <span class="k">struct</span> <span class="n">kmap</span> <span class="o">*</span><span class="n">k</span><span class="p">;</span>
    <span class="k">if</span><span class="p">((</span><span class="n">pgdir</span> <span class="o">=</span> <span class="p">(</span><span class="n">pde_t</span><span class="o">*</span><span class="p">)</span><span class="n">kalloc</span><span class="p">())</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
        <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
    <span class="n">memset</span><span class="p">(</span><span class="n">pgdir</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">PGSIZE</span><span class="p">);</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">P2V</span><span class="p">(</span><span class="n">PHYSTOP</span><span class="p">)</span> <span class="o">&gt;</span> <span class="p">(</span><span class="kt">void</span><span class="o">*</span><span class="p">)</span><span class="n">DEVSPACE</span><span class="p">)</span>
        <span class="n">panic</span><span class="p">(</span><span class="s">"PHYSTOP too high"</span><span class="p">);</span>
    <span class="k">for</span><span class="p">(</span><span class="n">k</span> <span class="o">=</span> <span class="n">kmap</span><span class="p">;</span> <span class="n">k</span> <span class="o">&lt;</span> <span class="o">&amp;</span><span class="n">kmap</span><span class="p">[</span><span class="n">NELEM</span><span class="p">(</span><span class="n">kmap</span><span class="p">)];</span> <span class="n">k</span><span class="o">++</span><span class="p">)</span>
        <span class="k">if</span><span class="p">(</span><span class="n">mappages</span><span class="p">(</span><span class="n">pgdir</span><span class="p">,</span> <span class="n">k</span><span class="err">−</span><span class="o">&gt;</span><span class="n">virt</span><span class="p">,</span> <span class="n">k</span><span class="err">−</span><span class="o">&gt;</span><span class="n">phys_end</span> <span class="err">−</span> <span class="n">k</span><span class="err">−</span><span class="o">&gt;</span><span class="n">phys_start</span><span class="p">,</span>
        <span class="p">(</span><span class="n">uint</span><span class="p">)</span><span class="n">k</span><span class="err">−</span><span class="o">&gt;</span><span class="n">phys_start</span><span class="p">,</span> <span class="n">k</span><span class="err">−</span><span class="o">&gt;</span><span class="n">perm</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
            <span class="n">freevm</span><span class="p">(</span><span class="n">pgdir</span><span class="p">);</span>
            <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
        <span class="p">}</span>
    <span class="k">return</span> <span class="n">pgdir</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div> <p>The page table entries are added by <code class="language-plaintext highlighter-rouge">mappages</code>. The arguments are page directory, range of virtual addresses, physical addresses to map to, and permissions of the pages. This function walks the page table for each page, gets the pointer to PTE via the function <code class="language-plaintext highlighter-rouge">walkpgdir</code>, and fills it with physical address and permissions. The function <code class="language-plaintext highlighter-rouge">walkpgdir</code> walks the page table and returns the PTE of a virtual address.</p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// Return the address of the PTE in page table pgdir</span>
<span class="c1">// that corresponds to virtual address va. If alloc!=0,</span>
<span class="c1">// create any required page table pages.</span>
<span class="k">static</span> <span class="n">pte_t</span> <span class="o">*</span>
<span class="nf">walkpgdir</span><span class="p">(</span><span class="n">pde_t</span> <span class="o">*</span><span class="n">pgdir</span><span class="p">,</span> <span class="k">const</span> <span class="kt">void</span> <span class="o">*</span><span class="n">va</span><span class="p">,</span> <span class="kt">int</span> <span class="n">alloc</span><span class="p">)</span>
<span class="p">{</span>
    <span class="n">pde_t</span> <span class="o">*</span><span class="n">pde</span><span class="p">;</span>
    <span class="n">pte_t</span> <span class="o">*</span><span class="n">pgtab</span><span class="p">;</span>
    <span class="n">pde</span> <span class="o">=</span> <span class="o">&amp;</span><span class="n">pgdir</span><span class="p">[</span><span class="n">PDX</span><span class="p">(</span><span class="n">va</span><span class="p">)];</span>
    <span class="k">if</span><span class="p">(</span><span class="o">*</span><span class="n">pde</span> <span class="o">&amp;</span> <span class="n">PTE_P</span><span class="p">){</span>
        <span class="n">pgtab</span> <span class="o">=</span> <span class="p">(</span><span class="n">pte_t</span><span class="o">*</span><span class="p">)</span><span class="n">P2V</span><span class="p">(</span><span class="n">PTE_ADDR</span><span class="p">(</span><span class="o">*</span><span class="n">pde</span><span class="p">));</span>
    <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
        <span class="k">if</span><span class="p">(</span><span class="o">!</span><span class="n">alloc</span> <span class="o">||</span> <span class="p">(</span><span class="n">pgtab</span> <span class="o">=</span> <span class="p">(</span><span class="n">pte_t</span><span class="o">*</span><span class="p">)</span><span class="n">kalloc</span><span class="p">())</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
            <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
        <span class="c1">// Make sure all those PTE_P bits are zero.</span>
        <span class="n">memset</span><span class="p">(</span><span class="n">pgtab</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">PGSIZE</span><span class="p">);</span>
        <span class="c1">// The permissions here are overly generous, but they can</span>
        <span class="c1">// be further restricted by the permissions in the page table</span>
        <span class="c1">// entries, if necessary.</span>
        <span class="o">*</span><span class="n">pde</span> <span class="o">=</span> <span class="n">V2P</span><span class="p">(</span><span class="n">pgtab</span><span class="p">)</span> <span class="o">|</span> <span class="n">PTE_P</span> <span class="o">|</span> <span class="n">PTE_W</span> <span class="o">|</span> <span class="n">PTE_U</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="k">return</span> <span class="o">&amp;</span><span class="n">pgtab</span><span class="p">[</span><span class="n">PTX</span><span class="p">(</span><span class="n">va</span><span class="p">)];</span>
<span class="p">}</span>
<span class="c1">// Create PTEs for virtual addresses starting at va that refer to</span>
<span class="c1">// physical addresses starting at pa. va and size might not</span>
<span class="c1">// be page−aligned.</span>
<span class="k">static</span> <span class="kt">int</span>
<span class="nf">mappages</span><span class="p">(</span><span class="n">pde_t</span> <span class="o">*</span><span class="n">pgdir</span><span class="p">,</span> <span class="kt">void</span> <span class="o">*</span><span class="n">va</span><span class="p">,</span> <span class="n">uint</span> <span class="n">size</span><span class="p">,</span> <span class="n">uint</span> <span class="n">pa</span><span class="p">,</span> <span class="kt">int</span> <span class="n">perm</span><span class="p">)</span>
<span class="p">{</span>
    <span class="kt">char</span> <span class="o">*</span><span class="n">a</span><span class="p">,</span> <span class="o">*</span><span class="n">last</span><span class="p">;</span>
    <span class="n">pte_t</span> <span class="o">*</span><span class="n">pte</span><span class="p">;</span>
    <span class="n">a</span> <span class="o">=</span> <span class="p">(</span><span class="kt">char</span><span class="o">*</span><span class="p">)</span><span class="n">PGROUNDDOWN</span><span class="p">((</span><span class="n">uint</span><span class="p">)</span><span class="n">va</span><span class="p">);</span>
    <span class="n">last</span> <span class="o">=</span> <span class="p">(</span><span class="kt">char</span><span class="o">*</span><span class="p">)</span><span class="n">PGROUNDDOWN</span><span class="p">(((</span><span class="n">uint</span><span class="p">)</span><span class="n">va</span><span class="p">)</span> <span class="o">+</span> <span class="n">size</span> <span class="err">−</span> <span class="mi">1</span><span class="p">);</span>
    <span class="k">for</span><span class="p">(;;){</span>
        <span class="k">if</span><span class="p">((</span><span class="n">pte</span> <span class="o">=</span> <span class="n">walkpgdir</span><span class="p">(</span><span class="n">pgdir</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
            <span class="k">return</span> <span class="err">−</span><span class="mi">1</span><span class="p">;</span>
        <span class="k">if</span><span class="p">(</span><span class="o">*</span><span class="n">pte</span> <span class="o">&amp;</span> <span class="n">PTE_P</span><span class="p">)</span>
            <span class="n">panic</span><span class="p">(</span><span class="s">"remap"</span><span class="p">);</span>
        <span class="o">*</span><span class="n">pte</span> <span class="o">=</span> <span class="n">pa</span> <span class="o">|</span> <span class="n">perm</span> <span class="o">|</span> <span class="n">PTE_P</span><span class="p">;</span>
        <span class="k">if</span><span class="p">(</span><span class="n">a</span> <span class="o">==</span> <span class="n">last</span><span class="p">)</span>
            <span class="k">break</span><span class="p">;</span>
        <span class="n">a</span> <span class="o">+=</span> <span class="n">PGSIZE</span><span class="p">;</span>
        <span class="n">pa</span> <span class="o">+=</span> <span class="n">PGSIZE</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div> <h2 id="fork-copying-the-memory-image">Fork: copying the memory image</h2> <p>The <code class="language-plaintext highlighter-rouge">copyuvm</code> function is called by the parent to copy the parent’s memory image to the child. Check out <code class="language-plaintext highlighter-rouge">fork</code>’s code <a href="#fork-system-call">here</a>. This function starts out by creating a new page table for the child. Then, it has to walk through the parent’s memory image page by page and copy it to the child while adding the child page table mappings.</p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">copyuvm</span><span class="p">(</span><span class="n">pde_t</span> <span class="o">*</span><span class="n">pgdir</span><span class="p">,</span> <span class="n">uint</span> <span class="n">sz</span><span class="p">)</span>
<span class="p">{</span>
    <span class="n">pde_t</span> <span class="o">*</span><span class="n">d</span><span class="p">;</span>
    <span class="n">pte_t</span> <span class="o">*</span><span class="n">pte</span><span class="p">;</span>
    <span class="n">uint</span> <span class="n">pa</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">flags</span><span class="p">;</span>
    <span class="kt">char</span> <span class="o">*</span><span class="n">mem</span><span class="p">;</span>
    <span class="k">if</span><span class="p">((</span><span class="n">d</span> <span class="o">=</span> <span class="n">setupkvm</span><span class="p">())</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
        <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
    <span class="k">for</span><span class="p">(</span><span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">sz</span><span class="p">;</span> <span class="n">i</span> <span class="o">+=</span> <span class="n">PGSIZE</span><span class="p">){</span>
        <span class="k">if</span><span class="p">((</span><span class="n">pte</span> <span class="o">=</span> <span class="n">walkpgdir</span><span class="p">(</span><span class="n">pgdir</span><span class="p">,</span> <span class="p">(</span><span class="kt">void</span> <span class="o">*</span><span class="p">)</span> <span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
            <span class="n">panic</span><span class="p">(</span><span class="s">"copyuvm: pte should exist"</span><span class="p">);</span>
        <span class="k">if</span><span class="p">(</span><span class="o">!</span><span class="p">(</span><span class="o">*</span><span class="n">pte</span> <span class="o">&amp;</span> <span class="n">PTE_P</span><span class="p">))</span>
            <span class="n">panic</span><span class="p">(</span><span class="s">"copyuvm: page not present"</span><span class="p">);</span>
        <span class="n">pa</span> <span class="o">=</span> <span class="n">PTE_ADDR</span><span class="p">(</span><span class="o">*</span><span class="n">pte</span><span class="p">);</span>
        <span class="n">flags</span> <span class="o">=</span> <span class="n">PTE_FLAGS</span><span class="p">(</span><span class="o">*</span><span class="n">pte</span><span class="p">);</span>
        <span class="k">if</span><span class="p">((</span><span class="n">mem</span> <span class="o">=</span> <span class="n">kalloc</span><span class="p">())</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
            <span class="k">goto</span> <span class="n">bad</span><span class="p">;</span>
        <span class="n">memmove</span><span class="p">(</span><span class="n">mem</span><span class="p">,</span> <span class="p">(</span><span class="kt">char</span><span class="o">*</span><span class="p">)</span><span class="n">P2V</span><span class="p">(</span><span class="n">pa</span><span class="p">),</span> <span class="n">PGSIZE</span><span class="p">);</span>
        <span class="k">if</span><span class="p">(</span><span class="n">mappages</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="p">(</span><span class="kt">void</span><span class="o">*</span><span class="p">)</span><span class="n">i</span><span class="p">,</span> <span class="n">PGSIZE</span><span class="p">,</span> <span class="n">V2P</span><span class="p">(</span><span class="n">mem</span><span class="p">),</span> <span class="n">flags</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
            <span class="n">kfree</span><span class="p">(</span><span class="n">mem</span><span class="p">);</span>
            <span class="k">goto</span> <span class="n">bad</span><span class="p">;</span>
        <span class="p">}</span>
    <span class="p">}</span>
    <span class="k">return</span> <span class="n">d</span><span class="p">;</span>
    <span class="nl">bad:</span>
        <span class="n">freevm</span><span class="p">(</span><span class="n">d</span><span class="p">);</span>
        <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div> <p>For each page in the parent,</p> <ul> <li>We fetch the PTE and gets its physical address and permissions</li> <li>We allocate a new page for the child and copy the parent’s page’s contents to the child’s new page.</li> <li>Then, we add a PTE from the virtual address to the physical address of the new page in the child page table.</li> </ul> <p>Real operating systems do copy-on-write fork - The child page table also points to the parent pages until either of them modifies the pages. Here, xv6 creates separate memory images for the parent and the child right away.</p> <h2 id="growing-memory-image---sbrk">Growing memory image - <code class="language-plaintext highlighter-rouge">sbrk</code> </h2> <p>Initially, the heap of a process is empty, and the program <em>break</em> is at the end of the stack. The <code class="language-plaintext highlighter-rouge">sbrk</code> system call is invoked by <code class="language-plaintext highlighter-rouge">malloc</code> to expand the heap. The <code class="language-plaintext highlighter-rouge">allocuvm</code> allocates new pages and adds mappings into the page table for the new pages to grow memory. Whenever the page table is updated, we must update the <code class="language-plaintext highlighter-rouge">cr3</code> register and TLB (using <code class="language-plaintext highlighter-rouge">switchuvm</code>).</p> <p>The <code class="language-plaintext highlighter-rouge">allocuvm</code> function walks through the new virtual addresses to be added in the page-sized chunks.</p> <h2 id="exec-system-call-1">Exec System call</h2> <p>Refer to the code in xv6 documentation. It reads the ELF (the new executable) binary file from the disk into memory. It starts with a new page table and adds mappings to the new executable pages to grow the virtual address space. So far, it hasn’t overwritten the old page table. Once the executable is copied to the memory image, we allocate 2 pages for stack (1 for guard page whose permissions are cleared, and upon accessing will trap). All the <code class="language-plaintext highlighter-rouge">exec</code> arguments are pushed on the user stack for the main function of the new program.</p> <p>If no errors have occurred so far, we switch to the new page table. We set <code class="language-plaintext highlighter-rouge">eip</code> in trapframe to start at the entry point of the new program.</p> <h1 id="live-session-6">Live Session 6</h1> <ul> <li> <p>Why do we have <code class="language-plaintext highlighter-rouge">walkpgdir</code> in <code class="language-plaintext highlighter-rouge">copyuvm</code>? <del>Aren’t page tables contiguous? Self-answered: The <code class="language-plaintext highlighter-rouge">copyuvm</code> function copies entire pages. The <code class="language-plaintext highlighter-rouge">walkpgdir</code> is only for the outer page directory.</del></p> <p><code class="language-plaintext highlighter-rouge">walkpgdir</code> simply returns the PFN of the input VPN, and allocates a new inner page if necessary. Therefore, there is no redundancy!</p> </li> <li> <p>Why is the kernel allocation memory from its free pages to the user processes? The purpose of double mapping in virtual space.</p> <p>Think of it this way. The true RAM of your computer is only from <code class="language-plaintext highlighter-rouge">0</code> to <code class="language-plaintext highlighter-rouge">PHYSTOP</code>. Every piece of allocated memory comes from <code class="language-plaintext highlighter-rouge">0</code> to <code class="language-plaintext highlighter-rouge">PHYSTOP</code>, and this maps to both kernel and user part of the memory image of a process. Yes, it’s naive! Modern Operating systems have other optimizations.</p> </li> <li> <p>In line 2600 of <code class="language-plaintext highlighter-rouge">fork</code> system call, why do we copy trapframe again? <code class="language-plaintext highlighter-rouge">uvm</code> in <code class="language-plaintext highlighter-rouge">copyuvm</code> means user virtual memory. This function only copies the user part of the memory. The kernel stack and other structures are built using <code class="language-plaintext highlighter-rouge">allocproc</code>. You have to manually copy the <code class="language-plaintext highlighter-rouge">struct proc</code> data or any other kernel data for that matter.</p> </li> <li> <p><strong>Note</strong>. A process can think it has \(1\)TB of memory too! The present bit takes care of this.</p> </li> <li> <p>The OS does not take part in every memory access. Why?</p> <p>The OS is only in play when the process is being initialised, page faults, or when it is being context switched. Otherwise, the MMU + TLB take care of the address translations. Therefore, the MMU also needs to perform checks on the virtual address and ensure the query is not invalid.</p> </li> </ul> <h1 id="lecture-12---threads-and-concurrency">Lecture 12 - Threads and Concurrency</h1> <p>So far, we have studied <strong>single-threaded</strong> programs. That is, there is only a single thread of execution. When a given memory image is being executed in the memory, there is only a single <em>execution flow</em>. A program can also have multiple threads of execution.</p> <p>Firstly, what is a <strong>thread</strong>? A thread is like another copy of a process that executes independently. In a multi-threaded program, we have multiple threads of execution. For example, a 2-thread process will have 2 PCs and 2 SPs. Threads share the same address space. However, each thread has a separate PC to run over different parts of the program simultaneously. Each thread also has a separate stack for independent function calls.</p> <h2 id="process-vs-thread">Process vs. Thread</h2> <p>When a parent process P forks a child C, P and C do not share any memory. They need complicated <a href="#lecture-6---inter-process-communication-ipc">IPC mechanisms</a>. If we want to transfer data while running different parts of the process simultaneously, we need extra copies of code and data in memory. It’s very complicated to handle simultaneous execution using processes.</p> <p>However, if a parent P executes two threads T1 and T2, they share parts of the address space. The process can use global variables for communication. This method also has a smaller memory footprint.</p> <p>In conclusion, threads are like separate processes, except they use the same address space.</p> <h2 id="why-threads">Why threads?</h2> <p>Why do we want to run different parts of the same program simultaneously? <strong>Parallelism</strong> - A single process can effectively utilize multiple CPU cores. There is a difference between <strong>concurrency</strong> and <strong>parallelism</strong>.</p> <ul> <li>Concurrency - Running multiple threads/ processes in tandem, even on a single CPU core, by interleaving their executions. Basically, all the stuff we’ve learned in the single thread execution.</li> <li>Parallelism - Running multiple threads/processes in parallel over different CPU cores.</li> </ul> <p>We can exploit parallelism using multiple threads. Even if there is no scope for parallelism, concurrently running threads ensures effective use of CPU when one of the thread blocks.</p> <h2 id="scheduling-threads">Scheduling threads</h2> <p>The OS schedules threads that are ready to run independently, much like processes. The context of a thread (PC, registers) is saved into/ restored from a <strong><em>thread control block (TCB)</em></strong>. Every PCB has one or more linked TCBs. Threads that are scheduled independently by the kernel are called <strong>kernel threads</strong>. For example, Linux <code class="language-plaintext highlighter-rouge">pthreads</code> are kernel threads.</p> <blockquote> <p>What are kernel threads?</p> </blockquote> <p>In contrast, some libraries provide user-level threads. These are not very common. This fact implies that not all threads are kernel threads. The library multiplexes a larger number of user threads over a smaller number of kernel threads. The kernel of the process sees these threads as separate processes. Also, note switching between user threads has a low overhead (nothing like context switching). However, multiple user threads cannot be run in parallel. Therefore, user threads are not very useful.</p> <blockquote> <p>What is going on in the above paragraph?</p> </blockquote> <h2 id="creating-threads-using-pthreads-api">Creating threads using <code class="language-plaintext highlighter-rouge">pthreads</code> API</h2> <p>Here is a simple thread creating code.</p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp"># include &lt;pthread.h&gt;
</span><span class="kt">int</span> <span class="nf">main</span><span class="p">(...)</span>
<span class="p">{</span>
	<span class="n">pthread_t</span> <span class="n">p1</span><span class="p">,</span> <span class="n">p2</span><span class="p">;</span>
	<span class="kt">int</span> <span class="n">rc</span> <span class="o">=</span> <span class="n">pthread_create</span><span class="p">(</span><span class="o">&amp;</span><span class="n">p1</span><span class="p">,</span> <span class="nb">NULL</span><span class="p">,</span> <span class="n">fun1</span><span class="p">,</span> <span class="s">"function_argument"</span><span class="p">);</span> 
	<span class="n">assert</span><span class="p">(</span><span class="n">rc</span> <span class="o">==</span> <span class="mi">0</span><span class="p">);</span>
	<span class="n">rc</span> <span class="o">=</span> <span class="n">pthread_create</span><span class="p">(</span><span class="o">&amp;</span><span class="n">p2</span><span class="p">,</span> <span class="nb">NULL</span><span class="p">,</span> <span class="n">fun2</span><span class="p">,</span> <span class="s">"arg2"</span><span class="p">);</span>
	<span class="n">assert</span><span class="p">(</span><span class="n">rc</span> <span class="o">==</span> <span class="mi">0</span><span class="p">);</span>
	<span class="c1">// Join wait for the threads to finish</span>
	<span class="n">rc</span> <span class="o">=</span> <span class="n">pthread_join</span><span class="p">(</span><span class="n">p1</span><span class="p">,</span> <span class="nb">NULL</span><span class="p">);</span> <span class="n">asssert</span><span class="p">(</span><span class="n">rc</span> <span class="o">==</span> <span class="mi">0</span><span class="p">);</span>
	<span class="n">rc</span> <span class="o">=</span> <span class="n">pthread_join</span><span class="p">(</span><span class="n">p2</span><span class="p">,</span> <span class="nb">NULL</span><span class="p">);</span> <span class="n">asssert</span><span class="p">(</span><span class="n">rc</span> <span class="o">==</span> <span class="mi">0</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div></div> <p>We usually want to run different threads for them to perform a job together. We do this using <em>global variables</em>. For example, suppose a function increments a global counter to 10. Suppose we run two threads for this function. The final counter value after the execution of both threads should be 20. Sometimes, it may be a lower value too! Why? An issue with threads.</p> <p>When multiple threads access the same space of data, all weird things happen. For example, a wrong value is propagated across threads when the OS/CPU switches from one thread to another before the thread could save the new value in the global variable. The problem is depicted in the following example.</p> <p>## Race conditions and synchronization</p> <p>What just happened is called a race condition where concurrent execution led to different results. The portion of code that can lead to race conditions is known as the <strong><em>critical section</em></strong>. We need <strong>mutual exclusion</strong>, where only one thread should be executing the critical section at any given time. For this to happen, the critical section should execute like one uninterruptable instruction - <strong><em>atomicity</em></strong> of the critical section. How is this achieved? <strong><em>Locks</em></strong>.</p> <h1 id="lecture-13---locks">Lecture 13 - Locks</h1> <p>We’ve concluded in the previous lecture that locks are the solution to the race conditions in threads. A lock variable helps in the exclusivity of the threads for protection.</p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">lock_t</span> <span class="n">mutex</span><span class="p">;</span>
<span class="n">lock</span><span class="p">(</span><span class="o">&amp;</span><span class="n">mutex</span><span class="p">);</span>
<span class="c1">// Critical Section</span>
<span class="n">unlock</span><span class="p">(</span><span class="o">&amp;</span><span class="n">mutex</span><span class="p">);</span>
</code></pre></div></div> <p>All threads accessing a critical section share a lock. One of the threads locks the section - <strong>owner of the lock</strong>. Any other thread that tries to lock cannot proceed further until the owner releases the lock. Locks are provided by the <code class="language-plaintext highlighter-rouge">pthreads</code> library.</p> <h2 id="building-a-lock">Building a lock</h2> <p>Goals of a lock implementation</p> <ul> <li>Mutual exclusion</li> <li>Fairness - All threads should eventually get the lock, and no thread should starve</li> <li>Low overhead - Acquiring, releasing, and waiting for a lock should not consume too many resources.</li> </ul> <p>Implementation of locks is needed for both user-space programs (e.g., <code class="language-plaintext highlighter-rouge">pthreads</code> library) and kernel code. Also, implementing locks needs support from hardware and the OS.</p> <h2 id="is-disabling-interrupts-enough">Is disabling interrupts enough?</h2> <p>Previously, the race condition issue arose due to an interrupt at the wrong moment. So can we simply disable interrupts when a thread acquired a lock and is executing a critical section? No! The following issues will occur in that case -</p> <ul> <li>Disabling interrupts is a privileged instruction, and the program can misuse it (e.g., run forever).</li> <li>It will not work on multiprocessor systems,since another thread on another core can enter the critical section.</li> </ul> <p>Basically, we don’t want to give a user program much power after acquiring a lock. However, this technique is used to implement locks on a single process system <strong>inside the OS</strong> (trusted code, e.g., xv6).</p> <h2 id="locks-implementation-failure">Locks implementation (Failure)</h2> <p>Suppose we use a flag variable for a lock. Set the flag for acquiring the lock, and unset it for unlocking.</p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">typedef</span> <span class="k">struct</span> <span class="n">__lock_t</span> <span class="p">{</span><span class="kt">int</span> <span class="n">flag</span><span class="p">;</span> <span class="p">}</span> <span class="n">lock_t</span><span class="p">;</span>
<span class="kt">void</span> <span class="nf">init</span><span class="p">(</span><span class="n">lock_t</span> <span class="o">*</span><span class="n">mutex</span><span class="p">)</span>
<span class="p">{</span>
	<span class="n">mutex</span> <span class="o">-&gt;</span> <span class="n">flag</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
<span class="kt">void</span> <span class="nf">lock</span> <span class="p">(</span><span class="n">lock_t</span> <span class="o">*</span><span class="n">mutex</span><span class="p">)</span>
<span class="p">{</span>
    <span class="k">while</span> <span class="p">(</span><span class="n">mutex</span> <span class="o">-&gt;</span> <span class="n">flag</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span>
    	<span class="p">;</span> <span class="c1">// spin-wait (do nothing) </span>
	<span class="n">mutex</span> <span class="o">-&gt;</span> <span class="n">flag</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
<span class="p">}</span>
<span class="kt">void</span> <span class="nf">unlock</span> <span class="p">(</span><span class="n">lock_t</span> <span class="o">*</span><span class="n">mutex</span><span class="p">)</span>
<span class="p">{</span>
    <span class="n">mutex</span> <span class="o">-&gt;</span> <span class="n">flag</span>  <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div> <p>What are the problems here? The race condition has moved to the lock acquisition code! How? Thread 1 spins, the lock is released, spin ends. Suppose thread 1 is interrupted just before setting the flag. Now, thread 2 sets the flag to 1. However, thread 1 still thinks lock is not acquired and sets the flag to 1. Therefore, both the threads have locks, and there is no mutual execution.</p> <p>Seeing the above implementation, it’s clear that we cannot implement locks only using software. Hence, we need hardware atomic instructions.</p> <h2 id="hardware-atomic-instructions">Hardware atomic instructions</h2> <p>Modern architectures provide hardware atomic instructions. For example, <code class="language-plaintext highlighter-rouge">test-and-set</code> - update a variable and return old value, all in one hardware instruction. We can design a simple lock using <code class="language-plaintext highlighter-rouge">test-and-set</code>.</p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">void</span> <span class="nf">lock</span> <span class="p">(</span><span class="n">lock_t</span> <span class="o">*</span><span class="n">mutex</span><span class="p">)</span>
<span class="p">{</span>
    <span class="k">while</span> <span class="p">(</span><span class="n">TestAndSet</span><span class="p">(</span><span class="o">&amp;</span><span class="n">lock</span> <span class="o">-&gt;</span> <span class="n">flag</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span>
    	<span class="p">;</span> <span class="c1">// spin-wait (do nothing) </span>
<span class="p">}</span>
</code></pre></div></div> <p>If <code class="language-plaintext highlighter-rouge">TestAndSet(flag, 1)</code> returns 1, it means the lock is held by someone else, so wait busily. This lock is called a <strong><em>spinlock</em></strong> - spins until the lock is acquired.</p> <p>There is also a <code class="language-plaintext highlighter-rouge">compare-and-swap</code> instruction which checks the expected value with the current value. If both the values are equal, the value is set to the new value. We can also implement a spinlock using this instruction.</p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">void</span> <span class="nf">lock</span><span class="p">(</span><span class="n">lock_t</span> <span class="o">*</span><span class="n">lock</span><span class="p">)</span> <span class="p">{</span>
<span class="k">while</span><span class="p">(</span><span class="n">CompareAndSwap</span><span class="p">(</span><span class="o">&amp;</span><span class="n">lock</span> <span class="o">-&gt;</span> <span class="n">flag</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span> <span class="p">;</span> <span class="c1">//spin</span>
<span class="p">}</span>
</code></pre></div></div> <h2 id="alternative-to-spinning">Alternative to spinning</h2> <p>We can make the thread sleep instead of spinning and utilizing the CPU. A contending thread could simply give up the CPU and check back later. In literature, a mutex by itself means a sleeping mutex.</p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">void</span> <span class="nf">lock</span><span class="p">(){</span>
    <span class="k">while</span><span class="p">(</span><span class="n">TestAndSet</span><span class="p">(</span><span class="o">&amp;</span><span class="n">flag</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">yield</span><span class="p">();</span> <span class="c1">// Name changes across OS</span>
<span class="p">}</span>
</code></pre></div></div> <p>## Spinlock vs. mutex</p> <p>Most user-space lock implementations are of sleeping mutex kind. However, the locks inside the OS are always spinlocks! Why? If we sleep in the OS code, we cannot context switch to another process. When OS acquires a spinlock -</p> <ul> <li> <p>It must disable interrupts (on that processor code) while the lock is held. Why? An interrupt handler could request the same lock and spin it forever - A deadlock situation.</p> <blockquote> <p>What?</p> </blockquote> </li> <li> <p>It must not perform any blocking operation - never go to sleep with a locked spinlock!</p> </li> </ul> <p>In general, we must use spinlocks with care and release them as soon as possible.</p> <h2 id="usage-of-locks">Usage of Locks</h2> <p>The user must acquire a lock before accessing any variable, or data structure shared between multiple threads of a process. This implementation is called a <strong>thread-safe</strong> data structure. All the shared kernel data structures must also be accessed only after locking.</p> <p>Coarse-grained vs. fine-grained locking - One big lock for all the shared data vs. separate locks for each variable. Fine-grained locking allows more parallelism but is harder to manage. The OS only provides locks, but the proper locking discipline is left to the user.</p> <h1 id="lecture-14---condition-variables">Lecture 14 - Condition variables</h1> <p>Locks allow one type of synchronization between threads. There is another typical requirement in multi-threaded applications. It is known as <strong>waiting and signaling</strong>. Here, one thread might want another thread to finish the job and signal to the original thread when the job is executed. We can accomplish such synchronization using <em>busy-waiting</em>, but it is inefficient. Therefore, most modern OS have a new synchronization primitive - <strong>condition variables</strong> (as called in <code class="language-plaintext highlighter-rouge">pthreads</code>).</p> <h2 id="condition-variables">Condition Variables</h2> <p>A condition variable (CV) is a queue that a thread can be placed into when waiting on some condition. Another thread can wake up the waiting thread by signaling CV after making the condition true. <code class="language-plaintext highlighter-rouge">pthreads</code> provides CV for user programs and also for kernel threads. There are two kinds of signaling -</p> <ul> <li>A signal wakes up a single thread</li> <li>A signal broadcast that wakes up all the waiting threads.</li> </ul> <p>Here is an example utilizing CV -</p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">int</span> <span class="n">done</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
<span class="n">pthread_mutex_t</span> <span class="n">m</span> <span class="o">=</span> <span class="n">PTHREAD_MUTEX_INITIALIZER</span><span class="p">;</span>
<span class="n">pthread_cond_t</span> <span class="n">c</span> <span class="o">=</span> <span class="n">PTHREAD_COND_INITIALIZER</span><span class="p">;</span>
<span class="kt">void</span> <span class="nf">thr_join</span><span class="p">(){</span>
<span class="n">Pthread_mutex_lock</span><span class="p">(</span><span class="o">&amp;</span><span class="n">m</span><span class="p">);</span> <span class="c1">// Line *</span>
<span class="k">while</span><span class="p">(</span><span class="n">done</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
	<span class="n">Pthread_cond_wait</span><span class="p">(</span><span class="o">&amp;</span><span class="n">c</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">m</span><span class="p">);</span> <span class="c1">//Parent thread goes to sleep</span>
	<span class="n">Pthread_mutex_unlock</span><span class="p">(</span><span class="o">&amp;</span><span class="n">m</span><span class="p">);</span>
<span class="p">}</span>
<span class="kt">void</span> <span class="nf">thr_exit</span><span class="p">()</span> <span class="p">{</span>
	<span class="n">Pthread_mutex_lock</span><span class="p">(</span><span class="o">&amp;</span><span class="n">m</span><span class="p">);</span>
	<span class="n">done</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
	<span class="n">Pthread_cond_signal</span><span class="p">(</span><span class="o">&amp;</span><span class="n">c</span><span class="p">);</span> <span class="c1">// Send a signal</span>
	<span class="n">Pthread_mutex_unlock</span><span class="p">(</span><span class="o">&amp;</span><span class="n">m</span><span class="p">);</span>
<span class="p">}</span>
<span class="kt">void</span> <span class="o">*</span><span class="nf">child</span> <span class="p">(</span><span class="kt">void</span> <span class="o">*</span><span class="n">arg</span><span class="p">)</span>
<span class="p">{</span>
	<span class="n">printf</span><span class="p">(</span><span class="s">"child</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
	<span class="n">thr_exit</span><span class="p">();</span>
	<span class="k">return</span> <span class="nb">NULL</span><span class="p">;</span>
<span class="p">}</span>
<span class="kt">int</span> <span class="nf">main</span> <span class="p">()</span>
<span class="p">{</span>
	<span class="n">printf</span><span class="p">(</span><span class="s">"Parent - begin</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
	<span class="n">pthread_t</span> <span class="n">p</span><span class="p">;</span>
	<span class="n">Pthread_create</span><span class="p">(</span><span class="o">&amp;</span><span class="n">p</span><span class="p">,</span> <span class="nb">NULL</span><span class="p">,</span> <span class="n">child</span><span class="p">,</span> <span class="nb">NULL</span><span class="p">);</span>
	<span class="n">thr_join</span><span class="p">;</span>
	<span class="n">printf</span><span class="p">(</span><span class="s">"Parent - end</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div></div> <blockquote> <p>Doesn’t the parent already wait in line * if the child is executed before?</p> <p>What if the parent acquires lock first? The wait function releases the lock. See below.</p> </blockquote> <p>In the above example, it doesn’t matter which thread (child/parent) gets executed first. The flow is still the same as expected. Note that it is always better to check the condition (in the <code class="language-plaintext highlighter-rouge">while</code> loop) before waiting. Otherwise, the parent thread will not be woken up.</p> <p>Why do we use a <code class="language-plaintext highlighter-rouge">while</code> instead of <code class="language-plaintext highlighter-rouge">if</code>? To avoid corner cases of thread being woken up even when the condition is not true (maybe an issue with some implementation). This is a good programming practice.</p> <p>Why do we hold locks before checking the condition? What if we didn’t use a lock? There would be a race condition for a missed wakeup</p> <ul> <li>Parent checks done to be 0, decides to sleep and is then interrupted.</li> <li>The child runs, sets done to 1, signals, but no one is sleeping.</li> <li>The parent now resumes and goes to sleep forever.</li> </ul> <p>Therefore, a lock must be held when calling wait and signal with CV. The wait function releases the lock before putting the thread to sleep, so the lock is available for the signaling thread.</p> <h2 id="producerconsumer-problem">Producer/Consumer Problem</h2> <p>This setting is a common pattern in multi-threaded programs. There are two pr more threads - producer(s) and consumer(s) which share a shared buffer (having a finite size). We need mutual exclusion in the buffer, and also a signaling mechanism to share information.</p> <p>For example, in a multi-threaded web server, one thread accepts requests from the network and puts them in a queue. The worker threads get requests from this queue and process them. Here’s how we implement this -</p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cond_t</span> <span class="n">empty</span><span class="p">,</span> <span class="n">fill</span><span class="p">;</span>
<span class="n">mutex_t</span> <span class="n">mutex</span><span class="p">;</span>
<span class="kt">void</span> <span class="o">*</span><span class="nf">producer</span><span class="p">(</span><span class="kt">void</span> <span class="o">*</span><span class="n">arg</span><span class="p">)</span>
<span class="p">{</span>
    <span class="kt">int</span> <span class="n">i</span><span class="p">;</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">lopps</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span>
    <span class="p">{</span>
        <span class="n">Pthread_mutex_lock</span><span class="p">(</span><span class="o">&amp;</span><span class="n">mutex</span><span class="p">);</span>
        <span class="k">while</span><span class="p">(</span><span class="n">count</span> <span class="o">==</span> <span class="n">MAX</span><span class="p">)</span>
        	<span class="n">Pthread_cont_wait</span><span class="p">(</span><span class="o">&amp;</span><span class="n">empty</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">mutex</span><span class="p">);</span>
        	<span class="n">put</span><span class="p">(</span><span class="n">i</span><span class="p">);</span>
        	<span class="n">Pthread_cond_signal</span><span class="p">(</span><span class="o">&amp;</span><span class="n">fill</span><span class="p">);</span>
        	<span class="n">Pthread_mutex_unlock</span><span class="p">(</span><span class="o">&amp;</span><span class="n">mutex</span><span class="p">);</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="kt">void</span> <span class="o">*</span><span class="nf">consumer</span><span class="p">(</span><span class="kt">void</span> <span class="o">*</span><span class="n">arg</span><span class="p">)</span>
<span class="p">{</span>
	<span class="kt">int</span> <span class="n">i</span><span class="p">;</span>
	<span class="k">for</span> <span class="p">(</span><span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">loops</span><span class="p">,</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span>
	<span class="p">{</span>
		<span class="n">Pthread_mutex_lock</span><span class="p">(</span><span class="o">&amp;</span><span class="n">mutex</span><span class="p">);</span>
		<span class="k">while</span><span class="p">(</span><span class="n">count</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
			<span class="n">Pthread_cond_wait</span><span class="p">(</span><span class="o">&amp;</span><span class="n">fill</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">mutex</span><span class="p">);</span>
		<span class="kt">int</span> <span class="n">tmp</span> <span class="o">=</span> <span class="n">get</span><span class="p">();</span>
		<span class="n">Pthread_cond_signal</span><span class="p">(</span><span class="o">&amp;</span><span class="n">empty</span><span class="p">);</span>
		<span class="n">Pthread_mutex_unlock</span><span class="p">(</span><span class="o">&amp;</span><span class="n">mutex</span><span class="p">);</span>
		<span class="n">printf</span><span class="p">(</span><span class="s">"%d</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">tmp</span><span class="p">);</span>
	<span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div> <h1 id="live-session-7">Live Session 7</h1> <ul> <li> <p>The OS does not raise a trap when you access a shared variable protected using a lock in another thread. Why? The usage of locks is wholly left to the user. The OS cannot see these variables too! A lock is nothing but another variable.</p> </li> <li> <p>Condition variable in a queue? That was a wrong statement in the slides. The implementation of the condition variables determines which thread is woken up first among the threads that are waiting. Even all of the threads can wake up at once. For example, in xv6, all the threads are woken up at once.</p> </li> <li> <p>Why <code class="language-plaintext highlighter-rouge">if</code> instead of a <code class="language-plaintext highlighter-rouge">while</code>? If all the waiting threads are woken up, then using <code class="language-plaintext highlighter-rouge">if</code> might cause a problem! <code class="language-plaintext highlighter-rouge">while</code> in case of <em>spurious</em> wake-ups.</p> </li> <li> <p>Why spinlocks in the OS code? The OS itself cannot yield itself to anybody else. It cannot rely on other processes to wake it up in case the lock is not acquired. The alternative to the spinlock implementation is using hardware help. The OS can wake up when the hardware gives an interrupt (after the lock is released). However, we don’t have this support.</p> </li> <li> <p>Why does disabling interrupts on a single core work? This method is only for OS that works on a single thread. The OS can interrupt the user programs. However, only hardware can interrupt the OS. So, when you disable interrupts, there is no way the OS can be interrupted.</p> <p>However, if you have a multicore architecture, another thread can access the shared variables from another core (not using locks here, just talking about disabling interrupts).</p> </li> <li> <p>The <code class="language-plaintext highlighter-rouge">sleep</code> function releases the lock. However, when the process wakes up, it reacquires the lock. So, there is no double-freeing. The doubt was asked based on <a href="#condition-variables">this</a> context.</p> </li> <li> <p>Do we need to disable interrupts on all cores for smooth execution of OS code? However, you need not disable interrupts on other cores. The OS code that needs to access this space has to acquire the lock (which is not possible as the original thread is the owner) and wait before accessing the shared space.</p> <p>We said disabling interrupts won’t work in multicore architecture (two points before). But that situation was not considering locks, and we have locks in this case.</p> <blockquote> <p>What happens if you disable interrupts on all cores anyway?</p> </blockquote> </li> <li> <blockquote> <p>What do we do if a serious interrupt occurs when interrupts are disabled?</p> </blockquote> </li> <li> <p>Once a process commits to a core, it cannot run on another core in between. It has to finish on the current core itself.</p> </li> <li> <p>The concept of user threads and kernel threads. User-level threading libraries create an illusion of multiple threads. However, the kernel does not see these as independent processes but as a single process. For example, the <code class="language-plaintext highlighter-rouge">pthread</code> library is only for kernel threads. It is not an illusion. Nevertheless, even with a user-level thread, you can get interrupted at the wrong time. Therefore, we need locks even in the user-level illusionary threads.</p> </li> <li> <code class="language-plaintext highlighter-rouge">int n</code> is an atomic instruction.</li> </ul> <h2 id="lecture-15---semaphores">Lecture 15 - Semaphores</h2> <p>We are going to study another synchronization primitive called semaphores.</p> <h2 id="what-is-a-semaphore">What is a semaphore?</h2> <p>They are very similar to condition variables. It is a variable with an underlying counter. You can call two functions on a semaphore variable -</p> <ul> <li> <code class="language-plaintext highlighter-rouge">up/post</code> increment the counter</li> <li> <code class="language-plaintext highlighter-rouge">down/wait</code> decrement the counter and block the calling thread if the resulting value is negative.</li> </ul> <p>The above two functions represent the interface to a semaphore. A semaphore with an initial value of 1 acts as a simple lock. That is, a binary semaphore is equivalent to a mutex. Here is a simple usage of a binary semaphore.</p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sem_t</span> <span class="n">m</span><span class="p">;</span>
<span class="n">sem_init</span><span class="p">(</span><span class="o">&amp;</span><span class="n">m</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">X</span><span class="p">);</span> <span class="c1">// X can be 1 here</span>
<span class="n">sem_wait</span><span class="p">(</span><span class="o">&amp;</span><span class="n">m</span><span class="p">);</span>
<span class="c1">// Critical section</span>
<span class="n">sem_post</span><span class="p">(</span><span class="o">&amp;</span><span class="n">m</span><span class="p">);</span>
</code></pre></div></div> <h2 id="semaphores-for-ordering">Semaphores for Ordering</h2> <p>They can be used to set the order of execution between threads like a CV. This example is similar to what we have seen before with the <a href="#condition-variables">“parent waiting for child”</a> example. An important point to note here is that the semaphore is initialized to 0 here. Why? Because the parent has to wait for the child to finish.</p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sem_t</span> <span class="n">s</span><span class="p">;</span>
<span class="kt">void</span><span class="o">*</span> <span class="nf">child</span> <span class="p">(</span><span class="kt">void</span> <span class="o">*</span><span class="n">arg</span><span class="p">)</span>
<span class="p">{</span>
	<span class="n">printf</span><span class="p">(</span><span class="s">"child</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
	<span class="n">sem_post</span><span class="p">(</span><span class="o">&amp;</span><span class="n">s</span><span class="p">);</span>
	<span class="k">return</span> <span class="nb">NULL</span><span class="p">;</span> <span class="c1">// Line *</span>
<span class="p">}</span>

<span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="n">chara</span> <span class="o">*</span><span class="n">argv</span><span class="p">[])</span>
<span class="p">{</span>
	<span class="n">sem_init</span><span class="p">(</span><span class="o">&amp;</span><span class="n">s</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>
	<span class="n">printf</span><span class="p">(</span><span class="s">"parent: begin</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
	<span class="n">pthread_t</span> <span class="n">c</span><span class="p">;</span>
	<span class="n">Pthread_create</span><span class="p">(</span><span class="o">&amp;</span><span class="n">c</span><span class="p">,</span> <span class="nb">NULL</span><span class="p">,</span> <span class="n">child</span><span class="p">,</span> <span class="nb">NULL</span><span class="p">);</span>
	<span class="n">sem_wait</span><span class="p">(</span><span class="o">&amp;</span><span class="n">s</span><span class="p">);</span>
	<span class="n">printf</span><span class="p">(</span><span class="s">"parent: end</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
	<span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div> <blockquote> <p>What if line * had a print statement? Where would that get printed?</p> </blockquote> <p>Therefore, it is essential to correctly determine the initial value of the semaphore for correct behavior.</p> <h2 id="producerconsumer-problem-1">Producer/Consumer Problem (1)</h2> <p>Let us revisit <a href="#producerconsumer-problem">this</a> problem in the context of semaphores. We need one semaphore to keep track of empty slots and another to keep track of full slots. The producer waits if there are no more empty slots, and the consumer waits if there are no more full slots. Also, we need another semaphore to act as a mutex for the buffer. Here is how these variables are initialized.</p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span> <span class="o">*</span><span class="n">argv</span><span class="p">[])</span>
<span class="p">{</span>
	<span class="c1">// ...</span>
	<span class="n">sem_init</span><span class="p">(</span><span class="o">&amp;</span><span class="n">empty</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">MAX</span><span class="p">);</span>
	<span class="n">sem_init</span><span class="p">(</span><span class="o">&amp;</span><span class="n">full</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>
	<span class="n">sem_init</span><span class="p">(</span><span class="o">&amp;</span><span class="n">mutex</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">);</span> <span class="c1">// Thumb rule - Locks are initialized with value 1</span>
	<span class="c1">// ...</span>
<span class="p">}</span>
</code></pre></div></div> <p>There is a subtle point in this example. Consider the <code class="language-plaintext highlighter-rouge">producer</code> function.</p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">void</span><span class="o">*</span> <span class="nf">producer</span> <span class="p">(</span><span class="kt">void</span> <span class="o">*</span><span class="n">arg</span><span class="p">)</span>
<span class="p">{</span>
	<span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">loops</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span>
	<span class="p">{</span>
		<span class="n">sem_wait</span><span class="p">(</span><span class="o">&amp;</span><span class="n">empty</span><span class="p">);</span>
		<span class="n">sem_wait</span><span class="p">(</span><span class="o">&amp;</span><span class="n">mutex</span><span class="p">);</span>
		<span class="n">put</span><span class="p">(</span><span class="n">i</span><span class="p">);</span>
		<span class="n">sem_post</span><span class="p">(</span><span class="o">&amp;</span><span class="n">mutex</span><span class="p">);</span>
		<span class="n">sem_post</span><span class="p">(</span><span class="o">&amp;</span><span class="n">full</span><span class="p">);</span>
	<span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div> <p><em>*</em> What if we acquire mutex before checking the other semaphores? It would result in a deadlock situation. The waiting thread can sleep with the mutex, and the signaling thread can never wake it up!</p> <h2 id="lecture-16---concurrency-bugs">Lecture 16 - Concurrency Bugs</h2> <p>In general, writing multi-threaded programs is tricky. These bugs are non-deterministic and occur based on the execution order of threads - challenging to debug. We shall discuss two types of bugs in this lecture and methods to prevent them.</p> <ul> <li>Deadlocks - Threads cannot execute any further and wait for each other. These are very dangerous.</li> <li>Non-deadlock bugs - Non-deadlock, but the results are incorrect when the threads execute.</li> </ul> <h2 id="non-deadlock-bugs">Non-deadlock bugs</h2> <p>These are of two types -</p> <ul> <li> <p><strong>Atomicity bugs</strong> - Occur due to false atomicity assumptions that are violated during the execution of concurrent threads. We fix these bugs using locks!</p> <p>Example -</p> <div class="language-c highlighter-rouge"> <div class="highlight"><pre class="highlight"><code><span class="n">Thread</span> <span class="mi">1</span><span class="o">::</span>
<span class="k">if</span> <span class="p">(</span><span class="n">thd</span> <span class="o">-&gt;</span> <span class="n">proc_info</span><span class="p">)</span>
<span class="p">{</span>
	<span class="n">fputs</span><span class="p">(</span><span class="n">thd</span> <span class="o">-&gt;</span> <span class="n">proc_infor</span><span class="p">,</span> <span class="p">...);</span>
<span class="p">}</span>
<span class="n">Thread</span> <span class="mi">2</span><span class="o">::</span>
<span class="n">thd</span> <span class="o">-&gt;</span> <span class="n">proc_info</span> <span class="o">=</span> <span class="nb">NULL</span><span class="p">;</span>
</code></pre></div> </div> <p>This situation is basically a race condition! Although, the crucial point to note here is atomicity bugs can occur, not just when writing to shared data, but even when reading it!</p> <p>Always use a <strong>lock</strong> when <strong>accessing shared data</strong>.</p> </li> <li> <p><strong>Order-violation bugs</strong> - Occur when desired order of memory accesses is flipped during concurrent execution. We fix these using condition variables.</p> <div class="language-c highlighter-rouge"> <div class="highlight"><pre class="highlight"><code><span class="n">Thread</span> <span class="mi">1</span><span class="o">::</span>
<span class="kt">void</span> <span class="nf">init</span><span class="p">()</span>
<span class="p">{</span>
	<span class="n">mThread</span> <span class="o">=</span> <span class="n">PR_CreateThread</span><span class="p">(</span><span class="n">mMain</span><span class="p">,</span> <span class="p">...);</span>
<span class="p">}</span>
<span class="n">Thread</span> <span class="mi">2</span><span class="o">::</span>
<span class="kt">void</span> <span class="nf">mMain</span><span class="p">(...)</span>
<span class="p">{</span>
<span class="n">mState</span> <span class="o">=</span> <span class="n">mThread</span> <span class="o">-&gt;</span> <span class="n">State</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div> </div> <p>Thread 1 assumes that Thread 2 had been executed before, and this causes an error.</p> </li> </ul> <h2 id="deadlock-bugs">Deadlock bugs</h2> <p>Here is a classic example of a deadlock situation.</p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// Thread 1:</span>
<span class="n">pthread_mutex_lock</span><span class="p">(</span><span class="n">L1</span><span class="p">);</span>
<span class="n">pthread_mutex_lock</span><span class="p">(</span><span class="n">L2</span><span class="p">);</span>
<span class="c1">// Thread 2:</span>
<span class="n">pthread_mutex_lock</span><span class="p">(</span><span class="n">L2</span><span class="p">);</span>
<span class="n">pthread_mutex_lock</span><span class="p">(</span><span class="n">L1</span><span class="p">);</span>
</code></pre></div></div> <p>Deadlock may not always occur in this situation. It only occurs when the executions overlap, and a context switch occurs from a thread after acquiring only one lock. It is easy to visualize these situations using a dependency graph. A cycle in a dependency graph causes a deadlock situation.</p> <p>When does a deadlock occur?</p> <ol> <li>Mutual exclusion - A thread claims exclusive control of a resource (e.g., lock)</li> <li>Hold-and-wait - The thread holds a resource and is waiting for another</li> <li>No preemption - A thread cannot be made to give up its resource (e.g., cannot take back a lock)</li> <li>Circular wait - There exists a cycle in the resource dependency graph.</li> </ol> <p>All of the above conditions must hold for a deadlock to occur.</p> <blockquote> <p>Isn’t (4) by itself enough for a deadlock? <em>the cycle must be reachable</em></p> </blockquote> <p>To prevent a circular wait, we need to acquire locks in a particular fixed order! e.g., both threads acquire L1 before L2 in the previous example.</p> <p>To do this, we need a total (partial) ordering of locks. For example, this ordering can be done via the address of lock variables.</p> <h3 id="preventing-hold-and-wait">Preventing hold-and-wait</h3> <p>Acquire all locks at once using a <em>master</em> lock. This way, you will hold all locks or none of them. However, this method may reduce concurrent execution and performance gains. <em>Think</em>.</p> <h3 id="other-solutions-to-deadlocks">Other solutions to deadlocks</h3> <p><strong>Deadlock avoidance</strong> - If the OS knows which process needs which locks, it can schedule the processes in that deadlock will not occur. One such algorithm is <strong><em>Banker’s algorithm</em></strong>. But it is impractical in real life to assume this knowledge.</p> <p><strong>Detect and recover</strong> - Reboot system or kill deadlocked processes. There is no standard implementation to tackle deadlocks. :(</p> <h1 id="live-session-8">Live Session 8</h1> <ul> <li>If you disable interrupts on all cores anyway, nothing bad happens. There are no emergency interrupts which might destroy your system if not handled immediately.</li> <li>semaphores no need to acquire lock. cv need to acquire lock. cv reacquires lock too.</li> <li>no context switch on post!</li> </ul> <h2 id="synchronization-problems">Synchronization problems</h2> <h3 id="question-26">Question 26</h3> <p>Allowing N guests all at once into the house.</p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// host</span>
<span class="n">lock</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
<span class="k">while</span><span class="p">(</span><span class="n">guest_count</span> <span class="o">&lt;</span> <span class="n">N</span><span class="p">)</span>
	<span class="n">wait</span><span class="p">(</span><span class="n">cv_host</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span>
<span class="n">openDoor</span><span class="p">()</span>
<span class="n">signal</span><span class="p">(</span><span class="n">cv_guest</span><span class="p">)</span>
<span class="c1">// signalbroadcast too</span>
<span class="n">unlock</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>

<span class="c1">// Guests code?</span>
<span class="n">lock</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
<span class="n">guest_count</span><span class="o">++</span>
<span class="k">if</span><span class="p">(</span><span class="n">guest_count</span> <span class="o">==</span> <span class="n">N</span><span class="p">)</span>
	<span class="n">signal</span><span class="p">(</span><span class="n">cv_host</span><span class="p">)</span>
<span class="n">wait</span><span class="p">(</span><span class="n">cv_guest</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span>
<span class="n">signal</span><span class="p">(</span><span class="n">cv_guest</span><span class="p">)</span> <span class="c1">// To signal other threads</span>
    <span class="c1">// above line not needed if singal braodcast is there</span>
<span class="n">unlock</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
<span class="n">enterHouse</span><span class="p">()</span>
</code></pre></div></div> <p>Whenever you write code, start with the wait signals. Then, put the logic in place and ensure there are no deadlocks. Also, pair up every wait with a signal.</p> <h3 id="question-25">Question 25</h3> <p>Passenger thread given -</p> <pre><code class="language-pseudocode">down(mutex)
waiting_count++
up(mutex)
down(bus_arrived)
board()
up(passenger_boarded)
</code></pre> <p>Bus code?</p> <pre><code class="language-pseudocode">down(mutex)
N = min(waiting_count, K)
for i = 1 to N
    up(bus_arrived)
    down(passenger_boarded)
waiting_count -= N;
up(mutex)
</code></pre> <h1 id="lecture-29---locking-in-xv6">Lecture 29 - Locking in xv6</h1> <p>Why do we need locking in xv6? There are no threads in xv6! Therefore, no two user programs can access the same userspace memory image. However, there is a scope for concurrency in xv6 kernel. For example, two processes in the kernel mode on different CPU cores can access the same data structures. Another example where this sort of thing happens is in the case of interrupts. When an interrupt occurs while processing the trap of another process, the new interrupt handler can access the previous kernel code. Therefore, we need <code class="language-plaintext highlighter-rouge">spinlocks</code> to protect critical sections in xv6. xv6 also has a sleeping lock which is built on spinlock.</p> <h2 id="spinlocks-in-xv6">Spinlocks in xv6</h2> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="c1">// Mutual exclusion lock.</span>
<span class="k">struct</span> <span class="n">spinlock</span> <span class="p">{</span>
<span class="n">uint</span> <span class="n">locked</span><span class="p">;</span> <span class="c1">// Is the lock held?</span>

<span class="c1">// For debugging:</span>
<span class="kt">char</span> <span class="o">*</span><span class="n">name</span><span class="p">;</span> <span class="c1">// Name of lock.</span>
<span class="k">struct</span> <span class="n">cpu</span> <span class="o">*</span><span class="n">cpu</span><span class="p">;</span> <span class="c1">// The cpu holding the lock.</span>
<span class="n">uint</span> <span class="n">pcs</span><span class="p">[</span><span class="mi">10</span><span class="p">];</span> <span class="c1">// The call stack (an array of program counters)</span>
<span class="c1">// that locked the lock.</span>
<span class="p">};</span>
<span class="c1">/////////////////////////////////</span>
<span class="kt">void</span>
<span class="nf">acquire</span><span class="p">(</span><span class="k">struct</span> <span class="n">spinlock</span> <span class="o">*</span><span class="n">lk</span><span class="p">)</span>
<span class="p">{</span>
<span class="n">pushcli</span><span class="p">();</span> <span class="c1">// disable interrupts to avoid deadlock.</span>
<span class="k">if</span><span class="p">(</span><span class="n">holding</span><span class="p">(</span><span class="n">lk</span><span class="p">))</span>
<span class="n">panic</span><span class="p">(</span><span class="s">"acquire"</span><span class="p">);</span>

<span class="c1">// The xchg is atomic.</span>
<span class="k">while</span><span class="p">(</span><span class="n">xchg</span><span class="p">(</span><span class="o">&amp;</span><span class="n">lk</span><span class="err">−</span><span class="o">&gt;</span><span class="n">locked</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span>
<span class="p">;</span>

<span class="c1">// Tell the C compiler and the processor to not move loads or stores</span>
<span class="c1">// past this point, to ensure that the critical section’s memory</span>
<span class="c1">// references happen after the lock is acquired.</span>
<span class="n">__sync_synchronize</span><span class="p">();</span>

<span class="c1">// Record info about lock acquisition for debugging.</span>
<span class="n">lk</span><span class="err">−</span><span class="o">&gt;</span><span class="n">cpu</span> <span class="o">=</span> <span class="n">mycpu</span><span class="p">();</span>
<span class="n">getcallerpcs</span><span class="p">(</span><span class="o">&amp;</span><span class="n">lk</span><span class="p">,</span> <span class="n">lk</span><span class="err">−</span><span class="o">&gt;</span><span class="n">pcs</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div></div> <p>Locks are acquired using <code class="language-plaintext highlighter-rouge">xchg</code> x86 atomic instruction. It is similar to <code class="language-plaintext highlighter-rouge">test-and-set</code> we’ve seen before. The <code class="language-plaintext highlighter-rouge">xchg</code> instruction sets the lock variable to 1 and returns the previous value. Remember, value of 1 means locked! Also, note that we need to disable interrupts on the CPU core before spinning for lock. It is okay for another process to spin for this lock on another core. This is because, the lock will be eventually released by this core (no deadlock can occur).</p> <h2 id="disabling-interrupts">Disabling interrupts</h2> <p>Interrupts are disabled using <code class="language-plaintext highlighter-rouge">pushcli</code>. The interrupts must stay disabled until <strong>all</strong> locks are released. <code class="language-plaintext highlighter-rouge">pushcli</code> disables interrupts on the first lock acquire, and increments count for future locks. Then, <code class="language-plaintext highlighter-rouge">popcli</code> decrements count and reenables interrupts only when count is zero.</p> <h2 id="ptablelock">ptable.lock()</h2> <p>The process table is protected by this lock. Normally, a process in kernel mode acquires <code class="language-plaintext highlighter-rouge">ptable.lock</code>, changes <code class="language-plaintext highlighter-rouge">ptable</code>, and then release the lock. However, during a context switch, from process P1 and P2, the <code class="language-plaintext highlighter-rouge">ptable</code> structure is changed continuously and repeatedly. So when do we release the lock? P1 acquires the lock, switches to scheduler, switches to P2, and then finally P2 releases the lock. This is a special case where one process acquires the lock and another releases it.</p> <p>Every function that calls <code class="language-plaintext highlighter-rouge">sched</code> will do so with <code class="language-plaintext highlighter-rouge">ptable.lock</code> held. <code class="language-plaintext highlighter-rouge">sched</code> is called from <code class="language-plaintext highlighter-rouge">yield</code>, <code class="language-plaintext highlighter-rouge">sleep</code>, and <code class="language-plaintext highlighter-rouge">exit</code>. Every function that <code class="language-plaintext highlighter-rouge">swtch</code> switches to will release <code class="language-plaintext highlighter-rouge">ptable.lock</code>. <code class="language-plaintext highlighter-rouge">swtch</code> also returns to</p> <ul> <li>Yield, when switching from process that is resuming after yielding is done</li> <li>Sleep, when switching in a process that is waking up after sleep</li> <li>Forkret for newly created processes</li> </ul> <p>Thus, the process of <code class="language-plaintext highlighter-rouge">forkret</code> is to release <code class="language-plaintext highlighter-rouge">ptable.lock</code> after context switch, before returning to <code class="language-plaintext highlighter-rouge">trapret</code>.</p> <p>What about the scheduler? We enter the scheduler with the lock held! Sometimes, the scheduler releases the lock (after it loops over all processes), and then reacquires it. Why does it do this? Whenever the lock is held, all interrupts are disabled. All processes might be in a blocked state waiting for interrupts. Therefore, the lock must be released periodically enabling interrupts and allowing process to become runnable.</p> <h1 id="lecture-30---sleep-and-wakeup-in-xv6"> <code class="language-plaintext highlighter-rouge">Lecture</code> 30 - Sleep and Wakeup in xv6</h1> <p>Consider the following example. A process P1 in kernel mode gives up the CPU to block on an event. For e.g., reading data from disk. Then, P1 invokes <code class="language-plaintext highlighter-rouge">sleep</code> which calls <code class="language-plaintext highlighter-rouge">sched</code>. Another process P2 in kernel mode calls <code class="language-plaintext highlighter-rouge">wakeup</code> when an event occurs. This function marks P1 as runnable so that the scheduler loop switches to P1 in the future. For e.g., disk interrupt occurs while P2 is running.</p> <p>How does P2 know which process to wake up? When P1 sleeps, it sets a <strong><em>channel</em></strong> <code class="language-plaintext highlighter-rouge">(void* chan)</code> in its struct proc, and P2 calls <code class="language-plaintext highlighter-rouge">wakeup</code> on the same channel. This channel is any value known to both P1 and P2. Example: The channel value for a disk read can be address of a disk block.</p> <p>A spinlock protects the atomicity of sleep: P1 calls sleep with some spinlock L held, P2 calls wakeup with same spinlock L held. Why do we need this setup?</p> <ul> <li>Eliminating missed <code class="language-plaintext highlighter-rouge">wakeup</code> problem that arises due to P2 issuing wakeup between P1 deciding to sleep and actually sleeping.</li> <li>Lock L is released after sleeping, available for wakeup</li> <li>Similar concept to condition variables studied before.</li> </ul> <p>The Sleep calls <code class="language-plaintext highlighter-rouge">sched</code> to give up the CPU with <code class="language-plaintext highlighter-rouge">ptable</code> lock held. The arguments to sleep are channel and a spinlock (not <code class="language-plaintext highlighter-rouge">ptable.lock</code>). <code class="language-plaintext highlighter-rouge">sleep</code> has to acquire <code class="language-plaintext highlighter-rouge">ptable.lock</code>, release the lock given to sleep (to make it available for wakeup). Unless lock given is <code class="language-plaintext highlighter-rouge">ptable.lock</code> itself, in which case no need to acquire the lock again. One of the two locks is always held!</p> <p>When the control returns back to <code class="language-plaintext highlighter-rouge">sleep</code>, it reacquires the spinlock.</p> <blockquote> <p>Why reacquire?</p> </blockquote> <h2 id="wakeup-function">Wakeup function</h2> <p>This is called by another process with lock held (same lock as when <code class="language-plaintext highlighter-rouge">sleep</code> was called). Since this function changes <code class="language-plaintext highlighter-rouge">ptable</code>, <code class="language-plaintext highlighter-rouge">ptable.lock</code> is also held. Now, this function wakes up all process sleeping on a channel in the <code class="language-plaintext highlighter-rouge">ptable</code>. It is also a good idea to check if the condition is still true upon waking up (use while loop while calling <code class="language-plaintext highlighter-rouge">sleep</code>).</p> <h2 id="example-pipes">Example: pipes</h2> <p>Two process are connected by a pipe (producer consumer). Addresses of pipe structure variables are channels (same channel known to both). There is a <em>pipe lock</em> given as input to <code class="language-plaintext highlighter-rouge">sleep</code>.</p> <h2 id="example-wait-and-exit">Example: wait and exit</h2> <p>If <code class="language-plaintext highlighter-rouge">wait</code> is called in parent while children are still running, parent calls <code class="language-plaintext highlighter-rouge">sleep</code> and gives up the CPU. Here, channel is parent struct proc pointer, and lock is <code class="language-plaintext highlighter-rouge">ptable.lock</code>. In exit, the child acquires <code class="language-plaintext highlighter-rouge">ptable.lock</code> and wakes up the sleeping parent. Notice that here the lock give to <code class="language-plaintext highlighter-rouge">sleep</code> is ptable lock, because parent and child both access <code class="language-plaintext highlighter-rouge">ptable</code> (sleep avoids double locking, doesn’t acquire <code class="language-plaintext highlighter-rouge">ptable.lock</code> if it already held before calling sleep).</p> <p>Why is terminated process memory cleaned up by the parent? When a process calls exit, CPU is using its memory (kernel stack is in use, <code class="language-plaintext highlighter-rouge">cr3</code> is pointing to page table) so all this memory cannot be cleared until the terminated process has been taken off the CPU. Therefore, we need <code class="language-plaintext highlighter-rouge">wait</code>.</p> <h1 id="live-session-9">Live Session 9</h1> <ul> <li>What if 2 threads on <em>different</em> CPU cores perform <code class="language-plaintext highlighter-rouge">test-and-set</code>? This is ensured on the micro-architectural level. These are called <strong>cache coherence protocols</strong>. Memory can only be modified by a single core at a given time. Two or more cores cannot edit a variable simultaneously. Therefore, atomicity at the CPU level is guaranteed.</li> <li>Why don’t we use sleep locks everywhere? The context switch overhead might be more than the wait time in sleeping locks. Suppose we have a single core, and a process on this core is spinning for a lock. Since there are no other cores, the lock owner cannot release lock at this instant. What happens here? The process will keep spinning until it eventually has to yield the CPU.</li> <li>In semaphores, every <code class="language-plaintext highlighter-rouge">up</code> should wake up one thread! <code class="language-plaintext highlighter-rouge">down</code> checks if the counter is negative and goes to sleep. When <code class="language-plaintext highlighter-rouge">up</code> signals these sleeping threads, they wake up even though the counter is negative.</li> <li>Interrupts are queued up when interrupts arrive on an interrupt-disabled core.</li> <li> <code class="language-plaintext highlighter-rouge">myproc()</code>? In xv6, we have an assumption that no processes on any other core edit the <code class="language-plaintext highlighter-rouge">struct proc</code> of the running process. Therefore, we don’t need any locks to access the <code class="language-plaintext highlighter-rouge">struct proc</code> of the running process.</li> <li>The reacquiring of the second lock in <code class="language-plaintext highlighter-rouge">sleep</code> is not necessary but is a convention. Why do we send this lock to <code class="language-plaintext highlighter-rouge">sleep</code>? To preserve the atomicity of <code class="language-plaintext highlighter-rouge">sleep</code>!</li> <li>How does an interrupt know the channel to wakeup a process? Every interrupt handler has a logic for deciphering the channel. For ex, a disk read interrupt handler knows that the sector of the address read is the channel.</li> <li>Missed wakeups cause deadlocks!</li> </ul> <h1 id="lecture-17---communication-with-io-devices">Lecture 17 - Communication with I/O devices</h1> <p>I/O devices connect to the CPU and memory via a bus. For example, a high speed bus, e.g., PCI and others like SCSI, USB, SATA, etc. The point of connection to the system is called the <strong><em>port</em></strong>.</p> <h2 id="simple-device-model">Simple Device Model</h2> <p>Devices are of two types -</p> <ul> <li>Block devices - The stored a set of numbered blocks. For ex, disks.</li> <li>Character devices - Produce/consume stream of bytes. For ex, keyboard.</li> </ul> <p>All these devices expose an interface of memory registers. These registers tell the current status of the device, command to execute, and the data to transfer. The remaining internals of the device are usually hidden. There might be a CPU, memory, and other chips inside the device.</p> <h2 id="interaction-with-the-os">Interaction with the OS</h2> <p>There are <strong>explicit I/O</strong> instructions provided by the hardware to read/write to registers in the interface. For example, on x86, <code class="language-plaintext highlighter-rouge">in</code> and <code class="language-plaintext highlighter-rouge">out</code> instructions can be used to read and write to specific registers on a device. These are privileged instructions accessed by the OS. A user program has to execute a system call in order to interact with the devices.</p> <p>The other way to do this is via the <strong>memory mapped I/O</strong>. The devices makes registers appear like memory locations. The OS simply reads and writes from memory. The underlying memory hardware routes the accesses to these special memory addresses to devices.</p> <blockquote> <p>What memory hardware?</p> </blockquote> <h2 id="simple-execution-of-io-requests">Simple execution of I/O requests</h2> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">While</span> <span class="n">STATUS</span> <span class="o">==</span> <span class="n">BUSY</span>
<span class="p">;</span> <span class="c1">//wait</span>
<span class="n">Write</span> <span class="n">data</span> <span class="n">to</span> <span class="n">DATA</span> <span class="k">register</span>
<span class="n">Write</span> <span class="n">command</span> <span class="n">to</span> <span class="n">COMMAND</span> <span class="k">register</span>
<span class="n">White</span> <span class="n">STATUS</span> <span class="o">==</span> <span class="n">BUSY</span>
<span class="p">;</span> <span class="c1">// wait till device is done with request</span>
</code></pre></div></div> <p>The above pseudocode is a simple protocol to communicate with an I/O device. The <strong>polling</strong> status to see of device is ready wastes a lot of CPU cycles. The <strong>Programmed I/O</strong> explicitly copies data to/from device. The CPU need to be involved in this task.</p> <h2 id="interrupts">Interrupts</h2> <p>As polling wastes CPU cycles, the OS can put the process to sleep and switch to another process. When the I/O request completes, the device raises an interrupt.</p> <p>The interrupt switches process to kernel mode. The Interrupt Descriptor Table (IDT) stores pointers to interrupt handlers (interrupt service routines). The interrupt (IRQ) number identifies the interrupt handler to run for a device.</p> <p>The interrupt handler acts upon device notification, unblocks the process waiting for I/O, and starts the next I/O request. Also, handling interrupts imposes kernel mode transition overheads. As a result, polling may be faster than interrupts if devices is fast.</p> <h2 id="direct-memory-access">Direct Memory Access</h2> <p>The CPU cycles are wasted in copying data to/from device. Instead, we can use a special piece of hardware (DMA engine, seen in CS305) copies from main memory to device. The CPU gives DMA engine the memory location of data. In case of a read, the interrupt is raised after DMA completes. On the other hand, in case of a write, the disk starts writing after DMA completes.</p> <h2 id="device-driver">Device Driver</h2> <p>The part of the OS code that talks to the specific device, gives commands, handles interrupts etc. Most of the OS code abstracts the device details. For example, the file system code is written on top of a generic block interface. the underneath implementation is done via the device drivers.</p> <h1 id="lecture-18---files-and-directories">Lecture 18 - Files and Directories</h1> <h2 id="the-file-abstraction">The file abstraction</h2> <p>A <strong><em>file</em></strong> is simply a linear array of bytes, stored persistently. It is identified with a file name and also has a OS-level identifier - <strong><em><code class="language-plaintext highlighter-rouge">inode</code> number</em></strong>.</p> <p>A <strong><em>directory</em></strong> contains other subdirectories and files, along with their inode numbers. A directory is stored like a file whose contents are filename-to-inode mappings. You can think of a directory as a special type of file.</p> <h2 id="directory-tree">Directory tree</h2> <p>Files and directories are arranged in a tree, start with root (<code class="language-plaintext highlighter-rouge">/</code>).</p> <h2 id="operations-on-files">Operations on files</h2> <p>We can create a file using the <code class="language-plaintext highlighter-rouge">open</code> system call with a flag to create. It returns a number called <strong>file descriptor</strong> which is used as a file handle in the program.</p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">int</span> <span class="n">fd</span> <span class="o">=</span> <span class="n">open</span><span class="p">(</span><span class="s">"foo"</span><span class="p">,</span> <span class="n">O_CREAT</span><span class="o">|</span><span class="n">O_WRONLY</span><span class="o">|</span><span class="n">O_TRUNC</span><span class="p">,</span> <span class="n">S_IRUSR</span><span class="o">|</span><span class="n">S_IWUSR</span><span class="p">);</span>
</code></pre></div></div> <p>We also open an existing file with the same system call. This must be done before reading or writing to a file. All other operations on files use the file descriptor. Finally, the <code class="language-plaintext highlighter-rouge">close</code> system call closes the file.</p> <p>Other operations on a file are -</p> <ul> <li> <code class="language-plaintext highlighter-rouge">read</code>/<code class="language-plaintext highlighter-rouge">write</code> system calls. These occur sequentially by default. Successive read/write calls fetch from the current offset. The arguments to these functions are file descriptor, buffer with data and size.</li> <li>To read/write at a random location in the file, we use <code class="language-plaintext highlighter-rouge">lseek</code> system call that lets us seek to a random offset.</li> <li>Writes are buffered in memory temporarily and are flushed using <code class="language-plaintext highlighter-rouge">fsync</code>.</li> <li>There are other operations to rename files, delete (unlink) files, or get statistics of a file.</li> </ul> <h2 id="operations-on-directories">Operations on directories</h2> <p>Directories can also be accessed like files. For example, the <code class="language-plaintext highlighter-rouge">ls</code> program opens and reads all directory entries. A directory entry contains file name, inode number, type of file, etc.</p> <p><strong>Note</strong>. All the shell commands are simply C programs compiled into executables.</p> <h2 id="hard-links">Hard Links</h2> <p>Hard linking creates another file that points to the same inode number (and hence, same underlying data). If one file is deleted, file data can be accessed through the other links! inode maintains a link count, and the file data is deleted only when no further links exist to the data. You can only unlink, and the OS decides when to delete the data.</p> <h2 id="soft-links-or-symbolic-links">Soft links or symbolic links</h2> <p>Soft link is a file that simply stores a pointer to another filename. However, if the main file is deleted, then the link points to an invalid entry - <strong>dangling reference</strong>.</p> <h2 id="mounting-a-filesystem">Mounting a filesystem</h2> <p>Mounting a filesystem connects the files to a specific point in the directory tree. Several devices and file systems are mounted on a typical machine and are accessed using <code class="language-plaintext highlighter-rouge">mount</code> command.</p> <h2 id="memory-mapping-a-file">Memory mapping a file</h2> <p>There exists an alternate way of accessing a file, instead of using file descriptors and read/write system calls. <code class="language-plaintext highlighter-rouge">mmap</code> allocates a page in the virtual address space of a process. We can ask for an <strong>anonymous</strong> page to store program data or a <strong>file-backed</strong> page that contains data of a file. When a file is mmaped, file data is copied into one or more pages in memory and can be accessed like any other memory location in the program. This way, we can conveniently read/write into the file from the program itself.</p> <h1 id="lecture-19---file-system-implementation">Lecture 19 - File System Implementation</h1> <p>A <strong><em>file system</em></strong> is a way of organization of files and directories on a disk. An OS has one or more file systems. There are two main aspects of a file system -</p> <ul> <li>Data structures to organize data and metadata on the disk.</li> <li>Implementation of system calls like open, read, write, etc. using the data structures.</li> </ul> <p>Usually, disks expose a set of blocks - of size 512 bytes in general. The file system organizes files onto blocks, and system calls are translated into reads and write on blocks.</p> <h2 id="a-simple-file-system">A simple file system</h2> <p>The blocks are organized as follows -</p> <ul> <li>Data blocks - File data stored in one or more blocks.</li> <li>Metadata such as location of data blocks of a file, permissions, etc. about every file stored in the inode blocks. Each block has one or more inodes.</li> <li> <strong>Bitmaps</strong> - Indicate which inodes/data blocks are free.</li> <li> <strong>Superblock</strong> - Holds a master plan of all other blocks (which are inodes, which are data blocks, etc.)</li> </ul> <h3 id="inode-table">inode table</h3> <p>Usually, inodes (index nodes) are stored in an array. Inode number of a file is index into this array. What does an inode store?</p> <ul> <li>File metadata - Permissions, access time, etc.</li> <li>Pointers (disk block numbers) of the file data.</li> </ul> <h3 id="inode-structure">inode structure</h3> <p>The file data need not be stored contiguously on the disk. It needs to be able to track multiple block number of a file. How does an inode track disk block numbers?</p> <ul> <li>Direct pointers - Numbers of first few blocks are sored in the inode itself (suffices for small files)</li> <li>Indirect blocks - For larger file, inode stores number of indirect block, which has block numbers of file data.</li> <li>Similarly, double and triple indirect blocks can be stores - <strong>multi-level</strong> index</li> </ul> <h3 id="file-allocation-table-fat">File Allocation Table (FAT)</h3> <p>Alternate way to track file blocks. FAT stores next block pointer for each block. FAT has one entry per disk block, and the blocks are stored as a linked list. The pointer to the first block is stored in the inode.</p> <h3 id="directory-structure">Directory Structure</h3> <p>A directory stores records mapping filename to inode number. Linked list of records, or more complex structures (hash tables, binary search trees, etc.). A directory is a special type of file and has inode and data blocks (which store the file records).</p> <h3 id="free-space-management">Free space management</h3> <p>How to track free blocks? Bitmaps, for inodes and data blocks, store on bit per block to indicate if free or not. Also, we can have a <strong>free list</strong> in which the super block stores a pointer to the first free block and the free blocks are stored as a linked list. We can also use a more complex structure.</p> <h3 id="opening-a-file">Opening a file</h3> <p>The file has to be opened to have the inode readily available (in memory) for future operations on the file. What happens during open?</p> <ul> <li>The pathname of the file is traversed, starting at root.</li> <li>inode of root is known, to bootstrap the traversal.</li> <li> <p>Then, we recursively fetch the inode of the parent directory, read its data blocks, get inode number of the relevant child, and fetch inode of a child.</p> </li> <li>If a new file, new inode and data blocks will have to be allocated using bitmap, and the directory entry is updated.</li> </ul> <h3 id="open-file-table">Open file table</h3> <p>There is a global open file table which stores on entry for every file opened (even sockets, pipes). The entry point to in-memory copy of the inode (other data structures for sockets and pipes).</p> <p>There also exists a per-process open file table which is an array of files opened by a process. The file descriptor number is an index into this array. The per-process table entry points to the global open file table entry. Every process has three file - standard in/out/err open by default (fd 0, 1, 2).</p> <p>Open system call creates entries in both tables and return the fd number.</p> <h3 id="reading-and-writing-a-file">Reading and writing a file</h3> <p>For reading/writing a file</p> <ul> <li>Access in-memory inode via the file descriptor.</li> <li>Find the location of data block at current read/write offset. We get the locations from the inode itself.</li> <li>Fetch block from disk and perform operation.</li> <li>Write may need to allocate new blocks from disk using bitmap of free blocks.</li> <li>Update time of access and other metadata in inode.</li> </ul> <p>Therefore, any access to a file accesses multiple data blocks - hence, we need multiple accesses to the disk.</p> <h3 id="virtual-file-system">Virtual File System</h3> <p>File systems differ in implementations of data structures - E.g., organization of file records in the directory. So, do the implementations of the system calls need to change across file systems? No! Linux supports virtual file system (<strong>VFS</strong>) abstraction. The VFS looks at a file system as objects (files, directories, inodes, superblock) and operations on these objects. The system call logic is written on these VFS objects.</p> <p>Therefore, in order to develop a new file system, simply implement functions on VFS objects and provide pointers to these functions to the kernel. Syscall implementations need not change with the file system implementation details.</p> <h2 id="disk-buffer-cache">Disk Buffer cache</h2> <p>Results of recently fetched disk blocks are cached. The file system issues block read/write requests to block numbers via a buffer cache. If the block is in the cache, served from the cache and disk I/O is not required. Otherwise, block fetched to cache and returned to the file system.</p> <blockquote> <p>What about inode updates?</p> </blockquote> <p>Write are applied to cache block first. Synchronous/write-through cache write to disk immediately. Asynchronous/write-back caches stores dirty blocks in memory and writes back after a delay.</p> <p>Usually, the page cache is unified in the OS. Free pages are allocated to both processes and disk buffer cache from a common pool. What are the benefits of caches?</p> <ul> <li>Improved performance due to reduced disk I/O.</li> <li>Single copy of block in memory - No inconsistency across processes</li> </ul> <blockquote> <p>Second point? It’s fine.</p> </blockquote> <p>Some applications like databases may avoid caching altogether, to avoid inconsistencies due to crashes - <strong>direct I/O</strong>.</p> <h1 id="live-session-10">Live Session 10</h1> <ul> <li> <p>What is a file system? File system is just part of the OS code. All of the infrastructure related to files constitutes file system. You can implement the system calls related to the files in multiple ways. All of these different implementations are called “file systems.” However, the structure inside the disk can also refer to the file system (All follow VFS). What does it mean by OS can have more than one filesystems?</p> </li> <li> <p>It take a finite amount of time to fetch the data from the interface of the disk to the internal memory. When the DMA is not implemented, the CPU has to oversee the data transfer from the disk to the Memory. Yes, context switching and all happens when a data query is called. However, the interrupt handler is invoked only when the data is ready (in the disk registers) in the disk itself. Once an interrupt is issued, the CPU copies data from the disk registers to multiple layers of caches and the main memory. DMA takes care of all this (The disk directly writes to the main memory).</p> <p>DMA only accesses kernel buffers. User buffers are the <code class="language-plaintext highlighter-rouge">char* buf</code> variables in the user code.</p> </li> <li> <p>Advantage of memory mapped files? When you have to read a large chunk, you don’t have to wait for the disk to send multiple blocks. The file is already available in the memory. The disk buffer cache stores all the changes, and it has its own logic to flush, etc. The main advantage of memory-mapped files is avoiding the extra copy of the data in the memory! Any disk access is first copied into the disk buffer cache. These data blocks are then added to the process’ virtual address space. However, the data blocks are only present in the virtual address space when you use memory-mapped files. As in, the disk buffer cache’s pages are directly used in the page table of the process. On the other hand, if we use a read() system call, the data is copied into some buffer in the process. In any case, disk buffer cache is must!</p> </li> <li> <p>Normal read/write - Get a block from the disk into the kernel data cache, copy the bytes into the user space buffer. In memory mapping, the user space buffer does not have a copy but a pointer to the kernel buffer directly. There exists a concept of block/page cache which is an advanced concept.</p> </li> <li> <p>Mounting - Joining two trees by creating a new node that is the root of another directory tree.</p> </li> <li> <p>We have different entries in file table when two processes open the same file to ensure concurrency and <strong>correctness</strong>. Two files can read/write simultaneously if there are two entries. However, a parent and the child will point to the same file entry! This is why STD ERR/IN/OUT are the same for all processes.</p> </li> <li> <p>What is the use of the global file table? For the OS to keep track of all the open files in a central repository.</p> </li> <li> <p>Why not store the offset in the process’ file descriptor array itself? We need to have some processes sharing the offsets and some to not share them. The implementation is difficult, but it can be done.</p> </li> <li> <p>The indirect blocks are not counted as the data blocks of the process!</p> </li> </ul> <h1 id="lecture-31---device-driver-and-block-io-in-xv6">Lecture 31 - Device driver and block I/O in xv6</h1> <p>Any filesystem is built as multiple layers of abstraction in file systems -</p> <ul> <li>System call implementations - open, read, write.</li> <li>Operations on file system data structures - inodes, files, directories.</li> <li>Block I/O layer - in-memory cache of disk blocks.</li> <li>Device driver - communicates with hard disk to read/write blocks.</li> </ul> <h2 id="disk-blocks-and-buffers">Disk blocks and buffers</h2> <p>Disk maintains data as 512-byte blocks. Any disk block handled by the OS is also backed up in the disk buffer (<code class="language-plaintext highlighter-rouge">struct buf</code> in kernel memory). This is basically a copy of disk block in the memory. All the <code class="language-plaintext highlighter-rouge">struct buf</code>s are stored in a fixed size Buffer cache called as <code class="language-plaintext highlighter-rouge">bcache</code>. This is maintained as a LRU linked list.</p> <p>When we read from the disk, we assign buffer for the block number in the buffer cache, and the device driver sends read request to the disk controller. The disk controller raises an interrupt when the data is ready, and then the data is copied from the disk controller to the buffer cache - <code class="language-plaintext highlighter-rouge">VALID</code> flag is set after data is read.</p> <p>When we write to the disk, we first write into the buffer cache, and then issue a request to the disk. The device driver copies data from the buffer to the disk controller, and the disk controller raises an interrupt when write is complete - <code class="language-plaintext highlighter-rouge">DIRTY</code> flag is set until disk is updated.</p> <h2 id="device-driver-1">Device Driver</h2> <p>Processes that wish to read/write call the <code class="language-plaintext highlighter-rouge">iderw</code> function with buffer as the argument. If the buffer is dirty, it initiates a write request. If a buffer is invalid, then it places a read request. Requests are added to the queue and the function <code class="language-plaintext highlighter-rouge">idestart</code> issues requests after one another. The process sleeps until the request completes. The communication with the disk controller registers is done in <code class="language-plaintext highlighter-rouge">idestart</code> via <code class="language-plaintext highlighter-rouge">in</code>/<code class="language-plaintext highlighter-rouge">out</code> instructions we’ve seen before. This function knows all the register addresses of the devices - code is customized for every device.</p> <p>When the disk controller completes read/write operation, it raises an interrupt</p> <ul> <li>Data is read from the disk controller intos the buffer using <code class="language-plaintext highlighter-rouge">in</code> instruction</li> <li>The sleeping processes are woken up</li> <li>The next request from the queue is issued</li> </ul> <p>All of this is done in <code class="language-plaintext highlighter-rouge">ideintr</code> function which is called via the <code class="language-plaintext highlighter-rouge">trap</code> function. Also, there is no support for DMA in x86. With a DMA, the data is copied by the disk controller into the memory buffers directly before raising an interrupt. However, the CPU has to oversee this in xv6 without the presence of the DMA.</p> <blockquote> <p>so the <code class="language-plaintext highlighter-rouge">insl</code> instruction is run by the DMA in DMA-supported cores?</p> </blockquote> <h2 id="disk-buffer-cache-1">Disk buffer cache</h2> <p>All processes access the disk via the buffer cache. There exists only one copy of the disk block in cache, and only one process can access it at a time.</p> <p>The process calls <code class="language-plaintext highlighter-rouge">bread</code> to read a disk block. This function in turn calls <code class="language-plaintext highlighter-rouge">bget</code> which returns buffer if it already exists in the cache and no other process using it (using locks). Otherwise, if valid buffer is not returned by <code class="language-plaintext highlighter-rouge">bget</code>, <code class="language-plaintext highlighter-rouge">bread</code> reads from the disk using <code class="language-plaintext highlighter-rouge">iderw</code>.</p> <p>A process calls <code class="language-plaintext highlighter-rouge">bwrite</code> to write a block to disk, set dirty bit and request device driver to write. When done with the block, the process calls <code class="language-plaintext highlighter-rouge">brelse</code> to release the block and moves it to the head of the list.</p> <p>Let’s delve into <code class="language-plaintext highlighter-rouge">bget</code>. It returns the pointer to the disk block if it exists in the cache. If the block is in cache and another process is using it, it sleeps until the block is released by the other process. However, if block is not in cache, it fins a least recently used non-dirty buffer and recycles it to use for this block.</p> <blockquote> <p>What if all blocks are dirty? <code class="language-plaintext highlighter-rouge">panic!</code></p> </blockquote> <p>The two goals achieved by the buffer cache are</p> <ul> <li>Recently used disk blocks are stored in the memory for future use.</li> <li>Disk block are modified by only one process at a time.</li> </ul> <h2 id="logging-layer">Logging layer</h2> <p>A system call can change multiple blocks at a time on the disk, and we want atomicity in case the system crashes during a system call. So, wither all changes are made or none is made. <strong>Logging</strong> ensures atomicity by grouping disk block changes into transactions</p> <ul> <li>Every system call starts a transaction in the log, write all changed disk blocks in the log, and commits the transaction.</li> <li>Later, the log installs the changes in the original disk blocks one by one.</li> <li>If a crash happens before the log is written fully, no changes are made. However, if a crash happens after the log entry is committed, the log entries are replayed when the system restarts after crash.</li> </ul> <blockquote> <p>restart from the start or last left entry?</p> </blockquote> <p>In xv6, changes of multiple system calls are collected in memory and committed to the log together. Actual changes happen to disk blocks only after the group transaction commits. The process must call <code class="language-plaintext highlighter-rouge">log_write</code> instead of <code class="language-plaintext highlighter-rouge">bwrite</code> during the system call. (?)</p> <h1 id="lecture-32---file-system-implementation-in-xv6">Lecture 32 - File system implementation in xv6</h1> <h2 id="disk-layout">Disk layout</h2> <p>The disk in xv6 is formatted to contain a superblock (followed by the boot block), log (for crash recovery), inode blocks (multiple inodes packed per block), bitmap (indicating which data blocks are free), and, finally, the actual data blocks.</p> <p>The disk inode contains block number of direct blocks and <strong>one</strong> indirect block. Also, directory is treated as a special file. The data blocks contain directory entries and the corresponding name-inode number mappings. The inode also stores the link count - number of directory entries pointing to a file inode.</p> <h2 id="in-memory-data-structures">In-memory data structures</h2> <p>Every open file has a struct file associated with it which contains some variables such as pointer to inode and pipe structure. All struct files are stored in a fixed size array called the file table (<a href="https://www.cse.iitd.ac.in/~sbansal/os/previous_years/2011/xv6_html/file_8c.html#5e3713b2e8d8fca04c15e52b9a315620" rel="external nofollow noopener" target="_blank"><code class="language-plaintext highlighter-rouge">ftable</code></a>). The <em>file descriptor array of a process</em> contains pointers to struct files in the file table.</p> <p>What happens if two different processes open the same file? They have two different entries in file table because they need to read and write independently at different offsets. However, the file table entries point to the same inode.</p> <p>On the other hand, when P forks C, both file descriptors will point to the same struct file (<code class="language-plaintext highlighter-rouge">ref</code> is increased) and the offsets are shared. The reference count of struct file is number of file descriptors that point to it. Similarly, an inode also has such a reference number.</p> <p>The in-memory <a href="https://www.cse.iitd.ac.in/~sbansal/os/previous_years/2011/xv6_html/fs_8c.html#6baaf26dd83b71b8d684c5d54a709e31" rel="external nofollow noopener" target="_blank">inode</a> is almost a copy of the disk inode, stored in the memory for open files. All of these in-memory inodes are stored in a fixed size array called <strong>inode cache</strong> <a href="https://www.cse.iitd.ac.in/~sbansal/os/previous_years/2011/xv6_html/fs_8c.html#1fbfdebf96af7ed1f992e387cba059b3" rel="external nofollow noopener" target="_blank"><code class="language-plaintext highlighter-rouge">icache</code></a>. The in-memory has a <code class="language-plaintext highlighter-rouge">ref</code> that the disk inode doesn’t have. It stores the number of pointers from the file table entries. This is different from the <code class="language-plaintext highlighter-rouge">nlink</code> which counts the number of files that point to this inode in the disk. A file is cleaned up on the disk only when both <code class="language-plaintext highlighter-rouge">ref</code> and <code class="language-plaintext highlighter-rouge">nlink</code> are zero.</p> <blockquote> <p>Cleaned up from memory or disk?</p> </blockquote> <h2 id="inode-functions">inode functions</h2> <ul> <li>Function <code class="language-plaintext highlighter-rouge">ialloc</code> allocates a free inode from the disk by looking over disk inodes and finding a free on for a file.</li> <li>Function <code class="language-plaintext highlighter-rouge">iget</code> returns a reference counted pointer to in-memory inode in <code class="language-plaintext highlighter-rouge">icache</code> to use in struct file etc. This is a non-exclusive pointer which means the information inside inode structure may not be up to date.</li> <li>Function <code class="language-plaintext highlighter-rouge">iput</code> does the opposite of the above function.</li> <li>Function <code class="language-plaintext highlighter-rouge">ilock</code> locks the inode for use by a process, and updates it information from the disk if needed. <code class="language-plaintext highlighter-rouge">iunlock</code> is the opposite.</li> <li>Function <code class="language-plaintext highlighter-rouge">iupdate</code> propagates changes from in-memory inode to on-disk inode.</li> </ul> <blockquote> <p><code class="language-plaintext highlighter-rouge">ilock</code> updates from disk? Also, why not up to date info? All share pointers right?</p> </blockquote> <p>Inode also has pointers to file data blocks. The function <a href="https://www.cse.iitd.ac.in/~sbansal/os/previous_years/2011/xv6_html/fs_8c.html#965e83e1fa9b15abf268784ce74181bb" rel="external nofollow noopener" target="_blank"><code class="language-plaintext highlighter-rouge">bmap</code></a> returns the address of the nth block of the file. If it’s a direct block, we read from the inode. Otherwise, we read indirect block first and then return block number from it. This function can allocate data blocks too - if n-th data block of the file is not present, it allocates a new block on the disk, writes it to the inode and returns the address. Function <code class="language-plaintext highlighter-rouge">readi</code>/<code class="language-plaintext highlighter-rouge">writei</code> are used to read/write file data at a given offset. They call <code class="language-plaintext highlighter-rouge">bmap</code> to find the corresponding data block. Additionally, <code class="language-plaintext highlighter-rouge">bmap</code> uses <code class="language-plaintext highlighter-rouge">balloc</code> to allocate a data block in the disk, and <code class="language-plaintext highlighter-rouge">bread</code> to read the data blocks.</p> <h2 id="directory-functions">Directory functions</h2> <p>We have two additional functions for directories:</p> <ul> <li>Directory lookup - Read directory entries from the data blocks of the directory. If file name matches, return pointer to the inode from <code class="language-plaintext highlighter-rouge">icache</code>. - <a href="https://www.cse.iitd.ac.in/~sbansal/os/previous_years/2011/xv6_html/fs_8c.html#a182c62fade7a0bae9408830d5e06d4f" rel="external nofollow noopener" target="_blank"><code class="language-plaintext highlighter-rouge">dirlookup</code></a> </li> <li>Linking a file to a directory - Check file with the same name does not exist, and add the mapping from file name to inode number to the directory. - <a href="https://www.cse.iitd.ac.in/~sbansal/os/previous_years/2011/xv6_html/fs_8c.html#69a135a0e8a06d9f306d77ebc0c1f7a0" rel="external nofollow noopener" target="_blank"><code class="language-plaintext highlighter-rouge">dirlink</code></a> </li> </ul> <h2 id="creating-a-file">Creating a file</h2> <p>We locate the inode of the parent directory by walking the filepath from the root. Then, we look up the filename in the parent directory. We return the inode if the file already exists. Otherwise, we allocate a new inode for it, lock it, and initialize it. If the new file is a directory, we add entries for <code class="language-plaintext highlighter-rouge">.</code> and <code class="language-plaintext highlighter-rouge">..</code>. Otherwise, we link it to its parent directory. All of this is done in the <a href="https://www.cse.iitd.ac.in/~sbansal/os/previous_years/2011/xv6_html/sysfile_8c.html#8700568adc174a9e10c167daf6296c8d" rel="external nofollow noopener" target="_blank">create</a> function.</p> <blockquote> <p>Is create a system call?</p> </blockquote> <h2 id="system-call---open">System call - <code class="language-plaintext highlighter-rouge">open</code> </h2> <p>We get the arguments - filename and the mode. We create a file (if specified) and get a pointer to its inode. Then, we allocate a new struct file in the <code class="language-plaintext highlighter-rouge">ftable</code>, and also a new file descriptor entry in struct proc of the process pointing to the struct file in <code class="language-plaintext highlighter-rouge">ftable</code>. Finally, we return the index of new entry in the file descriptor array of the process. <em>Note</em> - <code class="language-plaintext highlighter-rouge">begin_op</code> and <code class="language-plaintext highlighter-rouge">end_op</code> capture the transactions for the log file.</p> <h2 id="system-call---link">System call - <code class="language-plaintext highlighter-rouge">link</code> </h2> <p>This function links an existing file from another directory with a new name (hard linking).</p> <blockquote> <p>Is different directory necessary?</p> </blockquote> <p>We get the pointer to the file inode by walking the old file name. Then, we update the link count in the inode. Once we get the pointer to the inode in the new directory, we link the old inode from the parent directory using a new name.</p> <blockquote> <p>Do we need a new filename? Do we need a different directory?</p> </blockquote> <h2 id="system-call---fileread">System call - <code class="language-plaintext highlighter-rouge">fileread</code> </h2> <p>The <code class="language-plaintext highlighter-rouge">sys_read</code> system call calls <code class="language-plaintext highlighter-rouge">fileread</code>. This is a general template for the other system calls. For example, file read does the following -</p> <ul> <li>Get arguments (file descriptor number, buffer to read into, number of bytes to read)</li> <li>Fetch inode pointer from the struct file and perform read on inode (or pipe if the file descriptor pointed to pipe).</li> </ul> <blockquote> <p>What pipe?</p> </blockquote> <ul> <li>Function <code class="language-plaintext highlighter-rouge">readi</code> uses the function <code class="language-plaintext highlighter-rouge">bmap</code> to get the block corresponding to the nth byte and reads from it.</li> <li>Offset in struct file is updated.</li> </ul> <h2 id="summary">Summary</h2> <ul> <li>Disk is organized as inodes, data blocks and bitmaps</li> <li>The in-memory organization consists of file descriptor array which points to struct file in file table array which in turn points to in-memory inode in the inode cache.</li> <li>A directory is a special file where data blocks contain directory entries (filenames and corresponding inode numbers).</li> <li>Updates to disk happen via the buffer cache***. Changes to all blocks in a system call are wrapped in a transaction and are logged for atomicity.</li> </ul> <h3 id="references">References</h3> <ul> <li><a href="https://www.cse.iitd.ac.in/~sbansal/os/previous_years/2011/xv6_html/index.html" rel="external nofollow noopener" target="_blank">doxygen documentation of xv6 user code</a></li> </ul> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/philosophy/">Philosophy Notes</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/dbms/">DiBS Notes</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/ipl/">IPL Notes</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/automata/">Automata Notes</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/NumAn/">Numerical Analysis Notes</a> </li> </div> <script>document.querySelectorAll("#table-of-contents a").forEach(function(e){e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substring(1);document.querySelectorAll(".content-section").forEach(function(e){e.classList.add("hidden")});var n=document.getElementById(t);n&&n.classList.remove("hidden")})});</script> </div> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2024 Sudhansh Peddabomma. Last updated: October 29, 2024. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="/assets/js/bootstrap-toc.min.js?c82ff4de8b0955d6ff14f5b05eed7eb6"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?9b43d6e67ddc7c0855b1478ee4c48c2d" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-0K9MLG0V24"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-0K9MLG0V24");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>